{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-15T19:12:38.839197Z","iopub.execute_input":"2025-05-15T19:12:38.839585Z","iopub.status.idle":"2025-05-15T19:12:39.256850Z","shell.execute_reply.started":"2025-05-15T19:12:38.839558Z","shell.execute_reply":"2025-05-15T19:12:39.255819Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!pip install requests\n!pip install html5lib\n!pip install bs4","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T19:12:39.258259Z","iopub.execute_input":"2025-05-15T19:12:39.258807Z","iopub.status.idle":"2025-05-15T19:12:53.766897Z","shell.execute_reply.started":"2025-05-15T19:12:39.258766Z","shell.execute_reply":"2025-05-15T19:12:53.765247Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2025.1.31)\nRequirement already satisfied: html5lib in /usr/local/lib/python3.10/dist-packages (1.1)\nRequirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib) (1.17.0)\nRequirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib) (0.5.1)\nCollecting bs4\n  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4) (4.12.3)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4) (2.6)\nDownloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\nInstalling collected packages: bs4\nSuccessfully installed bs4-0.0.2\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from bs4 import BeautifulSoup\nimport requests","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T19:12:53.769514Z","iopub.execute_input":"2025-05-15T19:12:53.769977Z","iopub.status.idle":"2025-05-15T19:12:54.267065Z","shell.execute_reply.started":"2025-05-15T19:12:53.769933Z","shell.execute_reply":"2025-05-15T19:12:54.265837Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"url = \"https://en.wikipedia.org/wiki/Natural_language_processing\"\nhtml_content = requests.get(url).text\nsoup = BeautifulSoup(html_content, \"html.parser\")\n\ntexts = soup.find_all('p')\nfor text in texts:\n    print(text.get_text())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T19:12:54.268751Z","iopub.execute_input":"2025-05-15T19:12:54.269492Z","iopub.status.idle":"2025-05-15T19:12:54.760165Z","shell.execute_reply.started":"2025-05-15T19:12:54.269448Z","shell.execute_reply":"2025-05-15T19:12:54.759043Z"}},"outputs":[{"name":"stdout","text":"Natural language processing (NLP) is a subfield of computer science and especially artificial intelligence. It is primarily concerned with providing computers with the ability to process data encoded in natural language and is thus closely related to information retrieval, knowledge representation and computational linguistics, a subfield of linguistics.\n\nMajor tasks in natural language processing are speech recognition, text classification, natural-language understanding, and natural-language generation.\n\nNatural language processing has its roots in the 1950s.[1] Already in 1950, Alan Turing published an article titled \"Computing Machinery and Intelligence\" which proposed what is now called the Turing test as a criterion of intelligence, though at the time that was not articulated as a problem separate from artificial intelligence. The proposed test includes a task that involves the automated interpretation and generation of natural language.\n\nThe premise of symbolic NLP is well-summarized by John Searle's Chinese room experiment: Given a collection of rules (e.g., a Chinese phrasebook, with questions and matching answers), the computer emulates natural language understanding (or other NLP tasks) by applying those rules to the data it confronts.\n\nUp until the 1980s, most natural language processing systems were based on complex sets of hand-written rules.  Starting in the late 1980s, however, there was a revolution in natural language processing with the introduction of machine learning algorithms for language processing.  This was due to both the steady increase in computational power (see Moore's law) and the gradual lessening of the dominance of Chomskyan theories of linguistics (e.g. transformational grammar), whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing.[8]\n\nSymbolic approach, i.e., the hand-coding of a set of rules for manipulating symbols, coupled with a dictionary lookup, was historically the first approach used both by AI in general and by NLP in particular:[18][19] such as by writing grammars or devising heuristic rules for stemming.\n\nMachine learning approaches, which include both statistical and neural networks, on the other hand, have many advantages over the symbolic approach: \n\nRule-based systems are commonly used:\n\nIn the late 1980s and mid-1990s, the statistical approach ended a period of AI winter, which was caused by the inefficiencies of the rule-based approaches.[20][21]\n\nThe earliest decision trees, producing systems of hard ifâ€“then rules, were still very similar to the old rule-based approaches.\nOnly the introduction of hidden Markov models, applied to part-of-speech tagging, announced the end of the old rule-based approach.\n\nA major drawback of statistical methods is that they require elaborate feature engineering. Since 2015,[22] the statistical approach has been replaced by the neural networks approach, using semantic networks[23] and word embeddings to capture semantic properties of words.  \n\nIntermediate tasks (e.g., part-of-speech tagging and dependency parsing) are not needed anymore. \n\nNeural machine translation, based on then-newly invented sequence-to-sequence transformations, made obsolete the intermediate steps, such as word alignment, previously necessary for statistical machine translation.\n\nThe following is a list of some of the most commonly researched tasks in natural language processing. Some of these tasks have direct real-world applications, while others more commonly serve as subtasks that are used to aid in solving larger tasks.\n\nThough natural language processing tasks are closely intertwined, they can be subdivided into categories for convenience. A coarse division is given below.\n\nBased on long-standing trends in the field, it is possible to extrapolate future directions of NLP. As of 2020, three trends among the topics of the long-standing series of CoNLL Shared Tasks can be observed:[46]\n\nMost higher-level NLP applications involve aspects that emulate intelligent behaviour and apparent comprehension of natural language. More broadly speaking, the technical operationalization of increasingly advanced aspects of cognitive behaviour represents one of the developmental trajectories of NLP (see trends among CoNLL shared tasks above).\n\nCognition refers to \"the mental action or process of acquiring knowledge and understanding through thought, experience, and the senses.\"[47] Cognitive science is the interdisciplinary, scientific study of the mind and its processes.[48] Cognitive linguistics is an interdisciplinary branch of linguistics, combining knowledge and research from both psychology and linguistics.[49] Especially during the age of symbolic NLP, the area of computational linguistics maintained strong ties with cognitive studies.\n\nAs an example, George Lakoff offers a methodology to build natural language processing (NLP) algorithms through the perspective of cognitive science, along with the findings of cognitive linguistics,[50] with two defining aspects:\n\nTies with cognitive linguistics are part of the historical heritage of NLP, but they have been less frequently addressed since the statistical turn during the 1990s. Nevertheless, approaches to develop cognitive models towards technically operationalizable frameworks have been pursued in the context of various frameworks, e.g., of cognitive grammar,[53] functional grammar,[54] construction grammar,[55] computational psycholinguistics and cognitive neuroscience (e.g., ACT-R), however, with limited uptake in mainstream NLP (as measured by presence on major conferences[56] of the ACL). More recently, ideas of cognitive NLP have been revived as an approach to achieve explainability, e.g., under the notion of \"cognitive AI\".[57] Likewise, ideas of cognitive NLP are inherent to neural models multimodal NLP (although rarely made explicit)[58] and developments in artificial intelligence, specifically tools and technologies using large language model approaches[59] and new directions in artificial general intelligence based on the free energy principle[60] by British neuroscientist and theoretician at University College London Karl J. Friston.\n\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"docs=[]\nfor text in texts:\n    docs.append(text.get_text())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T19:12:54.761552Z","iopub.execute_input":"2025-05-15T19:12:54.761935Z","iopub.status.idle":"2025-05-15T19:12:54.768435Z","shell.execute_reply.started":"2025-05-15T19:12:54.761904Z","shell.execute_reply":"2025-05-15T19:12:54.766820Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"len(docs)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T19:12:54.771439Z","iopub.execute_input":"2025-05-15T19:12:54.771877Z","iopub.status.idle":"2025-05-15T19:12:54.802278Z","shell.execute_reply.started":"2025-05-15T19:12:54.771840Z","shell.execute_reply":"2025-05-15T19:12:54.801064Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"20"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"def getUniqueWords(allWords) :\n    uniqueWords = [] \n    for i in allWords:\n        if not i in uniqueWords:\n            uniqueWords.append(i)\n    return uniqueWords\n\nunique=getUniqueWords(docs)\nunique","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T19:12:54.803480Z","iopub.execute_input":"2025-05-15T19:12:54.803894Z","iopub.status.idle":"2025-05-15T19:12:54.823950Z","shell.execute_reply.started":"2025-05-15T19:12:54.803859Z","shell.execute_reply":"2025-05-15T19:12:54.822887Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"['Natural language processing (NLP) is a subfield of computer science and especially artificial intelligence. It is primarily concerned with providing computers with the ability to process data encoded in natural language and is thus closely related to information retrieval, knowledge representation and computational linguistics, a subfield of linguistics.\\n',\n 'Major tasks in natural language processing are speech recognition, text classification, natural-language understanding, and natural-language generation.\\n',\n 'Natural language processing has its roots in the 1950s.[1] Already in 1950, Alan Turing published an article titled \"Computing Machinery and Intelligence\" which proposed what is now called the Turing test as a criterion of intelligence, though at the time that was not articulated as a problem separate from artificial intelligence. The proposed test includes a task that involves the automated interpretation and generation of natural language.\\n',\n \"The premise of symbolic NLP is well-summarized by John Searle's Chinese room experiment: Given a collection of rules (e.g., a Chinese phrasebook, with questions and matching answers), the computer emulates natural language understanding (or other NLP tasks) by applying those rules to the data it confronts.\\n\",\n \"Up until the 1980s, most natural language processing systems were based on complex sets of hand-written rules.  Starting in the late 1980s, however, there was a revolution in natural language processing with the introduction of machine learning algorithms for language processing.  This was due to both the steady increase in computational power (see Moore's law) and the gradual lessening of the dominance of Chomskyan theories of linguistics (e.g. transformational grammar), whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing.[8]\\n\",\n 'Symbolic approach, i.e., the hand-coding of a set of rules for manipulating symbols, coupled with a dictionary lookup, was historically the first approach used both by AI in general and by NLP in particular:[18][19] such as by writing grammars or devising heuristic rules for stemming.\\n',\n 'Machine learning approaches, which include both statistical and neural networks, on the other hand, have many advantages over the symbolic approach: \\n',\n 'Rule-based systems are commonly used:\\n',\n 'In the late 1980s and mid-1990s, the statistical approach ended a period of AI winter, which was caused by the inefficiencies of the rule-based approaches.[20][21]\\n',\n 'The earliest decision trees, producing systems of hard ifâ€“then rules, were still very similar to the old rule-based approaches.\\nOnly the introduction of hidden Markov models, applied to part-of-speech tagging, announced the end of the old rule-based approach.\\n',\n 'A major drawback of statistical methods is that they require elaborate feature engineering. Since 2015,[22] the statistical approach has been replaced by the neural networks approach, using semantic networks[23] and word embeddings to capture semantic properties of words.  \\n',\n 'Intermediate tasks (e.g., part-of-speech tagging and dependency parsing) are not needed anymore. \\n',\n 'Neural machine translation, based on then-newly invented sequence-to-sequence transformations, made obsolete the intermediate steps, such as word alignment, previously necessary for statistical machine translation.\\n',\n 'The following is a list of some of the most commonly researched tasks in natural language processing. Some of these tasks have direct real-world applications, while others more commonly serve as subtasks that are used to aid in solving larger tasks.\\n',\n 'Though natural language processing tasks are closely intertwined, they can be subdivided into categories for convenience. A coarse division is given below.\\n',\n 'Based on long-standing trends in the field, it is possible to extrapolate future directions of NLP. As of 2020, three trends among the topics of the long-standing series of CoNLL Shared Tasks can be observed:[46]\\n',\n 'Most higher-level NLP applications involve aspects that emulate intelligent behaviour and apparent comprehension of natural language. More broadly speaking, the technical operationalization of increasingly advanced aspects of cognitive behaviour represents one of the developmental trajectories of NLP (see trends among CoNLL shared tasks above).\\n',\n 'Cognition refers to \"the mental action or process of acquiring knowledge and understanding through thought, experience, and the senses.\"[47] Cognitive science is the interdisciplinary, scientific study of the mind and its processes.[48] Cognitive linguistics is an interdisciplinary branch of linguistics, combining knowledge and research from both psychology and linguistics.[49] Especially during the age of symbolic NLP, the area of computational linguistics maintained strong ties with cognitive studies.\\n',\n 'As an example, George Lakoff offers a methodology to build natural language processing (NLP) algorithms through the perspective of cognitive science, along with the findings of cognitive linguistics,[50] with two defining aspects:\\n',\n 'Ties with cognitive linguistics are part of the historical heritage of NLP, but they have been less frequently addressed since the statistical turn during the 1990s. Nevertheless, approaches to develop cognitive models towards technically operationalizable frameworks have been pursued in the context of various frameworks, e.g., of cognitive grammar,[53] functional grammar,[54] construction grammar,[55] computational psycholinguistics and cognitive neuroscience (e.g., ACT-R), however, with limited uptake in mainstream NLP (as measured by presence on major conferences[56] of the ACL). More recently, ideas of cognitive NLP have been revived as an approach to achieve explainability, e.g., under the notion of \"cognitive AI\".[57] Likewise, ideas of cognitive NLP are inherent to neural models multimodal NLP (although rarely made explicit)[58] and developments in artificial intelligence, specifically tools and technologies using large language model approaches[59] and new directions in artificial general intelligence based on the free energy principle[60] by British neuroscientist and theoretician at University College London Karl J. Friston.\\n']"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"import re\nclean=[]\nfor s in unique:\n    cleaned = re.sub(r'[^a-zA-Z\\s]', '', s)\n    cleaned = cleaned.replace('\\n', '') \n    print(cleaned)\n    clean.append(cleaned)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T19:12:54.826993Z","iopub.execute_input":"2025-05-15T19:12:54.827579Z","iopub.status.idle":"2025-05-15T19:12:54.851886Z","shell.execute_reply.started":"2025-05-15T19:12:54.827533Z","shell.execute_reply":"2025-05-15T19:12:54.850671Z"}},"outputs":[{"name":"stdout","text":"Natural language processing NLP is a subfield of computer science and especially artificial intelligence It is primarily concerned with providing computers with the ability to process data encoded in natural language and is thus closely related to information retrieval knowledge representation and computational linguistics a subfield of linguistics\nMajor tasks in natural language processing are speech recognition text classification naturallanguage understanding and naturallanguage generation\nNatural language processing has its roots in the s Already in  Alan Turing published an article titled Computing Machinery and Intelligence which proposed what is now called the Turing test as a criterion of intelligence though at the time that was not articulated as a problem separate from artificial intelligence The proposed test includes a task that involves the automated interpretation and generation of natural language\nThe premise of symbolic NLP is wellsummarized by John Searles Chinese room experiment Given a collection of rules eg a Chinese phrasebook with questions and matching answers the computer emulates natural language understanding or other NLP tasks by applying those rules to the data it confronts\nUp until the s most natural language processing systems were based on complex sets of handwritten rules  Starting in the late s however there was a revolution in natural language processing with the introduction of machine learning algorithms for language processing  This was due to both the steady increase in computational power see Moores law and the gradual lessening of the dominance of Chomskyan theories of linguistics eg transformational grammar whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machinelearning approach to language processing\nSymbolic approach ie the handcoding of a set of rules for manipulating symbols coupled with a dictionary lookup was historically the first approach used both by AI in general and by NLP in particular such as by writing grammars or devising heuristic rules for stemming\nMachine learning approaches which include both statistical and neural networks on the other hand have many advantages over the symbolic approach \nRulebased systems are commonly used\nIn the late s and mids the statistical approach ended a period of AI winter which was caused by the inefficiencies of the rulebased approaches\nThe earliest decision trees producing systems of hard ifthen rules were still very similar to the old rulebased approachesOnly the introduction of hidden Markov models applied to partofspeech tagging announced the end of the old rulebased approach\nA major drawback of statistical methods is that they require elaborate feature engineering Since  the statistical approach has been replaced by the neural networks approach using semantic networks and word embeddings to capture semantic properties of words  \nIntermediate tasks eg partofspeech tagging and dependency parsing are not needed anymore \nNeural machine translation based on thennewly invented sequencetosequence transformations made obsolete the intermediate steps such as word alignment previously necessary for statistical machine translation\nThe following is a list of some of the most commonly researched tasks in natural language processing Some of these tasks have direct realworld applications while others more commonly serve as subtasks that are used to aid in solving larger tasks\nThough natural language processing tasks are closely intertwined they can be subdivided into categories for convenience A coarse division is given below\nBased on longstanding trends in the field it is possible to extrapolate future directions of NLP As of  three trends among the topics of the longstanding series of CoNLL Shared Tasks can be observed\nMost higherlevel NLP applications involve aspects that emulate intelligent behaviour and apparent comprehension of natural language More broadly speaking the technical operationalization of increasingly advanced aspects of cognitive behaviour represents one of the developmental trajectories of NLP see trends among CoNLL shared tasks above\nCognition refers to the mental action or process of acquiring knowledge and understanding through thought experience and the senses Cognitive science is the interdisciplinary scientific study of the mind and its processes Cognitive linguistics is an interdisciplinary branch of linguistics combining knowledge and research from both psychology and linguistics Especially during the age of symbolic NLP the area of computational linguistics maintained strong ties with cognitive studies\nAs an example George Lakoff offers a methodology to build natural language processing NLP algorithms through the perspective of cognitive science along with the findings of cognitive linguistics with two defining aspects\nTies with cognitive linguistics are part of the historical heritage of NLP but they have been less frequently addressed since the statistical turn during the s Nevertheless approaches to develop cognitive models towards technically operationalizable frameworks have been pursued in the context of various frameworks eg of cognitive grammar functional grammar construction grammar computational psycholinguistics and cognitive neuroscience eg ACTR however with limited uptake in mainstream NLP as measured by presence on major conferences of the ACL More recently ideas of cognitive NLP have been revived as an approach to achieve explainability eg under the notion of cognitive AI Likewise ideas of cognitive NLP are inherent to neural models multimodal NLP although rarely made explicit and developments in artificial intelligence specifically tools and technologies using large language model approaches and new directions in artificial general intelligence based on the free energy principle by British neuroscientist and theoretician at University College London Karl J Friston\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"#Stemming\n\nfrom nltk.stem import PorterStemmer\nfrom nltk.tokenize import word_tokenize\nfrom functools import reduce\n\nps = PorterStemmer()\n\nfor sentence in clean:\n    words = word_tokenize(sentence)\n    stemmed_sentence = reduce(lambda x, y: x + \" \" + ps.stem(y), words, \"\")\n    print(stemmed_sentence)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T19:12:54.853737Z","iopub.execute_input":"2025-05-15T19:12:54.854155Z","iopub.status.idle":"2025-05-15T19:12:56.431994Z","shell.execute_reply.started":"2025-05-15T19:12:54.854114Z","shell.execute_reply":"2025-05-15T19:12:56.430294Z"}},"outputs":[{"name":"stdout","text":" natur languag process nlp is a subfield of comput scienc and especi artifici intellig It is primarili concern with provid comput with the abil to process data encod in natur languag and is thu close relat to inform retriev knowledg represent and comput linguist a subfield of linguist\n major task in natur languag process are speech recognit text classif naturallanguag understand and naturallanguag gener\n natur languag process ha it root in the s alreadi in alan ture publish an articl titl comput machineri and intellig which propos what is now call the ture test as a criterion of intellig though at the time that wa not articul as a problem separ from artifici intellig the propos test includ a task that involv the autom interpret and gener of natur languag\n the premis of symbol nlp is wellsummar by john searl chines room experi given a collect of rule eg a chines phrasebook with question and match answer the comput emul natur languag understand or other nlp task by appli those rule to the data it confront\n Up until the s most natur languag process system were base on complex set of handwritten rule start in the late s howev there wa a revolut in natur languag process with the introduct of machin learn algorithm for languag process thi wa due to both the steadi increas in comput power see moor law and the gradual lessen of the domin of chomskyan theori of linguist eg transform grammar whose theoret underpin discourag the sort of corpu linguist that underli the machinelearn approach to languag process\n symbol approach ie the handcod of a set of rule for manipul symbol coupl with a dictionari lookup wa histor the first approach use both by AI in gener and by nlp in particular such as by write grammar or devis heurist rule for stem\n machin learn approach which includ both statist and neural network on the other hand have mani advantag over the symbol approach\n rulebas system are commonli use\n In the late s and mid the statist approach end a period of AI winter which wa caus by the ineffici of the rulebas approach\n the earliest decis tree produc system of hard ifthen rule were still veri similar to the old rulebas approachesonli the introduct of hidden markov model appli to partofspeech tag announc the end of the old rulebas approach\n A major drawback of statist method is that they requir elabor featur engin sinc the statist approach ha been replac by the neural network approach use semant network and word embed to captur semant properti of word\n intermedi task eg partofspeech tag and depend pars are not need anymor\n neural machin translat base on thennewli invent sequencetosequ transform made obsolet the intermedi step such as word align previous necessari for statist machin translat\n the follow is a list of some of the most commonli research task in natur languag process some of these task have direct realworld applic while other more commonli serv as subtask that are use to aid in solv larger task\n though natur languag process task are close intertwin they can be subdivid into categori for conveni A coars divis is given below\n base on longstand trend in the field it is possibl to extrapol futur direct of nlp As of three trend among the topic of the longstand seri of conll share task can be observ\n most higherlevel nlp applic involv aspect that emul intellig behaviour and appar comprehens of natur languag more broadli speak the technic operation of increasingli advanc aspect of cognit behaviour repres one of the development trajectori of nlp see trend among conll share task abov\n cognit refer to the mental action or process of acquir knowledg and understand through thought experi and the sens cognit scienc is the interdisciplinari scientif studi of the mind and it process cognit linguist is an interdisciplinari branch of linguist combin knowledg and research from both psycholog and linguist especi dure the age of symbol nlp the area of comput linguist maintain strong tie with cognit studi\n As an exampl georg lakoff offer a methodolog to build natur languag process nlp algorithm through the perspect of cognit scienc along with the find of cognit linguist with two defin aspect\n tie with cognit linguist are part of the histor heritag of nlp but they have been less frequent address sinc the statist turn dure the s nevertheless approach to develop cognit model toward technic operationaliz framework have been pursu in the context of variou framework eg of cognit grammar function grammar construct grammar comput psycholinguist and cognit neurosci eg actr howev with limit uptak in mainstream nlp as measur by presenc on major confer of the acl more recent idea of cognit nlp have been reviv as an approach to achiev explain eg under the notion of cognit AI likewis idea of cognit nlp are inher to neural model multimod nlp although rare made explicit and develop in artifici intellig specif tool and technolog use larg languag model approach and new direct in artifici gener intellig base on the free energi principl by british neuroscientist and theoretician at univers colleg london karl J friston\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"#lemmitzation\n\nimport spacy\nnlp = spacy.load('en_core_web_sm')\nfor text in clean:\n    doc = nlp(text)\n    lemmatized_tokens = [token.lemma_ for token in doc]\n    lemmatized_text = ' '.join(lemmatized_tokens)\n    print(lemmatized_text)\n    print(\"\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T19:12:56.433023Z","iopub.execute_input":"2025-05-15T19:12:56.433607Z","iopub.status.idle":"2025-05-15T19:13:04.316774Z","shell.execute_reply.started":"2025-05-15T19:12:56.433577Z","shell.execute_reply":"2025-05-15T19:13:04.315544Z"}},"outputs":[{"name":"stdout","text":"natural language processing NLP be a subfield of computer science and especially artificial intelligence it be primarily concern with provide computer with the ability to process datum encode in natural language and be thus closely relate to information retrieval knowledge representation and computational linguistic a subfield of linguistic\n\n\nmajor task in natural language processing be speech recognition text classification naturallanguage understanding and naturallanguage generation\n\n\nnatural language processing have its root in the s already in   Alan Turing publish an article title Computing Machinery and Intelligence which propose what be now call the ture test as a criterion of intelligence though at the time that be not articulate as a problem separate from artificial intelligence the propose test include a task that involve the automate interpretation and generation of natural language\n\n\nthe premise of symbolic NLP be wellsummarize by John Searles chinese room experiment give a collection of rule eg a chinese phrasebook with question and matching answer the computer emulate natural language understanding or other NLP task by apply those rule to the datum it confront\n\n\nup until the s most natural language processing system be base on complex set of handwritten rule   start in the late s however there be a revolution in natural language processing with the introduction of machine learn algorithm for language processing   this be due to both the steady increase in computational power see Moores law and the gradual lessening of the dominance of chomskyan theory of linguistic eg transformational grammar whose theoretical underpinning discourage the sort of corpus linguistic that underlie the machinelearne approach to language processing\n\n\nSymbolic approach ie the handcoding of a set of rule for manipulate symbol couple with a dictionary lookup be historically the first approach use both by AI in general and by NLP in particular such as by write grammar or devise heuristic rule for stem\n\n\nmachine learn approach which include both statistical and neural network on the other hand have many advantage over the symbolic approach\n\n\nrulebase system be commonly use\n\n\nin the late s and mid the statistical approach end a period of AI winter which be cause by the inefficiency of the rulebase approach\n\n\nthe early decision tree produce system of hard ifthen rule be still very similar to the old rulebase approachesonly the introduction of hidden Markov model apply to partofspeech tagging announce the end of the old rulebased approach\n\n\na major drawback of statistical method be that they require elaborate feature engineering since   the statistical approach have be replace by the neural network approach use semantic network and word embedding to capture semantic property of word  \n\n\nintermediate task eg partofspeech tagging and dependency parsing be not need anymore\n\n\nneural machine translation base on thennewly invent sequencetosequence transformation make obsolete the intermediate step such as word alignment previously necessary for statistical machine translation\n\n\nthe following be a list of some of the most commonly research task in natural language process some of these task have direct realworld application while other more commonly serve as subtask that be use to aid in solve large task\n\n\nthough natural language processing task be closely intertwine they can be subdivide into category for convenience a coarse division be give below\n\n\nbase on longstanding trend in the field it be possible to extrapolate future direction of NLP as of   three trend among the topic of the longstanding series of CoNLL Shared Tasks can be observe\n\n\nMost higherlevel nlp application involve aspect that emulate intelligent behaviour and apparent comprehension of natural language more broadly speak the technical operationalization of increasingly advanced aspect of cognitive behaviour represent one of the developmental trajectory of NLP see trend among conll share task above\n\n\ncognition refer to the mental action or process of acquire knowledge and understanding through think experience and the sense cognitive science be the interdisciplinary scientific study of the mind and its process cognitive linguistic be an interdisciplinary branch of linguistic combine knowledge and research from both psychology and linguistic especially during the age of symbolic NLP the area of computational linguistic maintain strong tie with cognitive study\n\n\nas an example George Lakoff offer a methodology to build natural language process NLP algorithm through the perspective of cognitive science along with the finding of cognitive linguistic with two define aspect\n\n\ntie with cognitive linguistic be part of the historical heritage of NLP but they have be less frequently address since the statistical turn during the s nevertheless approach to develop cognitive model towards technically operationalizable framework have be pursue in the context of various framework eg of cognitive grammar functional grammar construction grammar computational psycholinguistic and cognitive neuroscience eg ACTR however with limited uptake in mainstream NLP as measure by presence on major conference of the ACL more recently idea of cognitive NLP have be revive as an approach to achieve explainability eg under the notion of cognitive AI Likewise idea of cognitive NLP be inherent to neural model multimodal NLP although rarely make explicit and development in artificial intelligence specifically tool and technology use large language model approach and new direction in artificial general intelligence base on the free energy principle by british neuroscientist and theoretician at University College London Karl J Friston\n\n\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"#tokenization\n\nimport re\ntoken=[]\nfor s in clean:\n    res = [part if part.strip() else \" \" for part in s.split(\" \")]\n    token.append(res)\ntoken[1][:5]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T19:13:04.317851Z","iopub.execute_input":"2025-05-15T19:13:04.318506Z","iopub.status.idle":"2025-05-15T19:13:04.326881Z","shell.execute_reply.started":"2025-05-15T19:13:04.318472Z","shell.execute_reply":"2025-05-15T19:13:04.325724Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"['Major', 'tasks', 'in', 'natural', 'language']"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"words1=[]\nfor sentence in docs:\n    words1.extend(sentence.split())\nlen(words1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T19:13:04.327905Z","iopub.execute_input":"2025-05-15T19:13:04.328218Z","iopub.status.idle":"2025-05-15T19:13:04.348870Z","shell.execute_reply.started":"2025-05-15T19:13:04.328193Z","shell.execute_reply":"2025-05-15T19:13:04.347586Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"867"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"import re\n\n\nunique_words = set()\n\n\nfor sentence in clean:\n    words = sentence.split()  \n    unique_words.update(words)\n\n\nunique_words_list = list(unique_words)\nprint(unique_words_list)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T19:13:04.350212Z","iopub.execute_input":"2025-05-15T19:13:04.350626Z","iopub.status.idle":"2025-05-15T19:13:04.367592Z","shell.execute_reply.started":"2025-05-15T19:13:04.350587Z","shell.execute_reply":"2025-05-15T19:13:04.366551Z"}},"outputs":[{"name":"stdout","text":"['used', 'perspective', 'Cognition', 'frequently', 'data', 'higherlevel', 'confronts', 'acquiring', 'has', 'Some', 'systems', 'free', 'at', 'AI', 'University', 'functional', 'embeddings', 'symbols', 'commonly', 'neural', 'convenience', 'developmental', 'Since', 'cognitive', 'now', 'it', 'hand', 'Major', 'psycholinguistics', 'naturallanguage', 'word', 'A', 'encoded', 'complex', 'knowledge', 'heritage', 'time', 'branch', 'Most', 'grammar', 'Likewise', 'Intelligence', 'replaced', 'more', 'announced', 'similar', 'CoNLL', 'specifically', 'classification', 'rulebased', 'rarely', 'Moores', 'on', 'winter', 'studies', 'ifthen', 'Rulebased', 'sequencetosequence', 'Tasks', 'handcoding', 'computer', 'In', 'these', 'corpus', 'principle', 'or', 'historically', 'George', 'Neural', 'coarse', 'Starting', 'subtasks', 'involves', 'senses', 'represents', 'ACTR', 'speech', 'be', 'semantic', 'strong', 'intertwined', 'revived', 'serve', 'discouraged', 'collection', 'construction', 'from', 'J', 'law', 'elaborate', 'experiment', 'until', 'necessary', 'task', 'such', 'Nevertheless', 'developments', 'in', 'computational', 'linguistics', 'aspects', 'division', 'providing', 'action', 'among', 'premise', 'lookup', 'some', 'apparent', 'words', 'intelligent', 'operationalization', 'thought', 'networks', 'text', 'limited', 'historical', 'context', 'applied', 'during', 'age', 'article', 'matching', 'feature', 'made', 'Based', 'particular', 'especially', 'longstanding', 'proposed', 'ended', 'mids', 'set', 'intermediate', 'notion', 'primarily', 'not', 'was', 'interpretation', 'ties', 'dictionary', 'but', 'London', 'list', 'along', 'towards', 'explicit', 'can', 'possible', 'Turing', 'Symbolic', 'theoretician', 'coupled', 'mind', 'related', 'invented', 'John', 'Ties', 'presence', 'College', 'measured', 'advanced', 'other', 'science', 'lessening', 'over', 'roots', 'Though', 'intelligence', 'titled', 'Already', 'based', 'computers', 'advantages', 'sets', 'anymore', 'they', 'and', 'with', 'caused', 'operationalizable', 'This', 'tagging', 'which', 'through', 'steady', 'topics', 'properties', 'earliest', 'methodology', 'inefficiencies', 'end', 'broadly', 'shared', 'example', 'capture', 'psychology', 'retrieval', 'observed', 'whose', 'uptake', 'old', 'engineering', 'there', 'solving', 'study', 'problem', 'room', 'a', 'develop', 'thus', 'since', 'the', 'recognition', 'introduction', 'alignment', 'handwritten', 'statistical', 'Machinery', 'defining', 'while', 'period', 'that', 'below', 'many', 'Computing', 'large', 'manipulating', 'parsing', 'behaviour', 'subdivided', 'various', 'answers', 'offers', 'ie', 'Especially', 'three', 'technical', 'series', 'British', 'direct', 'are', 'automated', 'hidden', 'experience', 'Natural', 'its', 'comprehension', 'inherent', 'field', 'symbolic', 'most', 'using', 'decision', 'neuroscience', 'sort', 'technologies', 'researched', 'those', 'Searles', 'were', 'emulates', 'part', 'revolution', 'Friston', 'Lakoff', 'ability', 'representation', 'by', 'eg', 'extrapolate', 'Machine', 'language', 'explainability', 'model', 'criterion', 'rules', 'wellsummarized', 'approachesOnly', 'an', 'larger', 'multimodal', 'two', 'producing', 'processing', 'under', 'as', 'trajectories', 'Alan', 'heuristic', 'called', 'for', 'directions', 'grammars', 'although', 'includes', 'following', 'pursued', 'what', 'processes', 'recently', 'dependency', 'to', 'tasks', 'turn', 'needed', 'Markov', 'Chinese', 'build', 'Chomskyan', 'have', 'translation', 'combining', 'frameworks', 'above', 'aid', 'see', 'both', 'one', 'technically', 'addressed', 'late', 'realworld', 'is', 'More', 'theoretical', 'stemming', 'energy', 'approach', 'ACL', 'given', 'theories', 'concerned', 'learning', 'machinelearning', 'others', 'Intermediate', 'applications', 'interdisciplinary', 'Shared', 'applying', 'tools', 'speaking', 'first', 'into', 'very', 'published', 'underlies', 'methods', 'thennewly', 'separate', 'process', 'mainstream', 'Up', 'questions', 'Cognitive', 'require', 'algorithms', 'general', 'dominance', 'major', 'drawback', 'generation', 'gradual', 'natural', 'The', 'area', 'previously', 'increasingly', 'obsolete', 'emulate', 'artificial', 'research', 'machine', 'devising', 'information', 'maintained', 'trends', 'new', 'articulated', 'of', 'transformational', 'It', 'scientific', 'Given', 'test', 'increase', 'steps', 'Karl', 'refers', 'subfield', 'achieve', 'been', 'models', 'less', 'transformations', 'involve', 'findings', 'neuroscientist', 'approaches', 'include', 'however', 'though', 'conferences', 's', 'partofspeech', 'trees', 'ideas', 'categories', 'understanding', 'mental', 'As', 'still', 'due', 'future', 'power', 'NLP', 'phrasebook', 'underpinnings', 'writing', 'hard', 'closely']\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"#vocubalary\nlen(unique_words_list)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T19:13:04.368829Z","iopub.execute_input":"2025-05-15T19:13:04.369187Z","iopub.status.idle":"2025-05-15T19:13:04.389064Z","shell.execute_reply.started":"2025-05-15T19:13:04.369152Z","shell.execute_reply":"2025-05-15T19:13:04.387844Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"422"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"print(f\"No of Docs: {len(docs)}\")\nprint(f\"No of words: {len(words1)}\")\nprint(f\"No of Vocubalary: {len(unique_words_list)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T19:13:04.390104Z","iopub.execute_input":"2025-05-15T19:13:04.390470Z","iopub.status.idle":"2025-05-15T19:13:04.408753Z","shell.execute_reply.started":"2025-05-15T19:13:04.390442Z","shell.execute_reply":"2025-05-15T19:13:04.407408Z"}},"outputs":[{"name":"stdout","text":"No of Docs: 20\nNo of words: 867\nNo of Vocubalary: 422\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"#corpus\nclean","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T19:13:04.410085Z","iopub.execute_input":"2025-05-15T19:13:04.410492Z","iopub.status.idle":"2025-05-15T19:13:04.428893Z","shell.execute_reply.started":"2025-05-15T19:13:04.410465Z","shell.execute_reply":"2025-05-15T19:13:04.427791Z"},"scrolled":true},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"['Natural language processing NLP is a subfield of computer science and especially artificial intelligence It is primarily concerned with providing computers with the ability to process data encoded in natural language and is thus closely related to information retrieval knowledge representation and computational linguistics a subfield of linguistics',\n 'Major tasks in natural language processing are speech recognition text classification naturallanguage understanding and naturallanguage generation',\n 'Natural language processing has its roots in the s Already in  Alan Turing published an article titled Computing Machinery and Intelligence which proposed what is now called the Turing test as a criterion of intelligence though at the time that was not articulated as a problem separate from artificial intelligence The proposed test includes a task that involves the automated interpretation and generation of natural language',\n 'The premise of symbolic NLP is wellsummarized by John Searles Chinese room experiment Given a collection of rules eg a Chinese phrasebook with questions and matching answers the computer emulates natural language understanding or other NLP tasks by applying those rules to the data it confronts',\n 'Up until the s most natural language processing systems were based on complex sets of handwritten rules  Starting in the late s however there was a revolution in natural language processing with the introduction of machine learning algorithms for language processing  This was due to both the steady increase in computational power see Moores law and the gradual lessening of the dominance of Chomskyan theories of linguistics eg transformational grammar whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machinelearning approach to language processing',\n 'Symbolic approach ie the handcoding of a set of rules for manipulating symbols coupled with a dictionary lookup was historically the first approach used both by AI in general and by NLP in particular such as by writing grammars or devising heuristic rules for stemming',\n 'Machine learning approaches which include both statistical and neural networks on the other hand have many advantages over the symbolic approach ',\n 'Rulebased systems are commonly used',\n 'In the late s and mids the statistical approach ended a period of AI winter which was caused by the inefficiencies of the rulebased approaches',\n 'The earliest decision trees producing systems of hard ifthen rules were still very similar to the old rulebased approachesOnly the introduction of hidden Markov models applied to partofspeech tagging announced the end of the old rulebased approach',\n 'A major drawback of statistical methods is that they require elaborate feature engineering Since  the statistical approach has been replaced by the neural networks approach using semantic networks and word embeddings to capture semantic properties of words  ',\n 'Intermediate tasks eg partofspeech tagging and dependency parsing are not needed anymore ',\n 'Neural machine translation based on thennewly invented sequencetosequence transformations made obsolete the intermediate steps such as word alignment previously necessary for statistical machine translation',\n 'The following is a list of some of the most commonly researched tasks in natural language processing Some of these tasks have direct realworld applications while others more commonly serve as subtasks that are used to aid in solving larger tasks',\n 'Though natural language processing tasks are closely intertwined they can be subdivided into categories for convenience A coarse division is given below',\n 'Based on longstanding trends in the field it is possible to extrapolate future directions of NLP As of  three trends among the topics of the longstanding series of CoNLL Shared Tasks can be observed',\n 'Most higherlevel NLP applications involve aspects that emulate intelligent behaviour and apparent comprehension of natural language More broadly speaking the technical operationalization of increasingly advanced aspects of cognitive behaviour represents one of the developmental trajectories of NLP see trends among CoNLL shared tasks above',\n 'Cognition refers to the mental action or process of acquiring knowledge and understanding through thought experience and the senses Cognitive science is the interdisciplinary scientific study of the mind and its processes Cognitive linguistics is an interdisciplinary branch of linguistics combining knowledge and research from both psychology and linguistics Especially during the age of symbolic NLP the area of computational linguistics maintained strong ties with cognitive studies',\n 'As an example George Lakoff offers a methodology to build natural language processing NLP algorithms through the perspective of cognitive science along with the findings of cognitive linguistics with two defining aspects',\n 'Ties with cognitive linguistics are part of the historical heritage of NLP but they have been less frequently addressed since the statistical turn during the s Nevertheless approaches to develop cognitive models towards technically operationalizable frameworks have been pursued in the context of various frameworks eg of cognitive grammar functional grammar construction grammar computational psycholinguistics and cognitive neuroscience eg ACTR however with limited uptake in mainstream NLP as measured by presence on major conferences of the ACL More recently ideas of cognitive NLP have been revived as an approach to achieve explainability eg under the notion of cognitive AI Likewise ideas of cognitive NLP are inherent to neural models multimodal NLP although rarely made explicit and developments in artificial intelligence specifically tools and technologies using large language model approaches and new directions in artificial general intelligence based on the free energy principle by British neuroscientist and theoretician at University College London Karl J Friston']"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"#remove space\nnospace=\"\"\nfor s in clean:\n    s = s.replace(\" \", \"\")\n    nospace=nospace+s","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T19:13:04.430127Z","iopub.execute_input":"2025-05-15T19:13:04.430575Z","iopub.status.idle":"2025-05-15T19:13:04.445483Z","shell.execute_reply.started":"2025-05-15T19:13:04.430534Z","shell.execute_reply":"2025-05-15T19:13:04.444353Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"#Maximum Matching Algo \n\nfrom nltk.corpus import words\n\nstring = nospace[:150]\nstring=string.lower()\ntokens = []\nlowercaseCorpus = [x.lower() for x in words.words()]\ni = 0\nwhile i < len(string):\n    maxWord = \"\"\n    for j in range(i, len(string)):\n        tempWord = string[i:j+1]\n        if tempWord in lowercaseCorpus and len(tempWord) > len(maxWord):\n            maxWord = tempWord\n    i = i+len(maxWord)\n    tokens.append(maxWord)\nprint(tokens)","metadata":{"execution":{"iopub.status.busy":"2025-02-19T06:03:15.679981Z","iopub.execute_input":"2025-02-19T06:03:15.680392Z","iopub.status.idle":"2025-02-19T06:03:23.563026Z","shell.execute_reply.started":"2025-02-19T06:03:15.680358Z","shell.execute_reply":"2025-02-19T06:03:23.562080Z"}}},{"cell_type":"code","source":"\n#Maximum Matching Algo\nfrom nltk.corpus import words\n\nstring = nospace[:150]\nstring=string.lower()\ntokens = []\nlowercaseCorpus = [x.lower() for x in words.words()]\ni = 0\nwhile i < len(string):\n    maxWord = \"\"\n    for j in range(i, len(string)):\n        tempWord = string[i:j+1]\n        if tempWord in lowercaseCorpus and len(tempWord) > len(maxWord):\n            maxWord = tempWord\n    i = i+len(maxWord)\n    tokens.append(maxWord)\nprint(tokens)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T19:13:44.733482Z","iopub.execute_input":"2025-05-15T19:13:44.733889Z","iopub.status.idle":"2025-05-15T19:13:52.751397Z","shell.execute_reply.started":"2025-05-15T19:13:44.733857Z","shell.execute_reply":"2025-05-15T19:13:52.750194Z"}},"outputs":[{"name":"stdout","text":"['natural', 'language', 'process', 'ing', 'n', 'l', 'pi', 'sa', 'sub', 'field', 'of', 'computer', 'science', 'ande', 'specially', 'artificial', 'intelligence', 'it', 'is', 'primarily', 'concerned', 'with', 'providing', 'computer', 'swith', 'thea', 'b', 'i', 'lit', 'y', 't']\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"#Byte pair Encoding\n\nimport re\nfrom collections import defaultdict\n\ndef get_stats(vocab):\n    pairs = defaultdict(int)\n    for word, freq in vocab.items():\n        symbols = word.split()\n        for i in range(len(symbols)-1):\n            pairs[symbols[i],symbols[i+1]] += freq\n    return pairs\n\ndef merge_vocab(pair, v_in):\n    v_out = {}\n    bigram = re.escape(' '.join(pair))\n    p = re.compile(r'(?<!\\S)' + bigram + r'(?!\\S)')\n    for word in v_in:\n        w_out = p.sub(''.join(pair), word)\n        v_out[w_out] = v_in[word]\n    return v_out\n\ndef get_vocab(data):\n    vocab = defaultdict(int)\n    for line in data:\n        for word in line.split():\n            vocab[' '.join(list(word)) + ''] += 1\n    return vocab\n\ndef byte_pair_encoding(data, n):\n    vocab = get_vocab(data)\n    for i in range(n):\n        pairs = get_stats(vocab)\n        best = max(pairs, key=pairs.get)\n        vocab = merge_vocab(best, vocab)\n    return vocab\n\n# Example usage:\ntext=\"\"\nfor string in clean:\n    text+=string\ncorpus = text\ndata = corpus.split('.')\n\nn = 1000\nbpe_pairs = byte_pair_encoding(data, n)\nbpe_pairs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T19:14:10.202440Z","iopub.execute_input":"2025-05-15T19:14:10.202923Z","iopub.status.idle":"2025-05-15T19:14:11.142731Z","shell.execute_reply.started":"2025-05-15T19:14:10.202822Z","shell.execute_reply":"2025-05-15T19:14:11.141383Z"},"scrolled":true},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"{'Natural': 1,\n 'language': 14,\n 'processing': 9,\n 'NLP': 14,\n 'is': 11,\n 'a': 13,\n 'subfield': 2,\n 'of': 48,\n 'computer': 2,\n 'science': 3,\n 'and': 24,\n 'especially': 1,\n 'artificial': 4,\n 'intelligence': 5,\n 'It': 1,\n 'primarily': 1,\n 'concerned': 1,\n 'with': 10,\n 'providing': 1,\n 'computers': 1,\n 'the': 51,\n 'ability': 1,\n 'to': 15,\n 'process': 2,\n 'data': 2,\n 'encoded': 1,\n 'in': 16,\n 'natural': 10,\n 'thus': 1,\n 'closely': 2,\n 'related': 1,\n 'information': 1,\n 'retrieval': 1,\n 'knowledge': 3,\n 'representation': 1,\n 'computational': 4,\n 'linguistics': 9,\n 'linguisticsMajor': 1,\n 'tasks': 7,\n 'are': 7,\n 'speech': 1,\n 'recognition': 1,\n 'text': 1,\n 'classification': 1,\n 'naturallanguage': 2,\n 'understanding': 3,\n 'generationNatural': 1,\n 'has': 2,\n 'its': 2,\n 'roots': 1,\n 's': 5,\n 'Already': 1,\n 'Alan': 1,\n 'Turing': 2,\n 'published': 1,\n 'an': 4,\n 'article': 1,\n 'titled': 1,\n 'Computing': 1,\n 'Machinery': 1,\n 'Intelligence': 1,\n 'which': 3,\n 'proposed': 2,\n 'what': 1,\n 'now': 1,\n 'called': 1,\n 'test': 2,\n 'as': 7,\n 'criterion': 1,\n 'though': 1,\n 'at': 2,\n 'time': 1,\n 'that': 6,\n 'was': 5,\n 'not': 2,\n 'articulated': 1,\n 'problem': 1,\n 'separate': 1,\n 'from': 2,\n 'The': 1,\n 'includes': 1,\n 'task': 1,\n 'involves': 1,\n 'automated': 1,\n 'interpretation': 1,\n 'generation': 1,\n 'languageThe': 1,\n 'premise': 1,\n 'symbolic': 3,\n 'wellsummarized': 1,\n 'by': 9,\n 'John': 1,\n 'Searles': 1,\n 'Chinese': 2,\n 'room': 1,\n 'experiment': 1,\n 'Given': 1,\n 'collection': 1,\n 'rules': 6,\n 'eg': 6,\n 'phrasebook': 1,\n 'questions': 1,\n 'matching': 1,\n 'answers': 1,\n 'emulates': 1,\n 'or': 3,\n 'other': 2,\n 'applying': 1,\n 'those': 1,\n 'it': 2,\n 'confrontsUp': 1,\n 'until': 1,\n 'most': 2,\n 'systems': 3,\n 'were': 2,\n 'based': 3,\n 'on': 6,\n 'complex': 1,\n 'sets': 1,\n 'handwritten': 1,\n 'Starting': 1,\n 'late': 2,\n 'however': 2,\n 'there': 1,\n 'revolution': 1,\n 'introduction': 2,\n 'machine': 3,\n 'learning': 2,\n 'algorithms': 2,\n 'for': 5,\n 'This': 1,\n 'due': 1,\n 'both': 4,\n 'steady': 1,\n 'increase': 1,\n 'power': 1,\n 'see': 2,\n 'Moores': 1,\n 'law': 1,\n 'gradual': 1,\n 'lessening': 1,\n 'dominance': 1,\n 'Chomskyan': 1,\n 'theories': 1,\n 'transformational': 1,\n 'grammar': 4,\n 'whose': 1,\n 'theoretical': 1,\n 'underpinnings': 1,\n 'discouraged': 1,\n 'sort': 1,\n 'corpus': 1,\n 'underlies': 1,\n 'machinelearning': 1,\n 'approach': 8,\n 'processingSymbolic': 1,\n 'ie': 1,\n 'handcoding': 1,\n 'set': 1,\n 'manipulating': 1,\n 'symbols': 1,\n 'coupled': 1,\n 'dictionary': 1,\n 'lookup': 1,\n 'historically': 1,\n 'first': 1,\n 'used': 2,\n 'AI': 3,\n 'general': 2,\n 'particular': 1,\n 'such': 2,\n 'writing': 1,\n 'grammars': 1,\n 'devising': 1,\n 'heuristic': 1,\n 'stemmingMachine': 1,\n 'approaches': 3,\n 'include': 1,\n 'statistical': 6,\n 'neural': 3,\n 'networks': 3,\n 'hand': 1,\n 'have': 5,\n 'many': 1,\n 'advantages': 1,\n 'over': 1,\n 'Rulebased': 1,\n 'commonly': 3,\n 'usedIn': 1,\n 'mids': 1,\n 'ended': 1,\n 'period': 1,\n 'winter': 1,\n 'caused': 1,\n 'inefficiencies': 1,\n 'rulebased': 3,\n 'approachesThe': 1,\n 'earliest': 1,\n 'decision': 1,\n 'trees': 1,\n 'producing': 1,\n 'hard': 1,\n 'ifthen': 1,\n 'still': 1,\n 'very': 1,\n 'similar': 1,\n 'old': 2,\n 'approachesOnly': 1,\n 'hidden': 1,\n 'Markov': 1,\n 'models': 3,\n 'applied': 1,\n 'partofspeech': 2,\n 'tagging': 2,\n 'announced': 1,\n 'end': 1,\n 'approachA': 1,\n 'major': 2,\n 'drawback': 1,\n 'methods': 1,\n 'they': 3,\n 'require': 1,\n 'elaborate': 1,\n 'feature': 1,\n 'engineering': 1,\n 'Since': 1,\n 'been': 4,\n 'replaced': 1,\n 'using': 2,\n 'semantic': 2,\n 'word': 2,\n 'embeddings': 1,\n 'capture': 1,\n 'properties': 1,\n 'words': 1,\n 'Intermediate': 1,\n 'dependency': 1,\n 'parsing': 1,\n 'needed': 1,\n 'anymore': 1,\n 'Neural': 1,\n 'translation': 1,\n 'thennewly': 1,\n 'invented': 1,\n 'sequencetosequence': 1,\n 'transformations': 1,\n 'made': 2,\n 'obsolete': 1,\n 'intermediate': 1,\n 'steps': 1,\n 'alignment': 1,\n 'previously': 1,\n 'necessary': 1,\n 'translationThe': 1,\n 'following': 1,\n 'list': 1,\n 'some': 1,\n 'researched': 1,\n 'Some': 1,\n 'these': 1,\n 'direct': 1,\n 'realworld': 1,\n 'applications': 2,\n 'while': 1,\n 'others': 1,\n 'more': 1,\n 'serve': 1,\n 'subtasks': 1,\n 'aid': 1,\n 'solving': 1,\n 'larger': 1,\n 'tasksThough': 1,\n 'intertwined': 1,\n 'can': 2,\n 'be': 2,\n 'subdivided': 1,\n 'into': 1,\n 'categories': 1,\n 'convenience': 1,\n 'A': 1,\n 'coarse': 1,\n 'division': 1,\n 'given': 1,\n 'belowBased': 1,\n 'longstanding': 2,\n 'trends': 3,\n 'field': 1,\n 'possible': 1,\n 'extrapolate': 1,\n 'future': 1,\n 'directions': 2,\n 'As': 1,\n 'three': 1,\n 'among': 2,\n 'topics': 1,\n 'series': 1,\n 'CoNLL': 2,\n 'Shared': 1,\n 'Tasks': 1,\n 'observedMost': 1,\n 'higherlevel': 1,\n 'involve': 1,\n 'aspects': 2,\n 'emulate': 1,\n 'intelligent': 1,\n 'behaviour': 2,\n 'apparent': 1,\n 'comprehension': 1,\n 'More': 2,\n 'broadly': 1,\n 'speaking': 1,\n 'technical': 1,\n 'operationalization': 1,\n 'increasingly': 1,\n 'advanced': 1,\n 'cognitive': 11,\n 'represents': 1,\n 'one': 1,\n 'developmental': 1,\n 'trajectories': 1,\n 'shared': 1,\n 'aboveCognition': 1,\n 'refers': 1,\n 'mental': 1,\n 'action': 1,\n 'acquiring': 1,\n 'through': 2,\n 'thought': 1,\n 'experience': 1,\n 'senses': 1,\n 'Cognitive': 2,\n 'interdisciplinary': 2,\n 'scientific': 1,\n 'study': 1,\n 'mind': 1,\n 'processes': 1,\n 'branch': 1,\n 'combining': 1,\n 'research': 1,\n 'psychology': 1,\n 'Especially': 1,\n 'during': 2,\n 'age': 1,\n 'area': 1,\n 'maintained': 1,\n 'strong': 1,\n 'ties': 1,\n 'studiesAs': 1,\n 'example': 1,\n 'George': 1,\n 'Lakoff': 1,\n 'offers': 1,\n 'methodology': 1,\n 'build': 1,\n 'perspective': 1,\n 'along': 1,\n 'findings': 1,\n 'two': 1,\n 'defining': 1,\n 'aspectsTies': 1,\n 'part': 1,\n 'historical': 1,\n 'heritage': 1,\n 'but': 1,\n 'less': 1,\n 'frequently': 1,\n 'addressed': 1,\n 'since': 1,\n 'turn': 1,\n 'Nevertheless': 1,\n 'develop': 1,\n 'towards': 1,\n 'technically': 1,\n 'operationalizable': 1,\n 'frameworks': 2,\n 'pursu ed': 1,\n 'con text': 1,\n 'v ar i o us': 1,\n 'f un ction al': 1,\n 'con str u ction': 1,\n 'psych ol inguistics': 1,\n 'neuro science': 1,\n 'AC T R': 1,\n 'li m it ed': 1,\n 'up t ak e': 1,\n 'ma in st re am': 1,\n 'me as ure d': 1,\n 'pres ence': 1,\n 'conf e ren c es': 1,\n 'AC L': 1,\n 're c ently': 1,\n 'ideas': 2,\n 're vi ved': 1,\n 'ach ie ve': 1,\n 'ex pla in ability': 1,\n 'under': 1,\n 'no tion': 1,\n 'L i k e w ise': 1,\n 'in he ren t': 1,\n 'm ul ti mod al': 1,\n 'al though': 1,\n 'r are ly': 1,\n 'ex plic it': 1,\n 'development s': 1,\n 'spe ci fic ally': 1,\n 'to ol s': 1,\n 'techn olog ies': 1,\n 'lar ge': 1,\n 'model': 1,\n 'new': 1,\n 'f ree': 1,\n 'ener g y': 1,\n 'pr in ci ple': 1,\n 'B r i tis h': 1,\n 'neuro scien ti st': 1,\n 'theore tic i an': 1,\n 'U n i ver s it y': 1,\n 'C ol le ge': 1,\n 'L on d on': 1,\n 'K ar l': 1,\n 'J': 1,\n 'F r ist on': 1}"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}