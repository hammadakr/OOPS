{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-12T04:04:26.857930Z","iopub.execute_input":"2025-03-12T04:04:26.858273Z","iopub.status.idle":"2025-03-12T04:04:27.318459Z","shell.execute_reply.started":"2025-03-12T04:04:26.858247Z","shell.execute_reply":"2025-03-12T04:04:27.317411Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!pip install requests\n!pip install html5lib\n!pip install bs4","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T04:04:27.319849Z","iopub.execute_input":"2025-03-12T04:04:27.320431Z","iopub.status.idle":"2025-03-12T04:04:41.603290Z","shell.execute_reply.started":"2025-03-12T04:04:27.320390Z","shell.execute_reply":"2025-03-12T04:04:41.602040Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2025.1.31)\nRequirement already satisfied: html5lib in /usr/local/lib/python3.10/dist-packages (1.1)\nRequirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib) (1.17.0)\nRequirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib) (0.5.1)\nCollecting bs4\n  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4) (4.12.3)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4) (2.6)\nDownloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\nInstalling collected packages: bs4\nSuccessfully installed bs4-0.0.2\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from bs4 import BeautifulSoup\nimport requests","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T04:04:41.605696Z","iopub.execute_input":"2025-03-12T04:04:41.606058Z","iopub.status.idle":"2025-03-12T04:04:42.060266Z","shell.execute_reply.started":"2025-03-12T04:04:41.605991Z","shell.execute_reply":"2025-03-12T04:04:42.059237Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"url = \"https://en.wikipedia.org/wiki/Natural_language_processing\"\nhtml_content = requests.get(url).text\nsoup = BeautifulSoup(html_content, \"html.parser\")\n\ntexts = soup.find_all('p')\nfor text in texts:\n    print(text.get_text())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T04:04:42.061745Z","iopub.execute_input":"2025-03-12T04:04:42.062438Z","iopub.status.idle":"2025-03-12T04:04:42.584037Z","shell.execute_reply.started":"2025-03-12T04:04:42.062410Z","shell.execute_reply":"2025-03-12T04:04:42.582798Z"}},"outputs":[{"name":"stdout","text":"Natural language processing (NLP) is a subfield of computer science and especially artificial intelligence. It is primarily concerned with providing computers with the ability to process data encoded in natural language and is thus closely related to information retrieval, knowledge representation and computational linguistics, a subfield of linguistics.\n\nMajor tasks in natural language processing are speech recognition, text classification, natural-language understanding, and natural-language generation.\n\nNatural language processing has its roots in the 1950s.[1] Already in 1950, Alan Turing published an article titled \"Computing Machinery and Intelligence\" which proposed what is now called the Turing test as a criterion of intelligence, though at the time that was not articulated as a problem separate from artificial intelligence. The proposed test includes a task that involves the automated interpretation and generation of natural language.\n\nThe premise of symbolic NLP is well-summarized by John Searle's Chinese room experiment: Given a collection of rules (e.g., a Chinese phrasebook, with questions and matching answers), the computer emulates natural language understanding (or other NLP tasks) by applying those rules to the data it confronts.\n\nUp until the 1980s, most natural language processing systems were based on complex sets of hand-written rules.  Starting in the late 1980s, however, there was a revolution in natural language processing with the introduction of machine learning algorithms for language processing.  This was due to both the steady increase in computational power (see Moore's law) and the gradual lessening of the dominance of Chomskyan theories of linguistics (e.g. transformational grammar), whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing.[8]\n\nSymbolic approach, i.e., the hand-coding of a set of rules for manipulating symbols, coupled with a dictionary lookup, was historically the first approach used both by AI in general and by NLP in particular:[18][19] such as by writing grammars or devising heuristic rules for stemming.\n\nMachine learning approaches, which include both statistical and neural networks, on the other hand, have many advantages over the symbolic approach: \n\nRule-based systems are commonly used:\n\nIn the late 1980s and mid-1990s, the statistical approach ended a period of AI winter, which was caused by the inefficiencies of the rule-based approaches.[20][21]\n\nThe earliest decision trees, producing systems of hard if–then rules, were still very similar to the old rule-based approaches.\nOnly the introduction of hidden Markov models, applied to part-of-speech tagging, announced the end of the old rule-based approach.\n\nA major drawback of statistical methods is that they require elaborate feature engineering. Since 2015,[22] the statistical approach has been replaced by the neural networks approach, using semantic networks[23] and word embeddings to capture semantic properties of words.  \n\nIntermediate tasks (e.g., part-of-speech tagging and dependency parsing) are not needed anymore. \n\nNeural machine translation, based on then-newly invented sequence-to-sequence transformations, made obsolete the intermediate steps, such as word alignment, previously necessary for statistical machine translation.\n\nThe following is a list of some of the most commonly researched tasks in natural language processing. Some of these tasks have direct real-world applications, while others more commonly serve as subtasks that are used to aid in solving larger tasks.\n\nThough natural language processing tasks are closely intertwined, they can be subdivided into categories for convenience. A coarse division is given below.\n\nBased on long-standing trends in the field, it is possible to extrapolate future directions of NLP. As of 2020, three trends among the topics of the long-standing series of CoNLL Shared Tasks can be observed:[46]\n\nMost higher-level NLP applications involve aspects that emulate intelligent behaviour and apparent comprehension of natural language. More broadly speaking, the technical operationalization of increasingly advanced aspects of cognitive behaviour represents one of the developmental trajectories of NLP (see trends among CoNLL shared tasks above).\n\nCognition refers to \"the mental action or process of acquiring knowledge and understanding through thought, experience, and the senses.\"[47] Cognitive science is the interdisciplinary, scientific study of the mind and its processes.[48] Cognitive linguistics is an interdisciplinary branch of linguistics, combining knowledge and research from both psychology and linguistics.[49] Especially during the age of symbolic NLP, the area of computational linguistics maintained strong ties with cognitive studies.\n\nAs an example, George Lakoff offers a methodology to build natural language processing (NLP) algorithms through the perspective of cognitive science, along with the findings of cognitive linguistics,[50] with two defining aspects:\n\nTies with cognitive linguistics are part of the historical heritage of NLP, but they have been less frequently addressed since the statistical turn during the 1990s. Nevertheless, approaches to develop cognitive models towards technically operationalizable frameworks have been pursued in the context of various frameworks, e.g., of cognitive grammar,[53] functional grammar,[54] construction grammar,[55] computational psycholinguistics and cognitive neuroscience (e.g., ACT-R), however, with limited uptake in mainstream NLP (as measured by presence on major conferences[56] of the ACL). More recently, ideas of cognitive NLP have been revived as an approach to achieve explainability, e.g., under the notion of \"cognitive AI\".[57] Likewise, ideas of cognitive NLP are inherent to neural models multimodal NLP (although rarely made explicit)[58] and developments in artificial intelligence, specifically tools and technologies using large language model approaches[59] and new directions in artificial general intelligence based on the free energy principle[60] by British neuroscientist and theoretician at University College London Karl J. Friston.\n\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"docs=[]\nfor text in texts:\n    docs.append(text.get_text())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T04:04:42.585124Z","iopub.execute_input":"2025-03-12T04:04:42.585427Z","iopub.status.idle":"2025-03-12T04:04:42.590082Z","shell.execute_reply.started":"2025-03-12T04:04:42.585401Z","shell.execute_reply":"2025-03-12T04:04:42.589060Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"len(docs)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T04:04:42.591217Z","iopub.execute_input":"2025-03-12T04:04:42.591552Z","iopub.status.idle":"2025-03-12T04:04:42.609345Z","shell.execute_reply.started":"2025-03-12T04:04:42.591527Z","shell.execute_reply":"2025-03-12T04:04:42.608290Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"20"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"def getUniqueWords(allWords) :\n    uniqueWords = [] \n    for i in allWords:\n        if not i in uniqueWords:\n            uniqueWords.append(i)\n    return uniqueWords\n\nunique=getUniqueWords(docs)\nunique","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T04:04:42.611917Z","iopub.execute_input":"2025-03-12T04:04:42.612252Z","iopub.status.idle":"2025-03-12T04:04:42.633291Z","shell.execute_reply.started":"2025-03-12T04:04:42.612228Z","shell.execute_reply":"2025-03-12T04:04:42.632285Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"['Natural language processing (NLP) is a subfield of computer science and especially artificial intelligence. It is primarily concerned with providing computers with the ability to process data encoded in natural language and is thus closely related to information retrieval, knowledge representation and computational linguistics, a subfield of linguistics.\\n',\n 'Major tasks in natural language processing are speech recognition, text classification, natural-language understanding, and natural-language generation.\\n',\n 'Natural language processing has its roots in the 1950s.[1] Already in 1950, Alan Turing published an article titled \"Computing Machinery and Intelligence\" which proposed what is now called the Turing test as a criterion of intelligence, though at the time that was not articulated as a problem separate from artificial intelligence. The proposed test includes a task that involves the automated interpretation and generation of natural language.\\n',\n \"The premise of symbolic NLP is well-summarized by John Searle's Chinese room experiment: Given a collection of rules (e.g., a Chinese phrasebook, with questions and matching answers), the computer emulates natural language understanding (or other NLP tasks) by applying those rules to the data it confronts.\\n\",\n \"Up until the 1980s, most natural language processing systems were based on complex sets of hand-written rules.  Starting in the late 1980s, however, there was a revolution in natural language processing with the introduction of machine learning algorithms for language processing.  This was due to both the steady increase in computational power (see Moore's law) and the gradual lessening of the dominance of Chomskyan theories of linguistics (e.g. transformational grammar), whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing.[8]\\n\",\n 'Symbolic approach, i.e., the hand-coding of a set of rules for manipulating symbols, coupled with a dictionary lookup, was historically the first approach used both by AI in general and by NLP in particular:[18][19] such as by writing grammars or devising heuristic rules for stemming.\\n',\n 'Machine learning approaches, which include both statistical and neural networks, on the other hand, have many advantages over the symbolic approach: \\n',\n 'Rule-based systems are commonly used:\\n',\n 'In the late 1980s and mid-1990s, the statistical approach ended a period of AI winter, which was caused by the inefficiencies of the rule-based approaches.[20][21]\\n',\n 'The earliest decision trees, producing systems of hard if–then rules, were still very similar to the old rule-based approaches.\\nOnly the introduction of hidden Markov models, applied to part-of-speech tagging, announced the end of the old rule-based approach.\\n',\n 'A major drawback of statistical methods is that they require elaborate feature engineering. Since 2015,[22] the statistical approach has been replaced by the neural networks approach, using semantic networks[23] and word embeddings to capture semantic properties of words.  \\n',\n 'Intermediate tasks (e.g., part-of-speech tagging and dependency parsing) are not needed anymore. \\n',\n 'Neural machine translation, based on then-newly invented sequence-to-sequence transformations, made obsolete the intermediate steps, such as word alignment, previously necessary for statistical machine translation.\\n',\n 'The following is a list of some of the most commonly researched tasks in natural language processing. Some of these tasks have direct real-world applications, while others more commonly serve as subtasks that are used to aid in solving larger tasks.\\n',\n 'Though natural language processing tasks are closely intertwined, they can be subdivided into categories for convenience. A coarse division is given below.\\n',\n 'Based on long-standing trends in the field, it is possible to extrapolate future directions of NLP. As of 2020, three trends among the topics of the long-standing series of CoNLL Shared Tasks can be observed:[46]\\n',\n 'Most higher-level NLP applications involve aspects that emulate intelligent behaviour and apparent comprehension of natural language. More broadly speaking, the technical operationalization of increasingly advanced aspects of cognitive behaviour represents one of the developmental trajectories of NLP (see trends among CoNLL shared tasks above).\\n',\n 'Cognition refers to \"the mental action or process of acquiring knowledge and understanding through thought, experience, and the senses.\"[47] Cognitive science is the interdisciplinary, scientific study of the mind and its processes.[48] Cognitive linguistics is an interdisciplinary branch of linguistics, combining knowledge and research from both psychology and linguistics.[49] Especially during the age of symbolic NLP, the area of computational linguistics maintained strong ties with cognitive studies.\\n',\n 'As an example, George Lakoff offers a methodology to build natural language processing (NLP) algorithms through the perspective of cognitive science, along with the findings of cognitive linguistics,[50] with two defining aspects:\\n',\n 'Ties with cognitive linguistics are part of the historical heritage of NLP, but they have been less frequently addressed since the statistical turn during the 1990s. Nevertheless, approaches to develop cognitive models towards technically operationalizable frameworks have been pursued in the context of various frameworks, e.g., of cognitive grammar,[53] functional grammar,[54] construction grammar,[55] computational psycholinguistics and cognitive neuroscience (e.g., ACT-R), however, with limited uptake in mainstream NLP (as measured by presence on major conferences[56] of the ACL). More recently, ideas of cognitive NLP have been revived as an approach to achieve explainability, e.g., under the notion of \"cognitive AI\".[57] Likewise, ideas of cognitive NLP are inherent to neural models multimodal NLP (although rarely made explicit)[58] and developments in artificial intelligence, specifically tools and technologies using large language model approaches[59] and new directions in artificial general intelligence based on the free energy principle[60] by British neuroscientist and theoretician at University College London Karl J. Friston.\\n']"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"import re\nclean=[]\nfor s in unique:\n    cleaned = re.sub(r'[^a-zA-Z\\s]', '', s)\n    cleaned = cleaned.replace('\\n', '') \n    print(cleaned)\n    clean.append(cleaned)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T04:04:42.634900Z","iopub.execute_input":"2025-03-12T04:04:42.635333Z","iopub.status.idle":"2025-03-12T04:04:42.653909Z","shell.execute_reply.started":"2025-03-12T04:04:42.635294Z","shell.execute_reply":"2025-03-12T04:04:42.653069Z"}},"outputs":[{"name":"stdout","text":"Natural language processing NLP is a subfield of computer science and especially artificial intelligence It is primarily concerned with providing computers with the ability to process data encoded in natural language and is thus closely related to information retrieval knowledge representation and computational linguistics a subfield of linguistics\nMajor tasks in natural language processing are speech recognition text classification naturallanguage understanding and naturallanguage generation\nNatural language processing has its roots in the s Already in  Alan Turing published an article titled Computing Machinery and Intelligence which proposed what is now called the Turing test as a criterion of intelligence though at the time that was not articulated as a problem separate from artificial intelligence The proposed test includes a task that involves the automated interpretation and generation of natural language\nThe premise of symbolic NLP is wellsummarized by John Searles Chinese room experiment Given a collection of rules eg a Chinese phrasebook with questions and matching answers the computer emulates natural language understanding or other NLP tasks by applying those rules to the data it confronts\nUp until the s most natural language processing systems were based on complex sets of handwritten rules  Starting in the late s however there was a revolution in natural language processing with the introduction of machine learning algorithms for language processing  This was due to both the steady increase in computational power see Moores law and the gradual lessening of the dominance of Chomskyan theories of linguistics eg transformational grammar whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machinelearning approach to language processing\nSymbolic approach ie the handcoding of a set of rules for manipulating symbols coupled with a dictionary lookup was historically the first approach used both by AI in general and by NLP in particular such as by writing grammars or devising heuristic rules for stemming\nMachine learning approaches which include both statistical and neural networks on the other hand have many advantages over the symbolic approach \nRulebased systems are commonly used\nIn the late s and mids the statistical approach ended a period of AI winter which was caused by the inefficiencies of the rulebased approaches\nThe earliest decision trees producing systems of hard ifthen rules were still very similar to the old rulebased approachesOnly the introduction of hidden Markov models applied to partofspeech tagging announced the end of the old rulebased approach\nA major drawback of statistical methods is that they require elaborate feature engineering Since  the statistical approach has been replaced by the neural networks approach using semantic networks and word embeddings to capture semantic properties of words  \nIntermediate tasks eg partofspeech tagging and dependency parsing are not needed anymore \nNeural machine translation based on thennewly invented sequencetosequence transformations made obsolete the intermediate steps such as word alignment previously necessary for statistical machine translation\nThe following is a list of some of the most commonly researched tasks in natural language processing Some of these tasks have direct realworld applications while others more commonly serve as subtasks that are used to aid in solving larger tasks\nThough natural language processing tasks are closely intertwined they can be subdivided into categories for convenience A coarse division is given below\nBased on longstanding trends in the field it is possible to extrapolate future directions of NLP As of  three trends among the topics of the longstanding series of CoNLL Shared Tasks can be observed\nMost higherlevel NLP applications involve aspects that emulate intelligent behaviour and apparent comprehension of natural language More broadly speaking the technical operationalization of increasingly advanced aspects of cognitive behaviour represents one of the developmental trajectories of NLP see trends among CoNLL shared tasks above\nCognition refers to the mental action or process of acquiring knowledge and understanding through thought experience and the senses Cognitive science is the interdisciplinary scientific study of the mind and its processes Cognitive linguistics is an interdisciplinary branch of linguistics combining knowledge and research from both psychology and linguistics Especially during the age of symbolic NLP the area of computational linguistics maintained strong ties with cognitive studies\nAs an example George Lakoff offers a methodology to build natural language processing NLP algorithms through the perspective of cognitive science along with the findings of cognitive linguistics with two defining aspects\nTies with cognitive linguistics are part of the historical heritage of NLP but they have been less frequently addressed since the statistical turn during the s Nevertheless approaches to develop cognitive models towards technically operationalizable frameworks have been pursued in the context of various frameworks eg of cognitive grammar functional grammar construction grammar computational psycholinguistics and cognitive neuroscience eg ACTR however with limited uptake in mainstream NLP as measured by presence on major conferences of the ACL More recently ideas of cognitive NLP have been revived as an approach to achieve explainability eg under the notion of cognitive AI Likewise ideas of cognitive NLP are inherent to neural models multimodal NLP although rarely made explicit and developments in artificial intelligence specifically tools and technologies using large language model approaches and new directions in artificial general intelligence based on the free energy principle by British neuroscientist and theoretician at University College London Karl J Friston\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"#Stemming\n\nfrom nltk.stem import PorterStemmer\nfrom nltk.tokenize import word_tokenize\nfrom functools import reduce\n\nps = PorterStemmer()\n\nfor sentence in clean:\n    words = word_tokenize(sentence)\n    stemmed_sentence = reduce(lambda x, y: x + \" \" + ps.stem(y), words, \"\")\n    print(stemmed_sentence)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T04:04:42.655114Z","iopub.execute_input":"2025-03-12T04:04:42.655463Z","iopub.status.idle":"2025-03-12T04:04:44.055582Z","shell.execute_reply.started":"2025-03-12T04:04:42.655414Z","shell.execute_reply":"2025-03-12T04:04:44.054566Z"},"scrolled":true},"outputs":[{"name":"stdout","text":" natur languag process nlp is a subfield of comput scienc and especi artifici intellig It is primarili concern with provid comput with the abil to process data encod in natur languag and is thu close relat to inform retriev knowledg represent and comput linguist a subfield of linguist\n major task in natur languag process are speech recognit text classif naturallanguag understand and naturallanguag gener\n natur languag process ha it root in the s alreadi in alan ture publish an articl titl comput machineri and intellig which propos what is now call the ture test as a criterion of intellig though at the time that wa not articul as a problem separ from artifici intellig the propos test includ a task that involv the autom interpret and gener of natur languag\n the premis of symbol nlp is wellsummar by john searl chines room experi given a collect of rule eg a chines phrasebook with question and match answer the comput emul natur languag understand or other nlp task by appli those rule to the data it confront\n Up until the s most natur languag process system were base on complex set of handwritten rule start in the late s howev there wa a revolut in natur languag process with the introduct of machin learn algorithm for languag process thi wa due to both the steadi increas in comput power see moor law and the gradual lessen of the domin of chomskyan theori of linguist eg transform grammar whose theoret underpin discourag the sort of corpu linguist that underli the machinelearn approach to languag process\n symbol approach ie the handcod of a set of rule for manipul symbol coupl with a dictionari lookup wa histor the first approach use both by AI in gener and by nlp in particular such as by write grammar or devis heurist rule for stem\n machin learn approach which includ both statist and neural network on the other hand have mani advantag over the symbol approach\n rulebas system are commonli use\n In the late s and mid the statist approach end a period of AI winter which wa caus by the ineffici of the rulebas approach\n the earliest decis tree produc system of hard ifthen rule were still veri similar to the old rulebas approachesonli the introduct of hidden markov model appli to partofspeech tag announc the end of the old rulebas approach\n A major drawback of statist method is that they requir elabor featur engin sinc the statist approach ha been replac by the neural network approach use semant network and word embed to captur semant properti of word\n intermedi task eg partofspeech tag and depend pars are not need anymor\n neural machin translat base on thennewli invent sequencetosequ transform made obsolet the intermedi step such as word align previous necessari for statist machin translat\n the follow is a list of some of the most commonli research task in natur languag process some of these task have direct realworld applic while other more commonli serv as subtask that are use to aid in solv larger task\n though natur languag process task are close intertwin they can be subdivid into categori for conveni A coars divis is given below\n base on longstand trend in the field it is possibl to extrapol futur direct of nlp As of three trend among the topic of the longstand seri of conll share task can be observ\n most higherlevel nlp applic involv aspect that emul intellig behaviour and appar comprehens of natur languag more broadli speak the technic operation of increasingli advanc aspect of cognit behaviour repres one of the development trajectori of nlp see trend among conll share task abov\n cognit refer to the mental action or process of acquir knowledg and understand through thought experi and the sens cognit scienc is the interdisciplinari scientif studi of the mind and it process cognit linguist is an interdisciplinari branch of linguist combin knowledg and research from both psycholog and linguist especi dure the age of symbol nlp the area of comput linguist maintain strong tie with cognit studi\n As an exampl georg lakoff offer a methodolog to build natur languag process nlp algorithm through the perspect of cognit scienc along with the find of cognit linguist with two defin aspect\n tie with cognit linguist are part of the histor heritag of nlp but they have been less frequent address sinc the statist turn dure the s nevertheless approach to develop cognit model toward technic operationaliz framework have been pursu in the context of variou framework eg of cognit grammar function grammar construct grammar comput psycholinguist and cognit neurosci eg actr howev with limit uptak in mainstream nlp as measur by presenc on major confer of the acl more recent idea of cognit nlp have been reviv as an approach to achiev explain eg under the notion of cognit AI likewis idea of cognit nlp are inher to neural model multimod nlp although rare made explicit and develop in artifici intellig specif tool and technolog use larg languag model approach and new direct in artifici gener intellig base on the free energi principl by british neuroscientist and theoretician at univers colleg london karl J friston\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"#lemmitzation\n\nimport spacy\nnlp = spacy.load('en_core_web_sm')\nfor text in clean:\n    doc = nlp(text)\n    lemmatized_tokens = [token.lemma_ for token in doc]\n    lemmatized_text = ' '.join(lemmatized_tokens)\n    print(lemmatized_text)\n    print(\"\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T04:04:44.056808Z","iopub.execute_input":"2025-03-12T04:04:44.057479Z","iopub.status.idle":"2025-03-12T04:04:51.669861Z","shell.execute_reply.started":"2025-03-12T04:04:44.057436Z","shell.execute_reply":"2025-03-12T04:04:51.668922Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"natural language processing NLP be a subfield of computer science and especially artificial intelligence it be primarily concern with provide computer with the ability to process datum encode in natural language and be thus closely relate to information retrieval knowledge representation and computational linguistic a subfield of linguistic\n\n\nmajor task in natural language processing be speech recognition text classification naturallanguage understanding and naturallanguage generation\n\n\nnatural language processing have its root in the s already in   Alan Turing publish an article title Computing Machinery and Intelligence which propose what be now call the ture test as a criterion of intelligence though at the time that be not articulate as a problem separate from artificial intelligence the propose test include a task that involve the automate interpretation and generation of natural language\n\n\nthe premise of symbolic NLP be wellsummarize by John Searles chinese room experiment give a collection of rule eg a chinese phrasebook with question and matching answer the computer emulate natural language understanding or other NLP task by apply those rule to the datum it confront\n\n\nup until the s most natural language processing system be base on complex set of handwritten rule   start in the late s however there be a revolution in natural language processing with the introduction of machine learn algorithm for language processing   this be due to both the steady increase in computational power see Moores law and the gradual lessening of the dominance of chomskyan theory of linguistic eg transformational grammar whose theoretical underpinning discourage the sort of corpus linguistic that underlie the machinelearne approach to language processing\n\n\nSymbolic approach ie the handcoding of a set of rule for manipulate symbol couple with a dictionary lookup be historically the first approach use both by AI in general and by NLP in particular such as by write grammar or devise heuristic rule for stem\n\n\nmachine learn approach which include both statistical and neural network on the other hand have many advantage over the symbolic approach\n\n\nrulebase system be commonly use\n\n\nin the late s and mid the statistical approach end a period of AI winter which be cause by the inefficiency of the rulebase approach\n\n\nthe early decision tree produce system of hard ifthen rule be still very similar to the old rulebase approachesonly the introduction of hidden Markov model apply to partofspeech tagging announce the end of the old rulebased approach\n\n\na major drawback of statistical method be that they require elaborate feature engineering since   the statistical approach have be replace by the neural network approach use semantic network and word embedding to capture semantic property of word  \n\n\nintermediate task eg partofspeech tagging and dependency parsing be not need anymore\n\n\nneural machine translation base on thennewly invent sequencetosequence transformation make obsolete the intermediate step such as word alignment previously necessary for statistical machine translation\n\n\nthe following be a list of some of the most commonly research task in natural language process some of these task have direct realworld application while other more commonly serve as subtask that be use to aid in solve large task\n\n\nthough natural language processing task be closely intertwine they can be subdivide into category for convenience a coarse division be give below\n\n\nbase on longstanding trend in the field it be possible to extrapolate future direction of NLP as of   three trend among the topic of the longstanding series of CoNLL Shared Tasks can be observe\n\n\nMost higherlevel nlp application involve aspect that emulate intelligent behaviour and apparent comprehension of natural language more broadly speak the technical operationalization of increasingly advanced aspect of cognitive behaviour represent one of the developmental trajectory of NLP see trend among conll share task above\n\n\ncognition refer to the mental action or process of acquire knowledge and understanding through think experience and the sense cognitive science be the interdisciplinary scientific study of the mind and its process cognitive linguistic be an interdisciplinary branch of linguistic combine knowledge and research from both psychology and linguistic especially during the age of symbolic NLP the area of computational linguistic maintain strong tie with cognitive study\n\n\nas an example George Lakoff offer a methodology to build natural language process NLP algorithm through the perspective of cognitive science along with the finding of cognitive linguistic with two define aspect\n\n\ntie with cognitive linguistic be part of the historical heritage of NLP but they have be less frequently address since the statistical turn during the s nevertheless approach to develop cognitive model towards technically operationalizable framework have be pursue in the context of various framework eg of cognitive grammar functional grammar construction grammar computational psycholinguistic and cognitive neuroscience eg ACTR however with limited uptake in mainstream NLP as measure by presence on major conference of the ACL more recently idea of cognitive NLP have be revive as an approach to achieve explainability eg under the notion of cognitive AI Likewise idea of cognitive NLP be inherent to neural model multimodal NLP although rarely make explicit and development in artificial intelligence specifically tool and technology use large language model approach and new direction in artificial general intelligence base on the free energy principle by british neuroscientist and theoretician at University College London Karl J Friston\n\n\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"#tokenization\n\nimport re\ntoken=[]\nfor s in clean:\n    res = [part if part.strip() else \" \" for part in s.split(\" \")]\n    token.append(res)\ntoken[1][:5]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T04:04:51.671050Z","iopub.execute_input":"2025-03-12T04:04:51.671765Z","iopub.status.idle":"2025-03-12T04:04:51.679429Z","shell.execute_reply.started":"2025-03-12T04:04:51.671723Z","shell.execute_reply":"2025-03-12T04:04:51.678111Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"['Major', 'tasks', 'in', 'natural', 'language']"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"words1=[]\nfor sentence in docs:\n    words1.extend(sentence.split())\nlen(words1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T04:04:51.680704Z","iopub.execute_input":"2025-03-12T04:04:51.681197Z","iopub.status.idle":"2025-03-12T04:04:51.710976Z","shell.execute_reply.started":"2025-03-12T04:04:51.681160Z","shell.execute_reply":"2025-03-12T04:04:51.710072Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"867"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"import re\n\n\nunique_words = set()\n\n\nfor sentence in clean:\n    words = sentence.split()  \n    unique_words.update(words)\n\n\nunique_words_list = list(unique_words)\nprint(unique_words_list)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T04:04:51.711964Z","iopub.execute_input":"2025-03-12T04:04:51.712238Z","iopub.status.idle":"2025-03-12T04:04:51.733342Z","shell.execute_reply.started":"2025-03-12T04:04:51.712217Z","shell.execute_reply":"2025-03-12T04:04:51.732208Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"['similar', 'notion', 'below', 'steady', 'others', 'dependency', 'combining', 'encoded', 'related', 'tasks', 'translation', 'Neural', 'recognition', 'Markov', 'Alan', 'subdivided', 'into', 'on', 'sort', 'emulates', 'refers', 'partofspeech', 'heuristic', 'directions', 'necessary', 'example', 'along', 'closely', 'primarily', 'corpus', 'information', 'serve', 'construction', 'context', 'uptake', 'symbols', 'from', 'one', 'retrieval', 'George', 'ACL', 'general', 'grammars', 'machine', 'made', 'period', 'extrapolate', 'data', 'Karl', 'ie', 'eg', 'grammar', 'Given', 'matching', 'Up', 'machinelearning', 'increase', 'In', 'rulebased', 'anymore', 'power', 'its', 'thus', 'studies', 'recently', 'they', 'senses', 'cognitive', 'comprehension', 'energy', 'drawback', 'hand', 'shared', 'there', 'findings', 'longstanding', 'categories', 'increasingly', 'addressed', 'semantic', 'large', 'developmental', 'ability', 'words', 'using', 'criterion', 'law', 'Nevertheless', 'branch', 'applications', 'while', 'psycholinguistics', 'see', 'approachesOnly', 'interdisciplinary', 'problem', 'models', 'technical', 'can', 'however', 'Chomskyan', 'theories', 'transformational', 'since', 'future', 'tools', 'an', 'series', 'producing', 'at', 'late', 'ideas', 'area', 'some', 'the', 'subfield', 'build', 'Turing', 'topics', 'given', 'artificial', 'The', 'learning', 'not', 'particular', 'coupled', 'a', 'includes', 'until', 'principle', 'classification', 'thennewly', 'involve', 'ties', 'earliest', 'parsing', 'inefficiencies', 'tagging', 'interpretation', 'Especially', 'three', 'action', 'CoNLL', 'less', 'Based', 'British', 'Intermediate', 'which', 'scientific', 'generation', 'manipulating', 'This', 'speaking', 'steps', 'represents', 'developments', 'rarely', 'theoretical', 'mainstream', 'neural', 'called', 'AI', 'possible', 'include', 'hard', 'ended', 'are', 'providing', 'among', 'symbolic', 'methods', 'but', 'been', 'turn', 'wellsummarized', 'A', 'Machine', 'researched', 'Symbolic', 'room', 'is', 'ACTR', 'though', 'needed', 'presence', 'over', 'aid', 'various', 'subtasks', 'Already', 'confronts', 'defining', 'Though', 'intelligence', 'University', 'engineering', 'John', 'advanced', 'mids', 'computational', 'aspects', 's', 'inherent', 'Searles', 'task', 'Moores', 'used', 'convenience', 'transformations', 'elaborate', 'larger', 'articulated', 'end', 'sets', 'solving', 'maintained', 'limited', 'questions', 'technologies', 'heritage', 'by', 'direct', 'higherlevel', 'discouraged', 'these', 'with', 'collection', 'operationalization', 'computer', 'announced', 'still', 'research', 'whose', 'functional', 'offers', 'More', 'approaches', 'process', 'applying', 'both', 'in', 'or', 'coarse', 'through', 'operationalizable', 'thought', 'Friston', 'neuroscience', 'alignment', 'systems', 'obsolete', 'apparent', 'automated', 'due', 'titled', 'that', 'approach', 'College', 'realworld', 'explicit', 'answers', 'those', 'As', 'Natural', 'for', 'towards', 'concerned', 'historical', 'NLP', 'published', 'proposed', 'Intelligence', 'observed', 'algorithms', 'invented', 'measured', 'understanding', 'trends', 'free', 'old', 'part', 'applied', 'pursued', 'linguistics', 'lookup', 'explainability', 'strong', 'psychology', 'Cognitive', 'feature', 'revolution', 'caused', 'trees', 'natural', 'age', 'under', 'develop', 'list', 'mind', 'properties', 'word', 'science', 'such', 'be', 'especially', 'processes', 'lessening', 'Tasks', 'time', 'commonly', 'replaced', 'involves', 'ifthen', 'underlies', 'other', 'handcoding', 'technically', 'complex', 'very', 'dictionary', 'text', 'what', 'it', 'statistical', 'behaviour', 'study', 'premise', 'J', 'dominance', 'advantages', 'hidden', 'has', 'article', 'most', 'stemming', 'rules', 'intermediate', 'revived', 'new', 'Lakoff', 'more', 'Ties', 'have', 'perspective', 'knowledge', 'introduction', 'decision', 'many', 'intertwined', 'neuroscientist', 'previously', 'Since', 'gradual', 'were', 'following', 'two', 'theoretician', 'intelligent', 'was', 'and', 'Shared', 'frameworks', 'underpinnings', 'networks', 'Likewise', 'Rulebased', 'Starting', 'first', 'although', 'Chinese', 'test', 'historically', 'sequencetosequence', 'model', 'conferences', 'experiment', 'broadly', 'phrasebook', 'writing', 'Some', 'Most', 'as', 'processing', 'multimodal', 'now', 'specifically', 'division', 'London', 'methodology', 'language', 'Cognition', 'to', 'It', 'representation', 'major', 'winter', 'set', 'experience', 'Major', 'Computing', 'field', 'achieve', 'above', 'mental', 'based', 'of', 'require', 'capture', 'speech', 'computers', 'naturallanguage', 'Machinery', 'emulate', 'separate', 'acquiring', 'embeddings', 'roots', 'during', 'handwritten', 'devising', 'trajectories', 'frequently']\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"#vocubalary\nlen(unique_words_list)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T04:04:51.734515Z","iopub.execute_input":"2025-03-12T04:04:51.734898Z","iopub.status.idle":"2025-03-12T04:04:51.753636Z","shell.execute_reply.started":"2025-03-12T04:04:51.734863Z","shell.execute_reply":"2025-03-12T04:04:51.752573Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"422"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"print(f\"No of Docs: {len(docs)}\")\nprint(f\"No of words: {len(words1)}\")\nprint(f\"No of Vocubalary: {len(unique_words_list)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T04:04:51.754836Z","iopub.execute_input":"2025-03-12T04:04:51.755243Z","iopub.status.idle":"2025-03-12T04:04:51.773332Z","shell.execute_reply.started":"2025-03-12T04:04:51.755209Z","shell.execute_reply":"2025-03-12T04:04:51.772218Z"}},"outputs":[{"name":"stdout","text":"No of Docs: 20\nNo of words: 867\nNo of Vocubalary: 422\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"#corpus\nclean","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T04:04:51.774561Z","iopub.execute_input":"2025-03-12T04:04:51.774888Z","iopub.status.idle":"2025-03-12T04:04:51.792106Z","shell.execute_reply.started":"2025-03-12T04:04:51.774864Z","shell.execute_reply":"2025-03-12T04:04:51.790890Z"},"scrolled":true},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"['Natural language processing NLP is a subfield of computer science and especially artificial intelligence It is primarily concerned with providing computers with the ability to process data encoded in natural language and is thus closely related to information retrieval knowledge representation and computational linguistics a subfield of linguistics',\n 'Major tasks in natural language processing are speech recognition text classification naturallanguage understanding and naturallanguage generation',\n 'Natural language processing has its roots in the s Already in  Alan Turing published an article titled Computing Machinery and Intelligence which proposed what is now called the Turing test as a criterion of intelligence though at the time that was not articulated as a problem separate from artificial intelligence The proposed test includes a task that involves the automated interpretation and generation of natural language',\n 'The premise of symbolic NLP is wellsummarized by John Searles Chinese room experiment Given a collection of rules eg a Chinese phrasebook with questions and matching answers the computer emulates natural language understanding or other NLP tasks by applying those rules to the data it confronts',\n 'Up until the s most natural language processing systems were based on complex sets of handwritten rules  Starting in the late s however there was a revolution in natural language processing with the introduction of machine learning algorithms for language processing  This was due to both the steady increase in computational power see Moores law and the gradual lessening of the dominance of Chomskyan theories of linguistics eg transformational grammar whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machinelearning approach to language processing',\n 'Symbolic approach ie the handcoding of a set of rules for manipulating symbols coupled with a dictionary lookup was historically the first approach used both by AI in general and by NLP in particular such as by writing grammars or devising heuristic rules for stemming',\n 'Machine learning approaches which include both statistical and neural networks on the other hand have many advantages over the symbolic approach ',\n 'Rulebased systems are commonly used',\n 'In the late s and mids the statistical approach ended a period of AI winter which was caused by the inefficiencies of the rulebased approaches',\n 'The earliest decision trees producing systems of hard ifthen rules were still very similar to the old rulebased approachesOnly the introduction of hidden Markov models applied to partofspeech tagging announced the end of the old rulebased approach',\n 'A major drawback of statistical methods is that they require elaborate feature engineering Since  the statistical approach has been replaced by the neural networks approach using semantic networks and word embeddings to capture semantic properties of words  ',\n 'Intermediate tasks eg partofspeech tagging and dependency parsing are not needed anymore ',\n 'Neural machine translation based on thennewly invented sequencetosequence transformations made obsolete the intermediate steps such as word alignment previously necessary for statistical machine translation',\n 'The following is a list of some of the most commonly researched tasks in natural language processing Some of these tasks have direct realworld applications while others more commonly serve as subtasks that are used to aid in solving larger tasks',\n 'Though natural language processing tasks are closely intertwined they can be subdivided into categories for convenience A coarse division is given below',\n 'Based on longstanding trends in the field it is possible to extrapolate future directions of NLP As of  three trends among the topics of the longstanding series of CoNLL Shared Tasks can be observed',\n 'Most higherlevel NLP applications involve aspects that emulate intelligent behaviour and apparent comprehension of natural language More broadly speaking the technical operationalization of increasingly advanced aspects of cognitive behaviour represents one of the developmental trajectories of NLP see trends among CoNLL shared tasks above',\n 'Cognition refers to the mental action or process of acquiring knowledge and understanding through thought experience and the senses Cognitive science is the interdisciplinary scientific study of the mind and its processes Cognitive linguistics is an interdisciplinary branch of linguistics combining knowledge and research from both psychology and linguistics Especially during the age of symbolic NLP the area of computational linguistics maintained strong ties with cognitive studies',\n 'As an example George Lakoff offers a methodology to build natural language processing NLP algorithms through the perspective of cognitive science along with the findings of cognitive linguistics with two defining aspects',\n 'Ties with cognitive linguistics are part of the historical heritage of NLP but they have been less frequently addressed since the statistical turn during the s Nevertheless approaches to develop cognitive models towards technically operationalizable frameworks have been pursued in the context of various frameworks eg of cognitive grammar functional grammar construction grammar computational psycholinguistics and cognitive neuroscience eg ACTR however with limited uptake in mainstream NLP as measured by presence on major conferences of the ACL More recently ideas of cognitive NLP have been revived as an approach to achieve explainability eg under the notion of cognitive AI Likewise ideas of cognitive NLP are inherent to neural models multimodal NLP although rarely made explicit and developments in artificial intelligence specifically tools and technologies using large language model approaches and new directions in artificial general intelligence based on the free energy principle by British neuroscientist and theoretician at University College London Karl J Friston']"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"#remove space\nnospace=\"\"\nfor s in clean:\n    s = s.replace(\" \", \"\")\n    nospace=nospace+s","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T04:04:51.793269Z","iopub.execute_input":"2025-03-12T04:04:51.793644Z","iopub.status.idle":"2025-03-12T04:04:51.811082Z","shell.execute_reply.started":"2025-03-12T04:04:51.793608Z","shell.execute_reply":"2025-03-12T04:04:51.809899Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"#Byte pair Encoding\n\nimport re\nfrom collections import defaultdict\n\ndef get_stats(vocab):\n    pairs = defaultdict(int)\n    for word, freq in vocab.items():\n        symbols = word.split()\n        for i in range(len(symbols)-1):\n            pairs[symbols[i],symbols[i+1]] += freq\n    return pairs\n\ndef merge_vocab(pair, v_in):\n    v_out = {}\n    bigram = re.escape(' '.join(pair))\n    p = re.compile(r'(?<!\\S)' + bigram + r'(?!\\S)')\n    for word in v_in:\n        w_out = p.sub(''.join(pair), word)\n        v_out[w_out] = v_in[word]\n    return v_out\n\ndef get_vocab(data):\n    vocab = defaultdict(int)\n    for line in data:\n        for word in line.split():\n            vocab[' '.join(list(word)) + ''] += 1\n    return vocab\n\ndef byte_pair_encoding(data, n):\n    vocab = get_vocab(data)\n    for i in range(n):\n        pairs = get_stats(vocab)\n        best = max(pairs, key=pairs.get)\n        vocab = merge_vocab(best, vocab)\n    return vocab\n\n# Example usage:\ntext=\"\"\nfor string in clean:\n    text+=string\ncorpus = text\ndata = corpus.split('.')\n\nn = 1000\nbpe_pairs = byte_pair_encoding(data, n)\nbpe_pairs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T04:06:20.622072Z","iopub.execute_input":"2025-03-12T04:06:20.622480Z","iopub.status.idle":"2025-03-12T04:06:21.527694Z","shell.execute_reply.started":"2025-03-12T04:06:20.622454Z","shell.execute_reply":"2025-03-12T04:06:21.526543Z"},"scrolled":true},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"{'Natural': 1,\n 'language': 14,\n 'processing': 9,\n 'NLP': 14,\n 'is': 11,\n 'a': 13,\n 'subfield': 2,\n 'of': 48,\n 'computer': 2,\n 'science': 3,\n 'and': 24,\n 'especially': 1,\n 'artificial': 4,\n 'intelligence': 5,\n 'It': 1,\n 'primarily': 1,\n 'concerned': 1,\n 'with': 10,\n 'providing': 1,\n 'computers': 1,\n 'the': 51,\n 'ability': 1,\n 'to': 15,\n 'process': 2,\n 'data': 2,\n 'encoded': 1,\n 'in': 16,\n 'natural': 10,\n 'thus': 1,\n 'closely': 2,\n 'related': 1,\n 'information': 1,\n 'retrieval': 1,\n 'knowledge': 3,\n 'representation': 1,\n 'computational': 4,\n 'linguistics': 9,\n 'linguisticsMajor': 1,\n 'tasks': 7,\n 'are': 7,\n 'speech': 1,\n 'recognition': 1,\n 'text': 1,\n 'classification': 1,\n 'naturallanguage': 2,\n 'understanding': 3,\n 'generationNatural': 1,\n 'has': 2,\n 'its': 2,\n 'roots': 1,\n 's': 5,\n 'Already': 1,\n 'Alan': 1,\n 'Turing': 2,\n 'published': 1,\n 'an': 4,\n 'article': 1,\n 'titled': 1,\n 'Computing': 1,\n 'Machinery': 1,\n 'Intelligence': 1,\n 'which': 3,\n 'proposed': 2,\n 'what': 1,\n 'now': 1,\n 'called': 1,\n 'test': 2,\n 'as': 7,\n 'criterion': 1,\n 'though': 1,\n 'at': 2,\n 'time': 1,\n 'that': 6,\n 'was': 5,\n 'not': 2,\n 'articulated': 1,\n 'problem': 1,\n 'separate': 1,\n 'from': 2,\n 'The': 1,\n 'includes': 1,\n 'task': 1,\n 'involves': 1,\n 'automated': 1,\n 'interpretation': 1,\n 'generation': 1,\n 'languageThe': 1,\n 'premise': 1,\n 'symbolic': 3,\n 'wellsummarized': 1,\n 'by': 9,\n 'John': 1,\n 'Searles': 1,\n 'Chinese': 2,\n 'room': 1,\n 'experiment': 1,\n 'Given': 1,\n 'collection': 1,\n 'rules': 6,\n 'eg': 6,\n 'phrasebook': 1,\n 'questions': 1,\n 'matching': 1,\n 'answers': 1,\n 'emulates': 1,\n 'or': 3,\n 'other': 2,\n 'applying': 1,\n 'those': 1,\n 'it': 2,\n 'confrontsUp': 1,\n 'until': 1,\n 'most': 2,\n 'systems': 3,\n 'were': 2,\n 'based': 3,\n 'on': 6,\n 'complex': 1,\n 'sets': 1,\n 'handwritten': 1,\n 'Starting': 1,\n 'late': 2,\n 'however': 2,\n 'there': 1,\n 'revolution': 1,\n 'introduction': 2,\n 'machine': 3,\n 'learning': 2,\n 'algorithms': 2,\n 'for': 5,\n 'This': 1,\n 'due': 1,\n 'both': 4,\n 'steady': 1,\n 'increase': 1,\n 'power': 1,\n 'see': 2,\n 'Moores': 1,\n 'law': 1,\n 'gradual': 1,\n 'lessening': 1,\n 'dominance': 1,\n 'Chomskyan': 1,\n 'theories': 1,\n 'transformational': 1,\n 'grammar': 4,\n 'whose': 1,\n 'theoretical': 1,\n 'underpinnings': 1,\n 'discouraged': 1,\n 'sort': 1,\n 'corpus': 1,\n 'underlies': 1,\n 'machinelearning': 1,\n 'approach': 8,\n 'processingSymbolic': 1,\n 'ie': 1,\n 'handcoding': 1,\n 'set': 1,\n 'manipulating': 1,\n 'symbols': 1,\n 'coupled': 1,\n 'dictionary': 1,\n 'lookup': 1,\n 'historically': 1,\n 'first': 1,\n 'used': 2,\n 'AI': 3,\n 'general': 2,\n 'particular': 1,\n 'such': 2,\n 'writing': 1,\n 'grammars': 1,\n 'devising': 1,\n 'heuristic': 1,\n 'stemmingMachine': 1,\n 'approaches': 3,\n 'include': 1,\n 'statistical': 6,\n 'neural': 3,\n 'networks': 3,\n 'hand': 1,\n 'have': 5,\n 'many': 1,\n 'advantages': 1,\n 'over': 1,\n 'Rulebased': 1,\n 'commonly': 3,\n 'usedIn': 1,\n 'mids': 1,\n 'ended': 1,\n 'period': 1,\n 'winter': 1,\n 'caused': 1,\n 'inefficiencies': 1,\n 'rulebased': 3,\n 'approachesThe': 1,\n 'earliest': 1,\n 'decision': 1,\n 'trees': 1,\n 'producing': 1,\n 'hard': 1,\n 'ifthen': 1,\n 'still': 1,\n 'very': 1,\n 'similar': 1,\n 'old': 2,\n 'approachesOnly': 1,\n 'hidden': 1,\n 'Markov': 1,\n 'models': 3,\n 'applied': 1,\n 'partofspeech': 2,\n 'tagging': 2,\n 'announced': 1,\n 'end': 1,\n 'approachA': 1,\n 'major': 2,\n 'drawback': 1,\n 'methods': 1,\n 'they': 3,\n 'require': 1,\n 'elaborate': 1,\n 'feature': 1,\n 'engineering': 1,\n 'Since': 1,\n 'been': 4,\n 'replaced': 1,\n 'using': 2,\n 'semantic': 2,\n 'word': 2,\n 'embeddings': 1,\n 'capture': 1,\n 'properties': 1,\n 'words': 1,\n 'Intermediate': 1,\n 'dependency': 1,\n 'parsing': 1,\n 'needed': 1,\n 'anymore': 1,\n 'Neural': 1,\n 'translation': 1,\n 'thennewly': 1,\n 'invented': 1,\n 'sequencetosequence': 1,\n 'transformations': 1,\n 'made': 2,\n 'obsolete': 1,\n 'intermediate': 1,\n 'steps': 1,\n 'alignment': 1,\n 'previously': 1,\n 'necessary': 1,\n 'translationThe': 1,\n 'following': 1,\n 'list': 1,\n 'some': 1,\n 'researched': 1,\n 'Some': 1,\n 'these': 1,\n 'direct': 1,\n 'realworld': 1,\n 'applications': 2,\n 'while': 1,\n 'others': 1,\n 'more': 1,\n 'serve': 1,\n 'subtasks': 1,\n 'aid': 1,\n 'solving': 1,\n 'larger': 1,\n 'tasksThough': 1,\n 'intertwined': 1,\n 'can': 2,\n 'be': 2,\n 'subdivided': 1,\n 'into': 1,\n 'categories': 1,\n 'convenience': 1,\n 'A': 1,\n 'coarse': 1,\n 'division': 1,\n 'given': 1,\n 'belowBased': 1,\n 'longstanding': 2,\n 'trends': 3,\n 'field': 1,\n 'possible': 1,\n 'extrapolate': 1,\n 'future': 1,\n 'directions': 2,\n 'As': 1,\n 'three': 1,\n 'among': 2,\n 'topics': 1,\n 'series': 1,\n 'CoNLL': 2,\n 'Shared': 1,\n 'Tasks': 1,\n 'observedMost': 1,\n 'higherlevel': 1,\n 'involve': 1,\n 'aspects': 2,\n 'emulate': 1,\n 'intelligent': 1,\n 'behaviour': 2,\n 'apparent': 1,\n 'comprehension': 1,\n 'More': 2,\n 'broadly': 1,\n 'speaking': 1,\n 'technical': 1,\n 'operationalization': 1,\n 'increasingly': 1,\n 'advanced': 1,\n 'cognitive': 11,\n 'represents': 1,\n 'one': 1,\n 'developmental': 1,\n 'trajectories': 1,\n 'shared': 1,\n 'aboveCognition': 1,\n 'refers': 1,\n 'mental': 1,\n 'action': 1,\n 'acquiring': 1,\n 'through': 2,\n 'thought': 1,\n 'experience': 1,\n 'senses': 1,\n 'Cognitive': 2,\n 'interdisciplinary': 2,\n 'scientific': 1,\n 'study': 1,\n 'mind': 1,\n 'processes': 1,\n 'branch': 1,\n 'combining': 1,\n 'research': 1,\n 'psychology': 1,\n 'Especially': 1,\n 'during': 2,\n 'age': 1,\n 'area': 1,\n 'maintained': 1,\n 'strong': 1,\n 'ties': 1,\n 'studiesAs': 1,\n 'example': 1,\n 'George': 1,\n 'Lakoff': 1,\n 'offers': 1,\n 'methodology': 1,\n 'build': 1,\n 'perspective': 1,\n 'along': 1,\n 'findings': 1,\n 'two': 1,\n 'defining': 1,\n 'aspectsTies': 1,\n 'part': 1,\n 'historical': 1,\n 'heritage': 1,\n 'but': 1,\n 'less': 1,\n 'frequently': 1,\n 'addressed': 1,\n 'since': 1,\n 'turn': 1,\n 'Nevertheless': 1,\n 'develop': 1,\n 'towards': 1,\n 'technically': 1,\n 'operationalizable': 1,\n 'frameworks': 2,\n 'pursu ed': 1,\n 'con text': 1,\n 'v ar i o us': 1,\n 'f un ction al': 1,\n 'con str u ction': 1,\n 'psych ol inguistics': 1,\n 'neuro science': 1,\n 'AC T R': 1,\n 'li m it ed': 1,\n 'up t ak e': 1,\n 'ma in st re am': 1,\n 'me as ure d': 1,\n 'pres ence': 1,\n 'conf e ren c es': 1,\n 'AC L': 1,\n 're c ently': 1,\n 'ideas': 2,\n 're vi ved': 1,\n 'ach ie ve': 1,\n 'ex pla in ability': 1,\n 'under': 1,\n 'no tion': 1,\n 'L i k e w ise': 1,\n 'in he ren t': 1,\n 'm ul ti mod al': 1,\n 'al though': 1,\n 'r are ly': 1,\n 'ex plic it': 1,\n 'development s': 1,\n 'spe ci fic ally': 1,\n 'to ol s': 1,\n 'techn olog ies': 1,\n 'lar ge': 1,\n 'model': 1,\n 'new': 1,\n 'f ree': 1,\n 'ener g y': 1,\n 'pr in ci ple': 1,\n 'B r i tis h': 1,\n 'neuro scien ti st': 1,\n 'theore tic i an': 1,\n 'U n i ver s it y': 1,\n 'C ol le ge': 1,\n 'L on d on': 1,\n 'K ar l': 1,\n 'J': 1,\n 'F r ist on': 1}"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"import math\ndef generate_ngrams(tokens, n):\n    return [' '.join(tokens[i:i+n]) for i in range(len(tokens)-n+1)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T05:54:07.209521Z","iopub.execute_input":"2025-03-12T05:54:07.209906Z","iopub.status.idle":"2025-03-12T05:54:07.215197Z","shell.execute_reply.started":"2025-03-12T05:54:07.209839Z","shell.execute_reply":"2025-03-12T05:54:07.213934Z"}},"outputs":[],"execution_count":64},{"cell_type":"code","source":"corpus = clean\n\ndocs_ngrams = []\nfor doc in corpus:\n   \n    tokens = doc.lower().split()\n    tokens = [token.strip(\".,!?\") for token in tokens]\n\n    ngrams = []\n    for n in range(1, 4):  # 1, 2, and 3\n        ngrams.extend(generate_ngrams(tokens, n))\n    docs_ngrams.append(ngrams)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T05:54:17.954847Z","iopub.execute_input":"2025-03-12T05:54:17.955226Z","iopub.status.idle":"2025-03-12T05:54:17.961278Z","shell.execute_reply.started":"2025-03-12T05:54:17.955196Z","shell.execute_reply":"2025-03-12T05:54:17.960109Z"}},"outputs":[],"execution_count":65},{"cell_type":"code","source":"vocab = set()\nfor ngrams in docs_ngrams:\n    vocab.update(ngrams)\nvocab = sorted(list(vocab))\nprint(\"Vocabulary (n-grams):\")\nprint(vocab)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T05:54:21.179039Z","iopub.execute_input":"2025-03-12T05:54:21.179422Z","iopub.status.idle":"2025-03-12T05:54:21.187542Z","shell.execute_reply.started":"2025-03-12T05:54:21.179392Z","shell.execute_reply":"2025-03-12T05:54:21.186243Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"Vocabulary (n-grams):\n['a', 'a chinese', 'a chinese phrasebook', 'a coarse', 'a coarse division', 'a collection', 'a collection of', 'a criterion', 'a criterion of', 'a dictionary', 'a dictionary lookup', 'a list', 'a list of', 'a major', 'a major drawback', 'a methodology', 'a methodology to', 'a period', 'a period of', 'a problem', 'a problem separate', 'a revolution', 'a revolution in', 'a set', 'a set of', 'a subfield', 'a subfield of', 'a task', 'a task that', 'ability', 'ability to', 'ability to process', 'above', 'achieve', 'achieve explainability', 'achieve explainability eg', 'acl', 'acl more', 'acl more recently', 'acquiring', 'acquiring knowledge', 'acquiring knowledge and', 'action', 'action or', 'action or process', 'actr', 'actr however', 'actr however with', 'addressed', 'addressed since', 'addressed since the', 'advanced', 'advanced aspects', 'advanced aspects of', 'advantages', 'advantages over', 'advantages over the', 'age', 'age of', 'age of symbolic', 'ai', 'ai in', 'ai in general', 'ai likewise', 'ai likewise ideas', 'ai winter', 'ai winter which', 'aid', 'aid in', 'aid in solving', 'alan', 'alan turing', 'alan turing published', 'algorithms', 'algorithms for', 'algorithms for language', 'algorithms through', 'algorithms through the', 'alignment', 'alignment previously', 'alignment previously necessary', 'along', 'along with', 'along with the', 'already', 'already in', 'already in alan', 'although', 'although rarely', 'although rarely made', 'among', 'among conll', 'among conll shared', 'among the', 'among the topics', 'an', 'an approach', 'an approach to', 'an article', 'an article titled', 'an example', 'an example george', 'an interdisciplinary', 'an interdisciplinary branch', 'and', 'and apparent', 'and apparent comprehension', 'and by', 'and by nlp', 'and cognitive', 'and cognitive neuroscience', 'and computational', 'and computational linguistics', 'and dependency', 'and dependency parsing', 'and developments', 'and developments in', 'and especially', 'and especially artificial', 'and generation', 'and generation of', 'and intelligence', 'and intelligence which', 'and is', 'and is thus', 'and its', 'and its processes', 'and linguistics', 'and linguistics especially', 'and matching', 'and matching answers', 'and mids', 'and mids the', 'and naturallanguage', 'and naturallanguage generation', 'and neural', 'and neural networks', 'and new', 'and new directions', 'and research', 'and research from', 'and technologies', 'and technologies using', 'and the', 'and the gradual', 'and the senses', 'and theoretician', 'and theoretician at', 'and understanding', 'and understanding through', 'and word', 'and word embeddings', 'announced', 'announced the', 'announced the end', 'answers', 'answers the', 'answers the computer', 'anymore', 'apparent', 'apparent comprehension', 'apparent comprehension of', 'applications', 'applications involve', 'applications involve aspects', 'applications while', 'applications while others', 'applied', 'applied to', 'applied to partofspeech', 'applying', 'applying those', 'applying those rules', 'approach', 'approach ended', 'approach ended a', 'approach has', 'approach has been', 'approach ie', 'approach ie the', 'approach to', 'approach to achieve', 'approach to language', 'approach used', 'approach used both', 'approach using', 'approach using semantic', 'approaches', 'approaches and', 'approaches and new', 'approaches to', 'approaches to develop', 'approaches which', 'approaches which include', 'approachesonly', 'approachesonly the', 'approachesonly the introduction', 'are', 'are closely', 'are closely intertwined', 'are commonly', 'are commonly used', 'are inherent', 'are inherent to', 'are not', 'are not needed', 'are part', 'are part of', 'are speech', 'are speech recognition', 'are used', 'are used to', 'area', 'area of', 'area of computational', 'article', 'article titled', 'article titled computing', 'articulated', 'articulated as', 'articulated as a', 'artificial', 'artificial general', 'artificial general intelligence', 'artificial intelligence', 'artificial intelligence it', 'artificial intelligence specifically', 'artificial intelligence the', 'as', 'as a', 'as a criterion', 'as a problem', 'as an', 'as an approach', 'as an example', 'as by', 'as by writing', 'as measured', 'as measured by', 'as of', 'as of three', 'as subtasks', 'as subtasks that', 'as word', 'as word alignment', 'aspects', 'aspects of', 'aspects of cognitive', 'aspects that', 'aspects that emulate', 'at', 'at the', 'at the time', 'at university', 'at university college', 'automated', 'automated interpretation', 'automated interpretation and', 'based', 'based on', 'based on complex', 'based on longstanding', 'based on the', 'based on thennewly', 'be', 'be observed', 'be subdivided', 'be subdivided into', 'been', 'been less', 'been less frequently', 'been pursued', 'been pursued in', 'been replaced', 'been replaced by', 'been revived', 'been revived as', 'behaviour', 'behaviour and', 'behaviour and apparent', 'behaviour represents', 'behaviour represents one', 'below', 'both', 'both by', 'both by ai', 'both psychology', 'both psychology and', 'both statistical', 'both statistical and', 'both the', 'both the steady', 'branch', 'branch of', 'branch of linguistics', 'british', 'british neuroscientist', 'british neuroscientist and', 'broadly', 'broadly speaking', 'broadly speaking the', 'build', 'build natural', 'build natural language', 'but', 'but they', 'but they have', 'by', 'by ai', 'by ai in', 'by applying', 'by applying those', 'by british', 'by british neuroscientist', 'by john', 'by john searles', 'by nlp', 'by nlp in', 'by presence', 'by presence on', 'by the', 'by the inefficiencies', 'by the neural', 'by writing', 'by writing grammars', 'called', 'called the', 'called the turing', 'can', 'can be', 'can be observed', 'can be subdivided', 'capture', 'capture semantic', 'capture semantic properties', 'categories', 'categories for', 'categories for convenience', 'caused', 'caused by', 'caused by the', 'chinese', 'chinese phrasebook', 'chinese phrasebook with', 'chinese room', 'chinese room experiment', 'chomskyan', 'chomskyan theories', 'chomskyan theories of', 'classification', 'classification naturallanguage', 'classification naturallanguage understanding', 'closely', 'closely intertwined', 'closely intertwined they', 'closely related', 'closely related to', 'coarse', 'coarse division', 'coarse division is', 'cognition', 'cognition refers', 'cognition refers to', 'cognitive', 'cognitive ai', 'cognitive ai likewise', 'cognitive behaviour', 'cognitive behaviour represents', 'cognitive grammar', 'cognitive grammar functional', 'cognitive linguistics', 'cognitive linguistics are', 'cognitive linguistics is', 'cognitive linguistics with', 'cognitive models', 'cognitive models towards', 'cognitive neuroscience', 'cognitive neuroscience eg', 'cognitive nlp', 'cognitive nlp are', 'cognitive nlp have', 'cognitive science', 'cognitive science along', 'cognitive science is', 'cognitive studies', 'collection', 'collection of', 'collection of rules', 'college', 'college london', 'college london karl', 'combining', 'combining knowledge', 'combining knowledge and', 'commonly', 'commonly researched', 'commonly researched tasks', 'commonly serve', 'commonly serve as', 'commonly used', 'complex', 'complex sets', 'complex sets of', 'comprehension', 'comprehension of', 'comprehension of natural', 'computational', 'computational linguistics', 'computational linguistics a', 'computational linguistics maintained', 'computational power', 'computational power see', 'computational psycholinguistics', 'computational psycholinguistics and', 'computer', 'computer emulates', 'computer emulates natural', 'computer science', 'computer science and', 'computers', 'computers with', 'computers with the', 'computing', 'computing machinery', 'computing machinery and', 'concerned', 'concerned with', 'concerned with providing', 'conferences', 'conferences of', 'conferences of the', 'confronts', 'conll', 'conll shared', 'conll shared tasks', 'construction', 'construction grammar', 'construction grammar computational', 'context', 'context of', 'context of various', 'convenience', 'convenience a', 'convenience a coarse', 'corpus', 'corpus linguistics', 'corpus linguistics that', 'coupled', 'coupled with', 'coupled with a', 'criterion', 'criterion of', 'criterion of intelligence', 'data', 'data encoded', 'data encoded in', 'data it', 'data it confronts', 'decision', 'decision trees', 'decision trees producing', 'defining', 'defining aspects', 'dependency', 'dependency parsing', 'dependency parsing are', 'develop', 'develop cognitive', 'develop cognitive models', 'developmental', 'developmental trajectories', 'developmental trajectories of', 'developments', 'developments in', 'developments in artificial', 'devising', 'devising heuristic', 'devising heuristic rules', 'dictionary', 'dictionary lookup', 'dictionary lookup was', 'direct', 'direct realworld', 'direct realworld applications', 'directions', 'directions in', 'directions in artificial', 'directions of', 'directions of nlp', 'discouraged', 'discouraged the', 'discouraged the sort', 'division', 'division is', 'division is given', 'dominance', 'dominance of', 'dominance of chomskyan', 'drawback', 'drawback of', 'drawback of statistical', 'due', 'due to', 'due to both', 'during', 'during the', 'during the age', 'during the s', 'earliest', 'earliest decision', 'earliest decision trees', 'eg', 'eg a', 'eg a chinese', 'eg actr', 'eg actr however', 'eg of', 'eg of cognitive', 'eg partofspeech', 'eg partofspeech tagging', 'eg transformational', 'eg transformational grammar', 'eg under', 'eg under the', 'elaborate', 'elaborate feature', 'elaborate feature engineering', 'embeddings', 'embeddings to', 'embeddings to capture', 'emulate', 'emulate intelligent', 'emulate intelligent behaviour', 'emulates', 'emulates natural', 'emulates natural language', 'encoded', 'encoded in', 'encoded in natural', 'end', 'end of', 'end of the', 'ended', 'ended a', 'ended a period', 'energy', 'energy principle', 'energy principle by', 'engineering', 'engineering since', 'engineering since the', 'especially', 'especially artificial', 'especially artificial intelligence', 'especially during', 'especially during the', 'example', 'example george', 'example george lakoff', 'experience', 'experience and', 'experience and the', 'experiment', 'experiment given', 'experiment given a', 'explainability', 'explainability eg', 'explainability eg under', 'explicit', 'explicit and', 'explicit and developments', 'extrapolate', 'extrapolate future', 'extrapolate future directions', 'feature', 'feature engineering', 'feature engineering since', 'field', 'field it', 'field it is', 'findings', 'findings of', 'findings of cognitive', 'first', 'first approach', 'first approach used', 'following', 'following is', 'following is a', 'for', 'for convenience', 'for convenience a', 'for language', 'for language processing', 'for manipulating', 'for manipulating symbols', 'for statistical', 'for statistical machine', 'for stemming', 'frameworks', 'frameworks eg', 'frameworks eg of', 'frameworks have', 'frameworks have been', 'free', 'free energy', 'free energy principle', 'frequently', 'frequently addressed', 'frequently addressed since', 'friston', 'from', 'from artificial', 'from artificial intelligence', 'from both', 'from both psychology', 'functional', 'functional grammar', 'functional grammar construction', 'future', 'future directions', 'future directions of', 'general', 'general and', 'general and by', 'general intelligence', 'general intelligence based', 'generation', 'generation of', 'generation of natural', 'george', 'george lakoff', 'george lakoff offers', 'given', 'given a', 'given a collection', 'given below', 'gradual', 'gradual lessening', 'gradual lessening of', 'grammar', 'grammar computational', 'grammar computational psycholinguistics', 'grammar construction', 'grammar construction grammar', 'grammar functional', 'grammar functional grammar', 'grammar whose', 'grammar whose theoretical', 'grammars', 'grammars or', 'grammars or devising', 'hand', 'hand have', 'hand have many', 'handcoding', 'handcoding of', 'handcoding of a', 'handwritten', 'handwritten rules', 'handwritten rules starting', 'hard', 'hard ifthen', 'hard ifthen rules', 'has', 'has been', 'has been replaced', 'has its', 'has its roots', 'have', 'have been', 'have been less', 'have been pursued', 'have been revived', 'have direct', 'have direct realworld', 'have many', 'have many advantages', 'heritage', 'heritage of', 'heritage of nlp', 'heuristic', 'heuristic rules', 'heuristic rules for', 'hidden', 'hidden markov', 'hidden markov models', 'higherlevel', 'higherlevel nlp', 'higherlevel nlp applications', 'historical', 'historical heritage', 'historical heritage of', 'historically', 'historically the', 'historically the first', 'however', 'however there', 'however there was', 'however with', 'however with limited', 'ideas', 'ideas of', 'ideas of cognitive', 'ie', 'ie the', 'ie the handcoding', 'ifthen', 'ifthen rules', 'ifthen rules were', 'in', 'in alan', 'in alan turing', 'in artificial', 'in artificial general', 'in artificial intelligence', 'in computational', 'in computational power', 'in general', 'in general and', 'in mainstream', 'in mainstream nlp', 'in natural', 'in natural language', 'in particular', 'in particular such', 'in solving', 'in solving larger', 'in the', 'in the context', 'in the field', 'in the late', 'in the s', 'include', 'include both', 'include both statistical', 'includes', 'includes a', 'includes a task', 'increase', 'increase in', 'increase in computational', 'increasingly', 'increasingly advanced', 'increasingly advanced aspects', 'inefficiencies', 'inefficiencies of', 'inefficiencies of the', 'information', 'information retrieval', 'information retrieval knowledge', 'inherent', 'inherent to', 'inherent to neural', 'intelligence', 'intelligence based', 'intelligence based on', 'intelligence it', 'intelligence it is', 'intelligence specifically', 'intelligence specifically tools', 'intelligence the', 'intelligence the proposed', 'intelligence though', 'intelligence though at', 'intelligence which', 'intelligence which proposed', 'intelligent', 'intelligent behaviour', 'intelligent behaviour and', 'interdisciplinary', 'interdisciplinary branch', 'interdisciplinary branch of', 'interdisciplinary scientific', 'interdisciplinary scientific study', 'intermediate', 'intermediate steps', 'intermediate steps such', 'intermediate tasks', 'intermediate tasks eg', 'interpretation', 'interpretation and', 'interpretation and generation', 'intertwined', 'intertwined they', 'intertwined they can', 'into', 'into categories', 'into categories for', 'introduction', 'introduction of', 'introduction of hidden', 'introduction of machine', 'invented', 'invented sequencetosequence', 'invented sequencetosequence transformations', 'involve', 'involve aspects', 'involve aspects that', 'involves', 'involves the', 'involves the automated', 'is', 'is a', 'is a list', 'is a subfield', 'is an', 'is an interdisciplinary', 'is given', 'is given below', 'is now', 'is now called', 'is possible', 'is possible to', 'is primarily', 'is primarily concerned', 'is that', 'is that they', 'is the', 'is the interdisciplinary', 'is thus', 'is thus closely', 'is wellsummarized', 'is wellsummarized by', 'it', 'it confronts', 'it is', 'it is possible', 'it is primarily', 'its', 'its processes', 'its processes cognitive', 'its roots', 'its roots in', 'j', 'j friston', 'john', 'john searles', 'john searles chinese', 'karl', 'karl j', 'karl j friston', 'knowledge', 'knowledge and', 'knowledge and research', 'knowledge and understanding', 'knowledge representation', 'knowledge representation and', 'lakoff', 'lakoff offers', 'lakoff offers a', 'language', 'language and', 'language and is', 'language model', 'language model approaches', 'language more', 'language more broadly', 'language processing', 'language processing are', 'language processing has', 'language processing nlp', 'language processing some', 'language processing systems', 'language processing tasks', 'language processing this', 'language processing with', 'language understanding', 'language understanding or', 'large', 'large language', 'large language model', 'larger', 'larger tasks', 'late', 'late s', 'late s and', 'late s however', 'law', 'law and', 'law and the', 'learning', 'learning algorithms', 'learning algorithms for', 'learning approaches', 'learning approaches which', 'less', 'less frequently', 'less frequently addressed', 'lessening', 'lessening of', 'lessening of the', 'likewise', 'likewise ideas', 'likewise ideas of', 'limited', 'limited uptake', 'limited uptake in', 'linguistics', 'linguistics a', 'linguistics a subfield', 'linguistics are', 'linguistics are part', 'linguistics combining', 'linguistics combining knowledge', 'linguistics eg', 'linguistics eg transformational', 'linguistics especially', 'linguistics especially during', 'linguistics is', 'linguistics is an', 'linguistics maintained', 'linguistics maintained strong', 'linguistics that', 'linguistics that underlies', 'linguistics with', 'linguistics with two', 'list', 'list of', 'list of some', 'london', 'london karl', 'london karl j', 'longstanding', 'longstanding series', 'longstanding series of', 'longstanding trends', 'longstanding trends in', 'lookup', 'lookup was', 'lookup was historically', 'machine', 'machine learning', 'machine learning algorithms', 'machine learning approaches', 'machine translation', 'machine translation based', 'machinelearning', 'machinelearning approach', 'machinelearning approach to', 'machinery', 'machinery and', 'machinery and intelligence', 'made', 'made explicit', 'made explicit and', 'made obsolete', 'made obsolete the', 'mainstream', 'mainstream nlp', 'mainstream nlp as', 'maintained', 'maintained strong', 'maintained strong ties', 'major', 'major conferences', 'major conferences of', 'major drawback', 'major drawback of', 'major tasks', 'major tasks in', 'manipulating', 'manipulating symbols', 'manipulating symbols coupled', 'many', 'many advantages', 'many advantages over', 'markov', 'markov models', 'markov models applied', 'matching', 'matching answers', 'matching answers the', 'measured', 'measured by', 'measured by presence', 'mental', 'mental action', 'mental action or', 'methodology', 'methodology to', 'methodology to build', 'methods', 'methods is', 'methods is that', 'mids', 'mids the', 'mids the statistical', 'mind', 'mind and', 'mind and its', 'model', 'model approaches', 'model approaches and', 'models', 'models applied', 'models applied to', 'models multimodal', 'models multimodal nlp', 'models towards', 'models towards technically', 'moores', 'moores law', 'moores law and', 'more', 'more broadly', 'more broadly speaking', 'more commonly', 'more commonly serve', 'more recently', 'more recently ideas', 'most', 'most commonly', 'most commonly researched', 'most higherlevel', 'most higherlevel nlp', 'most natural', 'most natural language', 'multimodal', 'multimodal nlp', 'multimodal nlp although', 'natural', 'natural language', 'natural language and', 'natural language more', 'natural language processing', 'natural language understanding', 'naturallanguage', 'naturallanguage generation', 'naturallanguage understanding', 'naturallanguage understanding and', 'necessary', 'necessary for', 'necessary for statistical', 'needed', 'needed anymore', 'networks', 'networks and', 'networks and word', 'networks approach', 'networks approach using', 'networks on', 'networks on the', 'neural', 'neural machine', 'neural machine translation', 'neural models', 'neural models multimodal', 'neural networks', 'neural networks approach', 'neural networks on', 'neuroscience', 'neuroscience eg', 'neuroscience eg actr', 'neuroscientist', 'neuroscientist and', 'neuroscientist and theoretician', 'nevertheless', 'nevertheless approaches', 'nevertheless approaches to', 'new', 'new directions', 'new directions in', 'nlp', 'nlp algorithms', 'nlp algorithms through', 'nlp although', 'nlp although rarely', 'nlp applications', 'nlp applications involve', 'nlp are', 'nlp are inherent', 'nlp as', 'nlp as measured', 'nlp as of', 'nlp but', 'nlp but they', 'nlp have', 'nlp have been', 'nlp in', 'nlp in particular', 'nlp is', 'nlp is a', 'nlp is wellsummarized', 'nlp see', 'nlp see trends', 'nlp tasks', 'nlp tasks by', 'nlp the', 'nlp the area', 'not', 'not articulated', 'not articulated as', 'not needed', 'not needed anymore', 'notion', 'notion of', 'notion of cognitive', 'now', 'now called', 'now called the', 'observed', 'obsolete', 'obsolete the', 'obsolete the intermediate', 'of', 'of a', 'of a set', 'of acquiring', 'of acquiring knowledge', 'of ai', 'of ai winter', 'of chomskyan', 'of chomskyan theories', 'of cognitive', 'of cognitive ai', 'of cognitive behaviour', 'of cognitive grammar', 'of cognitive linguistics', 'of cognitive nlp', 'of cognitive science', 'of computational', 'of computational linguistics', 'of computer', 'of computer science', 'of conll', 'of conll shared', 'of corpus', 'of corpus linguistics', 'of handwritten', 'of handwritten rules', 'of hard', 'of hard ifthen', 'of hidden', 'of hidden markov', 'of increasingly', 'of increasingly advanced', 'of intelligence', 'of intelligence though', 'of linguistics', 'of linguistics combining', 'of linguistics eg', 'of machine', 'of machine learning', 'of natural', 'of natural language', 'of nlp', 'of nlp as', 'of nlp but', 'of nlp see', 'of rules', 'of rules eg', 'of rules for', 'of some', 'of some of', 'of statistical', 'of statistical methods', 'of symbolic', 'of symbolic nlp', 'of the', 'of the acl', 'of the developmental', 'of the dominance', 'of the historical', 'of the longstanding', 'of the mind', 'of the most', 'of the old', 'of the rulebased', 'of these', 'of these tasks', 'of three', 'of three trends', 'of various', 'of various frameworks', 'of words', 'offers', 'offers a', 'offers a methodology', 'old', 'old rulebased', 'old rulebased approach', 'old rulebased approachesonly', 'on', 'on complex', 'on complex sets', 'on longstanding', 'on longstanding trends', 'on major', 'on major conferences', 'on the', 'on the free', 'on the other', 'on thennewly', 'on thennewly invented', 'one', 'one of', 'one of the', 'operationalizable', 'operationalizable frameworks', 'operationalizable frameworks have', 'operationalization', 'operationalization of', 'operationalization of increasingly', 'or', 'or devising', 'or devising heuristic', 'or other', 'or other nlp', 'or process', 'or process of', 'other', 'other hand', 'other hand have', 'other nlp', 'other nlp tasks', 'others', 'others more', 'others more commonly', 'over', 'over the', 'over the symbolic', 'parsing', 'parsing are', 'parsing are not', 'part', 'part of', 'part of the', 'particular', 'particular such', 'particular such as', 'partofspeech', 'partofspeech tagging', 'partofspeech tagging and', 'partofspeech tagging announced', 'period', 'period of', 'period of ai', 'perspective', 'perspective of', 'perspective of cognitive', 'phrasebook', 'phrasebook with', 'phrasebook with questions', 'possible', 'possible to', 'possible to extrapolate', 'power', 'power see', 'power see moores', 'premise', 'premise of', 'premise of symbolic', 'presence', 'presence on', 'presence on major', 'previously', 'previously necessary', 'previously necessary for', 'primarily', 'primarily concerned', 'primarily concerned with', 'principle', 'principle by', 'principle by british', 'problem', 'problem separate', 'problem separate from', 'process', 'process data', 'process data encoded', 'process of', 'process of acquiring', 'processes', 'processes cognitive', 'processes cognitive linguistics', 'processing', 'processing are', 'processing are speech', 'processing has', 'processing has its', 'processing nlp', 'processing nlp algorithms', 'processing nlp is', 'processing some', 'processing some of', 'processing systems', 'processing systems were', 'processing tasks', 'processing tasks are', 'processing this', 'processing this was', 'processing with', 'processing with the', 'producing', 'producing systems', 'producing systems of', 'properties', 'properties of', 'properties of words', 'proposed', 'proposed test', 'proposed test includes', 'proposed what', 'proposed what is', 'providing', 'providing computers', 'providing computers with', 'psycholinguistics', 'psycholinguistics and', 'psycholinguistics and cognitive', 'psychology', 'psychology and', 'psychology and linguistics', 'published', 'published an', 'published an article', 'pursued', 'pursued in', 'pursued in the', 'questions', 'questions and', 'questions and matching', 'rarely', 'rarely made', 'rarely made explicit', 'realworld', 'realworld applications', 'realworld applications while', 'recently', 'recently ideas', 'recently ideas of', 'recognition', 'recognition text', 'recognition text classification', 'refers', 'refers to', 'refers to the', 'related', 'related to', 'related to information', 'replaced', 'replaced by', 'replaced by the', 'representation', 'representation and', 'representation and computational', 'represents', 'represents one', 'represents one of', 'require', 'require elaborate', 'require elaborate feature', 'research', 'research from', 'research from both', 'researched', 'researched tasks', 'researched tasks in', 'retrieval', 'retrieval knowledge', 'retrieval knowledge representation', 'revived', 'revived as', 'revived as an', 'revolution', 'revolution in', 'revolution in natural', 'room', 'room experiment', 'room experiment given', 'roots', 'roots in', 'roots in the', 'rulebased', 'rulebased approach', 'rulebased approaches', 'rulebased approachesonly', 'rulebased approachesonly the', 'rulebased systems', 'rulebased systems are', 'rules', 'rules eg', 'rules eg a', 'rules for', 'rules for manipulating', 'rules for stemming', 'rules starting', 'rules starting in', 'rules to', 'rules to the', 'rules were', 'rules were still', 's', 's already', 's already in', 's and', 's and mids', 's however', 's however there', 's most', 's most natural', 's nevertheless', 's nevertheless approaches', 'science', 'science along', 'science along with', 'science and', 'science and especially', 'science is', 'science is the', 'scientific', 'scientific study', 'scientific study of', 'searles', 'searles chinese', 'searles chinese room', 'see', 'see moores', 'see moores law', 'see trends', 'see trends among', 'semantic', 'semantic networks', 'semantic networks and', 'semantic properties', 'semantic properties of', 'senses', 'senses cognitive', 'senses cognitive science', 'separate', 'separate from', 'separate from artificial', 'sequencetosequence', 'sequencetosequence transformations', 'sequencetosequence transformations made', 'series', 'series of', 'series of conll', 'serve', 'serve as', 'serve as subtasks', 'set', 'set of', 'set of rules', 'sets', 'sets of', 'sets of handwritten', 'shared', 'shared tasks', 'shared tasks above', 'shared tasks can', 'similar', 'similar to', 'similar to the', 'since', 'since the', 'since the statistical', 'solving', 'solving larger', 'solving larger tasks', 'some', 'some of', 'some of the', 'some of these', 'sort', 'sort of', 'sort of corpus', 'speaking', 'speaking the', 'speaking the technical', 'specifically', 'specifically tools', 'specifically tools and', 'speech', 'speech recognition', 'speech recognition text', 'starting', 'starting in', 'starting in the', 'statistical', 'statistical and', 'statistical and neural', 'statistical approach', 'statistical approach ended', 'statistical approach has', 'statistical machine', 'statistical machine translation', 'statistical methods', 'statistical methods is', 'statistical turn', 'statistical turn during', 'steady', 'steady increase', 'steady increase in', 'stemming', 'steps', 'steps such', 'steps such as', 'still', 'still very', 'still very similar', 'strong', 'strong ties', 'strong ties with', 'studies', 'study', 'study of', 'study of the', 'subdivided', 'subdivided into', 'subdivided into categories', 'subfield', 'subfield of', 'subfield of computer', 'subfield of linguistics', 'subtasks', 'subtasks that', 'subtasks that are', 'such', 'such as', 'such as by', 'such as word', 'symbolic', 'symbolic approach', 'symbolic approach ie', 'symbolic nlp', 'symbolic nlp is', 'symbolic nlp the', 'symbols', 'symbols coupled', 'symbols coupled with', 'systems', 'systems are', 'systems are commonly', 'systems of', 'systems of hard', 'systems were', 'systems were based', 'tagging', 'tagging and', 'tagging and dependency', 'tagging announced', 'tagging announced the', 'task', 'task that', 'task that involves', 'tasks', 'tasks above', 'tasks are', 'tasks are closely', 'tasks by', 'tasks by applying', 'tasks can', 'tasks can be', 'tasks eg', 'tasks eg partofspeech', 'tasks have', 'tasks have direct', 'tasks in', 'tasks in natural', 'technical', 'technical operationalization', 'technical operationalization of', 'technically', 'technically operationalizable', 'technically operationalizable frameworks', 'technologies', 'technologies using', 'technologies using large', 'test', 'test as', 'test as a', 'test includes', 'test includes a', 'text', 'text classification', 'text classification naturallanguage', 'that', 'that are', 'that are used', 'that emulate', 'that emulate intelligent', 'that involves', 'that involves the', 'that they', 'that they require', 'that underlies', 'that underlies the', 'that was', 'that was not', 'the', 'the ability', 'the ability to', 'the acl', 'the acl more', 'the age', 'the age of', 'the area', 'the area of', 'the automated', 'the automated interpretation', 'the computer', 'the computer emulates', 'the context', 'the context of', 'the data', 'the data it', 'the developmental', 'the developmental trajectories', 'the dominance', 'the dominance of', 'the earliest', 'the earliest decision', 'the end', 'the end of', 'the field', 'the field it', 'the findings', 'the findings of', 'the first', 'the first approach', 'the following', 'the following is', 'the free', 'the free energy', 'the gradual', 'the gradual lessening', 'the handcoding', 'the handcoding of', 'the historical', 'the historical heritage', 'the inefficiencies', 'the inefficiencies of', 'the interdisciplinary', 'the interdisciplinary scientific', 'the intermediate', 'the intermediate steps', 'the introduction', 'the introduction of', 'the late', 'the late s', 'the longstanding', 'the longstanding series', 'the machinelearning', 'the machinelearning approach', 'the mental', 'the mental action', 'the mind', 'the mind and', 'the most', 'the most commonly', 'the neural', 'the neural networks', 'the notion', 'the notion of', 'the old', 'the old rulebased', 'the other', 'the other hand', 'the perspective', 'the perspective of', 'the premise', 'the premise of', 'the proposed', 'the proposed test', 'the rulebased', 'the rulebased approaches', 'the s', 'the s already', 'the s most', 'the s nevertheless', 'the senses', 'the senses cognitive', 'the sort', 'the sort of', 'the statistical', 'the statistical approach', 'the statistical turn', 'the steady', 'the steady increase', 'the symbolic', 'the symbolic approach', 'the technical', 'the technical operationalization', 'the time', 'the time that', 'the topics', 'the topics of', 'the turing', 'the turing test', 'thennewly', 'thennewly invented', 'thennewly invented sequencetosequence', 'theoretical', 'theoretical underpinnings', 'theoretical underpinnings discouraged', 'theoretician', 'theoretician at', 'theoretician at university', 'theories', 'theories of', 'theories of linguistics', 'there', 'there was', 'there was a', 'these', 'these tasks', 'these tasks have', 'they', 'they can', 'they can be', 'they have', 'they have been', 'they require', 'they require elaborate', 'this', 'this was', 'this was due', 'those', 'those rules', 'those rules to', 'though', 'though at', 'though at the', 'though natural', 'though natural language', 'thought', 'thought experience', 'thought experience and', 'three', 'three trends', 'three trends among', 'through', 'through the', 'through the perspective', 'through thought', 'through thought experience', 'thus', 'thus closely', 'thus closely related', 'ties', 'ties with', 'ties with cognitive', 'time', 'time that', 'time that was', 'titled', 'titled computing', 'titled computing machinery', 'to', 'to achieve', 'to achieve explainability', 'to aid', 'to aid in', 'to both', 'to both the', 'to build', 'to build natural', 'to capture', 'to capture semantic', 'to develop', 'to develop cognitive', 'to extrapolate', 'to extrapolate future', 'to information', 'to information retrieval', 'to language', 'to language processing', 'to neural', 'to neural models', 'to partofspeech', 'to partofspeech tagging', 'to process', 'to process data', 'to the', 'to the data', 'to the mental', 'to the old', 'tools', 'tools and', 'tools and technologies', 'topics', 'topics of', 'topics of the', 'towards', 'towards technically', 'towards technically operationalizable', 'trajectories', 'trajectories of', 'trajectories of nlp', 'transformational', 'transformational grammar', 'transformational grammar whose', 'transformations', 'transformations made', 'transformations made obsolete', 'translation', 'translation based', 'translation based on', 'trees', 'trees producing', 'trees producing systems', 'trends', 'trends among', 'trends among conll', 'trends among the', 'trends in', 'trends in the', 'turing', 'turing published', 'turing published an', 'turing test', 'turing test as', 'turn', 'turn during', 'turn during the', 'two', 'two defining', 'two defining aspects', 'under', 'under the', 'under the notion', 'underlies', 'underlies the', 'underlies the machinelearning', 'underpinnings', 'underpinnings discouraged', 'underpinnings discouraged the', 'understanding', 'understanding and', 'understanding and naturallanguage', 'understanding or', 'understanding or other', 'understanding through', 'understanding through thought', 'university', 'university college', 'university college london', 'until', 'until the', 'until the s', 'up', 'up until', 'up until the', 'uptake', 'uptake in', 'uptake in mainstream', 'used', 'used both', 'used both by', 'used to', 'used to aid', 'using', 'using large', 'using large language', 'using semantic', 'using semantic networks', 'various', 'various frameworks', 'various frameworks eg', 'very', 'very similar', 'very similar to', 'was', 'was a', 'was a revolution', 'was caused', 'was caused by', 'was due', 'was due to', 'was historically', 'was historically the', 'was not', 'was not articulated', 'wellsummarized', 'wellsummarized by', 'wellsummarized by john', 'were', 'were based', 'were based on', 'were still', 'were still very', 'what', 'what is', 'what is now', 'which', 'which include', 'which include both', 'which proposed', 'which proposed what', 'which was', 'which was caused', 'while', 'while others', 'while others more', 'whose', 'whose theoretical', 'whose theoretical underpinnings', 'winter', 'winter which', 'winter which was', 'with', 'with a', 'with a dictionary', 'with cognitive', 'with cognitive linguistics', 'with cognitive studies', 'with limited', 'with limited uptake', 'with providing', 'with providing computers', 'with questions', 'with questions and', 'with the', 'with the ability', 'with the findings', 'with the introduction', 'with two', 'with two defining', 'word', 'word alignment', 'word alignment previously', 'word embeddings', 'word embeddings to', 'words', 'writing', 'writing grammars', 'writing grammars or']\n","output_type":"stream"}],"execution_count":66},{"cell_type":"code","source":"doc_tf = []\nfor ngrams in docs_ngrams:\n    tf = {}\n    for term in ngrams:\n        tf[term] = tf.get(term, 0) + 1\n    doc_tf.append(tf)\n    \ndf = {}\nfor tf in doc_tf:\n    for term in tf.keys():\n        df[term] = df.get(term, 0) + 1\n\nN = len(corpus)\n# idf = log((N+1)/(df+1)) + 1\nidf = {term: math.log((N + 1) / (df_count + 1)) + 1 for term, df_count in df.items()}\n\n\ndoc_tfidf = []\nfor tf in doc_tf:\n    tfidf = {}\n    for term, freq in tf.items():\n        tfidf[term] = freq * idf[term]\n    doc_tfidf.append(tfidf)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T05:54:27.191559Z","iopub.execute_input":"2025-03-12T05:54:27.191870Z","iopub.status.idle":"2025-03-12T05:54:27.201817Z","shell.execute_reply.started":"2025-03-12T05:54:27.191847Z","shell.execute_reply":"2025-03-12T05:54:27.200748Z"},"scrolled":true},"outputs":[],"execution_count":67},{"cell_type":"code","source":"\nprint(\"\\nTF-IDF values for each document (pure python):\")\nfor i, tfidf in enumerate(doc_tfidf):\n    print(f\"\\nDocument {i+1}:\")\n    for term, score in sorted(tfidf.items()):\n        print(f\"  {term}: {score:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T05:54:30.032944Z","iopub.execute_input":"2025-03-12T05:54:30.033374Z","iopub.status.idle":"2025-03-12T05:54:30.479882Z","shell.execute_reply.started":"2025-03-12T05:54:30.033343Z","shell.execute_reply":"2025-03-12T05:54:30.478714Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"\nTF-IDF values for each document (pure python):\n\nDocument 1:\n  a: 3.2933\n  a subfield: 6.7028\n  a subfield of: 6.7028\n  ability: 3.3514\n  ability to: 3.3514\n  ability to process: 3.3514\n  and: 4.2164\n  and computational: 3.3514\n  and computational linguistics: 3.3514\n  and especially: 3.3514\n  and especially artificial: 3.3514\n  and is: 3.3514\n  and is thus: 3.3514\n  artificial: 2.6582\n  artificial intelligence: 2.6582\n  artificial intelligence it: 3.3514\n  closely: 2.9459\n  closely related: 3.3514\n  closely related to: 3.3514\n  computational: 2.4351\n  computational linguistics: 2.9459\n  computational linguistics a: 3.3514\n  computer: 2.9459\n  computer science: 3.3514\n  computer science and: 3.3514\n  computers: 3.3514\n  computers with: 3.3514\n  computers with the: 3.3514\n  concerned: 3.3514\n  concerned with: 3.3514\n  concerned with providing: 3.3514\n  data: 2.9459\n  data encoded: 3.3514\n  data encoded in: 3.3514\n  encoded: 3.3514\n  encoded in: 3.3514\n  encoded in natural: 3.3514\n  especially: 2.9459\n  especially artificial: 3.3514\n  especially artificial intelligence: 3.3514\n  in: 1.7419\n  in natural: 2.4351\n  in natural language: 2.4351\n  information: 3.3514\n  information retrieval: 3.3514\n  information retrieval knowledge: 3.3514\n  intelligence: 2.6582\n  intelligence it: 3.3514\n  intelligence it is: 3.3514\n  is: 5.5419\n  is a: 2.9459\n  is a subfield: 3.3514\n  is primarily: 3.3514\n  is primarily concerned: 3.3514\n  is thus: 3.3514\n  is thus closely: 3.3514\n  it: 2.6582\n  it is: 2.9459\n  it is primarily: 3.3514\n  knowledge: 2.9459\n  knowledge representation: 3.3514\n  knowledge representation and: 3.3514\n  language: 3.2933\n  language and: 3.3514\n  language and is: 3.3514\n  language processing: 1.9651\n  language processing nlp: 2.9459\n  linguistics: 4.5055\n  linguistics a: 3.3514\n  linguistics a subfield: 3.3514\n  natural: 3.4839\n  natural language: 3.4839\n  natural language and: 3.3514\n  natural language processing: 1.9651\n  nlp: 1.8473\n  nlp is: 2.9459\n  nlp is a: 3.3514\n  of: 2.6729\n  of computer: 3.3514\n  of computer science: 3.3514\n  of linguistics: 2.6582\n  primarily: 3.3514\n  primarily concerned: 3.3514\n  primarily concerned with: 3.3514\n  process: 2.9459\n  process data: 3.3514\n  process data encoded: 3.3514\n  processing: 1.9651\n  processing nlp: 2.9459\n  processing nlp is: 3.3514\n  providing: 3.3514\n  providing computers: 3.3514\n  providing computers with: 3.3514\n  related: 3.3514\n  related to: 3.3514\n  related to information: 3.3514\n  representation: 3.3514\n  representation and: 3.3514\n  representation and computational: 3.3514\n  retrieval: 3.3514\n  retrieval knowledge: 3.3514\n  retrieval knowledge representation: 3.3514\n  science: 2.6582\n  science and: 3.3514\n  science and especially: 3.3514\n  subfield: 6.7028\n  subfield of: 6.7028\n  subfield of computer: 3.3514\n  subfield of linguistics: 3.3514\n  the: 1.2113\n  the ability: 3.3514\n  the ability to: 3.3514\n  thus: 3.3514\n  thus closely: 3.3514\n  thus closely related: 3.3514\n  to: 3.2933\n  to information: 3.3514\n  to information retrieval: 3.3514\n  to process: 3.3514\n  to process data: 3.3514\n  with: 3.9302\n  with providing: 3.3514\n  with providing computers: 3.3514\n  with the: 2.6582\n  with the ability: 3.3514\n\nDocument 2:\n  and: 1.4055\n  and naturallanguage: 3.3514\n  and naturallanguage generation: 3.3514\n  are: 2.0986\n  are speech: 3.3514\n  are speech recognition: 3.3514\n  classification: 3.3514\n  classification naturallanguage: 3.3514\n  classification naturallanguage understanding: 3.3514\n  generation: 2.9459\n  in: 1.7419\n  in natural: 2.4351\n  in natural language: 2.4351\n  language: 1.6466\n  language processing: 1.9651\n  language processing are: 3.3514\n  major: 2.6582\n  major tasks: 3.3514\n  major tasks in: 3.3514\n  natural: 1.7419\n  natural language: 1.7419\n  natural language processing: 1.9651\n  naturallanguage: 6.7028\n  naturallanguage generation: 3.3514\n  naturallanguage understanding: 3.3514\n  naturallanguage understanding and: 3.3514\n  processing: 1.9651\n  processing are: 3.3514\n  processing are speech: 3.3514\n  recognition: 3.3514\n  recognition text: 3.3514\n  recognition text classification: 3.3514\n  speech: 3.3514\n  speech recognition: 3.3514\n  speech recognition text: 3.3514\n  tasks: 1.9651\n  tasks in: 2.9459\n  tasks in natural: 2.9459\n  text: 3.3514\n  text classification: 3.3514\n  text classification naturallanguage: 3.3514\n  understanding: 2.6582\n  understanding and: 3.3514\n  understanding and naturallanguage: 3.3514\n\nDocument 3:\n  a: 4.9399\n  a criterion: 3.3514\n  a criterion of: 3.3514\n  a problem: 3.3514\n  a problem separate: 3.3514\n  a task: 3.3514\n  a task that: 3.3514\n  alan: 3.3514\n  alan turing: 3.3514\n  alan turing published: 3.3514\n  already: 3.3514\n  already in: 3.3514\n  already in alan: 3.3514\n  an: 2.4351\n  an article: 3.3514\n  an article titled: 3.3514\n  and: 2.8109\n  and generation: 3.3514\n  and generation of: 3.3514\n  and intelligence: 3.3514\n  and intelligence which: 3.3514\n  article: 3.3514\n  article titled: 3.3514\n  article titled computing: 3.3514\n  articulated: 3.3514\n  articulated as: 3.3514\n  articulated as a: 3.3514\n  artificial: 2.6582\n  artificial intelligence: 2.6582\n  artificial intelligence the: 3.3514\n  as: 3.9302\n  as a: 6.7028\n  as a criterion: 3.3514\n  as a problem: 3.3514\n  at: 2.9459\n  at the: 3.3514\n  at the time: 3.3514\n  automated: 3.3514\n  automated interpretation: 3.3514\n  automated interpretation and: 3.3514\n  called: 3.3514\n  called the: 3.3514\n  called the turing: 3.3514\n  computing: 3.3514\n  computing machinery: 3.3514\n  computing machinery and: 3.3514\n  criterion: 3.3514\n  criterion of: 3.3514\n  criterion of intelligence: 3.3514\n  from: 2.9459\n  from artificial: 3.3514\n  from artificial intelligence: 3.3514\n  generation: 2.9459\n  generation of: 3.3514\n  generation of natural: 3.3514\n  has: 2.9459\n  has its: 3.3514\n  has its roots: 3.3514\n  in: 3.4839\n  in alan: 3.3514\n  in alan turing: 3.3514\n  in the: 2.2528\n  in the s: 3.3514\n  includes: 3.3514\n  includes a: 3.3514\n  includes a task: 3.3514\n  intelligence: 7.9747\n  intelligence the: 3.3514\n  intelligence the proposed: 3.3514\n  intelligence though: 3.3514\n  intelligence though at: 3.3514\n  intelligence which: 3.3514\n  intelligence which proposed: 3.3514\n  interpretation: 3.3514\n  interpretation and: 3.3514\n  interpretation and generation: 3.3514\n  involves: 3.3514\n  involves the: 3.3514\n  involves the automated: 3.3514\n  is: 1.8473\n  is now: 3.3514\n  is now called: 3.3514\n  its: 2.9459\n  its roots: 3.3514\n  its roots in: 3.3514\n  language: 3.2933\n  language processing: 1.9651\n  language processing has: 3.3514\n  machinery: 3.3514\n  machinery and: 3.3514\n  machinery and intelligence: 3.3514\n  natural: 3.4839\n  natural language: 3.4839\n  natural language processing: 1.9651\n  not: 2.9459\n  not articulated: 3.3514\n  not articulated as: 3.3514\n  now: 3.3514\n  now called: 3.3514\n  now called the: 3.3514\n  of: 2.6729\n  of intelligence: 3.3514\n  of intelligence though: 3.3514\n  of natural: 2.9459\n  of natural language: 2.9459\n  problem: 3.3514\n  problem separate: 3.3514\n  problem separate from: 3.3514\n  processing: 1.9651\n  processing has: 3.3514\n  processing has its: 3.3514\n  proposed: 6.7028\n  proposed test: 3.3514\n  proposed test includes: 3.3514\n  proposed what: 3.3514\n  proposed what is: 3.3514\n  published: 3.3514\n  published an: 3.3514\n  published an article: 3.3514\n  roots: 3.3514\n  roots in: 3.3514\n  roots in the: 3.3514\n  s: 2.4351\n  s already: 3.3514\n  s already in: 3.3514\n  separate: 3.3514\n  separate from: 3.3514\n  separate from artificial: 3.3514\n  task: 3.3514\n  task that: 3.3514\n  task that involves: 3.3514\n  test: 6.7028\n  test as: 3.3514\n  test as a: 3.3514\n  test includes: 3.3514\n  test includes a: 3.3514\n  that: 4.5055\n  that involves: 3.3514\n  that involves the: 3.3514\n  that was: 3.3514\n  that was not: 3.3514\n  the: 6.0565\n  the automated: 3.3514\n  the automated interpretation: 3.3514\n  the proposed: 3.3514\n  the proposed test: 3.3514\n  the s: 2.6582\n  the s already: 3.3514\n  the time: 3.3514\n  the time that: 3.3514\n  the turing: 3.3514\n  the turing test: 3.3514\n  though: 2.9459\n  though at: 3.3514\n  though at the: 3.3514\n  time: 3.3514\n  time that: 3.3514\n  time that was: 3.3514\n  titled: 3.3514\n  titled computing: 3.3514\n  titled computing machinery: 3.3514\n  turing: 6.7028\n  turing published: 3.3514\n  turing published an: 3.3514\n  turing test: 3.3514\n  turing test as: 3.3514\n  was: 2.4351\n  was not: 3.3514\n  was not articulated: 3.3514\n  what: 3.3514\n  what is: 3.3514\n  what is now: 3.3514\n  which: 2.6582\n  which proposed: 3.3514\n  which proposed what: 3.3514\n\nDocument 4:\n  a: 3.2933\n  a chinese: 3.3514\n  a chinese phrasebook: 3.3514\n  a collection: 3.3514\n  a collection of: 3.3514\n  and: 1.4055\n  and matching: 3.3514\n  and matching answers: 3.3514\n  answers: 3.3514\n  answers the: 3.3514\n  answers the computer: 3.3514\n  applying: 3.3514\n  applying those: 3.3514\n  applying those rules: 3.3514\n  by: 4.5055\n  by applying: 3.3514\n  by applying those: 3.3514\n  by john: 3.3514\n  by john searles: 3.3514\n  chinese: 6.7028\n  chinese phrasebook: 3.3514\n  chinese phrasebook with: 3.3514\n  chinese room: 3.3514\n  chinese room experiment: 3.3514\n  collection: 3.3514\n  collection of: 3.3514\n  collection of rules: 3.3514\n  computer: 2.9459\n  computer emulates: 3.3514\n  computer emulates natural: 3.3514\n  confronts: 3.3514\n  data: 2.9459\n  data it: 3.3514\n  data it confronts: 3.3514\n  eg: 2.4351\n  eg a: 3.3514\n  eg a chinese: 3.3514\n  emulates: 3.3514\n  emulates natural: 3.3514\n  emulates natural language: 3.3514\n  experiment: 3.3514\n  experiment given: 3.3514\n  experiment given a: 3.3514\n  given: 2.9459\n  given a: 3.3514\n  given a collection: 3.3514\n  is: 1.8473\n  is wellsummarized: 3.3514\n  is wellsummarized by: 3.3514\n  it: 2.6582\n  it confronts: 3.3514\n  john: 3.3514\n  john searles: 3.3514\n  john searles chinese: 3.3514\n  language: 1.6466\n  language understanding: 3.3514\n  language understanding or: 3.3514\n  matching: 3.3514\n  matching answers: 3.3514\n  matching answers the: 3.3514\n  natural: 1.7419\n  natural language: 1.7419\n  natural language understanding: 3.3514\n  nlp: 3.6946\n  nlp is: 2.9459\n  nlp is wellsummarized: 3.3514\n  nlp tasks: 3.3514\n  nlp tasks by: 3.3514\n  of: 2.6729\n  of rules: 2.9459\n  of rules eg: 3.3514\n  of symbolic: 2.9459\n  of symbolic nlp: 2.9459\n  or: 2.6582\n  or other: 3.3514\n  or other nlp: 3.3514\n  other: 2.9459\n  other nlp: 3.3514\n  other nlp tasks: 3.3514\n  phrasebook: 3.3514\n  phrasebook with: 3.3514\n  phrasebook with questions: 3.3514\n  premise: 3.3514\n  premise of: 3.3514\n  premise of symbolic: 3.3514\n  questions: 3.3514\n  questions and: 3.3514\n  questions and matching: 3.3514\n  room: 3.3514\n  room experiment: 3.3514\n  room experiment given: 3.3514\n  rules: 4.8702\n  rules eg: 3.3514\n  rules eg a: 3.3514\n  rules to: 3.3514\n  rules to the: 3.3514\n  searles: 3.3514\n  searles chinese: 3.3514\n  searles chinese room: 3.3514\n  symbolic: 2.4351\n  symbolic nlp: 2.9459\n  symbolic nlp is: 3.3514\n  tasks: 1.9651\n  tasks by: 3.3514\n  tasks by applying: 3.3514\n  the: 3.6339\n  the computer: 3.3514\n  the computer emulates: 3.3514\n  the data: 3.3514\n  the data it: 3.3514\n  the premise: 3.3514\n  the premise of: 3.3514\n  those: 3.3514\n  those rules: 3.3514\n  those rules to: 3.3514\n  to: 1.6466\n  to the: 2.6582\n  to the data: 3.3514\n  understanding: 2.6582\n  understanding or: 3.3514\n  understanding or other: 3.3514\n  wellsummarized: 3.3514\n  wellsummarized by: 3.3514\n  wellsummarized by john: 3.3514\n  with: 1.9651\n  with questions: 3.3514\n  with questions and: 3.3514\n\nDocument 5:\n  a: 1.6466\n  a revolution: 3.3514\n  a revolution in: 3.3514\n  algorithms: 2.9459\n  algorithms for: 3.3514\n  algorithms for language: 3.3514\n  and: 1.4055\n  and the: 2.9459\n  and the gradual: 3.3514\n  approach: 1.9651\n  approach to: 2.9459\n  approach to language: 3.3514\n  based: 2.4351\n  based on: 2.4351\n  based on complex: 3.3514\n  both: 2.4351\n  both the: 3.3514\n  both the steady: 3.3514\n  chomskyan: 3.3514\n  chomskyan theories: 3.3514\n  chomskyan theories of: 3.3514\n  complex: 3.3514\n  complex sets: 3.3514\n  complex sets of: 3.3514\n  computational: 2.4351\n  computational power: 3.3514\n  computational power see: 3.3514\n  corpus: 3.3514\n  corpus linguistics: 3.3514\n  corpus linguistics that: 3.3514\n  discouraged: 3.3514\n  discouraged the: 3.3514\n  discouraged the sort: 3.3514\n  dominance: 3.3514\n  dominance of: 3.3514\n  dominance of chomskyan: 3.3514\n  due: 3.3514\n  due to: 3.3514\n  due to both: 3.3514\n  eg: 2.4351\n  eg transformational: 3.3514\n  eg transformational grammar: 3.3514\n  for: 2.4351\n  for language: 3.3514\n  for language processing: 3.3514\n  gradual: 3.3514\n  gradual lessening: 3.3514\n  gradual lessening of: 3.3514\n  grammar: 2.9459\n  grammar whose: 3.3514\n  grammar whose theoretical: 3.3514\n  handwritten: 3.3514\n  handwritten rules: 3.3514\n  handwritten rules starting: 3.3514\n  however: 2.9459\n  however there: 3.3514\n  however there was: 3.3514\n  in: 5.2258\n  in computational: 3.3514\n  in computational power: 3.3514\n  in natural: 2.4351\n  in natural language: 2.4351\n  in the: 2.2528\n  in the late: 2.9459\n  increase: 3.3514\n  increase in: 3.3514\n  increase in computational: 3.3514\n  introduction: 2.9459\n  introduction of: 2.9459\n  introduction of machine: 3.3514\n  language: 6.5865\n  language processing: 7.8603\n  language processing systems: 3.3514\n  language processing this: 3.3514\n  language processing with: 3.3514\n  late: 2.9459\n  late s: 2.9459\n  late s however: 3.3514\n  law: 3.3514\n  law and: 3.3514\n  law and the: 3.3514\n  learning: 2.9459\n  learning algorithms: 3.3514\n  learning algorithms for: 3.3514\n  lessening: 3.3514\n  lessening of: 3.3514\n  lessening of the: 3.3514\n  linguistics: 4.5055\n  linguistics eg: 3.3514\n  linguistics eg transformational: 3.3514\n  linguistics that: 3.3514\n  linguistics that underlies: 3.3514\n  machine: 2.6582\n  machine learning: 2.9459\n  machine learning algorithms: 3.3514\n  machinelearning: 3.3514\n  machinelearning approach: 3.3514\n  machinelearning approach to: 3.3514\n  moores: 3.3514\n  moores law: 3.3514\n  moores law and: 3.3514\n  most: 2.6582\n  most natural: 3.3514\n  most natural language: 3.3514\n  natural: 3.4839\n  natural language: 3.4839\n  natural language processing: 3.9302\n  of: 8.0188\n  of chomskyan: 3.3514\n  of chomskyan theories: 3.3514\n  of corpus: 3.3514\n  of corpus linguistics: 3.3514\n  of handwritten: 3.3514\n  of handwritten rules: 3.3514\n  of linguistics: 2.6582\n  of linguistics eg: 3.3514\n  of machine: 3.3514\n  of machine learning: 3.3514\n  of the: 1.8473\n  of the dominance: 3.3514\n  on: 2.2528\n  on complex: 3.3514\n  on complex sets: 3.3514\n  power: 3.3514\n  power see: 3.3514\n  power see moores: 3.3514\n  processing: 7.8603\n  processing systems: 3.3514\n  processing systems were: 3.3514\n  processing this: 3.3514\n  processing this was: 3.3514\n  processing with: 3.3514\n  processing with the: 3.3514\n  revolution: 3.3514\n  revolution in: 3.3514\n  revolution in natural: 3.3514\n  rules: 2.4351\n  rules starting: 3.3514\n  rules starting in: 3.3514\n  s: 4.8702\n  s however: 3.3514\n  s however there: 3.3514\n  s most: 3.3514\n  s most natural: 3.3514\n  see: 2.9459\n  see moores: 3.3514\n  see moores law: 3.3514\n  sets: 3.3514\n  sets of: 3.3514\n  sets of handwritten: 3.3514\n  sort: 3.3514\n  sort of: 3.3514\n  sort of corpus: 3.3514\n  starting: 3.3514\n  starting in: 3.3514\n  starting in the: 3.3514\n  steady: 3.3514\n  steady increase: 3.3514\n  steady increase in: 3.3514\n  systems: 2.6582\n  systems were: 3.3514\n  systems were based: 3.3514\n  that: 2.2528\n  that underlies: 3.3514\n  that underlies the: 3.3514\n  the: 9.6905\n  the dominance: 3.3514\n  the dominance of: 3.3514\n  the gradual: 3.3514\n  the gradual lessening: 3.3514\n  the introduction: 2.9459\n  the introduction of: 2.9459\n  the late: 2.9459\n  the late s: 2.9459\n  the machinelearning: 3.3514\n  the machinelearning approach: 3.3514\n  the s: 2.6582\n  the s most: 3.3514\n  the sort: 3.3514\n  the sort of: 3.3514\n  the steady: 3.3514\n  the steady increase: 3.3514\n  theoretical: 3.3514\n  theoretical underpinnings: 3.3514\n  theoretical underpinnings discouraged: 3.3514\n  theories: 3.3514\n  theories of: 3.3514\n  theories of linguistics: 3.3514\n  there: 3.3514\n  there was: 3.3514\n  there was a: 3.3514\n  this: 3.3514\n  this was: 3.3514\n  this was due: 3.3514\n  to: 3.2933\n  to both: 3.3514\n  to both the: 3.3514\n  to language: 3.3514\n  to language processing: 3.3514\n  transformational: 3.3514\n  transformational grammar: 3.3514\n  transformational grammar whose: 3.3514\n  underlies: 3.3514\n  underlies the: 3.3514\n  underlies the machinelearning: 3.3514\n  underpinnings: 3.3514\n  underpinnings discouraged: 3.3514\n  underpinnings discouraged the: 3.3514\n  until: 3.3514\n  until the: 3.3514\n  until the s: 3.3514\n  up: 3.3514\n  up until: 3.3514\n  up until the: 3.3514\n  was: 4.8702\n  was a: 3.3514\n  was a revolution: 3.3514\n  was due: 3.3514\n  was due to: 3.3514\n  were: 2.9459\n  were based: 3.3514\n  were based on: 3.3514\n  whose: 3.3514\n  whose theoretical: 3.3514\n  whose theoretical underpinnings: 3.3514\n  with: 1.9651\n  with the: 2.6582\n  with the introduction: 3.3514\n\nDocument 6:\n  a: 3.2933\n  a dictionary: 3.3514\n  a dictionary lookup: 3.3514\n  a set: 3.3514\n  a set of: 3.3514\n  ai: 2.6582\n  ai in: 3.3514\n  ai in general: 3.3514\n  and: 1.4055\n  and by: 3.3514\n  and by nlp: 3.3514\n  approach: 3.9302\n  approach ie: 3.3514\n  approach ie the: 3.3514\n  approach used: 3.3514\n  approach used both: 3.3514\n  as: 1.9651\n  as by: 3.3514\n  as by writing: 3.3514\n  both: 2.4351\n  both by: 3.3514\n  both by ai: 3.3514\n  by: 6.7583\n  by ai: 3.3514\n  by ai in: 3.3514\n  by nlp: 3.3514\n  by nlp in: 3.3514\n  by writing: 3.3514\n  by writing grammars: 3.3514\n  coupled: 3.3514\n  coupled with: 3.3514\n  coupled with a: 3.3514\n  devising: 3.3514\n  devising heuristic: 3.3514\n  devising heuristic rules: 3.3514\n  dictionary: 3.3514\n  dictionary lookup: 3.3514\n  dictionary lookup was: 3.3514\n  first: 3.3514\n  first approach: 3.3514\n  first approach used: 3.3514\n  for: 4.8702\n  for manipulating: 3.3514\n  for manipulating symbols: 3.3514\n  for stemming: 3.3514\n  general: 2.9459\n  general and: 3.3514\n  general and by: 3.3514\n  grammars: 3.3514\n  grammars or: 3.3514\n  grammars or devising: 3.3514\n  handcoding: 3.3514\n  handcoding of: 3.3514\n  handcoding of a: 3.3514\n  heuristic: 3.3514\n  heuristic rules: 3.3514\n  heuristic rules for: 3.3514\n  historically: 3.3514\n  historically the: 3.3514\n  historically the first: 3.3514\n  ie: 3.3514\n  ie the: 3.3514\n  ie the handcoding: 3.3514\n  in: 3.4839\n  in general: 3.3514\n  in general and: 3.3514\n  in particular: 3.3514\n  in particular such: 3.3514\n  lookup: 3.3514\n  lookup was: 3.3514\n  lookup was historically: 3.3514\n  manipulating: 3.3514\n  manipulating symbols: 3.3514\n  manipulating symbols coupled: 3.3514\n  nlp: 1.8473\n  nlp in: 3.3514\n  nlp in particular: 3.3514\n  of: 2.6729\n  of a: 3.3514\n  of a set: 3.3514\n  of rules: 2.9459\n  of rules for: 3.3514\n  or: 2.6582\n  or devising: 3.3514\n  or devising heuristic: 3.3514\n  particular: 3.3514\n  particular such: 3.3514\n  particular such as: 3.3514\n  rules: 4.8702\n  rules for: 6.7028\n  rules for manipulating: 3.3514\n  rules for stemming: 3.3514\n  set: 3.3514\n  set of: 3.3514\n  set of rules: 3.3514\n  stemming: 3.3514\n  such: 2.9459\n  such as: 2.9459\n  such as by: 3.3514\n  symbolic: 2.4351\n  symbolic approach: 2.9459\n  symbolic approach ie: 3.3514\n  symbols: 3.3514\n  symbols coupled: 3.3514\n  symbols coupled with: 3.3514\n  the: 2.4226\n  the first: 3.3514\n  the first approach: 3.3514\n  the handcoding: 3.3514\n  the handcoding of: 3.3514\n  used: 2.6582\n  used both: 3.3514\n  used both by: 3.3514\n  was: 2.4351\n  was historically: 3.3514\n  was historically the: 3.3514\n  with: 1.9651\n  with a: 3.3514\n  with a dictionary: 3.3514\n  writing: 3.3514\n  writing grammars: 3.3514\n  writing grammars or: 3.3514\n\nDocument 7:\n  advantages: 3.3514\n  advantages over: 3.3514\n  advantages over the: 3.3514\n  and: 1.4055\n  and neural: 3.3514\n  and neural networks: 3.3514\n  approach: 1.9651\n  approaches: 2.6582\n  approaches which: 3.3514\n  approaches which include: 3.3514\n  both: 2.4351\n  both statistical: 3.3514\n  both statistical and: 3.3514\n  hand: 3.3514\n  hand have: 3.3514\n  hand have many: 3.3514\n  have: 2.6582\n  have many: 3.3514\n  have many advantages: 3.3514\n  include: 3.3514\n  include both: 3.3514\n  include both statistical: 3.3514\n  learning: 2.9459\n  learning approaches: 3.3514\n  learning approaches which: 3.3514\n  machine: 2.6582\n  machine learning: 2.9459\n  machine learning approaches: 3.3514\n  many: 3.3514\n  many advantages: 3.3514\n  many advantages over: 3.3514\n  networks: 2.9459\n  networks on: 3.3514\n  networks on the: 3.3514\n  neural: 2.4351\n  neural networks: 2.9459\n  neural networks on: 3.3514\n  on: 2.2528\n  on the: 2.9459\n  on the other: 3.3514\n  other: 2.9459\n  other hand: 3.3514\n  other hand have: 3.3514\n  over: 3.3514\n  over the: 3.3514\n  over the symbolic: 3.3514\n  statistical: 2.2528\n  statistical and: 3.3514\n  statistical and neural: 3.3514\n  symbolic: 2.4351\n  symbolic approach: 2.9459\n  the: 2.4226\n  the other: 3.3514\n  the other hand: 3.3514\n  the symbolic: 3.3514\n  the symbolic approach: 3.3514\n  which: 2.6582\n  which include: 3.3514\n  which include both: 3.3514\n\nDocument 8:\n  are: 2.0986\n  are commonly: 3.3514\n  are commonly used: 3.3514\n  commonly: 2.9459\n  commonly used: 3.3514\n  rulebased: 2.6582\n  rulebased systems: 3.3514\n  rulebased systems are: 3.3514\n  systems: 2.6582\n  systems are: 3.3514\n  systems are commonly: 3.3514\n  used: 2.6582\n\nDocument 9:\n  a: 1.6466\n  a period: 3.3514\n  a period of: 3.3514\n  ai: 2.6582\n  ai winter: 3.3514\n  ai winter which: 3.3514\n  and: 1.4055\n  and mids: 3.3514\n  and mids the: 3.3514\n  approach: 1.9651\n  approach ended: 3.3514\n  approach ended a: 3.3514\n  approaches: 2.6582\n  by: 2.2528\n  by the: 2.9459\n  by the inefficiencies: 3.3514\n  caused: 3.3514\n  caused by: 3.3514\n  caused by the: 3.3514\n  ended: 3.3514\n  ended a: 3.3514\n  ended a period: 3.3514\n  in: 1.7419\n  in the: 2.2528\n  in the late: 2.9459\n  inefficiencies: 3.3514\n  inefficiencies of: 3.3514\n  inefficiencies of the: 3.3514\n  late: 2.9459\n  late s: 2.9459\n  late s and: 3.3514\n  mids: 3.3514\n  mids the: 3.3514\n  mids the statistical: 3.3514\n  of: 2.6729\n  of ai: 3.3514\n  of ai winter: 3.3514\n  of the: 1.8473\n  of the rulebased: 3.3514\n  period: 3.3514\n  period of: 3.3514\n  period of ai: 3.3514\n  rulebased: 2.6582\n  rulebased approaches: 3.3514\n  s: 2.4351\n  s and: 3.3514\n  s and mids: 3.3514\n  statistical: 2.2528\n  statistical approach: 2.9459\n  statistical approach ended: 3.3514\n  the: 4.8452\n  the inefficiencies: 3.3514\n  the inefficiencies of: 3.3514\n  the late: 2.9459\n  the late s: 2.9459\n  the rulebased: 3.3514\n  the rulebased approaches: 3.3514\n  the statistical: 2.6582\n  the statistical approach: 2.9459\n  was: 2.4351\n  was caused: 3.3514\n  was caused by: 3.3514\n  which: 2.6582\n  which was: 3.3514\n  which was caused: 3.3514\n  winter: 3.3514\n  winter which: 3.3514\n  winter which was: 3.3514\n\nDocument 10:\n  announced: 3.3514\n  announced the: 3.3514\n  announced the end: 3.3514\n  applied: 3.3514\n  applied to: 3.3514\n  applied to partofspeech: 3.3514\n  approach: 1.9651\n  approachesonly: 3.3514\n  approachesonly the: 3.3514\n  approachesonly the introduction: 3.3514\n  decision: 3.3514\n  decision trees: 3.3514\n  decision trees producing: 3.3514\n  earliest: 3.3514\n  earliest decision: 3.3514\n  earliest decision trees: 3.3514\n  end: 3.3514\n  end of: 3.3514\n  end of the: 3.3514\n  hard: 3.3514\n  hard ifthen: 3.3514\n  hard ifthen rules: 3.3514\n  hidden: 3.3514\n  hidden markov: 3.3514\n  hidden markov models: 3.3514\n  ifthen: 3.3514\n  ifthen rules: 3.3514\n  ifthen rules were: 3.3514\n  introduction: 2.9459\n  introduction of: 2.9459\n  introduction of hidden: 3.3514\n  markov: 3.3514\n  markov models: 3.3514\n  markov models applied: 3.3514\n  models: 2.9459\n  models applied: 3.3514\n  models applied to: 3.3514\n  of: 4.0094\n  of hard: 3.3514\n  of hard ifthen: 3.3514\n  of hidden: 3.3514\n  of hidden markov: 3.3514\n  of the: 1.8473\n  of the old: 3.3514\n  old: 6.7028\n  old rulebased: 6.7028\n  old rulebased approach: 3.3514\n  old rulebased approachesonly: 3.3514\n  partofspeech: 2.9459\n  partofspeech tagging: 2.9459\n  partofspeech tagging announced: 3.3514\n  producing: 3.3514\n  producing systems: 3.3514\n  producing systems of: 3.3514\n  rulebased: 5.3165\n  rulebased approach: 3.3514\n  rulebased approachesonly: 3.3514\n  rulebased approachesonly the: 3.3514\n  rules: 2.4351\n  rules were: 3.3514\n  rules were still: 3.3514\n  similar: 3.3514\n  similar to: 3.3514\n  similar to the: 3.3514\n  still: 3.3514\n  still very: 3.3514\n  still very similar: 3.3514\n  systems: 2.6582\n  systems of: 3.3514\n  systems of hard: 3.3514\n  tagging: 2.9459\n  tagging announced: 3.3514\n  tagging announced the: 3.3514\n  the: 6.0565\n  the earliest: 3.3514\n  the earliest decision: 3.3514\n  the end: 3.3514\n  the end of: 3.3514\n  the introduction: 2.9459\n  the introduction of: 2.9459\n  the old: 6.7028\n  the old rulebased: 6.7028\n  to: 3.2933\n  to partofspeech: 3.3514\n  to partofspeech tagging: 3.3514\n  to the: 2.6582\n  to the old: 3.3514\n  trees: 3.3514\n  trees producing: 3.3514\n  trees producing systems: 3.3514\n  very: 3.3514\n  very similar: 3.3514\n  very similar to: 3.3514\n  were: 2.9459\n  were still: 3.3514\n  were still very: 3.3514\n\nDocument 11:\n  a: 1.6466\n  a major: 3.3514\n  a major drawback: 3.3514\n  and: 1.4055\n  and word: 3.3514\n  and word embeddings: 3.3514\n  approach: 3.9302\n  approach has: 3.3514\n  approach has been: 3.3514\n  approach using: 3.3514\n  approach using semantic: 3.3514\n  been: 2.9459\n  been replaced: 3.3514\n  been replaced by: 3.3514\n  by: 2.2528\n  by the: 2.9459\n  by the neural: 3.3514\n  capture: 3.3514\n  capture semantic: 3.3514\n  capture semantic properties: 3.3514\n  drawback: 3.3514\n  drawback of: 3.3514\n  drawback of statistical: 3.3514\n  elaborate: 3.3514\n  elaborate feature: 3.3514\n  elaborate feature engineering: 3.3514\n  embeddings: 3.3514\n  embeddings to: 3.3514\n  embeddings to capture: 3.3514\n  engineering: 3.3514\n  engineering since: 3.3514\n  engineering since the: 3.3514\n  feature: 3.3514\n  feature engineering: 3.3514\n  feature engineering since: 3.3514\n  has: 2.9459\n  has been: 3.3514\n  has been replaced: 3.3514\n  is: 1.8473\n  is that: 3.3514\n  is that they: 3.3514\n  major: 2.6582\n  major drawback: 3.3514\n  major drawback of: 3.3514\n  methods: 3.3514\n  methods is: 3.3514\n  methods is that: 3.3514\n  networks: 5.8918\n  networks and: 3.3514\n  networks and word: 3.3514\n  networks approach: 3.3514\n  networks approach using: 3.3514\n  neural: 2.4351\n  neural networks: 2.9459\n  neural networks approach: 3.3514\n  of: 2.6729\n  of statistical: 3.3514\n  of statistical methods: 3.3514\n  of words: 3.3514\n  properties: 3.3514\n  properties of: 3.3514\n  properties of words: 3.3514\n  replaced: 3.3514\n  replaced by: 3.3514\n  replaced by the: 3.3514\n  require: 3.3514\n  require elaborate: 3.3514\n  require elaborate feature: 3.3514\n  semantic: 6.7028\n  semantic networks: 3.3514\n  semantic networks and: 3.3514\n  semantic properties: 3.3514\n  semantic properties of: 3.3514\n  since: 2.9459\n  since the: 2.9459\n  since the statistical: 2.9459\n  statistical: 4.5055\n  statistical approach: 2.9459\n  statistical approach has: 3.3514\n  statistical methods: 3.3514\n  statistical methods is: 3.3514\n  that: 2.2528\n  that they: 3.3514\n  that they require: 3.3514\n  the: 2.4226\n  the neural: 3.3514\n  the neural networks: 3.3514\n  the statistical: 2.6582\n  the statistical approach: 2.9459\n  they: 2.6582\n  they require: 3.3514\n  they require elaborate: 3.3514\n  to: 1.6466\n  to capture: 3.3514\n  to capture semantic: 3.3514\n  using: 2.9459\n  using semantic: 3.3514\n  using semantic networks: 3.3514\n  word: 2.9459\n  word embeddings: 3.3514\n  word embeddings to: 3.3514\n  words: 3.3514\n\nDocument 12:\n  and: 1.4055\n  and dependency: 3.3514\n  and dependency parsing: 3.3514\n  anymore: 3.3514\n  are: 2.0986\n  are not: 3.3514\n  are not needed: 3.3514\n  dependency: 3.3514\n  dependency parsing: 3.3514\n  dependency parsing are: 3.3514\n  eg: 2.4351\n  eg partofspeech: 3.3514\n  eg partofspeech tagging: 3.3514\n  intermediate: 2.9459\n  intermediate tasks: 3.3514\n  intermediate tasks eg: 3.3514\n  needed: 3.3514\n  needed anymore: 3.3514\n  not: 2.9459\n  not needed: 3.3514\n  not needed anymore: 3.3514\n  parsing: 3.3514\n  parsing are: 3.3514\n  parsing are not: 3.3514\n  partofspeech: 2.9459\n  partofspeech tagging: 2.9459\n  partofspeech tagging and: 3.3514\n  tagging: 2.9459\n  tagging and: 3.3514\n  tagging and dependency: 3.3514\n  tasks: 1.9651\n  tasks eg: 3.3514\n  tasks eg partofspeech: 3.3514\n\nDocument 13:\n  alignment: 3.3514\n  alignment previously: 3.3514\n  alignment previously necessary: 3.3514\n  as: 1.9651\n  as word: 3.3514\n  as word alignment: 3.3514\n  based: 2.4351\n  based on: 2.4351\n  based on thennewly: 3.3514\n  for: 2.4351\n  for statistical: 3.3514\n  for statistical machine: 3.3514\n  intermediate: 2.9459\n  intermediate steps: 3.3514\n  intermediate steps such: 3.3514\n  invented: 3.3514\n  invented sequencetosequence: 3.3514\n  invented sequencetosequence transformations: 3.3514\n  machine: 5.3165\n  machine translation: 6.7028\n  machine translation based: 3.3514\n  made: 2.9459\n  made obsolete: 3.3514\n  made obsolete the: 3.3514\n  necessary: 3.3514\n  necessary for: 3.3514\n  necessary for statistical: 3.3514\n  neural: 2.4351\n  neural machine: 3.3514\n  neural machine translation: 3.3514\n  obsolete: 3.3514\n  obsolete the: 3.3514\n  obsolete the intermediate: 3.3514\n  on: 2.2528\n  on thennewly: 3.3514\n  on thennewly invented: 3.3514\n  previously: 3.3514\n  previously necessary: 3.3514\n  previously necessary for: 3.3514\n  sequencetosequence: 3.3514\n  sequencetosequence transformations: 3.3514\n  sequencetosequence transformations made: 3.3514\n  statistical: 2.2528\n  statistical machine: 3.3514\n  statistical machine translation: 3.3514\n  steps: 3.3514\n  steps such: 3.3514\n  steps such as: 3.3514\n  such: 2.9459\n  such as: 2.9459\n  such as word: 3.3514\n  the: 1.2113\n  the intermediate: 3.3514\n  the intermediate steps: 3.3514\n  thennewly: 3.3514\n  thennewly invented: 3.3514\n  thennewly invented sequencetosequence: 3.3514\n  transformations: 3.3514\n  transformations made: 3.3514\n  transformations made obsolete: 3.3514\n  translation: 6.7028\n  translation based: 3.3514\n  translation based on: 3.3514\n  word: 2.9459\n  word alignment: 3.3514\n  word alignment previously: 3.3514\n\nDocument 14:\n  a: 1.6466\n  a list: 3.3514\n  a list of: 3.3514\n  aid: 3.3514\n  aid in: 3.3514\n  aid in solving: 3.3514\n  applications: 2.9459\n  applications while: 3.3514\n  applications while others: 3.3514\n  are: 2.0986\n  are used: 3.3514\n  are used to: 3.3514\n  as: 1.9651\n  as subtasks: 3.3514\n  as subtasks that: 3.3514\n  commonly: 5.8918\n  commonly researched: 3.3514\n  commonly researched tasks: 3.3514\n  commonly serve: 3.3514\n  commonly serve as: 3.3514\n  direct: 3.3514\n  direct realworld: 3.3514\n  direct realworld applications: 3.3514\n  following: 3.3514\n  following is: 3.3514\n  following is a: 3.3514\n  have: 2.6582\n  have direct: 3.3514\n  have direct realworld: 3.3514\n  in: 3.4839\n  in natural: 2.4351\n  in natural language: 2.4351\n  in solving: 3.3514\n  in solving larger: 3.3514\n  is: 1.8473\n  is a: 2.9459\n  is a list: 3.3514\n  language: 1.6466\n  language processing: 1.9651\n  language processing some: 3.3514\n  larger: 3.3514\n  larger tasks: 3.3514\n  list: 3.3514\n  list of: 3.3514\n  list of some: 3.3514\n  more: 2.6582\n  more commonly: 3.3514\n  more commonly serve: 3.3514\n  most: 2.6582\n  most commonly: 3.3514\n  most commonly researched: 3.3514\n  natural: 1.7419\n  natural language: 1.7419\n  natural language processing: 1.9651\n  of: 4.0094\n  of some: 3.3514\n  of some of: 3.3514\n  of the: 1.8473\n  of the most: 3.3514\n  of these: 3.3514\n  of these tasks: 3.3514\n  others: 3.3514\n  others more: 3.3514\n  others more commonly: 3.3514\n  processing: 1.9651\n  processing some: 3.3514\n  processing some of: 3.3514\n  realworld: 3.3514\n  realworld applications: 3.3514\n  realworld applications while: 3.3514\n  researched: 3.3514\n  researched tasks: 3.3514\n  researched tasks in: 3.3514\n  serve: 3.3514\n  serve as: 3.3514\n  serve as subtasks: 3.3514\n  solving: 3.3514\n  solving larger: 3.3514\n  solving larger tasks: 3.3514\n  some: 6.7028\n  some of: 6.7028\n  some of the: 3.3514\n  some of these: 3.3514\n  subtasks: 3.3514\n  subtasks that: 3.3514\n  subtasks that are: 3.3514\n  tasks: 5.8952\n  tasks have: 3.3514\n  tasks have direct: 3.3514\n  tasks in: 2.9459\n  tasks in natural: 2.9459\n  that: 2.2528\n  that are: 3.3514\n  that are used: 3.3514\n  the: 2.4226\n  the following: 3.3514\n  the following is: 3.3514\n  the most: 3.3514\n  the most commonly: 3.3514\n  these: 3.3514\n  these tasks: 3.3514\n  these tasks have: 3.3514\n  to: 1.6466\n  to aid: 3.3514\n  to aid in: 3.3514\n  used: 2.6582\n  used to: 3.3514\n  used to aid: 3.3514\n  while: 3.3514\n  while others: 3.3514\n  while others more: 3.3514\n\nDocument 15:\n  a: 1.6466\n  a coarse: 3.3514\n  a coarse division: 3.3514\n  are: 2.0986\n  are closely: 3.3514\n  are closely intertwined: 3.3514\n  be: 2.9459\n  be subdivided: 3.3514\n  be subdivided into: 3.3514\n  below: 3.3514\n  can: 2.9459\n  can be: 2.9459\n  can be subdivided: 3.3514\n  categories: 3.3514\n  categories for: 3.3514\n  categories for convenience: 3.3514\n  closely: 2.9459\n  closely intertwined: 3.3514\n  closely intertwined they: 3.3514\n  coarse: 3.3514\n  coarse division: 3.3514\n  coarse division is: 3.3514\n  convenience: 3.3514\n  convenience a: 3.3514\n  convenience a coarse: 3.3514\n  division: 3.3514\n  division is: 3.3514\n  division is given: 3.3514\n  for: 2.4351\n  for convenience: 3.3514\n  for convenience a: 3.3514\n  given: 2.9459\n  given below: 3.3514\n  intertwined: 3.3514\n  intertwined they: 3.3514\n  intertwined they can: 3.3514\n  into: 3.3514\n  into categories: 3.3514\n  into categories for: 3.3514\n  is: 1.8473\n  is given: 3.3514\n  is given below: 3.3514\n  language: 1.6466\n  language processing: 1.9651\n  language processing tasks: 3.3514\n  natural: 1.7419\n  natural language: 1.7419\n  natural language processing: 1.9651\n  processing: 1.9651\n  processing tasks: 3.3514\n  processing tasks are: 3.3514\n  subdivided: 3.3514\n  subdivided into: 3.3514\n  subdivided into categories: 3.3514\n  tasks: 1.9651\n  tasks are: 3.3514\n  tasks are closely: 3.3514\n  they: 2.6582\n  they can: 3.3514\n  they can be: 3.3514\n  though: 2.9459\n  though natural: 3.3514\n  though natural language: 3.3514\n\nDocument 16:\n  among: 2.9459\n  among the: 3.3514\n  among the topics: 3.3514\n  as: 1.9651\n  as of: 3.3514\n  as of three: 3.3514\n  based: 2.4351\n  based on: 2.4351\n  based on longstanding: 3.3514\n  be: 2.9459\n  be observed: 3.3514\n  can: 2.9459\n  can be: 2.9459\n  can be observed: 3.3514\n  conll: 2.9459\n  conll shared: 2.9459\n  conll shared tasks: 2.9459\n  directions: 2.9459\n  directions of: 3.3514\n  directions of nlp: 3.3514\n  extrapolate: 3.3514\n  extrapolate future: 3.3514\n  extrapolate future directions: 3.3514\n  field: 3.3514\n  field it: 3.3514\n  field it is: 3.3514\n  future: 3.3514\n  future directions: 3.3514\n  future directions of: 3.3514\n  in: 1.7419\n  in the: 2.2528\n  in the field: 3.3514\n  is: 1.8473\n  is possible: 3.3514\n  is possible to: 3.3514\n  it: 2.6582\n  it is: 2.9459\n  it is possible: 3.3514\n  longstanding: 6.7028\n  longstanding series: 3.3514\n  longstanding series of: 3.3514\n  longstanding trends: 3.3514\n  longstanding trends in: 3.3514\n  nlp: 1.8473\n  nlp as: 2.9459\n  nlp as of: 3.3514\n  observed: 3.3514\n  of: 5.3459\n  of conll: 3.3514\n  of conll shared: 3.3514\n  of nlp: 2.6582\n  of nlp as: 3.3514\n  of the: 1.8473\n  of the longstanding: 3.3514\n  of three: 3.3514\n  of three trends: 3.3514\n  on: 2.2528\n  on longstanding: 3.3514\n  on longstanding trends: 3.3514\n  possible: 3.3514\n  possible to: 3.3514\n  possible to extrapolate: 3.3514\n  series: 3.3514\n  series of: 3.3514\n  series of conll: 3.3514\n  shared: 2.9459\n  shared tasks: 2.9459\n  shared tasks can: 3.3514\n  tasks: 1.9651\n  tasks can: 3.3514\n  tasks can be: 3.3514\n  the: 3.6339\n  the field: 3.3514\n  the field it: 3.3514\n  the longstanding: 3.3514\n  the longstanding series: 3.3514\n  the topics: 3.3514\n  the topics of: 3.3514\n  three: 3.3514\n  three trends: 3.3514\n  three trends among: 3.3514\n  to: 1.6466\n  to extrapolate: 3.3514\n  to extrapolate future: 3.3514\n  topics: 3.3514\n  topics of: 3.3514\n  topics of the: 3.3514\n  trends: 5.8918\n  trends among: 2.9459\n  trends among the: 3.3514\n  trends in: 3.3514\n  trends in the: 3.3514\n\nDocument 17:\n  above: 3.3514\n  advanced: 3.3514\n  advanced aspects: 3.3514\n  advanced aspects of: 3.3514\n  among: 2.9459\n  among conll: 3.3514\n  among conll shared: 3.3514\n  and: 1.4055\n  and apparent: 3.3514\n  and apparent comprehension: 3.3514\n  apparent: 3.3514\n  apparent comprehension: 3.3514\n  apparent comprehension of: 3.3514\n  applications: 2.9459\n  applications involve: 3.3514\n  applications involve aspects: 3.3514\n  aspects: 5.8918\n  aspects of: 3.3514\n  aspects of cognitive: 3.3514\n  aspects that: 3.3514\n  aspects that emulate: 3.3514\n  behaviour: 6.7028\n  behaviour and: 3.3514\n  behaviour and apparent: 3.3514\n  behaviour represents: 3.3514\n  behaviour represents one: 3.3514\n  broadly: 3.3514\n  broadly speaking: 3.3514\n  broadly speaking the: 3.3514\n  cognitive: 2.4351\n  cognitive behaviour: 3.3514\n  cognitive behaviour represents: 3.3514\n  comprehension: 3.3514\n  comprehension of: 3.3514\n  comprehension of natural: 3.3514\n  conll: 2.9459\n  conll shared: 2.9459\n  conll shared tasks: 2.9459\n  developmental: 3.3514\n  developmental trajectories: 3.3514\n  developmental trajectories of: 3.3514\n  emulate: 3.3514\n  emulate intelligent: 3.3514\n  emulate intelligent behaviour: 3.3514\n  higherlevel: 3.3514\n  higherlevel nlp: 3.3514\n  higherlevel nlp applications: 3.3514\n  increasingly: 3.3514\n  increasingly advanced: 3.3514\n  increasingly advanced aspects: 3.3514\n  intelligent: 3.3514\n  intelligent behaviour: 3.3514\n  intelligent behaviour and: 3.3514\n  involve: 3.3514\n  involve aspects: 3.3514\n  involve aspects that: 3.3514\n  language: 1.6466\n  language more: 3.3514\n  language more broadly: 3.3514\n  more: 2.6582\n  more broadly: 3.3514\n  more broadly speaking: 3.3514\n  most: 2.6582\n  most higherlevel: 3.3514\n  most higherlevel nlp: 3.3514\n  natural: 1.7419\n  natural language: 1.7419\n  natural language more: 3.3514\n  nlp: 3.6946\n  nlp applications: 3.3514\n  nlp applications involve: 3.3514\n  nlp see: 3.3514\n  nlp see trends: 3.3514\n  of: 6.6824\n  of cognitive: 2.6582\n  of cognitive behaviour: 3.3514\n  of increasingly: 3.3514\n  of increasingly advanced: 3.3514\n  of natural: 2.9459\n  of natural language: 2.9459\n  of nlp: 2.6582\n  of nlp see: 3.3514\n  of the: 1.8473\n  of the developmental: 3.3514\n  one: 3.3514\n  one of: 3.3514\n  one of the: 3.3514\n  operationalization: 3.3514\n  operationalization of: 3.3514\n  operationalization of increasingly: 3.3514\n  represents: 3.3514\n  represents one: 3.3514\n  represents one of: 3.3514\n  see: 2.9459\n  see trends: 3.3514\n  see trends among: 3.3514\n  shared: 2.9459\n  shared tasks: 2.9459\n  shared tasks above: 3.3514\n  speaking: 3.3514\n  speaking the: 3.3514\n  speaking the technical: 3.3514\n  tasks: 1.9651\n  tasks above: 3.3514\n  technical: 3.3514\n  technical operationalization: 3.3514\n  technical operationalization of: 3.3514\n  that: 2.2528\n  that emulate: 3.3514\n  that emulate intelligent: 3.3514\n  the: 2.4226\n  the developmental: 3.3514\n  the developmental trajectories: 3.3514\n  the technical: 3.3514\n  the technical operationalization: 3.3514\n  trajectories: 3.3514\n  trajectories of: 3.3514\n  trajectories of nlp: 3.3514\n  trends: 2.9459\n  trends among: 2.9459\n  trends among conll: 3.3514\n\nDocument 18:\n  acquiring: 3.3514\n  acquiring knowledge: 3.3514\n  acquiring knowledge and: 3.3514\n  action: 3.3514\n  action or: 3.3514\n  action or process: 3.3514\n  age: 3.3514\n  age of: 3.3514\n  age of symbolic: 3.3514\n  an: 2.4351\n  an interdisciplinary: 3.3514\n  an interdisciplinary branch: 3.3514\n  and: 7.0273\n  and its: 3.3514\n  and its processes: 3.3514\n  and linguistics: 3.3514\n  and linguistics especially: 3.3514\n  and research: 3.3514\n  and research from: 3.3514\n  and the: 2.9459\n  and the senses: 3.3514\n  and understanding: 3.3514\n  and understanding through: 3.3514\n  area: 3.3514\n  area of: 3.3514\n  area of computational: 3.3514\n  both: 2.4351\n  both psychology: 3.3514\n  both psychology and: 3.3514\n  branch: 3.3514\n  branch of: 3.3514\n  branch of linguistics: 3.3514\n  cognition: 3.3514\n  cognition refers: 3.3514\n  cognition refers to: 3.3514\n  cognitive: 7.3053\n  cognitive linguistics: 2.6582\n  cognitive linguistics is: 3.3514\n  cognitive science: 2.9459\n  cognitive science is: 3.3514\n  cognitive studies: 3.3514\n  combining: 3.3514\n  combining knowledge: 3.3514\n  combining knowledge and: 3.3514\n  computational: 2.4351\n  computational linguistics: 2.9459\n  computational linguistics maintained: 3.3514\n  during: 2.9459\n  during the: 2.9459\n  during the age: 3.3514\n  especially: 2.9459\n  especially during: 3.3514\n  especially during the: 3.3514\n  experience: 3.3514\n  experience and: 3.3514\n  experience and the: 3.3514\n  from: 2.9459\n  from both: 3.3514\n  from both psychology: 3.3514\n  interdisciplinary: 6.7028\n  interdisciplinary branch: 3.3514\n  interdisciplinary branch of: 3.3514\n  interdisciplinary scientific: 3.3514\n  interdisciplinary scientific study: 3.3514\n  is: 3.6946\n  is an: 3.3514\n  is an interdisciplinary: 3.3514\n  is the: 3.3514\n  is the interdisciplinary: 3.3514\n  its: 2.9459\n  its processes: 3.3514\n  its processes cognitive: 3.3514\n  knowledge: 5.8918\n  knowledge and: 6.7028\n  knowledge and research: 3.3514\n  knowledge and understanding: 3.3514\n  linguistics: 9.0111\n  linguistics combining: 3.3514\n  linguistics combining knowledge: 3.3514\n  linguistics especially: 3.3514\n  linguistics especially during: 3.3514\n  linguistics is: 3.3514\n  linguistics is an: 3.3514\n  linguistics maintained: 3.3514\n  linguistics maintained strong: 3.3514\n  maintained: 3.3514\n  maintained strong: 3.3514\n  maintained strong ties: 3.3514\n  mental: 3.3514\n  mental action: 3.3514\n  mental action or: 3.3514\n  mind: 3.3514\n  mind and: 3.3514\n  mind and its: 3.3514\n  nlp: 1.8473\n  nlp the: 3.3514\n  nlp the area: 3.3514\n  of: 6.6824\n  of acquiring: 3.3514\n  of acquiring knowledge: 3.3514\n  of computational: 3.3514\n  of computational linguistics: 3.3514\n  of linguistics: 2.6582\n  of linguistics combining: 3.3514\n  of symbolic: 2.9459\n  of symbolic nlp: 2.9459\n  of the: 1.8473\n  of the mind: 3.3514\n  or: 2.6582\n  or process: 3.3514\n  or process of: 3.3514\n  process: 2.9459\n  process of: 3.3514\n  process of acquiring: 3.3514\n  processes: 3.3514\n  processes cognitive: 3.3514\n  processes cognitive linguistics: 3.3514\n  psychology: 3.3514\n  psychology and: 3.3514\n  psychology and linguistics: 3.3514\n  refers: 3.3514\n  refers to: 3.3514\n  refers to the: 3.3514\n  research: 3.3514\n  research from: 3.3514\n  research from both: 3.3514\n  science: 2.6582\n  science is: 3.3514\n  science is the: 3.3514\n  scientific: 3.3514\n  scientific study: 3.3514\n  scientific study of: 3.3514\n  senses: 3.3514\n  senses cognitive: 3.3514\n  senses cognitive science: 3.3514\n  strong: 3.3514\n  strong ties: 3.3514\n  strong ties with: 3.3514\n  studies: 3.3514\n  study: 3.3514\n  study of: 3.3514\n  study of the: 3.3514\n  symbolic: 2.4351\n  symbolic nlp: 2.9459\n  symbolic nlp the: 3.3514\n  the: 7.2679\n  the age: 3.3514\n  the age of: 3.3514\n  the area: 3.3514\n  the area of: 3.3514\n  the interdisciplinary: 3.3514\n  the interdisciplinary scientific: 3.3514\n  the mental: 3.3514\n  the mental action: 3.3514\n  the mind: 3.3514\n  the mind and: 3.3514\n  the senses: 3.3514\n  the senses cognitive: 3.3514\n  thought: 3.3514\n  thought experience: 3.3514\n  thought experience and: 3.3514\n  through: 2.9459\n  through thought: 3.3514\n  through thought experience: 3.3514\n  ties: 2.9459\n  ties with: 2.9459\n  ties with cognitive: 2.9459\n  to: 1.6466\n  to the: 2.6582\n  to the mental: 3.3514\n  understanding: 2.6582\n  understanding through: 3.3514\n  understanding through thought: 3.3514\n  with: 1.9651\n  with cognitive: 2.9459\n  with cognitive studies: 3.3514\n\nDocument 19:\n  a: 1.6466\n  a methodology: 3.3514\n  a methodology to: 3.3514\n  algorithms: 2.9459\n  algorithms through: 3.3514\n  algorithms through the: 3.3514\n  along: 3.3514\n  along with: 3.3514\n  along with the: 3.3514\n  an: 2.4351\n  an example: 3.3514\n  an example george: 3.3514\n  as: 1.9651\n  as an: 2.9459\n  as an example: 3.3514\n  aspects: 2.9459\n  build: 3.3514\n  build natural: 3.3514\n  build natural language: 3.3514\n  cognitive: 4.8702\n  cognitive linguistics: 2.6582\n  cognitive linguistics with: 3.3514\n  cognitive science: 2.9459\n  cognitive science along: 3.3514\n  defining: 3.3514\n  defining aspects: 3.3514\n  example: 3.3514\n  example george: 3.3514\n  example george lakoff: 3.3514\n  findings: 3.3514\n  findings of: 3.3514\n  findings of cognitive: 3.3514\n  george: 3.3514\n  george lakoff: 3.3514\n  george lakoff offers: 3.3514\n  lakoff: 3.3514\n  lakoff offers: 3.3514\n  lakoff offers a: 3.3514\n  language: 1.6466\n  language processing: 1.9651\n  language processing nlp: 2.9459\n  linguistics: 2.2528\n  linguistics with: 3.3514\n  linguistics with two: 3.3514\n  methodology: 3.3514\n  methodology to: 3.3514\n  methodology to build: 3.3514\n  natural: 1.7419\n  natural language: 1.7419\n  natural language processing: 1.9651\n  nlp: 1.8473\n  nlp algorithms: 3.3514\n  nlp algorithms through: 3.3514\n  of: 2.6729\n  of cognitive: 5.3165\n  of cognitive linguistics: 3.3514\n  of cognitive science: 3.3514\n  offers: 3.3514\n  offers a: 3.3514\n  offers a methodology: 3.3514\n  perspective: 3.3514\n  perspective of: 3.3514\n  perspective of cognitive: 3.3514\n  processing: 1.9651\n  processing nlp: 2.9459\n  processing nlp algorithms: 3.3514\n  science: 2.6582\n  science along: 3.3514\n  science along with: 3.3514\n  the: 2.4226\n  the findings: 3.3514\n  the findings of: 3.3514\n  the perspective: 3.3514\n  the perspective of: 3.3514\n  through: 2.9459\n  through the: 3.3514\n  through the perspective: 3.3514\n  to: 1.6466\n  to build: 3.3514\n  to build natural: 3.3514\n  two: 3.3514\n  two defining: 3.3514\n  two defining aspects: 3.3514\n  with: 3.9302\n  with the: 2.6582\n  with the findings: 3.3514\n  with two: 3.3514\n  with two defining: 3.3514\n\nDocument 20:\n  achieve: 3.3514\n  achieve explainability: 3.3514\n  achieve explainability eg: 3.3514\n  acl: 3.3514\n  acl more: 3.3514\n  acl more recently: 3.3514\n  actr: 3.3514\n  actr however: 3.3514\n  actr however with: 3.3514\n  addressed: 3.3514\n  addressed since: 3.3514\n  addressed since the: 3.3514\n  ai: 2.6582\n  ai likewise: 3.3514\n  ai likewise ideas: 3.3514\n  although: 3.3514\n  although rarely: 3.3514\n  although rarely made: 3.3514\n  an: 2.4351\n  an approach: 3.3514\n  an approach to: 3.3514\n  and: 7.0273\n  and cognitive: 3.3514\n  and cognitive neuroscience: 3.3514\n  and developments: 3.3514\n  and developments in: 3.3514\n  and new: 3.3514\n  and new directions: 3.3514\n  and technologies: 3.3514\n  and technologies using: 3.3514\n  and theoretician: 3.3514\n  and theoretician at: 3.3514\n  approach: 1.9651\n  approach to: 2.9459\n  approach to achieve: 3.3514\n  approaches: 5.3165\n  approaches and: 3.3514\n  approaches and new: 3.3514\n  approaches to: 3.3514\n  approaches to develop: 3.3514\n  are: 4.1972\n  are inherent: 3.3514\n  are inherent to: 3.3514\n  are part: 3.3514\n  are part of: 3.3514\n  artificial: 5.3165\n  artificial general: 3.3514\n  artificial general intelligence: 3.3514\n  artificial intelligence: 2.6582\n  artificial intelligence specifically: 3.3514\n  as: 3.9302\n  as an: 2.9459\n  as an approach: 3.3514\n  as measured: 3.3514\n  as measured by: 3.3514\n  at: 2.9459\n  at university: 3.3514\n  at university college: 3.3514\n  based: 2.4351\n  based on: 2.4351\n  based on the: 3.3514\n  been: 8.8377\n  been less: 3.3514\n  been less frequently: 3.3514\n  been pursued: 3.3514\n  been pursued in: 3.3514\n  been revived: 3.3514\n  been revived as: 3.3514\n  british: 3.3514\n  british neuroscientist: 3.3514\n  british neuroscientist and: 3.3514\n  but: 3.3514\n  but they: 3.3514\n  but they have: 3.3514\n  by: 4.5055\n  by british: 3.3514\n  by british neuroscientist: 3.3514\n  by presence: 3.3514\n  by presence on: 3.3514\n  cognitive: 17.0456\n  cognitive ai: 3.3514\n  cognitive ai likewise: 3.3514\n  cognitive grammar: 3.3514\n  cognitive grammar functional: 3.3514\n  cognitive linguistics: 2.6582\n  cognitive linguistics are: 3.3514\n  cognitive models: 3.3514\n  cognitive models towards: 3.3514\n  cognitive neuroscience: 3.3514\n  cognitive neuroscience eg: 3.3514\n  cognitive nlp: 6.7028\n  cognitive nlp are: 3.3514\n  cognitive nlp have: 3.3514\n  college: 3.3514\n  college london: 3.3514\n  college london karl: 3.3514\n  computational: 2.4351\n  computational psycholinguistics: 3.3514\n  computational psycholinguistics and: 3.3514\n  conferences: 3.3514\n  conferences of: 3.3514\n  conferences of the: 3.3514\n  construction: 3.3514\n  construction grammar: 3.3514\n  construction grammar computational: 3.3514\n  context: 3.3514\n  context of: 3.3514\n  context of various: 3.3514\n  develop: 3.3514\n  develop cognitive: 3.3514\n  develop cognitive models: 3.3514\n  developments: 3.3514\n  developments in: 3.3514\n  developments in artificial: 3.3514\n  directions: 2.9459\n  directions in: 3.3514\n  directions in artificial: 3.3514\n  during: 2.9459\n  during the: 2.9459\n  during the s: 3.3514\n  eg: 7.3053\n  eg actr: 3.3514\n  eg actr however: 3.3514\n  eg of: 3.3514\n  eg of cognitive: 3.3514\n  eg under: 3.3514\n  eg under the: 3.3514\n  energy: 3.3514\n  energy principle: 3.3514\n  energy principle by: 3.3514\n  explainability: 3.3514\n  explainability eg: 3.3514\n  explainability eg under: 3.3514\n  explicit: 3.3514\n  explicit and: 3.3514\n  explicit and developments: 3.3514\n  frameworks: 6.7028\n  frameworks eg: 3.3514\n  frameworks eg of: 3.3514\n  frameworks have: 3.3514\n  frameworks have been: 3.3514\n  free: 3.3514\n  free energy: 3.3514\n  free energy principle: 3.3514\n  frequently: 3.3514\n  frequently addressed: 3.3514\n  frequently addressed since: 3.3514\n  friston: 3.3514\n  functional: 3.3514\n  functional grammar: 3.3514\n  functional grammar construction: 3.3514\n  general: 2.9459\n  general intelligence: 3.3514\n  general intelligence based: 3.3514\n  grammar: 8.8377\n  grammar computational: 3.3514\n  grammar computational psycholinguistics: 3.3514\n  grammar construction: 3.3514\n  grammar construction grammar: 3.3514\n  grammar functional: 3.3514\n  grammar functional grammar: 3.3514\n  have: 7.9747\n  have been: 10.0541\n  have been less: 3.3514\n  have been pursued: 3.3514\n  have been revived: 3.3514\n  heritage: 3.3514\n  heritage of: 3.3514\n  heritage of nlp: 3.3514\n  historical: 3.3514\n  historical heritage: 3.3514\n  historical heritage of: 3.3514\n  however: 2.9459\n  however with: 3.3514\n  however with limited: 3.3514\n  ideas: 6.7028\n  ideas of: 6.7028\n  ideas of cognitive: 6.7028\n  in: 6.9677\n  in artificial: 6.7028\n  in artificial general: 3.3514\n  in artificial intelligence: 3.3514\n  in mainstream: 3.3514\n  in mainstream nlp: 3.3514\n  in the: 2.2528\n  in the context: 3.3514\n  inherent: 3.3514\n  inherent to: 3.3514\n  inherent to neural: 3.3514\n  intelligence: 5.3165\n  intelligence based: 3.3514\n  intelligence based on: 3.3514\n  intelligence specifically: 3.3514\n  intelligence specifically tools: 3.3514\n  j: 3.3514\n  j friston: 3.3514\n  karl: 3.3514\n  karl j: 3.3514\n  karl j friston: 3.3514\n  language: 1.6466\n  language model: 3.3514\n  language model approaches: 3.3514\n  large: 3.3514\n  large language: 3.3514\n  large language model: 3.3514\n  less: 3.3514\n  less frequently: 3.3514\n  less frequently addressed: 3.3514\n  likewise: 3.3514\n  likewise ideas: 3.3514\n  likewise ideas of: 3.3514\n  limited: 3.3514\n  limited uptake: 3.3514\n  limited uptake in: 3.3514\n  linguistics: 2.2528\n  linguistics are: 3.3514\n  linguistics are part: 3.3514\n  london: 3.3514\n  london karl: 3.3514\n  london karl j: 3.3514\n  made: 2.9459\n  made explicit: 3.3514\n  made explicit and: 3.3514\n  mainstream: 3.3514\n  mainstream nlp: 3.3514\n  mainstream nlp as: 3.3514\n  major: 2.6582\n  major conferences: 3.3514\n  major conferences of: 3.3514\n  measured: 3.3514\n  measured by: 3.3514\n  measured by presence: 3.3514\n  model: 3.3514\n  model approaches: 3.3514\n  model approaches and: 3.3514\n  models: 5.8918\n  models multimodal: 3.3514\n  models multimodal nlp: 3.3514\n  models towards: 3.3514\n  models towards technically: 3.3514\n  more: 2.6582\n  more recently: 3.3514\n  more recently ideas: 3.3514\n  multimodal: 3.3514\n  multimodal nlp: 3.3514\n  multimodal nlp although: 3.3514\n  neural: 2.4351\n  neural models: 3.3514\n  neural models multimodal: 3.3514\n  neuroscience: 3.3514\n  neuroscience eg: 3.3514\n  neuroscience eg actr: 3.3514\n  neuroscientist: 3.3514\n  neuroscientist and: 3.3514\n  neuroscientist and theoretician: 3.3514\n  nevertheless: 3.3514\n  nevertheless approaches: 3.3514\n  nevertheless approaches to: 3.3514\n  new: 3.3514\n  new directions: 3.3514\n  new directions in: 3.3514\n  nlp: 9.2365\n  nlp although: 3.3514\n  nlp although rarely: 3.3514\n  nlp are: 3.3514\n  nlp are inherent: 3.3514\n  nlp as: 2.9459\n  nlp as measured: 3.3514\n  nlp but: 3.3514\n  nlp but they: 3.3514\n  nlp have: 3.3514\n  nlp have been: 3.3514\n  notion: 3.3514\n  notion of: 3.3514\n  notion of cognitive: 3.3514\n  of: 10.6918\n  of cognitive: 10.6329\n  of cognitive ai: 3.3514\n  of cognitive grammar: 3.3514\n  of cognitive nlp: 6.7028\n  of nlp: 2.6582\n  of nlp but: 3.3514\n  of the: 3.6946\n  of the acl: 3.3514\n  of the historical: 3.3514\n  of various: 3.3514\n  of various frameworks: 3.3514\n  on: 4.5055\n  on major: 3.3514\n  on major conferences: 3.3514\n  on the: 2.9459\n  on the free: 3.3514\n  operationalizable: 3.3514\n  operationalizable frameworks: 3.3514\n  operationalizable frameworks have: 3.3514\n  part: 3.3514\n  part of: 3.3514\n  part of the: 3.3514\n  presence: 3.3514\n  presence on: 3.3514\n  presence on major: 3.3514\n  principle: 3.3514\n  principle by: 3.3514\n  principle by british: 3.3514\n  psycholinguistics: 3.3514\n  psycholinguistics and: 3.3514\n  psycholinguistics and cognitive: 3.3514\n  pursued: 3.3514\n  pursued in: 3.3514\n  pursued in the: 3.3514\n  rarely: 3.3514\n  rarely made: 3.3514\n  rarely made explicit: 3.3514\n  recently: 3.3514\n  recently ideas: 3.3514\n  recently ideas of: 3.3514\n  revived: 3.3514\n  revived as: 3.3514\n  revived as an: 3.3514\n  s: 2.4351\n  s nevertheless: 3.3514\n  s nevertheless approaches: 3.3514\n  since: 2.9459\n  since the: 2.9459\n  since the statistical: 2.9459\n  specifically: 3.3514\n  specifically tools: 3.3514\n  specifically tools and: 3.3514\n  statistical: 2.2528\n  statistical turn: 3.3514\n  statistical turn during: 3.3514\n  technically: 3.3514\n  technically operationalizable: 3.3514\n  technically operationalizable frameworks: 3.3514\n  technologies: 3.3514\n  technologies using: 3.3514\n  technologies using large: 3.3514\n  the: 8.4792\n  the acl: 3.3514\n  the acl more: 3.3514\n  the context: 3.3514\n  the context of: 3.3514\n  the free: 3.3514\n  the free energy: 3.3514\n  the historical: 3.3514\n  the historical heritage: 3.3514\n  the notion: 3.3514\n  the notion of: 3.3514\n  the s: 2.6582\n  the s nevertheless: 3.3514\n  the statistical: 2.6582\n  the statistical turn: 3.3514\n  theoretician: 3.3514\n  theoretician at: 3.3514\n  theoretician at university: 3.3514\n  they: 2.6582\n  they have: 3.3514\n  they have been: 3.3514\n  ties: 2.9459\n  ties with: 2.9459\n  ties with cognitive: 2.9459\n  to: 4.9399\n  to achieve: 3.3514\n  to achieve explainability: 3.3514\n  to develop: 3.3514\n  to develop cognitive: 3.3514\n  to neural: 3.3514\n  to neural models: 3.3514\n  tools: 3.3514\n  tools and: 3.3514\n  tools and technologies: 3.3514\n  towards: 3.3514\n  towards technically: 3.3514\n  towards technically operationalizable: 3.3514\n  turn: 3.3514\n  turn during: 3.3514\n  turn during the: 3.3514\n  under: 3.3514\n  under the: 3.3514\n  under the notion: 3.3514\n  university: 3.3514\n  university college: 3.3514\n  university college london: 3.3514\n  uptake: 3.3514\n  uptake in: 3.3514\n  uptake in mainstream: 3.3514\n  using: 2.9459\n  using large: 3.3514\n  using large language: 3.3514\n  various: 3.3514\n  various frameworks: 3.3514\n  various frameworks eg: 3.3514\n  with: 3.9302\n  with cognitive: 2.9459\n  with cognitive linguistics: 3.3514\n  with limited: 3.3514\n  with limited uptake: 3.3514\n","output_type":"stream"}],"execution_count":68},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom nltk.util import ngrams\nfrom collections import Counter\nimport pandas as pd\nimport nltk\nnltk.download('punkt')\n\ndef generate_ngrams(text, n):\n    tokens = text.split() \n    return list(ngrams(tokens, n))\n\ndef main():\n#     documents = [\n#     \"This is a sample document.\",\n#     \"This document is another example document.\",\n#     \"TF-IDF is a useful technique for text analysis.\"\n# ]\n\n    documents=clean[:2]\n\n    for doc in documents:\n        print(f\"\\nDocument: {doc}\")\n        print(\"Unigrams:\", generate_ngrams(doc, 1))\n        print(\"Bigrams:\", generate_ngrams(doc, 2))\n        print(\"Trigrams:\", generate_ngrams(doc, 3))\n    \n\n    vectorizer = TfidfVectorizer(ngram_range=(1,3))  \n    tfidf_matrix = vectorizer.fit_transform(documents)\n    feature_names = vectorizer.get_feature_names_out()\n    \n    tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), index=[f\"Document {i+1}\" for i in range(len(documents))], columns=feature_names)\n    \n    print(\"\\nTF-IDF Matrix:\")\n    print(tfidf_df)\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-03-12T05:54:35.851268Z","iopub.execute_input":"2025-03-12T05:54:35.851609Z","iopub.status.idle":"2025-03-12T05:54:35.877864Z","shell.execute_reply.started":"2025-03-12T05:54:35.851575Z","shell.execute_reply":"2025-03-12T05:54:35.876633Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n\nDocument: Natural language processing NLP is a subfield of computer science and especially artificial intelligence It is primarily concerned with providing computers with the ability to process data encoded in natural language and is thus closely related to information retrieval knowledge representation and computational linguistics a subfield of linguistics\nUnigrams: [('Natural',), ('language',), ('processing',), ('NLP',), ('is',), ('a',), ('subfield',), ('of',), ('computer',), ('science',), ('and',), ('especially',), ('artificial',), ('intelligence',), ('It',), ('is',), ('primarily',), ('concerned',), ('with',), ('providing',), ('computers',), ('with',), ('the',), ('ability',), ('to',), ('process',), ('data',), ('encoded',), ('in',), ('natural',), ('language',), ('and',), ('is',), ('thus',), ('closely',), ('related',), ('to',), ('information',), ('retrieval',), ('knowledge',), ('representation',), ('and',), ('computational',), ('linguistics',), ('a',), ('subfield',), ('of',), ('linguistics',)]\nBigrams: [('Natural', 'language'), ('language', 'processing'), ('processing', 'NLP'), ('NLP', 'is'), ('is', 'a'), ('a', 'subfield'), ('subfield', 'of'), ('of', 'computer'), ('computer', 'science'), ('science', 'and'), ('and', 'especially'), ('especially', 'artificial'), ('artificial', 'intelligence'), ('intelligence', 'It'), ('It', 'is'), ('is', 'primarily'), ('primarily', 'concerned'), ('concerned', 'with'), ('with', 'providing'), ('providing', 'computers'), ('computers', 'with'), ('with', 'the'), ('the', 'ability'), ('ability', 'to'), ('to', 'process'), ('process', 'data'), ('data', 'encoded'), ('encoded', 'in'), ('in', 'natural'), ('natural', 'language'), ('language', 'and'), ('and', 'is'), ('is', 'thus'), ('thus', 'closely'), ('closely', 'related'), ('related', 'to'), ('to', 'information'), ('information', 'retrieval'), ('retrieval', 'knowledge'), ('knowledge', 'representation'), ('representation', 'and'), ('and', 'computational'), ('computational', 'linguistics'), ('linguistics', 'a'), ('a', 'subfield'), ('subfield', 'of'), ('of', 'linguistics')]\nTrigrams: [('Natural', 'language', 'processing'), ('language', 'processing', 'NLP'), ('processing', 'NLP', 'is'), ('NLP', 'is', 'a'), ('is', 'a', 'subfield'), ('a', 'subfield', 'of'), ('subfield', 'of', 'computer'), ('of', 'computer', 'science'), ('computer', 'science', 'and'), ('science', 'and', 'especially'), ('and', 'especially', 'artificial'), ('especially', 'artificial', 'intelligence'), ('artificial', 'intelligence', 'It'), ('intelligence', 'It', 'is'), ('It', 'is', 'primarily'), ('is', 'primarily', 'concerned'), ('primarily', 'concerned', 'with'), ('concerned', 'with', 'providing'), ('with', 'providing', 'computers'), ('providing', 'computers', 'with'), ('computers', 'with', 'the'), ('with', 'the', 'ability'), ('the', 'ability', 'to'), ('ability', 'to', 'process'), ('to', 'process', 'data'), ('process', 'data', 'encoded'), ('data', 'encoded', 'in'), ('encoded', 'in', 'natural'), ('in', 'natural', 'language'), ('natural', 'language', 'and'), ('language', 'and', 'is'), ('and', 'is', 'thus'), ('is', 'thus', 'closely'), ('thus', 'closely', 'related'), ('closely', 'related', 'to'), ('related', 'to', 'information'), ('to', 'information', 'retrieval'), ('information', 'retrieval', 'knowledge'), ('retrieval', 'knowledge', 'representation'), ('knowledge', 'representation', 'and'), ('representation', 'and', 'computational'), ('and', 'computational', 'linguistics'), ('computational', 'linguistics', 'a'), ('linguistics', 'a', 'subfield'), ('a', 'subfield', 'of'), ('subfield', 'of', 'linguistics')]\n\nDocument: Major tasks in natural language processing are speech recognition text classification naturallanguage understanding and naturallanguage generation\nUnigrams: [('Major',), ('tasks',), ('in',), ('natural',), ('language',), ('processing',), ('are',), ('speech',), ('recognition',), ('text',), ('classification',), ('naturallanguage',), ('understanding',), ('and',), ('naturallanguage',), ('generation',)]\nBigrams: [('Major', 'tasks'), ('tasks', 'in'), ('in', 'natural'), ('natural', 'language'), ('language', 'processing'), ('processing', 'are'), ('are', 'speech'), ('speech', 'recognition'), ('recognition', 'text'), ('text', 'classification'), ('classification', 'naturallanguage'), ('naturallanguage', 'understanding'), ('understanding', 'and'), ('and', 'naturallanguage'), ('naturallanguage', 'generation')]\nTrigrams: [('Major', 'tasks', 'in'), ('tasks', 'in', 'natural'), ('in', 'natural', 'language'), ('natural', 'language', 'processing'), ('language', 'processing', 'are'), ('processing', 'are', 'speech'), ('are', 'speech', 'recognition'), ('speech', 'recognition', 'text'), ('recognition', 'text', 'classification'), ('text', 'classification', 'naturallanguage'), ('classification', 'naturallanguage', 'understanding'), ('naturallanguage', 'understanding', 'and'), ('understanding', 'and', 'naturallanguage'), ('and', 'naturallanguage', 'generation')]\n\nTF-IDF Matrix:\n             ability  ability to  ability to process       and  \\\nDocument 1  0.081199    0.081199            0.081199  0.173322   \nDocument 2  0.000000    0.000000            0.000000  0.109707   \n\n            and computational  and computational linguistics  and especially  \\\nDocument 1           0.081199                       0.081199        0.081199   \nDocument 2           0.000000                       0.000000        0.000000   \n\n            and especially artificial    and is  and is thus  ...  to process  \\\nDocument 1                   0.081199  0.081199     0.081199  ...    0.081199   \nDocument 2                   0.000000  0.000000     0.000000  ...    0.000000   \n\n            to process data  understanding  understanding and  \\\nDocument 1         0.081199       0.000000           0.000000   \nDocument 2         0.000000       0.154189           0.154189   \n\n            understanding and naturallanguage      with  with providing  \\\nDocument 1                           0.000000  0.162399        0.081199   \nDocument 2                           0.154189  0.000000        0.000000   \n\n            with providing computers  with the  with the ability  \nDocument 1                  0.081199  0.081199          0.081199  \nDocument 2                  0.000000  0.000000          0.000000  \n\n[2 rows x 156 columns]\n","output_type":"stream"}],"execution_count":69},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}