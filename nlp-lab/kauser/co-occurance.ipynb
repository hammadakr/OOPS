{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport re\nfrom collections import defaultdict\nfrom sklearn.metrics.pairwise import cosine_similarity\n\ndef tokenize(text):\n    text = re.sub(r'[^\\w\\s]', '', text.lower())\n    return text.split()\n\ntokens = tokenize(text)\nvocab = sorted(set(tokens))\nword_to_idx = {word: i for i, word in enumerate(vocab)}\nidx_to_word = {i: word for word, i in word_to_idx.items()}\n","metadata":{"id":"rYPP-vIuw77b","trusted":true,"execution":{"iopub.status.busy":"2025-04-16T05:27:52.403178Z","iopub.execute_input":"2025-04-16T05:27:52.403855Z","iopub.status.idle":"2025-04-16T05:27:52.409375Z","shell.execute_reply.started":"2025-04-16T05:27:52.403828Z","shell.execute_reply":"2025-04-16T05:27:52.408497Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"text = \"I love natural language processing and I love machine learning I enjoy data science and explore deep learning techniques\"\n","metadata":{"id":"yq9Tx4fZw9FZ","trusted":true,"execution":{"iopub.status.busy":"2025-04-16T05:27:54.073103Z","iopub.execute_input":"2025-04-16T05:27:54.073425Z","iopub.status.idle":"2025-04-16T05:27:54.077568Z","shell.execute_reply.started":"2025-04-16T05:27:54.073404Z","shell.execute_reply":"2025-04-16T05:27:54.076874Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"def generate_cooccurrence_matrix(tokens, window_size=2):\n    vocab_size = len(vocab)\n    matrix = np.zeros((vocab_size, vocab_size), dtype=int)\n\n    for idx, word in enumerate(tokens):\n        word_idx = word_to_idx[word]\n        start = max(0, idx - window_size)\n        end = min(len(tokens), idx + window_size + 1)\n\n        for i in range(start, end):\n            if i != idx:\n                context_word = tokens[i]\n                context_idx = word_to_idx[context_word]\n                matrix[word_idx][context_idx] += 1\n\n    return matrix\n","metadata":{"id":"ZdxwJCd8w79x","trusted":true,"execution":{"iopub.status.busy":"2025-04-16T05:27:57.718868Z","iopub.execute_input":"2025-04-16T05:27:57.719627Z","iopub.status.idle":"2025-04-16T05:27:57.724820Z","shell.execute_reply.started":"2025-04-16T05:27:57.719598Z","shell.execute_reply":"2025-04-16T05:27:57.724107Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"window_size = 2\nco_matrix = generate_cooccurrence_matrix(tokens, window_size)\nco_df = pd.DataFrame(co_matrix)\nprint(co_df)\n\n\nprint(\"\\nWord Index:\")\nfor i, word in enumerate(vocab):\n    print(f\"{i}: {word}\")\n","metadata":{"id":"-qlWrLKBw8AH","trusted":true,"execution":{"iopub.status.busy":"2025-04-16T05:27:59.277851Z","iopub.execute_input":"2025-04-16T05:27:59.278476Z","iopub.status.idle":"2025-04-16T05:27:59.286152Z","shell.execute_reply.started":"2025-04-16T05:27:59.278452Z","shell.execute_reply":"2025-04-16T05:27:59.285364Z"}},"outputs":[{"name":"stdout","text":"    0   1   2   3   4   5   6   7   8   9   10  11  12  13\n0    0   1   1   0   1   1   1   0   1   0   0   1   1   0\n1    1   0   0   1   0   1   0   0   0   0   0   0   1   0\n2    1   0   0   0   1   0   0   1   0   0   0   0   0   1\n3    0   1   0   0   0   1   0   1   0   0   0   0   1   0\n4    1   0   1   0   0   0   0   1   0   0   0   0   1   0\n5    1   1   0   1   0   0   0   1   2   2   1   1   0   0\n6    1   0   0   0   0   0   0   0   1   0   1   1   0   0\n7    0   0   1   1   1   1   0   0   1   1   0   0   0   1\n8    1   0   0   0   0   2   1   1   0   1   1   0   0   0\n9    0   0   0   0   0   2   0   1   1   0   0   0   0   0\n10   0   0   0   0   0   1   1   0   1   0   0   1   0   0\n11   1   0   0   0   0   1   1   0   0   0   1   0   0   0\n12   1   1   0   1   1   0   0   0   0   0   0   0   0   0\n13   0   0   1   0   0   0   0   1   0   0   0   0   0   0\n\nWord Index:\n0: and\n1: data\n2: deep\n3: enjoy\n4: explore\n5: i\n6: language\n7: learning\n8: love\n9: machine\n10: natural\n11: processing\n12: science\n13: techniques\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"word_vecs = co_matrix\ntarget_word = 'love'\ntarget_idx = word_to_idx[target_word]\n\n\nsimilarities = cosine_similarity([word_vecs[target_idx]], word_vecs)[0]\nsim_df = pd.DataFrame({'word': vocab, 'similarity_to_love': similarities})\nprint(sim_df.sort_values(by='similarity_to_love', ascending=False))\n","metadata":{"id":"P8jvP0Hqw8Cd","trusted":true,"execution":{"iopub.status.busy":"2025-04-16T05:28:01.212279Z","iopub.execute_input":"2025-04-16T05:28:01.212897Z","iopub.status.idle":"2025-04-16T05:28:01.222044Z","shell.execute_reply.started":"2025-04-16T05:28:01.212870Z","shell.execute_reply":"2025-04-16T05:28:01.221270Z"}},"outputs":[{"name":"stdout","text":"          word  similarity_to_love\n8         love            1.000000\n11  processing            0.833333\n9      machine            0.680414\n1         data            0.500000\n3        enjoy            0.500000\n10     natural            0.500000\n5            i            0.445435\n7     learning            0.377964\n0          and            0.353553\n2         deep            0.333333\n4      explore            0.333333\n6     language            0.333333\n13  techniques            0.235702\n12     science            0.166667\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"","metadata":{"id":"1yT4p_0yw8FV","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"RkZ-OR5Rw8Hq","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"Bt1lm6xWw8Ki"},"outputs":[],"execution_count":null}]}