{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Tdsckv6ZfdQ2"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def generate_ngrams(tokens, n):\n",
    "    return [' '.join(tokens[i:i+n]) for i in range(len(tokens)-n+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Machine learning ML is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalise to unseen data and thus perform tasks without explicit instructions Within a subdiscipline in machine learning advances in the field of deep learning have allowed neural networks a class of statistical algorithms to surpass many previous machine learning approaches in performance\n",
      "ML finds application in many fields including natural language processing computer vision speech recognition email filtering agriculture and medicine The application of ML to business problems is known as predictive analytics\n",
      "Statistics and mathematical optimisation mathematical programming methods comprise the foundations of machine learning Data mining is a related field of study focusing on exploratory data analysis EDA via unsupervised learning\n",
      "From a theoretical viewpoint probably approximately correct learning provides a framework for describing machine learning\n",
      "The term machine learning was coined in  by Arthur Samuel an IBM employee and pioneer in the field of computer gaming and artificial intelligence The synonym selfteaching computers was also used in this time period\n",
      "Although the earliest machine learning model was introduced in the s when Arthur Samuel invented a program that calculated the winning chance in checkers for each side the history of machine learning roots back to decades of human desire and effort to study human cognitive processes In  Canadian psychologist Donald Hebb published the book The Organization of Behavior in which he introduced a theoretical neural structure formed by certain interactions among nerve cells Hebbs model of neurons interacting with one another set a groundwork for how AIs and machine learning algorithms work under nodes or artificial neurons used by computers to communicate data Other researchers who have studied human cognitive systems contributed to the modern machine learning technologies as well including logician Walter Pitts and Warren McCulloch who proposed the early mathematical models of neural networks to come up with algorithms that mirror human thought processes\n",
      "By the early s an experimental learning machine with punched tape memory called Cybertron had been developed by Raytheon Company to analyse sonar signals electrocardiograms and speech patterns using rudimentary reinforcement learning It was repetitively trained by a human operatorteacher to recognise patterns and equipped with a goof button to cause it to reevaluate incorrect decisions A representative book on research into machine learning during the s was Nilssons book on Learning Machines dealing mostly with machine learning for pattern classification Interest related to pattern recognition continued into the s as described by Duda and Hart in  In  a report was given on using teaching strategies so that an artificial neural network learns to recognise  characters  letters  digits and  special symbols from a computer terminal\n",
      "Tom M Mitchell provided a widely quoted more formal definition of the algorithms studied in the machine learning field A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T as measured by P  improves with experience E This definition of the tasks in which machine learning is concerned offers a fundamentally operational definition rather than defining the field in cognitive terms This follows Alan Turings proposal in his paper Computing Machinery and Intelligence in which the question Can machines think is replaced with the question Can machines do what we as thinking entities can do\n",
      "Modernday machine learning has two objectives  One is to classify data based on models which have been developed the other purpose is to make predictions for future outcomes based on these models A hypothetical algorithm specific to classifying data may use computer vision of moles coupled with supervised learning in order to train it to classify the cancerous moles A machine learning algorithm for stock trading may inform the trader of future potential predictions\n",
      "As a scientific endeavour machine learning grew out of the quest for artificial intelligence AI In the early days of AI as an academic discipline some researchers were interested in having machines learn from data They attempted to approach the problem with various symbolic methods as well as what were then termed neural networks these were mostly perceptrons and other models that were later found to be reinventions of the generalised linear models of statistics Probabilistic reasoning was also employed especially in automated medical diagnosis\n",
      "However an increasing emphasis on the logical knowledgebased approach caused a rift between AI and machine learning Probabilistic systems were plagued by theoretical and practical problems of data acquisition and representation By  expert systems had come to dominate AI and statistics was out of favour Work on symbolicknowledgebased learning did continue within AI leading to inductive logic programmingILP but the more statistical line of research was now outside the field of AI proper in pattern recognition and information retrieval Neural networks research had been abandoned by AI and computer science around the same time This line too was continued outside the AICS field as connectionism by researchers from other disciplines including John Hopfield David Rumelhart and Geoffrey Hinton Their main success came in the mids with the reinvention of backpropagation\n",
      "Machine learning ML reorganised and recognised as its own field started to flourish in the s The field changed its goal from achieving artificial intelligence to tackling solvable problems of a practical nature It shifted focus away from the symbolic approaches it had inherited from AI and toward methods and models borrowed from statistics fuzzy logic and probability theory\n",
      "There is a close connection between machine learning and compression A system that predicts the posterior probabilities of a sequence given its entire history can be used for optimal data compression by using arithmetic coding on the output distribution Conversely an optimal compressor can be used for prediction by finding the symbol that compresses best given the previous history This equivalence has been used as a justification for using data compression as a benchmark for general intelligence\n",
      "An alternative view can show compression algorithms implicitly map strings into implicit feature space vectors and compressionbased similarity measures compute similarity within these feature spaces For each compressor C we define an associated vector space â„µ such that C maps an input string x corresponding to the vector norm x An exhaustive examination of the feature spaces underlying all compression algorithms is precluded by space instead feature vectors chooses to examine three representative lossless compression methods LZW LZ and PPM\n",
      "According to AIXI theory a connection more directly explained in Hutter Prize the best possible compression of x is the smallest possible software that generates x For example in that model a zip files compressed size includes both the zip file and the unzipping software since you can not unzip it without both but there may be an even smaller combined form\n",
      "Examples of AIpowered audiovideo compression software include NVIDIA Maxine AIVC Examples of software that can perform AIpowered image compression include OpenCV TensorFlow MATLABs Image Processing Toolbox IPT and HighFidelity Generative Image Compression\n",
      "In unsupervised machine learning kmeans clustering can be utilized to compress data by grouping similar data points into clusters This technique simplifies handling extensive datasets that lack predefined labels and finds widespread use in fields such as image compression\n",
      "Data compression aims to reduce the size of data files enhancing storage efficiency and speeding up data transmission Kmeans clustering an unsupervised machine learning algorithm is employed to partition a dataset into a specified number of clusters k each represented by the centroid of its points This process condenses extensive datasets into a more compact set of representative points Particularly beneficial in image and signal processing kmeans clustering aids in data reduction by replacing groups of data points with their centroids thereby preserving the core information of the original data while significantly decreasing the required storage space\n",
      "Machine learning and data mining often employ the same methods and overlap significantly but while machine learning focuses on prediction based on known properties learned from the training data data mining focuses on the discovery of previously unknown properties in the data this is the analysis step of knowledge discovery in databases Data mining uses many machine learning methods but with different goals on the other hand machine learning also employs data mining methods as unsupervised learning or as a preprocessing step to improve learner accuracy Much of the confusion between these two research communities which do often have separate conferences and separate journals ECML PKDD being a major exception comes from the basic assumptions they work with in machine learning performance is usually evaluated with respect to the ability to reproduce known knowledge while in knowledge discovery and data mining KDD the key task is the discovery of previously unknown knowledge Evaluated with respect to known knowledge an uninformed unsupervised method will easily be outperformed by other supervised methods while in a typical KDD task supervised methods cannot be used due to the unavailability of training data\n",
      "Machine learning also has intimate ties to optimisation Many learning problems are formulated as minimisation of some loss function on a training set of examples Loss functions express the discrepancy between the predictions of the model being trained and the actual problem instances for example in classification one wants to assign a label to instances and models are trained to correctly predict the preassigned labels of a set of examples\n",
      "Characterizing the generalisation of various learning algorithms is an active topic of current research especially for deep learning algorithms\n",
      "Machine learning and statistics are closely related fields in terms of methods but distinct in their principal goal statistics draws population inferences from a sample while machine learning finds generalisable predictive patterns According to Michael I Jordan the ideas of machine learning from methodological principles to theoretical tools have had a long prehistory in statistics He also suggested the term data science as a placeholder to call the overall field\n",
      "Conventional statistical analyses require the a priori selection of a model most suitable for the study data set In addition only significant or theoretically relevant variables based on previous experience are included for analysis In contrast machine learning is not built on a prestructured model rather the data shape the model by detecting underlying patterns The more variables input used to train the model the more accurate the ultimate model will be\n",
      "Leo Breiman distinguished two statistical modelling paradigms data model and algorithmic model wherein algorithmic model means more or less the machine learning algorithms like Random Forest\n",
      "Some statisticians have adopted methods from machine learning leading to a combined field that they call statistical learning\n",
      "Analytical and computational techniques derived from deeprooted physics of disordered systems can be extended to largescale problems including machine learning eg to analyse the weight space of deep neural networks Statistical physics is thus finding applications in the area of medical diagnostics\n",
      "A core objective of a learner is to generalise from its experience Generalisation in this context is the ability of a learning machine to perform accurately on new unseen examplestasks after having experienced a learning data set The training examples come from some generally unknown probability distribution considered representative of the space of occurrences and the learner has to build a general model about this space that enables it to produce sufficiently accurate predictions in new cases\n",
      "The computational analysis of machine learning algorithms and their performance is a branch of theoretical computer science known as computational learning theory via the probably approximately correct learning  model Because training sets are finite and the future is uncertain learning theory usually does not yield guarantees of the performance of algorithms Instead probabilistic bounds on the performance are quite common The biasvariance decomposition is one way to quantify generalisation error\n",
      "For the best performance in the context of generalisation the complexity of the hypothesis should match the complexity of the function underlying the data If the hypothesis is less complex than the function then the model has under fitted the data If the complexity of the model is increased in response then the training error decreases But if the hypothesis is too complex then the model is subject to overfitting and generalisation will be poorer\n",
      "In addition to performance bounds learning theorists study the time complexity and feasibility of learning In computational learning theory a computation is considered feasible if it can be done in polynomial time There are two kinds of time complexity results Positive results show that a certain class of functions can be learned in polynomial time Negative results show that certain classes cannot be learned in polynomial time\n",
      "\n",
      "Machine learning approaches are traditionally divided into three broad categories which correspond to learning paradigms depending on the nature of the signal or feedback available to the learning system\n",
      "Although each algorithm has advantages and limitations no single algorithm works for all problems\n",
      "Supervised learning algorithms build a mathematical model of a set of data that contains both the inputs and the desired outputs The data known as training data consists of a set of training examples Each training example has one or more inputs and the desired output also known as a supervisory signal In the mathematical model each training example is represented by an array or vector sometimes called a feature vector and the training data is represented by a matrix Through iterative optimisation of an objective function supervised learning algorithms learn a function that can be used to predict the output associated with new inputs An optimal function allows the algorithm to correctly determine the output for inputs that were not a part of the training data An algorithm that improves the accuracy of its outputs or predictions over time is said to have learned to perform that task\n",
      "Types of supervisedlearning algorithms include active learning classification and regression Classification algorithms are used when the outputs are restricted to a limited set of values while regression algorithms are used when the outputs can take any numerical value within a range For example in a classification algorithm that filters emails the input is an incoming email and the output is the folder in which to file the email In contrast regression is used for tasks such as predicting a persons height based on factors like age and genetics or forecasting future temperatures based on historical data\n",
      "Similarity learning is an area of supervised machine learning closely related to regression and classification but the goal is to learn from examples using a similarity function that measures how similar or related two objects are It has applications in ranking recommendation systems visual identity tracking face verification and speaker verification\n",
      "Unsupervised learning algorithms find structures in data that has not been labelled classified or categorised Instead of responding to feedback unsupervised learning algorithms identify commonalities in the data and react based on the presence or absence of such commonalities in each new piece of data Central applications of unsupervised machine learning include clustering dimensionality reduction and density estimation\n",
      "Cluster analysis is the assignment of a set of observations into subsets called clusters so that observations within the same cluster are similar according to one or more predesignated criteria while observations drawn from different clusters are dissimilar Different clustering techniques make different assumptions on the structure of the data often defined by some similarity metric and evaluated for example by internal compactness or the similarity between members of the same cluster and separation the difference between clusters Other methods are based on estimated density and graph connectivity\n",
      "A special type of unsupervised learning called selfsupervised learning involves training a model by generating the supervisory signal from the data itself\n",
      "Semisupervised learning falls between unsupervised learning without any labelled training data and supervised learning with completely labelled training data Some of the training examples are missing training labels yet many machinelearning researchers have found that unlabelled data when used in conjunction with a small amount of labelled data can produce a considerable improvement in learning accuracy\n",
      "In weakly supervised learning the training labels are noisy limited or imprecise however these labels are often cheaper to obtain resulting in larger effective training sets\n",
      "Reinforcement learning is an area of machine learning concerned with how software agents ought to take actions in an environment so as to maximise some notion of cumulative reward Due to its generality the field is studied in many other disciplines such as game theory control theory operations research information theory simulationbased optimisation multiagent systems swarm intelligence statistics and genetic algorithms In reinforcement learning the environment is typically represented as a Markov decision process MDP Many reinforcement learning algorithms use dynamic programming techniques Reinforcement learning algorithms do not assume knowledge of an exact mathematical model of the MDP and are used when exact models are infeasible Reinforcement learning algorithms are used in autonomous vehicles or in learning to play a game against a human opponent\n",
      "Dimensionality reduction is a process of reducing the number of random variables under consideration by obtaining a set of principal variables In other words it is a process of reducing the dimension of the feature set also called the number of features Most of the dimensionality reduction techniques can be considered as either feature elimination or extraction One of the popular methods of dimensionality reduction is principal component analysis PCA PCA involves changing higherdimensional data eg D to a smaller space eg DThe manifold hypothesis proposes that highdimensional data sets lie along lowdimensional manifolds and many dimensionality reduction techniques make this assumption leading to the area of manifold learning and manifold regularisation\n",
      "Other approaches have been developed which do not fit neatly into this threefold categorisation and sometimes more than one is used by the same machine learning system For example topic modelling metalearning\n",
      "Selflearning as a machine learning paradigm was introduced in  along with a neural network capable of selflearning named crossbar adaptive array CAA It gives a solution to the problem learning without any external reward by introducing emotion as an internal reward Emotion is used as state evaluation of a selflearning agent The CAA selflearning algorithm computes in a crossbar fashion both decisions about actions and emotions feelings about consequence situations The system is driven by the interaction between cognition and emotionThe selflearning algorithm updates a memory matrix W was such that in each iteration executes the following machine learning routine \n",
      "It is a system with only one input situation and only one output action or behaviour a There is neither a separate reinforcement input nor an advice input from the environment The backpropagated value secondary reinforcement is the emotion toward the consequence situation The CAA exists in two environments one is the behavioural environment where it behaves and the other is the genetic environment wherefrom it initially and only once receives initial emotions about situations to be encountered in the behavioural environment After receiving the genome species vector from the genetic environment the CAA learns a goalseeking behaviour in an environment that contains both desirable and undesirable situations\n",
      "Several learning algorithms aim at discovering better representations of the inputs provided during training Classic examples include principal component analysis and cluster analysis Feature learning algorithms also called representation learning algorithms often attempt to preserve the information in their input but also transform it in a way that makes it useful often as a preprocessing step before performing classification or predictions This technique allows reconstruction of the inputs coming from the unknown datagenerating distribution while not being necessarily faithful to configurations that are implausible under that distribution This replaces manual feature engineering and allows a machine to both learn the features and use them to perform a specific task\n",
      "Feature learning can be either supervised or unsupervised In supervised feature learning features are learned using labelled input data Examples include artificial neural networks multilayer perceptrons and supervised dictionary learning In unsupervised feature learning features are learned with unlabelled input data  Examples include dictionary learning independent component analysis autoencoders matrix factorisation and various forms of clustering\n",
      "Manifold learning algorithms attempt to do so under the constraint that the learned representation is lowdimensional Sparse coding algorithms attempt to do so under the constraint that the learned representation is sparse meaning that the mathematical model has many zeros Multilinear subspace learning algorithms aim to learn lowdimensional representations directly from tensor representations for multidimensional data without reshaping them into higherdimensional vectors Deep learning algorithms discover multiple levels of representation or a hierarchy of features with higherlevel more abstract features defined in terms of or generating lowerlevel features It has been argued that an intelligent machine is one that learns a representation that disentangles the underlying factors of variation that explain the observed data\n",
      "Feature learning is motivated by the fact that machine learning tasks such as classification often require input that is mathematically and computationally convenient to process However realworld data such as images video and sensory data has not yielded attempts to algorithmically define specific features An alternative is to discover such features or representations through examination without relying on explicit algorithms\n",
      "Sparse dictionary learning is a feature learning method where a training example is represented as a linear combination of basis functions and assumed to be a sparse matrix The method is strongly NPhard and difficult to solve approximately A popular heuristic method for sparse dictionary learning is the kSVD algorithm Sparse dictionary learning has been applied in several contexts In classification the problem is to determine the class to which a previously unseen training example belongs For a dictionary where each class has already been built a new training example is associated with the class that is best sparsely represented by the corresponding dictionary Sparse dictionary learning has also been applied in image denoising The key idea is that a clean image patch can be sparsely represented by an image dictionary but the noise cannot\n",
      "In data mining anomaly detection also known as outlier detection is the identification of rare items events or observations which raise suspicions by differing significantly from the majority of the data Typically the anomalous items represent an issue such as bank fraud a structural defect medical problems or errors in a text Anomalies are referred to as outliers novelties noise deviations and exceptions\n",
      "In particular in the context of abuse and network intrusion detection the interesting objects are often not rare objects but unexpected bursts of inactivity This pattern does not adhere to the common statistical definition of an outlier as a rare object Many outlier detection methods in particular unsupervised algorithms will fail on such data unless aggregated appropriately Instead a cluster analysis algorithm may be able to detect the microclusters formed by these patterns\n",
      "Three broad categories of anomaly detection techniques exist Unsupervised anomaly detection techniques detect anomalies in an unlabelled test data set under the assumption that the majority of the instances in the data set are normal by looking for instances that seem to fit the least to the remainder of the data set Supervised anomaly detection techniques require a data set that has been labelled as normal and abnormal and involves training a classifier the key difference from many other statistical classification problems is the inherently unbalanced nature of outlier detection Semisupervised anomaly detection techniques construct a model representing normal behaviour from a given normal training data set and then test the likelihood of a test instance to be generated by the model\n",
      "Robot learning is inspired by a multitude of machine learning methods starting from supervised learning reinforcement learning and finally metalearning eg MAML\n",
      "Association rule learning is a rulebased machine learning method for discovering relationships between variables in large databases It is intended to identify strong rules discovered in databases using some measure of interestingness\n",
      "Rulebased machine learning is a general term for any machine learning method that identifies learns or evolves rules to store manipulate or apply knowledge The defining characteristic of a rulebased machine learning algorithm is the identification and utilisation of a set of relational rules that collectively represent the knowledge captured by the system This is in contrast to other machine learning algorithms that commonly identify a singular model that can be universally applied to any instance in order to make a prediction Rulebased machine learning approaches include learning classifier systems association rule learning and artificial immune systems\n",
      "Based on the concept of strong rules Rakesh Agrawal Tomasz ImieliÅ„ski and Arun Swami introduced association rules for discovering regularities between products in largescale transaction data recorded by pointofsale POS systems in supermarkets For example the rule onionspotatoesburgerdisplaystyle mathrm onionspotatoes Rightarrow mathrm burger  found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together they are likely to also buy hamburger meat Such information can be used as the basis for decisions about marketing activities such as promotional pricing or product placements In addition to market basket analysis association rules are employed today in application areas including Web usage mining intrusion detection continuous production and bioinformatics In contrast with sequence mining association rule learning typically does not consider the order of items either within a transaction or across transactions\n",
      "Learning classifier systems LCS are a family of rulebased machine learning algorithms that combine a discovery component typically a genetic algorithm with a learning component performing either supervised learning reinforcement learning or unsupervised learning They seek to identify a set of contextdependent rules that collectively store and apply knowledge in a piecewise manner in order to make predictions\n",
      "Inductive logic programming ILP is an approach to rule learning using logic programming as a uniform representation for input examples background knowledge and hypotheses Given an encoding of the known background knowledge and a set of examples represented as a logical database of facts an ILP system will derive a hypothesized logic program that entails all positive and no negative examples Inductive programming is a related field that considers any kind of programming language for representing hypotheses and not only logic programming such as functional programs\n",
      "Inductive logic programming is particularly useful in bioinformatics and natural language processing Gordon Plotkin and Ehud Shapiro laid the initial theoretical foundation for inductive machine learning in a logical setting Shapiro built their first implementation Model Inference System in  a Prolog program that inductively inferred logic programs from positive and negative examples The term inductive here refers to philosophical induction suggesting a theory to explain observed facts rather than mathematical induction proving a property for all members of a wellordered set\n",
      "A machine learning model is a type of mathematical model that once trained on a given dataset can be used to make predictions or classifications on new data During training a learning algorithm iteratively adjusts the models internal parameters to minimise errors in its predictions By extension the term model can refer to several levels of specificity from a general class of models and their associated learning algorithms to a fully trained model with all its internal parameters tuned\n",
      "Various types of models have been used and researched for machine learning systems picking the best model for a task is called model selection\n",
      "Artificial neural networks ANNs or connectionist systems are computing systems vaguely inspired by the biological neural networks that constitute animal brains Such systems learn to perform tasks by considering examples generally without being programmed with any taskspecific rules\n",
      "An ANN is a model based on a collection of connected units or nodes called artificial neurons which loosely model the neurons in a biological brain Each connection like the synapses in a biological brain can transmit information a signal from one artificial neuron to another An artificial neuron that receives a signal can process it and then signal additional artificial neurons connected to it In common ANN implementations the signal at a connection between artificial neurons is a real number and the output of each artificial neuron is computed by some nonlinear function of the sum of its inputs The connections between artificial neurons are called edges Artificial neurons and edges typically have a weight that adjusts as learning proceeds The weight increases or decreases the strength of the signal at a connection Artificial neurons may have a threshold such that the signal is only sent if the aggregate signal crosses that threshold Typically artificial neurons are aggregated into layers Different layers may perform different kinds of transformations on their inputs Signals travel from the first layer the input layer to the last layer the output layer possibly after traversing the layers multiple times\n",
      "The original goal of the ANN approach was to solve problems in the same way that a human brain would However over time attention moved to performing specific tasks leading to deviations from biology Artificial neural networks have been used on a variety of tasks including computer vision speech recognition machine translation social network filtering playing board and video games and medical diagnosis\n",
      "Deep learning consists of multiple hidden layers in an artificial neural network This approach tries to model the way the human brain processes light and sound into vision and hearing Some successful applications of deep learning are computer vision and speech recognition\n",
      "Decision tree learning uses a decision tree as a predictive model to go from observations about an item represented in the branches to conclusions about the items target value represented in the leaves It is one of the predictive modelling approaches used in statistics data mining and machine learning Tree models where the target variable can take a discrete set of values are called classification trees in these tree structures leaves represent class labels and branches represent conjunctions of features that lead to those class labels Decision trees where the target variable can take continuous values typically real numbers are called regression trees In decision analysis a decision tree can be used to visually and explicitly represent decisions and decision making In data mining a decision tree describes data but the resulting classification tree can be an input for decisionmaking\n",
      "Random forest regression RFR falls under umbrella of decision treebased models RFR is an ensemble learning method that builds multiple decision trees and averages their predictions to improve accuracy and to avoid overfitting To build decision trees RFR uses bootstrapped sampling for instance each decision tree is trained on random data of from training set This random selection of RFR for training enables model to reduce bias predictions and achieve accuracy RFR generates independent decision trees and it can work on single output data as well multiple regressor task This makes RFR compatible to be used in various application\n",
      "Supportvector machines SVMs also known as supportvector networks are a set of related supervised learning methods used for classification and regression Given a set of training examples each marked as belonging to one of two categories an SVM training algorithm builds a model that predicts whether a new example falls into one category An SVM training algorithm is a nonprobabilistic binary linear classifier although methods such as Platt scaling exist to use SVM in a probabilistic classification setting In addition to performing linear classification SVMs can efficiently perform a nonlinear classification using what is called the kernel trick implicitly mapping their inputs into highdimensional feature spaces\n",
      "Regression analysis encompasses a large variety of statistical methods to estimate the relationship between input variables and their associated features Its most common form is linear regression where a single line is drawn to best fit the given data according to a mathematical criterion such as ordinary least squares The latter is often extended by regularisation methods to mitigate overfitting and bias as in ridge regression When dealing with nonlinear problems goto models include polynomial regression for example used for trendline fitting in Microsoft Excel logistic regression often used in statistical classification or even kernel regression which introduces nonlinearity by taking advantage of the kernel trick to implicitly map input variables to higherdimensional space\n",
      "Multivariate linear regression extends the concept of linear regression to handle multiple dependent variables simultaneously This approach estimates the relationships between a set of input variables and several output variables by fitting a multidimensional linear model It is particularly useful in scenarios where outputs are interdependent or share underlying patterns such as predicting multiple economic indicators or reconstructing images which are inherently multidimensional\n",
      "A Bayesian network belief network or directed acyclic graphical model is a probabilistic graphical model that represents a set of random variables and their conditional independence with a directed acyclic graph DAG For example a Bayesian network could represent the probabilistic relationships between diseases and symptoms Given symptoms the network can be used to compute the probabilities of the presence of various diseases Efficient algorithms exist that perform inference and learning Bayesian networks that model sequences of variables like speech signals or protein sequences are called dynamic Bayesian networks Generalisations of Bayesian networks that can represent and solve decision problems under uncertainty are called influence diagrams\n",
      "A Gaussian process is a stochastic process in which every finite collection of the random variables in the process has a multivariate normal distribution and it relies on a predefined covariance function or kernel that models how pairs of points relate to each other depending on their locations\n",
      "Given a set of observed points or inputoutput examples the distribution of the unobserved output of a new point as function of its input data can be directly computed by looking like the observed points and the covariances between those points and the new unobserved point\n",
      "Gaussian processes are popular surrogate models in Bayesian optimisation used to do hyperparameter optimisation\n",
      "A genetic algorithm GA is a search algorithm and heuristic technique that mimics the process of natural selection using methods such as mutation and crossover to generate new genotypes in the hope of finding good solutions to a given problem In machine learning genetic algorithms were used in the s and s Conversely machine learning techniques have been used to improve the performance of genetic and evolutionary algorithms\n",
      "The theory of belief functions also referred to as evidence theory or DempsterShafer theory is a general framework for reasoning with uncertainty with understood connections to other frameworks such as probability possibility and  imprecise probability theories These theoretical frameworks can be thought of as a kind of learner and have some analogous properties of how evidence is combined eg  Dempsters rule of combination just like how in a pmfbased Bayesian approach would combine probabilities However there are many caveats to these beliefs functions when compared to Bayesian approaches in order to incorporate ignorance and uncertainty quantification These belief function approaches that are implemented within the machine learning domain typically leverage a fusion approach of various ensemble methods to better handle the learners decision boundary low samples and ambiguous class issues that standard machine learning approach tend to have difficulty resolving However the computational complexity of these algorithms are dependent on the number of propositions classes and can lead to a much higher computation time when compared to other machine learning approaches\n",
      "Rulebased machine learning RBML is a branch of machine learning that automatically discovers and learns rules from data It provides interpretable models making it useful for decisionmaking in fields like healthcare fraud detection and cybersecurity Key RBML techniques includes learning classifier systems association rule learning artificial immune systems and other similar models These methods extract patterns from data and evolve rules over time\n",
      "Typically machine learning models require a high quantity of reliable data to perform accurate predictions When training a machine learning model machine learning engineers need to target and collect a large and representative sample of data Data from the training set can be as varied as a corpus of text a collection of images sensor data and data collected from individual users of a service Overfitting is something to watch out for when training a machine learning model Trained models derived from biased or nonevaluated data can result in skewed or undesired predictions Biased models may result in detrimental outcomes thereby furthering the negative impacts on society or objectives Algorithmic bias is a potential result of data not being fully prepared for training Machine learning ethics is becoming a field of study and notably becoming integrated within machine learning engineering teams\n",
      "Federated learning is an adapted form of distributed artificial intelligence to training machine learning models that decentralises the training process allowing for users privacy to be maintained by not needing to send their data to a centralised server This also increases efficiency by decentralising the training process to many devices For example Gboard uses federated machine learning to train search query prediction models on users mobile phones without having to send individual searches back to Google\n",
      "There are many applications for machine learning including\n",
      "In  the mediaservices provider Netflix held the first Netflix Prize competition to find a program to better predict user preferences and improve the accuracy of its existing Cinematch movie recommendation algorithm by at least  A joint team made up of researchers from ATT LabsResearch in collaboration with the teams Big Chaos and Pragmatic Theory built an ensemble model to win the Grand Prize in  for  million Shortly after the prize was awarded Netflix realised that viewers ratings were not the best indicators of their viewing patterns everything is a recommendation and they changed their recommendation engine accordingly In  The Wall Street Journal wrote about the firm Rebellion Research and their use of machine learning to predict the financial crisis In  cofounder of Sun Microsystems Vinod Khosla predicted that  of medical doctors jobs would be lost in the next two decades to automated machine learning medical diagnostic software In  it was reported that a machine learning algorithm had been applied in the field of art history to study fine art paintings and that it may have revealed previously unrecognised influences among artists In  Springer Nature published the first research book created using machine learning In  machine learning technology was used to help make diagnoses and aid researchers in developing a cure for COVID Machine learning was recently applied to predict the proenvironmental behaviour of travellers Recently machine learning technology was also applied to optimise smartphones performance and thermal behaviour based on the users interaction with the phone When applied correctly machine learning algorithms MLAs can utilise a wide range of company characteristics to predict stock returns without overfitting By employing effective feature engineering and combining forecasts MLAs can generate results that far surpass those obtained from basic linear techniques like OLS\n",
      "Recent advancements in machine learning have extended into the field of quantum chemistry where novel algorithms now enable the prediction of solvent effects on chemical reactions thereby offering new tools for chemists to tailor experimental conditions for optimal outcomes\n",
      "Machine Learning is becoming a useful tool to investigate and predict evacuation decision making in large scale and small scale disasters Different solutions have been tested to predict if and when householders decide to evacuate during wildfires and hurricanes Other applications have been focusing on pre evacuation decisions in building fires\n",
      "Machine learning is also emerging as a promising tool in geotechnical engineering where it is used to support tasks such as ground classification hazard prediction and site characterization Recent research emphasizes a move toward datacentric methods in this field where machine learning is not a replacement for engineering judgment but a way to enhance it using sitespecific data and patterns\n",
      "Although machine learning has been transformative in some fields machinelearning programs often fail to deliver expected results Reasons for this are numerous lack of suitable data lack of access to the data data bias privacy problems badly chosen tasks and algorithms wrong tools and people lack of resources and evaluation problems\n",
      "The black box theory poses another yet significant challenge Black box refers to a situation where the algorithm or the process of producing an output is entirely opaque meaning that even the coders of the algorithm cannot audit the pattern that the machine extracted out of the data The House of Lords Select Committee which claimed that such an intelligence system that could have a substantial impact on an individuals life would not be considered acceptable unless it provided a full and satisfactory explanation for the decisions it makes\n",
      "In  a selfdriving car from Uber failed to detect a pedestrian who was killed after a collision Attempts to use machine learning in healthcare with the IBM Watson system failed to deliver even after years of time and billions of dollars invested Microsofts Bing Chat chatbot has been reported to produce hostile and offensive response against its users\n",
      "Machine learning has been used as a strategy to update the evidence related to a systematic review and increased reviewer burden related to the growth of biomedical literature While it has improved with training sets it has not yet developed sufficiently to reduce the workload burden without limiting the necessary sensitivity for the findings research themselves\n",
      "Explainable AI XAI or Interpretable AI or Explainable Machine Learning XML is artificial intelligence AI in which humans can understand the decisions or predictions made by the AI It contrasts with the black box concept in machine learning where even its designers cannot explain why an AI arrived at a specific decision By refining the mental models of users of AIpowered systems and dismantling their misconceptions XAI promises to help users perform more effectively XAI may be an implementation of the social right to explanation\n",
      "Settling on a bad overly complex theory gerrymandered to fit all the past training data is known as overfitting Many systems attempt to reduce overfitting by rewarding a theory in accordance with how well it fits the data but penalising the theory in accordance with how complex the theory is\n",
      "Learners can also disappoint by learning the wrong lesson A toy example is that an image classifier trained only on pictures of brown horses and black cats might conclude that all brown patches are likely to be horses A realworld example is that unlike humans current image classifiers often do not primarily make judgements from the spatial relationship between components of the picture and they learn relationships between pixels that humans are oblivious to but that still correlate with images of certain types of real objects Modifying these patterns on a legitimate image can result in adversarial images that the system misclassifies\n",
      "Adversarial vulnerabilities can also result in nonlinear systems or from nonpattern perturbations For some systems it is possible to change the output by only changing a single adversarially chosen pixel Machine learning models are often vulnerable to manipulation or evasion via adversarial machine learning\n",
      "Researchers have demonstrated how backdoors can be placed undetectably into classifying eg for categories spam and wellvisible not spam of posts machine learning models that are often developed or trained by third parties Parties can change the classification of any input including in cases for which a type of datasoftware transparency is provided possibly including whitebox access\n",
      "Classification of machine learning models can be validated by accuracy estimation techniques like the holdout method which splits the data in a training and test set conventionally  training set and  test set designation and evaluates the performance of the training model on the test set In comparison the Kfoldcrossvalidation method randomly partitions the data into K subsets and then K experiments are performed each respectively considering  subset for evaluation and the remaining K subsets for training the model In addition to the holdout and crossvalidation methods bootstrap which samples n instances with replacement from the dataset can be used to assess model accuracy\n",
      "In addition to overall accuracy investigators frequently report sensitivity and specificity meaning true positive rate TPR and true negative rate TNR respectively Similarly investigators sometimes report the false positive rate FPR as well as the false negative rate FNR However these rates are ratios that fail to reveal their numerators and denominators Receiver operating characteristic ROC along with the accompanying Area Under the ROC Curve AUC offer additional tools for classification model assessment Higher AUC is associated with a better performing model\n",
      "\n",
      "The ethics of artificial intelligence covers a broad range of topics within AI that are considered to have particular ethical stakes This includes algorithmic biases fairness automated decisionmaking accountability privacy and regulation It also covers various emerging or potential future challenges such as machine ethics how to make machines that behave ethically lethal autonomous weapon systems arms race dynamics AI safety and alignment technological unemployment AIenabled misinformation how to treat certain AI systems if they have a moral status AI welfare and rights artificial superintelligence and existential risks\n",
      "Different machine learning approaches can suffer from different data biases A machine learning system trained specifically on current customers may not be able to predict the needs of new customer groups that are not represented in the training data When trained on humanmade data machine learning is likely to pick up the constitutional and unconscious biases already present in society\n",
      "Systems that are trained on datasets collected with biases may exhibit these biases upon use algorithmic bias thus digitising cultural prejudices For example in  the UKs Commission for Racial Equality found that St Georges Medical School had been using a computer program trained from data of previous admissions staff and that this program had denied nearly  candidates who were found to either be women or have nonEuropean sounding names Using job hiring data from a firm with racist hiring policies may lead to a machine learning system duplicating the bias by scoring job applicants by similarity to previous successful applicants Another example includes predictive policing company Geoliticas predictive algorithm that resulted in disproportionately high levels of overpolicing in lowincome and minority communities after being trained with historical crime data\n",
      "While responsible collection of data and documentation of algorithmic rules used by a system is considered a critical part of machine learning some researchers blame lack of participation and representation of minority population in the field of AI for machine learnings vulnerability to biases In fact according to research carried out by the Computing Research Association CRA in  female faculty merely make up  of all faculty members who focus on AI among several universities around the world Furthermore among the group of new US resident AI PhD graduates  identified as white  as Asian  as Hispanic and  as African American which further demonstrates a lack of diversity in the field of AI\n",
      "Language models learned from data have been shown to contain humanlike biases Because human languages contain biases machines trained on language corpora will necessarily also learn these biases In  Microsoft tested Tay a chatbot that learned from Twitter and it quickly picked up racist and sexist language\n",
      "In an experiment carried out by ProPublica an investigative journalism organisation a machine learning algorithms insight into the recidivism rates among prisoners falsely flagged black defendants high risk twice as often as white defendants In  Google Photos once tagged a couple of black people as gorillas which caused controversy The gorilla label was subsequently removed and in  it still cannot recognise gorillas Similar issues with recognising nonwhite people have been found in many other systems\n",
      "Because of such challenges the effective use of machine learning may take longer to be adopted in other domains Concern for fairness in machine learning that is reducing bias in machine learning and propelling its use for human good is increasingly expressed by artificial intelligence scientists including FeiFei Li who said that theres nothing artificial about AI Its inspired by people its created by people andmost importantlyit impacts people It is a powerful tool we are only just beginning to understand and that is a profound responsibility\n",
      "There are concerns among health care professionals that these systems might not be designed in the publics interest but as incomegenerating machines This is especially true in the United States where there is a longstanding ethical dilemma of improving health care but also increasing profits For example the algorithms could be designed to provide patients with unnecessary tests or medication in which the algorithms proprietary owners hold stakes There is potential for machine learning in health care to provide professionals an additional tool to diagnose medicate and plan recovery paths for patients but this requires these biases to be mitigated\n",
      "Since the s advances in both machine learning algorithms and computer hardware have led to more efficient methods for training deep neural networks a particular narrow subdomain of machine learning that contain many layers of nonlinear hidden units By  graphics processing units GPUs often with AIspecific enhancements had displaced CPUs as the dominant method of training largescale commercial cloud AI OpenAI estimated the hardware compute used in the largest deep learning projects from AlexNet  to AlphaZero  and found a fold increase in the amount of compute required with a doublingtime trendline of  months\n",
      "Tensor Processing Units TPUs are specialised hardware accelerators developed by Google specifically for machine learning workloads Unlike generalpurpose GPUs and FPGAs TPUs are optimised for tensor computations making them particularly efficient for deep learning tasks such as training and inference They are widely used in Google Cloud AI services and largescale machine learning models like Googles DeepMind AlphaFold and large language models TPUs leverage matrix multiplication units and highbandwidth memory to accelerate computations while maintaining energy efficiency Since their introduction in  TPUs have become a key component of AI infrastructure especially in cloudbased environments\n",
      "Neuromorphic computing refers to a class of computing systems designed to emulate the structure and functionality of biological neural networks These systems may be implemented through softwarebased simulations on conventional hardware or through specialised hardware architectures\n",
      "A physical neural network is a specific type of neuromorphic hardware that relies on electrically adjustable materials such as memristors to emulate the function of neural synapses The term physical neural network highlights the use of physical hardware for computation as opposed to softwarebased implementations It broadly refers to artificial neural networks that use materials with adjustable resistance to replicate neural synapses\n",
      "Embedded machine learning is a subfield of machine learning where models are deployed on embedded systems with limited computing resources such as wearable computers edge devices and microcontrollers Running models directly on these devices eliminates the need to transfer and store data on cloud servers for further processing thereby reducing the risk of data breaches privacy leaks and theft of intellectual property personal data and business secrets Embedded machine learning can be achieved through various techniques such as hardware acceleration approximate computing and model optimisation Common optimisation techniques include pruning quantisation knowledge distillation lowrank factorisation network architecture search and parameter sharing\n",
      "Software suites containing a variety of machine learning algorithms include the following\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "link=\"https://en.wikipedia.org/wiki/Machine_learning\"\n",
    "\n",
    "data=requests.get(link)\n",
    "\n",
    "soup_1 = BeautifulSoup(data.text, \"html.parser\")\n",
    "\n",
    "para=soup_1.find_all(\"p\")\n",
    "\n",
    "docs=[]\n",
    "for p in para :\n",
    "    docs.append(p.get_text())\n",
    "uni=[]\n",
    "s=\" \"\n",
    "for d in docs:\n",
    "    s+=''.join(set(d))\n",
    "uni=list(set(s))\n",
    "special_char=[]\n",
    "for  i in uni :\n",
    "    if not i.isalpha() :\n",
    "        special_char.append(i)\n",
    "special_char.remove(\" \")\n",
    "for d in range(len(docs)) :\n",
    "    for i in special_char :\n",
    "        docs[d]=docs[d].replace(i,\"\")\n",
    "        \n",
    "    print(docs[d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "MsMRt5z1gaHO"
   },
   "outputs": [],
   "source": [
    "docs_ngrams = []\n",
    "for doc in docs:\n",
    "    tokens = doc.lower().split()\n",
    "\n",
    "    ngrams = []\n",
    "    for n in range(1, 4):\n",
    "        ngrams.extend(generate_ngrams(tokens, n))\n",
    "    docs_ngrams.append(ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "98D1eQ4Tgl7U",
    "outputId": "3161ff45-38c8-4fbd-e3df-54a85424fcf9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary (n-grams):\n",
      "['a', 'a bad', 'a bad overly', 'a bayesian', 'a bayesian network', 'a benchmark', 'a benchmark for', 'a better', 'a better performing', 'a biological', 'a biological brain', 'a branch', 'a branch of', 'a broad', 'a broad range', 'a centralised', 'a centralised server', 'a certain', 'a certain class', 'a chatbot', 'a chatbot that', 'a class', 'a class of', 'a classification', 'a classification algorithm', 'a classifier', 'a classifier the', 'a clean', 'a clean image', 'a close', 'a close connection', 'a cluster', 'a cluster analysis', 'a collection', 'a collection of', 'a collision', 'a collision attempts', 'a combined', 'a combined field', 'a computation', 'a computation is', 'a computer', 'a computer program', 'a computer terminal', 'a connection', 'a connection artificial', 'a connection between', 'a connection more', 'a considerable', 'a considerable improvement', 'a core', 'a core objective', 'a corpus', 'a corpus of', 'a couple', 'a couple of', 'a critical', 'a critical part', 'a crossbar', 'a crossbar fashion', 'a cure', 'a cure for', 'a customer', 'a customer buys', 'a data', 'a data set', 'a dataset', 'a dataset into', 'a decision', 'a decision tree', 'a dictionary', 'a dictionary where', 'a directed', 'a directed acyclic', 'a discovery', 'a discovery component', 'a discrete', 'a discrete set', 'a doublingtime', 'a doublingtime trendline', 'a family', 'a family of', 'a feature', 'a feature learning', 'a feature vector', 'a field', 'a field of', 'a firm', 'a firm with', 'a fold', 'a fold increase', 'a framework', 'a framework for', 'a full', 'a full and', 'a fully', 'a fully trained', 'a function', 'a function that', 'a fundamentally', 'a fundamentally operational', 'a fusion', 'a fusion approach', 'a game', 'a game against', 'a gaussian', 'a gaussian process', 'a general', 'a general class', 'a general framework', 'a general model', 'a general term', 'a genetic', 'a genetic algorithm', 'a given', 'a given dataset', 'a given normal', 'a given problem', 'a goalseeking', 'a goalseeking behaviour', 'a goof', 'a goof button', 'a groundwork', 'a groundwork for', 'a hierarchy', 'a hierarchy of', 'a high', 'a high quantity', 'a human', 'a human brain', 'a human operatorteacher', 'a human opponent', 'a hypothesized', 'a hypothesized logic', 'a hypothetical', 'a hypothetical algorithm', 'a joint', 'a joint team', 'a justification', 'a justification for', 'a key', 'a key component', 'a kind', 'a kind of', 'a label', 'a label to', 'a lack', 'a lack of', 'a large', 'a large and', 'a large variety', 'a learner', 'a learner is', 'a learning', 'a learning algorithm', 'a learning component', 'a learning data', 'a learning machine', 'a legitimate', 'a legitimate image', 'a limited', 'a limited set', 'a linear', 'a linear combination', 'a logical', 'a logical database', 'a logical setting', 'a long', 'a long prehistory', 'a longstanding', 'a longstanding ethical', 'a machine', 'a machine learning', 'a machine to', 'a major', 'a major exception', 'a markov', 'a markov decision', 'a mathematical', 'a mathematical criterion', 'a mathematical model', 'a matrix', 'a matrix through', 'a memory', 'a memory matrix', 'a model', 'a model based', 'a model by', 'a model most', 'a model representing', 'a model that', 'a moral', 'a moral status', 'a more', 'a more compact', 'a move', 'a move toward', 'a much', 'a much higher', 'a multidimensional', 'a multidimensional linear', 'a multitude', 'a multitude of', 'a multivariate', 'a multivariate normal', 'a neural', 'a neural network', 'a new', 'a new example', 'a new point', 'a new training', 'a nonlinear', 'a nonlinear classification', 'a nonprobabilistic', 'a nonprobabilistic binary', 'a part', 'a part of', 'a particular', 'a particular narrow', 'a pedestrian', 'a pedestrian who', 'a persons', 'a persons height', 'a physical', 'a physical neural', 'a piecewise', 'a piecewise manner', 'a placeholder', 'a placeholder to', 'a pmfbased', 'a pmfbased bayesian', 'a popular', 'a popular heuristic', 'a potential', 'a potential result', 'a powerful', 'a powerful tool', 'a practical', 'a practical nature', 'a predefined', 'a predefined covariance', 'a prediction', 'a prediction rulebased', 'a predictive', 'a predictive model', 'a preprocessing', 'a preprocessing step', 'a prestructured', 'a prestructured model', 'a previously', 'a previously unseen', 'a priori', 'a priori selection', 'a probabilistic', 'a probabilistic classification', 'a probabilistic graphical', 'a process', 'a process of', 'a profound', 'a profound responsibility', 'a program', 'a program that', 'a program to', 'a prolog', 'a prolog program', 'a promising', 'a promising tool', 'a property', 'a property for', 'a range', 'a range for', 'a rare', 'a rare object', 'a real', 'a real number', 'a realworld', 'a realworld example', 'a recommendation', 'a recommendation and', 'a related', 'a related field', 'a replacement', 'a replacement for', 'a report', 'a report was', 'a representation', 'a representation that', 'a representative', 'a representative book', 'a rift', 'a rift between', 'a rulebased', 'a rulebased machine', 'a sample', 'a sample while', 'a scientific', 'a scientific endeavour', 'a search', 'a search algorithm', 'a selfdriving', 'a selfdriving car', 'a selflearning', 'a selflearning agent', 'a separate', 'a separate reinforcement', 'a sequence', 'a sequence given', 'a service', 'a service overfitting', 'a set', 'a set of', 'a signal', 'a signal can', 'a signal from', 'a similarity', 'a similarity function', 'a single', 'a single adversarially', 'a single line', 'a singular', 'a singular model', 'a situation', 'a situation where', 'a small', 'a small amount', 'a smaller', 'a smaller space', 'a solution', 'a solution to', 'a sparse', 'a sparse matrix', 'a special', 'a special type', 'a specific', 'a specific decision', 'a specific task', 'a specific type', 'a specified', 'a specified number', 'a stochastic', 'a stochastic process', 'a strategy', 'a strategy to', 'a structural', 'a structural defect', 'a subdiscipline', 'a subdiscipline in', 'a subfield', 'a subfield of', 'a substantial', 'a substantial impact', 'a supermarket', 'a supermarket would', 'a supervisory', 'a supervisory signal', 'a system', 'a system is', 'a system that', 'a system with', 'a systematic', 'a systematic review', 'a task', 'a task is', 'a test', 'a test instance', 'a text', 'a text anomalies', 'a theoretical', 'a theoretical neural', 'a theoretical viewpoint', 'a theory', 'a theory in', 'a theory to', 'a there', 'a there is', 'a threshold', 'a threshold such', 'a toy', 'a toy example', 'a training', 'a training and', 'a training example', 'a training set', 'a transaction', 'a transaction or', 'a type', 'a type of', 'a typical', 'a typical kdd', 'a uniform', 'a uniform representation', 'a useful', 'a useful tool', 'a variety', 'a variety of', 'a way', 'a way that', 'a way to', 'a weight', 'a weight that', 'a wellordered', 'a wellordered set', 'a wide', 'a wide range', 'a widely', 'a widely quoted', 'a zip', 'a zip files', 'abandoned', 'abandoned by', 'abandoned by ai', 'ability', 'ability of', 'ability of a', 'ability to', 'ability to reproduce', 'able', 'able to', 'able to detect', 'able to predict', 'abnormal', 'abnormal and', 'abnormal and involves', 'about', 'about actions', 'about actions and', 'about ai', 'about ai its', 'about an', 'about an item', 'about consequence', 'about consequence situations', 'about marketing', 'about marketing activities', 'about situations', 'about situations to', 'about the', 'about the firm', 'about the items', 'about this', 'about this space', 'absence', 'absence of', 'absence of such', 'abstract', 'abstract features', 'abstract features defined', 'abuse', 'abuse and', 'abuse and network', 'academic', 'academic discipline', 'academic discipline some', 'accelerate', 'accelerate computations', 'accelerate computations while', 'acceleration', 'acceleration approximate', 'acceleration approximate computing', 'accelerators', 'accelerators developed', 'accelerators developed by', 'acceptable', 'acceptable unless', 'acceptable unless it', 'access', 'access to', 'access to the', 'accompanying', 'accompanying area', 'accompanying area under', 'accordance', 'accordance with', 'accordance with how', 'according', 'according to', 'according to a', 'according to aixi', 'according to michael', 'according to one', 'according to research', 'accordingly', 'accordingly in', 'accordingly in the', 'accountability', 'accountability privacy', 'accountability privacy and', 'accuracy', 'accuracy and', 'accuracy and to', 'accuracy estimation', 'accuracy estimation techniques', 'accuracy investigators', 'accuracy investigators frequently', 'accuracy much', 'accuracy much of', 'accuracy of', 'accuracy of its', 'accuracy rfr', 'accuracy rfr generates', 'accurate', 'accurate predictions', 'accurate predictions in', 'accurate predictions when', 'accurate the', 'accurate the ultimate', 'accurately', 'accurately on', 'accurately on new', 'achieve', 'achieve accuracy', 'achieve accuracy rfr', 'achieved', 'achieved through', 'achieved through various', 'achieving', 'achieving artificial', 'achieving artificial intelligence', 'acquisition', 'acquisition and', 'acquisition and representation', 'across', 'across transactions', 'action', 'action or', 'action or behaviour', 'actions', 'actions and', 'actions and emotions', 'actions in', 'actions in an', 'active', 'active learning', 'active learning classification', 'active topic', 'active topic of', 'activities', 'activities such', 'activities such as', 'actual', 'actual problem', 'actual problem instances', 'acyclic', 'acyclic graph', 'acyclic graph dag', 'acyclic graphical', 'acyclic graphical model', 'adapted', 'adapted form', 'adapted form of', 'adaptive', 'adaptive array', 'adaptive array caa', 'addition', 'addition only', 'addition only significant', 'addition to', 'addition to market', 'addition to overall', 'addition to performance', 'addition to performing', 'addition to the', 'additional', 'additional artificial', 'additional artificial neurons', 'additional tool', 'additional tool to', 'additional tools', 'additional tools for', 'adhere', 'adhere to', 'adhere to the', 'adjustable', 'adjustable materials', 'adjustable materials such', 'adjustable resistance', 'adjustable resistance to', 'adjusts', 'adjusts as', 'adjusts as learning', 'adjusts the', 'adjusts the models', 'admissions', 'admissions staff', 'admissions staff and', 'adopted', 'adopted in', 'adopted in other', 'adopted methods', 'adopted methods from', 'advancements', 'advancements in', 'advancements in machine', 'advances', 'advances in', 'advances in both', 'advances in the', 'advantage', 'advantage of', 'advantage of the', 'advantages', 'advantages and', 'advantages and limitations', 'adversarial', 'adversarial images', 'adversarial images that', 'adversarial machine', 'adversarial machine learning', 'adversarial vulnerabilities', 'adversarial vulnerabilities can', 'adversarially', 'adversarially chosen', 'adversarially chosen pixel', 'advice', 'advice input', 'advice input from', 'african', 'african american', 'african american which', 'after', 'after a', 'after a collision', 'after being', 'after being trained', 'after having', 'after having experienced', 'after receiving', 'after receiving the', 'after the', 'after the prize', 'after traversing', 'after traversing the', 'after years', 'after years of', 'against', 'against a', 'against a human', 'against its', 'against its users', 'age', 'age and', 'age and genetics', 'agent', 'agent the', 'agent the caa', 'agents', 'agents ought', 'agents ought to', 'aggregate', 'aggregate signal', 'aggregate signal crosses', 'aggregated', 'aggregated appropriately', 'aggregated appropriately instead', 'aggregated into', 'aggregated into layers', 'agrawal', 'agrawal tomasz', 'agrawal tomasz imieliÅ„ski', 'agriculture', 'agriculture and', 'agriculture and medicine', 'ai', 'ai among', 'ai among several', 'ai and', 'ai and computer', 'ai and machine', 'ai and statistics', 'ai and toward', 'ai arrived', 'ai arrived at', 'ai as', 'ai as an', 'ai for', 'ai for machine', 'ai in', 'ai in the', 'ai in which', 'ai infrastructure', 'ai infrastructure especially', 'ai it', 'ai it contrasts', 'ai its', 'ai its inspired', 'ai leading', 'ai leading to', 'ai openai', 'ai openai estimated', 'ai or', 'ai or explainable', 'ai phd', 'ai phd graduates', 'ai proper', 'ai proper in', 'ai safety', 'ai safety and', 'ai services', 'ai services and', 'ai systems', 'ai systems if', 'ai that', 'ai that are', 'ai welfare', 'ai welfare and', 'ai xai', 'ai xai or', 'aics', 'aics field', 'aics field as', 'aid', 'aid researchers', 'aid researchers in', 'aids', 'aids in', 'aids in data', 'aienabled', 'aienabled misinformation', 'aienabled misinformation how', 'aim', 'aim at', 'aim at discovering', 'aim to', 'aim to learn', 'aims', 'aims to', 'aims to reduce', 'aipowered', 'aipowered audiovideo', 'aipowered audiovideo compression', 'aipowered image', 'aipowered image compression', 'aipowered systems', 'aipowered systems and', 'ais', 'ais and', 'ais and machine', 'aispecific', 'aispecific enhancements', 'aispecific enhancements had', 'aivc', 'aivc examples', 'aivc examples of', 'aixi', 'aixi theory', 'aixi theory a', 'alan', 'alan turings', 'alan turings proposal', 'alexnet', 'alexnet to', 'alexnet to alphazero', 'algorithm', 'algorithm and', 'algorithm and heuristic', 'algorithm builds', 'algorithm builds a', 'algorithm by', 'algorithm by at', 'algorithm cannot', 'algorithm cannot audit', 'algorithm computes', 'algorithm computes in', 'algorithm for', 'algorithm for stock', 'algorithm ga', 'algorithm ga is', 'algorithm had', 'algorithm had been', 'algorithm has', 'algorithm has advantages', 'algorithm is', 'algorithm is a', 'algorithm is employed', 'algorithm is the', 'algorithm iteratively', 'algorithm iteratively adjusts', 'algorithm may', 'algorithm may be', 'algorithm or', 'algorithm or the', 'algorithm sparse', 'algorithm sparse dictionary', 'algorithm specific', 'algorithm specific to', 'algorithm that', 'algorithm that filters', 'algorithm that improves', 'algorithm that resulted', 'algorithm to', 'algorithm to correctly', 'algorithm updates', 'algorithm updates a', 'algorithm with', 'algorithm with a', 'algorithm works', 'algorithm works for', 'algorithmic', 'algorithmic bias', 'algorithmic bias is', 'algorithmic bias thus', 'algorithmic biases', 'algorithmic biases fairness', 'algorithmic model', 'algorithmic model means', 'algorithmic model wherein', 'algorithmic rules', 'algorithmic rules used', 'algorithmically', 'algorithmically define', 'algorithmically define specific', 'algorithms', 'algorithms aim', 'algorithms aim at', 'algorithms aim to', 'algorithms also', 'algorithms also called', 'algorithms and', 'algorithms and computer', 'algorithms and their', 'algorithms are', 'algorithms are dependent', 'algorithms are used', 'algorithms attempt', 'algorithms attempt to', 'algorithms build', 'algorithms build a', 'algorithms could', 'algorithms could be', 'algorithms discover', 'algorithms discover multiple', 'algorithms do', 'algorithms do not', 'algorithms exist', 'algorithms exist that', 'algorithms find', 'algorithms find structures', 'algorithms identify', 'algorithms identify commonalities', 'algorithms implicitly', 'algorithms implicitly map', 'algorithms in', 'algorithms in reinforcement', 'algorithms include', 'algorithms include active', 'algorithms include the', 'algorithms insight', 'algorithms insight into', 'algorithms instead', 'algorithms instead probabilistic', 'algorithms is', 'algorithms is an', 'algorithms is precluded', 'algorithms learn', 'algorithms learn a', 'algorithms like', 'algorithms like random', 'algorithms mlas', 'algorithms mlas can', 'algorithms now', 'algorithms now enable', 'algorithms often', 'algorithms often attempt', 'algorithms proprietary', 'algorithms proprietary owners', 'algorithms studied', 'algorithms studied in', 'algorithms that', 'algorithms that can', 'algorithms that combine', 'algorithms that commonly', 'algorithms that mirror', 'algorithms to', 'algorithms to a', 'algorithms to surpass', 'algorithms use', 'algorithms use dynamic', 'algorithms were', 'algorithms were used', 'algorithms will', 'algorithms will fail', 'algorithms work', 'algorithms work under', 'algorithms wrong', 'algorithms wrong tools', 'alignment', 'alignment technological', 'alignment technological unemployment', 'all', 'all brown', 'all brown patches', 'all compression', 'all compression algorithms', 'all faculty', 'all faculty members', 'all its', 'all its internal', 'all members', 'all members of', 'all positive', 'all positive and', 'all problems', 'all the', 'all the past', 'allowed', 'allowed neural', 'allowed neural networks', 'allowing', 'allowing for', 'allowing for users', 'allows', 'allows a', 'allows a machine', 'allows reconstruction', 'allows reconstruction of', 'allows the', 'allows the algorithm', 'along', 'along lowdimensional', 'along lowdimensional manifolds', 'along with', 'along with a', 'along with the', 'alphafold', 'alphafold and', 'alphafold and large', 'alphazero', 'alphazero and', 'alphazero and found', 'already', 'already been', 'already been built', 'already present', 'already present in', 'also', 'also applied', 'also applied to', 'also been', 'also been applied', 'also buy', 'also buy hamburger', 'also called', 'also called representation', 'also called the', 'also covers', 'also covers various', 'also disappoint', 'also disappoint by', 'also emerging', 'also emerging as', 'also employed', 'also employed especially', 'also employs', 'also employs data', 'also has', 'also has intimate', 'also increases', 'also increases efficiency', 'also increasing', 'also increasing profits', 'also known', 'also known as', 'also learn', 'also learn these', 'also referred', 'also referred to', 'also result', 'also result in', 'also suggested', 'also suggested the', 'also transform', 'also transform it', 'also used', 'also used in', 'alternative', 'alternative is', 'alternative is to', 'alternative view', 'alternative view can', 'although', 'although each', 'although each algorithm', 'although machine', 'although machine learning', 'although methods', 'although methods such', 'although the', 'although the earliest', 'ambiguous', 'ambiguous class', 'ambiguous class issues', 'american', 'american which', 'american which further', 'among', 'among artists', 'among artists in', 'among health', 'among health care', 'among nerve', 'among nerve cells', 'among prisoners', 'among prisoners falsely', 'among several', 'among several universities', 'among the', 'among the group', 'amount', 'amount of', 'amount of compute', 'amount of labelled', 'an', 'an academic', 'an academic discipline', 'an active', 'an active topic', 'an adapted', 'an adapted form', 'an additional', 'an additional tool', 'an advice', 'an advice input', 'an ai', 'an ai arrived', 'an algorithm', 'an algorithm that', 'an alternative', 'an alternative is', 'an alternative view', 'an ann', 'an ann is', 'an approach', 'an approach to', 'an area', 'an area of', 'an array', 'an array or', 'an artificial', 'an artificial neural', 'an artificial neuron', 'an associated', 'an associated vector', 'an encoding', 'an encoding of', 'an ensemble', 'an ensemble learning', 'an ensemble model', 'an environment', 'an environment so', 'an environment that', 'an even', 'an even smaller', 'an exact', 'an exact mathematical', 'an exhaustive', 'an exhaustive examination', 'an experiment', 'an experiment carried', 'an experimental', 'an experimental learning', 'an ibm', 'an ibm employee', 'an ilp', 'an ilp system', 'an image', 'an image classifier', 'an image dictionary', 'an implementation', 'an implementation of', 'an incoming', 'an incoming email', 'an increasing', 'an increasing emphasis', 'an individuals', 'an individuals life', 'an input', 'an input for', 'an input string', 'an intelligence', 'an intelligence system', 'an intelligent', 'an intelligent machine', 'an internal', 'an internal reward', 'an investigative', 'an investigative journalism', 'an issue', 'an issue such', 'an item', 'an item represented', 'an objective', 'an objective function', 'an optimal', 'an optimal compressor', 'an optimal function', 'an outlier', 'an outlier as', 'an output', 'an output is', 'an svm', 'an svm training', 'an uninformed', 'an uninformed unsupervised', 'an unlabelled', 'an unlabelled test', 'an unsupervised', 'an unsupervised machine', 'analogous', 'analogous properties', 'analogous properties of', 'analyse', 'analyse sonar', 'analyse sonar signals', 'analyse the', 'analyse the weight', 'analyses', 'analyses require', 'analyses require the', 'analysis', 'analysis a', 'analysis a decision', 'analysis algorithm', 'analysis algorithm may', 'analysis and', 'analysis and cluster', 'analysis association', 'analysis association rules', 'analysis autoencoders', 'analysis autoencoders matrix', 'analysis eda', 'analysis eda via', 'analysis encompasses', 'analysis encompasses a', 'analysis feature', 'analysis feature learning', 'analysis in', 'analysis in contrast', 'analysis is', 'analysis is the', 'analysis of', 'analysis of machine', 'analysis pca', 'analysis pca pca', 'analysis step', 'analysis step of', 'analytical', 'analytical and', 'analytical and computational', 'analytics', 'and', 'and a', 'and a set', 'and abnormal', 'and abnormal and', 'and achieve', 'and achieve accuracy', 'and aid', 'and aid researchers', 'and algorithmic', 'and algorithmic model', 'and algorithms', 'and algorithms wrong', 'and alignment', 'and alignment technological', 'and allows', 'and allows a', 'and ambiguous', 'and ambiguous class', 'and apply', 'and apply knowledge', 'and are', 'and are used', 'and artificial', 'and artificial immune', 'and artificial intelligence', 'and arun', 'and arun swami', 'and as', 'and as african', 'and assumed', 'and assumed to', 'and averages', 'and averages their', 'and bias', 'and bias as', 'and billions', 'and billions of', 'and bioinformatics', 'and bioinformatics in', 'and black', 'and black cats', 'and branches', 'and branches represent', 'and business', 'and business secrets', 'and can', 'and can lead', 'and classification', 'and classification but', 'and cluster', 'and cluster analysis', 'and collect', 'and collect a', 'and combining', 'and combining forecasts', 'and compression', 'and compression a', 'and compressionbased', 'and compressionbased similarity', 'and computational', 'and computational techniques', 'and computationally', 'and computationally convenient', 'and computer', 'and computer hardware', 'and computer science', 'and crossover', 'and crossover to', 'and crossvalidation', 'and crossvalidation methods', 'and cybersecurity', 'and cybersecurity key', 'and data', 'and data collected', 'and data mining', 'and decision', 'and decision making', 'and denominators', 'and denominators receiver', 'and density', 'and density estimation', 'and difficult', 'and difficult to', 'and dismantling', 'and dismantling their', 'and documentation', 'and documentation of', 'and edges', 'and edges typically', 'and effort', 'and effort to', 'and ehud', 'and ehud shapiro', 'and emotions', 'and emotions feelings', 'and emotionthe', 'and emotionthe selflearning', 'and equipped', 'and equipped with', 'and evaluated', 'and evaluated for', 'and evaluates', 'and evaluates the', 'and evaluation', 'and evaluation problems', 'and evolutionary', 'and evolutionary algorithms', 'and evolve', 'and evolve rules', 'and exceptions', 'and existential', 'and existential risks', 'and explicitly', 'and explicitly represent', 'and feasibility', 'and feasibility of', 'and finally', 'and finally metalearning', 'and finds', 'and finds widespread', 'and found', 'and found a', 'and fpgas', 'and fpgas tpus', 'and functionality', 'and functionality of', 'and generalisation', 'and generalisation will', 'and generalise', 'and generalise to', 'and genetic', 'and genetic algorithms', 'and genetics', 'and genetics or', 'and geoffrey', 'and geoffrey hinton', 'and graph', 'and graph connectivity', 'and hart', 'and hart in', 'and have', 'and have some', 'and hearing', 'and hearing some', 'and heuristic', 'and heuristic technique', 'and highbandwidth', 'and highbandwidth memory', 'and highfidelity', 'and highfidelity generative', 'and hurricanes', 'and hurricanes other', 'and hypotheses', 'and hypotheses given', 'and imprecise', 'and imprecise probability', 'and improve', 'and improve the', 'and in', 'and in it', 'and increased', 'and increased reviewer', 'and inference', 'and inference they', 'and information', 'and information retrieval', 'and intelligence', 'and intelligence in', 'and involves', 'and involves training', 'and it', 'and it can', 'and it quickly', 'and it relies', 'and large', 'and large language', 'and largescale', 'and largescale machine', 'and learning', 'and learning bayesian', 'and learns', 'and learns rules', 'and limitations', 'and limitations no', 'and machine', 'and machine learning', 'and manifold', 'and manifold regularisation', 'and many', 'and many dimensionality', 'and mathematical', 'and mathematical optimisation', 'and medical', 'and medical diagnosis', 'and medicine', 'and medicine the', 'and microcontrollers', 'and microcontrollers running', 'and minority', 'and minority communities', 'and model', 'and model optimisation', 'and models', 'and models are', 'and models borrowed', 'and natural', 'and natural language', 'and negative', 'and negative examples', 'and network', 'and network intrusion', 'and no', 'and no negative', 'and not', 'and not only', 'and notably', 'and notably becoming', 'and offensive', 'and offensive response', 'and only', 'and only once', 'and only one', 'and other', 'and other models', 'and other similar', 'and overlap', 'and overlap significantly', 'and parameter', 'and parameter sharing', 'and patterns', 'and people', 'and people lack', 'and performance', 'and performance measure', 'and pioneer', 'and pioneer in', 'and plan', 'and plan recovery', 'and potatoes', 'and potatoes together', 'and ppm', 'and practical', 'and practical problems', 'and pragmatic', 'and pragmatic theory', 'and predict', 'and predict evacuation', 'and probability', 'and probability theory', 'and propelling', 'and propelling its', 'and react', 'and react based', 'and recognised', 'and recognised as', 'and regression', 'and regression classification', 'and regression given', 'and regulation', 'and regulation it', 'and representation', 'and representation by', 'and representation of', 'and representative', 'and representative sample', 'and researched', 'and researched for', 'and rights', 'and rights artificial', 'and s', 'and s conversely', 'and satisfactory', 'and satisfactory explanation', 'and sensory', 'and sensory data', 'and separate', 'and separate journals', 'and separation', 'and separation the', 'and several', 'and several output', 'and sexist', 'and sexist language', 'and signal', 'and signal processing', 'and site', 'and site characterization', 'and small', 'and small scale', 'and solve', 'and solve decision', 'and sometimes', 'and sometimes more', 'and sound', 'and sound into', 'and speaker', 'and speaker verification', 'and special', 'and special symbols', 'and specificity', 'and specificity meaning', 'and speech', 'and speech patterns', 'and speech recognition', 'and speeding', 'and speeding up', 'and statistics', 'and statistics are', 'and statistics was', 'and store', 'and store data', 'and study', 'and study of', 'and supervised', 'and supervised dictionary', 'and supervised learning', 'and symptoms', 'and symptoms given', 'and test', 'and test set', 'and that', 'and that is', 'and that it', 'and that this', 'and the', 'and the actual', 'and the covariances', 'and the desired', 'and the future', 'and the learner', 'and the new', 'and the other', 'and the output', 'and the remaining', 'and the training', 'and the unzipping', 'and theft', 'and theft of', 'and their', 'and their associated', 'and their conditional', 'and their performance', 'and their use', 'and then', 'and then k', 'and then signal', 'and then test', 'and thermal', 'and thermal behaviour', 'and they', 'and they changed', 'and they learn', 'and thus', 'and thus perform', 'and to', 'and to avoid', 'and toward', 'and toward methods', 'and true', 'and true negative', 'and uncertainty', 'and uncertainty quantification', 'and unconscious', 'and unconscious biases', 'and undesirable', 'and undesirable situations', 'and use', 'and use them', 'and utilisation', 'and utilisation of', 'and various', 'and various forms', 'and video', 'and video games', 'and warren', 'and warren mcculloch', 'and wellvisible', 'and wellvisible not', 'and when', 'and when householders', 'andmost', 'andmost importantlyit', 'andmost importantlyit impacts', 'animal', 'animal brains', 'animal brains such', 'ann', 'ann approach', 'ann approach was', 'ann implementations', 'ann implementations the', 'ann is', 'ann is a', 'anns', 'anns or', 'anns or connectionist', 'anomalies', 'anomalies are', 'anomalies are referred', 'anomalies in', 'anomalies in an', 'anomalous', 'anomalous items', 'anomalous items represent', 'anomaly', 'anomaly detection', 'anomaly detection also', 'anomaly detection techniques', 'another', 'another an', 'another an artificial', 'another example', 'another example includes', 'another set', 'another set a', 'another yet', 'another yet significant', 'any', 'any external', 'any external reward', 'any input', 'any input including', 'any instance', 'any instance in', 'any kind', 'any kind of', 'any labelled', 'any labelled training', 'any machine', 'any machine learning', 'any numerical', 'any numerical value', 'any taskspecific', 'any taskspecific rules', 'applicants', 'applicants another', 'applicants another example', 'applicants by', 'applicants by similarity', 'application', 'application areas', 'application areas including', 'application in', 'application in many', 'application of', 'application of ml', 'applications', 'applications for', 'applications for machine', 'applications have', 'applications have been', 'applications in', 'applications in ranking', 'applications in the', 'applications of', 'applications of deep', 'applications of unsupervised', 'applied', 'applied correctly', 'applied correctly machine', 'applied in', 'applied in image', 'applied in several', 'applied in the', 'applied to', 'applied to any', 'applied to optimise', 'applied to predict', 'apply', 'apply knowledge', 'apply knowledge in', 'apply knowledge the', 'approach', 'approach caused', 'approach caused a', 'approach estimates', 'approach estimates the', 'approach of', 'approach of various', 'approach tend', 'approach tend to', 'approach the', 'approach the problem', 'approach to', 'approach to rule', 'approach tries', 'approach tries to', 'approach was', 'approach was to', 'approach would', 'approach would combine', 'approaches', 'approaches are', 'approaches are traditionally', 'approaches can', 'approaches can suffer', 'approaches have', 'approaches have been', 'approaches in', 'approaches in order', 'approaches in performance', 'approaches include', 'approaches include learning', 'approaches it', 'approaches it had', 'approaches that', 'approaches that are', 'approaches used', 'approaches used in', 'appropriately', 'appropriately instead', 'appropriately instead a', 'approximate', 'approximate computing', 'approximate computing and', 'approximately', 'approximately a', 'approximately a popular', 'approximately correct', 'approximately correct learning', 'architecture', 'architecture search', 'architecture search and', 'architectures', 'are', 'are a', 'are a family', 'are a set', 'are aggregated', 'are aggregated into', 'are based', 'are based on', 'are called', 'are called classification', 'are called dynamic', 'are called edges', 'are called influence', 'are called regression', 'are closely', 'are closely related', 'are computer', 'are computer vision', 'are computing', 'are computing systems', 'are concerns', 'are concerns among', 'are considered', 'are considered to', 'are dependent', 'are dependent on', 'are deployed', 'are deployed on', 'are dissimilar', 'are dissimilar different', 'are employed', 'are employed today', 'are finite', 'are finite and', 'are formulated', 'are formulated as', 'are implausible', 'are implausible under', 'are implemented', 'are implemented within', 'are included', 'are included for', 'are infeasible', 'are infeasible reinforcement', 'are inherently', 'are inherently multidimensional', 'are interdependent', 'are interdependent or', 'are it', 'are it has', 'are learned', 'are learned using', 'are learned with', 'are likely', 'are likely to', 'are many', 'are many applications', 'are many caveats', 'are missing', 'are missing training', 'are noisy', 'are noisy limited', 'are normal', 'are normal by', 'are not', 'are not represented', 'are numerous', 'are numerous lack', 'are oblivious', 'are oblivious to', 'are often', 'are often cheaper', 'are often developed', 'are often not', 'are often vulnerable', 'are only', 'are only just', 'are optimised', 'are optimised for', 'are performed', 'are performed each', 'are popular', 'are popular surrogate', 'are quite', 'are quite common', 'are ratios', 'are ratios that', 'are referred', 'are referred to', 'are restricted', 'are restricted to', 'are similar', 'are similar according', 'are specialised', 'are specialised hardware', 'are traditionally', 'are traditionally divided', 'are trained', 'are trained on', 'are trained to', 'are two', 'are two kinds', 'are used', 'are used in', 'are used when', 'are widely', 'are widely used', 'area', 'area of', 'area of machine', 'area of manifold', 'area of medical', 'area of supervised', 'area under', 'area under the', 'areas', 'areas including', 'areas including web', 'argued', 'argued that', 'argued that an', 'arithmetic', 'arithmetic coding', 'arithmetic coding on', 'arms', 'arms race', 'arms race dynamics', 'around', 'around the', 'around the same', 'around the world', 'array', 'array caa', 'array caa it', 'array or', 'array or vector', 'arrived', 'arrived at', 'arrived at a', 'art', 'art history', 'art history to', 'art paintings', 'art paintings and', 'arthur', 'arthur samuel', 'arthur samuel an', 'arthur samuel invented', 'artificial', 'artificial about', 'artificial about ai', 'artificial immune', 'artificial immune systems', 'artificial intelligence', 'artificial intelligence ai', 'artificial intelligence concerned', 'artificial intelligence covers', 'artificial intelligence scientists', 'artificial intelligence the', 'artificial intelligence to', 'artificial neural', 'artificial neural network', 'artificial neural networks', 'artificial neuron', 'artificial neuron is', 'artificial neuron that', 'artificial neuron to', 'artificial neurons', 'artificial neurons and', 'artificial neurons are', 'artificial neurons connected', 'artificial neurons is', 'artificial neurons may', 'artificial neurons used', 'artificial neurons which', 'artificial superintelligence', 'artificial superintelligence and', 'artists', 'artists in', 'artists in springer', 'arun', 'arun swami', 'arun swami introduced', 'as', 'as a', 'as a benchmark', 'as a corpus', 'as a justification', 'as a kind', 'as a linear', 'as a logical', 'as a machine', 'as a markov', 'as a placeholder', 'as a predictive', 'as a preprocessing', 'as a promising', 'as a rare', 'as a scientific', 'as a strategy', 'as a supervisory', 'as a uniform', 'as african', 'as african american', 'as an', 'as an academic', 'as an internal', 'as asian', 'as asian as', 'as bank', 'as bank fraud', 'as belonging', 'as belonging to', 'as classification', 'as classification often', 'as computational', 'as computational learning', 'as connectionism', 'as connectionism by', 'as described', 'as described by', 'as either', 'as either feature', 'as evidence', 'as evidence theory', 'as function', 'as function of', 'as functional', 'as functional programs', 'as game', 'as game theory', 'as gorillas', 'as gorillas which', 'as ground', 'as ground classification', 'as hardware', 'as hardware acceleration', 'as hispanic', 'as hispanic and', 'as image', 'as image compression', 'as images', 'as images video', 'as in', 'as in ridge', 'as incomegenerating', 'as incomegenerating machines', 'as its', 'as its own', 'as learning', 'as learning proceeds', 'as machine', 'as machine ethics', 'as measured', 'as measured by', 'as memristors', 'as memristors to', 'as minimisation', 'as minimisation of', 'as mutation', 'as mutation and', 'as normal', 'as normal and', 'as often', 'as often as', 'as opposed', 'as opposed to', 'as ordinary', 'as ordinary least', 'as outlier', 'as outlier detection', 'as outliers', 'as outliers novelties', 'as overfitting', 'as overfitting many', 'as platt', 'as platt scaling', 'as predicting', 'as predicting a', 'as predicting multiple', 'as predictive', 'as predictive analytics', 'as probability', 'as probability possibility', 'as promotional', 'as promotional pricing', 'as state', 'as state evaluation', 'as supportvector', 'as supportvector networks', 'as the', 'as the basis', 'as the dominant', 'as the false', 'as thinking', 'as thinking entities', 'as to', 'as to maximise', 'as training', 'as training and', 'as training data', 'as unsupervised', 'as unsupervised learning', 'as varied', 'as varied as', 'as wearable', 'as wearable computers', 'as well', 'as well as', 'as well including', 'as well multiple', 'as what', 'as what were', 'as white', 'as white as', 'as white defendants', 'asian', 'asian as', 'asian as hispanic', 'assess', 'assess model', 'assess model accuracy', 'assessment', 'assessment higher', 'assessment higher auc', 'assign', 'assign a', 'assign a label', 'assignment', 'assignment of', 'assignment of a', 'associated', 'associated features', 'associated features its', 'associated learning', 'associated learning algorithms', 'associated vector', 'associated vector space', 'associated with', 'associated with a', 'associated with new', 'associated with the', 'association', 'association cra', 'association cra in', 'association rule', 'association rule learning', 'association rules', 'association rules are', 'association rules for', 'assume', 'assume knowledge', 'assume knowledge of', 'assumed', 'assumed to', 'assumed to be', 'assumption', 'assumption leading', 'assumption leading to', 'assumption that', 'assumption that the', 'assumptions', 'assumptions on', 'assumptions on the', 'assumptions they', 'assumptions they work', 'at', 'at a', 'at a connection', 'at a specific', 'at discovering', 'at discovering better', 'at least', 'at least a', 'at tasks', 'at tasks in', 'att', 'att labsresearch', 'att labsresearch in', 'attempt', 'attempt to', 'attempt to do', 'attempt to preserve', 'attempt to reduce', 'attempted', 'attempted to', 'attempted to approach', 'attempts', 'attempts to', 'attempts to algorithmically', 'attempts to use', 'attention', 'attention moved', 'attention moved to', 'auc', 'auc is', 'auc is associated', 'auc offer', 'auc offer additional', 'audiovideo', 'audiovideo compression', 'audiovideo compression software', 'audit', 'audit the', 'audit the pattern', 'autoencoders', 'autoencoders matrix', 'autoencoders matrix factorisation', 'automated', 'automated decisionmaking', 'automated decisionmaking accountability', 'automated machine', 'automated machine learning', 'automated medical', 'automated medical diagnosis', 'automatically', 'automatically discovers', 'automatically discovers and', 'autonomous', 'autonomous vehicles', 'autonomous vehicles or', 'autonomous weapon', 'autonomous weapon systems', 'available', 'available to', 'available to the', 'averages', 'averages their', 'averages their predictions', 'avoid', 'avoid overfitting', 'avoid overfitting to', 'awarded', 'awarded netflix', 'awarded netflix realised', 'away', 'away from', 'away from the', 'back', 'back to', 'back to decades', 'back to google', 'backdoors', 'backdoors can', 'backdoors can be', 'background', 'background knowledge', 'background knowledge and', 'backpropagated', 'backpropagated value', 'backpropagated value secondary', 'backpropagation', 'bad', 'bad overly', 'bad overly complex', 'badly', 'badly chosen', 'badly chosen tasks', 'bank', 'bank fraud', 'bank fraud a', 'based', 'based on', 'based on a', 'based on estimated', 'based on factors', 'based on historical', 'based on known', 'based on models', 'based on previous', 'based on the', 'based on these', 'basic', 'basic assumptions', 'basic assumptions they', 'basic linear', 'basic linear techniques', 'basis', 'basis for', 'basis for decisions', 'basis functions', 'basis functions and', 'basket', 'basket analysis', 'basket analysis association', 'bayesian', 'bayesian approach', 'bayesian approach would', 'bayesian approaches', 'bayesian approaches in', 'bayesian network', 'bayesian network belief', 'bayesian network could', 'bayesian networks', 'bayesian networks generalisations', 'bayesian networks that', 'bayesian optimisation', 'bayesian optimisation used', 'be', 'be a', 'be a sparse', 'be able', 'be able to', 'be achieved', 'be achieved through', 'be adopted', 'be adopted in', 'be an', 'be an even', 'be an implementation', 'be an input', 'be as', 'be as varied', 'be considered', 'be considered acceptable', 'be considered as', 'be designed', 'be designed in', 'be designed to', 'be directly', 'be directly computed', 'be done', 'be done in', 'be either', 'be either supervised', 'be encountered', 'be encountered in', 'be extended', 'be extended to', 'be generated', 'be generated by', 'be horses', 'be horses a', 'be implemented', 'be implemented through', 'be learned', 'be learned in', 'be lost', 'be lost in', 'be maintained', 'be maintained by', 'be mitigated', 'be outperformed', 'be outperformed by', 'be placed', 'be placed undetectably', 'be poorer', 'be reinventions', 'be reinventions of', 'be sparsely', 'be sparsely represented', 'be thought', 'be thought of', 'be universally', 'be universally applied', 'be used', 'be used as', 'be used due', 'be used for', 'be used in', 'be used to', 'be utilized', 'be utilized to', 'be validated', 'be validated by', 'be women', 'be women or', 'because', 'because human', 'because human languages', 'because of', 'because of such', 'because training', 'because training sets', 'become', 'become a', 'become a key', 'becoming', 'becoming a', 'becoming a field', 'becoming a useful', 'becoming integrated', 'becoming integrated within', 'been', 'been abandoned', 'been abandoned by', 'been applied', 'been applied in', 'been argued', 'been argued that', 'been built', 'been built a', 'been developed', 'been developed by', 'been developed the', 'been developed which', 'been focusing', 'been focusing on', 'been found', 'been found in', 'been labelled', 'been labelled as', 'been labelled classified', 'been reported', 'been reported to', 'been shown', 'been shown to', 'been tested', 'been tested to', 'been transformative', 'been transformative in', 'been used', 'been used and', 'been used as', 'been used on', 'been used to', 'been using', 'been using a', 'before', 'before performing', 'before performing classification', 'beginning', 'beginning to', 'beginning to understand', 'behave', 'behave ethically', 'behave ethically lethal', 'behaves', 'behaves and', 'behaves and the', 'behavior', 'behavior in', 'behavior in which', 'behaviour', 'behaviour a', 'behaviour a there', 'behaviour based', 'behaviour based on', 'behaviour from', 'behaviour from a', 'behaviour in', 'behaviour in an', 'behaviour of', 'behaviour of travellers', 'behavioural', 'behavioural environment', 'behavioural environment after', 'behavioural environment where', 'being', 'being a', 'being a major', 'being fully', 'being fully prepared', 'being necessarily', 'being necessarily faithful', 'being programmed', 'being programmed with', 'being trained', 'being trained and', 'being trained with', 'belief', 'belief function', 'belief function approaches', 'belief functions', 'belief functions also', 'belief network', 'belief network or', 'beliefs', 'beliefs functions', 'beliefs functions when', 'belonging', 'belonging to', 'belonging to one', 'belongs', 'belongs for', 'belongs for a', 'benchmark', 'benchmark for', 'benchmark for general', 'beneficial', 'beneficial in', 'beneficial in image', 'best', 'best fit', 'best fit the', 'best given', 'best given the', 'best indicators', 'best indicators of', 'best model', 'best model for', 'best performance', 'best performance in', 'best possible', 'best possible compression', 'best sparsely', 'best sparsely represented', 'better', 'better handle', 'better handle the', 'better performing', 'better performing model', 'better predict', 'better predict user', 'better representations', 'better representations of', 'between', 'between a', 'between a set', 'between ai', 'between ai and', 'between artificial', 'between artificial neurons', 'between clusters', 'between clusters other', 'between cognition', 'between cognition and', 'between components', 'between components of', 'between diseases', 'between diseases and', 'between input', 'between input variables', 'between machine', 'between machine learning', 'between members', 'between members of', 'between pixels', 'between pixels that', 'between products', 'between products in', 'between the', 'between the predictions', 'between these', 'between these two', 'between those', 'between those points', 'between unsupervised', 'between unsupervised learning', 'between variables', 'between variables in', 'bias', 'bias as', 'bias as in', 'bias by', 'bias by scoring', 'bias in', 'bias in machine', 'bias is', 'bias is a', 'bias predictions', 'bias predictions and', 'bias privacy', 'bias privacy problems', 'bias thus', 'bias thus digitising', 'biased', 'biased models', 'biased models may', 'biased or', 'biased or nonevaluated', 'biases', 'biases a', 'biases a machine', 'biases already', 'biases already present', 'biases because', 'biases because human', 'biases fairness', 'biases fairness automated', 'biases in', 'biases in fact', 'biases in microsoft', 'biases machines', 'biases machines trained', 'biases may', 'biases may exhibit', 'biases to', 'biases to be', 'biases upon', 'biases upon use', 'biasvariance', 'biasvariance decomposition', 'biasvariance decomposition is', 'big', 'big chaos', 'big chaos and', 'billions', 'billions of', 'billions of dollars', 'binary', 'binary linear', 'binary linear classifier', 'bing', 'bing chat', 'bing chat chatbot', 'bioinformatics', 'bioinformatics and', 'bioinformatics and natural', 'bioinformatics in', 'bioinformatics in contrast', 'biological', 'biological brain', 'biological brain can', 'biological brain each', 'biological neural', 'biological neural networks', 'biology', 'biology artificial', 'biology artificial neural', 'biomedical', 'biomedical literature', 'biomedical literature while', 'black', 'black box', 'black box concept', 'black box refers', 'black box theory', 'black cats', 'black cats might', 'black defendants', 'black defendants high', 'black people', 'black people as', 'blame', 'blame lack', 'blame lack of', 'board', 'board and', 'board and video', 'book', 'book created', 'book created using', 'book on', 'book on learning', 'book on research', 'book the', 'book the organization', 'bootstrap', 'bootstrap which', 'bootstrap which samples', 'bootstrapped', 'bootstrapped sampling', 'bootstrapped sampling for', 'borrowed', 'borrowed from', 'borrowed from statistics', 'both', 'both but', 'both but there', 'both decisions', 'both decisions about', 'both desirable', 'both desirable and', 'both learn', 'both learn the', 'both machine', 'both machine learning', 'both the', 'both the inputs', 'both the zip', 'boundary', 'boundary low', 'boundary low samples', 'bounds', 'bounds learning', 'bounds learning theorists', 'bounds on', 'bounds on the', 'box', 'box concept', 'box concept in', 'box refers', 'box refers to', 'box theory', 'box theory poses', 'brain', 'brain can', 'brain can transmit', 'brain each', 'brain each connection', 'brain processes', 'brain processes light', 'brain would', 'brain would however', 'brains', 'brains such', 'brains such systems', 'branch', 'branch of', 'branch of machine', 'branch of theoretical', 'branches', 'branches represent', 'branches represent conjunctions', 'branches to', 'branches to conclusions', 'breaches', 'breaches privacy', 'breaches privacy leaks', 'breiman', 'breiman distinguished', 'breiman distinguished two', 'broad', 'broad categories', 'broad categories of', 'broad categories which', 'broad range', 'broad range of', 'broadly', 'broadly refers', 'broadly refers to', 'brown', 'brown horses', 'brown horses and', 'brown patches', 'brown patches are', 'build', 'build a', 'build a general', 'build a mathematical', 'build decision', 'build decision trees', 'building', 'building fires', 'builds', 'builds a', 'builds a model', 'builds multiple', 'builds multiple decision', 'built', 'built a', 'built a new', 'built an', 'built an ensemble', 'built on', 'built on a', 'built their', 'built their first', 'burden', 'burden related', 'burden related to', 'burden without', 'burden without limiting', 'burger', 'burger found', 'burger found in', 'bursts', 'bursts of', 'bursts of inactivity', 'business', 'business problems', 'business problems is', 'business secrets', 'business secrets embedded', 'but', 'but a', 'but a way', 'but also', 'but also increasing', 'but also transform', 'but as', 'but as incomegenerating', 'but distinct', 'but distinct in', 'but if', 'but if the', 'but penalising', 'but penalising the', 'but that', 'but that still', 'but the', 'but the goal', 'but the more', 'but the noise', 'but the resulting', 'but there', 'but there may', 'but this', 'but this requires', 'but unexpected', 'but unexpected bursts', 'but while', 'but while machine', 'but with', 'but with different', 'button', 'button to', 'button to cause', 'buy', 'buy hamburger', 'buy hamburger meat', 'buys', 'buys onions', 'buys onions and', 'by', 'by a', 'by a human', 'by a matrix', 'by a multitude', 'by a system', 'by accuracy', 'by accuracy estimation', 'by ai', 'by ai and', 'by an', 'by an array', 'by an image', 'by arthur', 'by arthur samuel', 'by artificial', 'by artificial intelligence', 'by at', 'by at least', 'by certain', 'by certain interactions', 'by computers', 'by computers to', 'by considering', 'by considering examples', 'by decentralising', 'by decentralising the', 'by detecting', 'by detecting underlying', 'by differing', 'by differing significantly', 'by duda', 'by duda and', 'by employing', 'by employing effective', 'by expert', 'by expert systems', 'by extension', 'by extension the', 'by finding', 'by finding the', 'by fitting', 'by fitting a', 'by generating', 'by generating the', 'by google', 'by google specifically', 'by graphics', 'by graphics processing', 'by grouping', 'by grouping similar', 'by internal', 'by internal compactness', 'by introducing', 'by introducing emotion', 'by learning', 'by learning the', 'by looking', 'by looking for', 'by looking like', 'by not', 'by not needing', 'by obtaining', 'by obtaining a', 'by only', 'by only changing', 'by other', 'by other supervised', 'by p', 'by p improves', 'by people', 'by people andmost', 'by people its', 'by pointofsale', 'by pointofsale pos', 'by propublica', 'by propublica an', 'by raytheon', 'by raytheon company', 'by refining', 'by refining the', 'by regularisation', 'by regularisation methods', 'by replacing', 'by replacing groups', 'by researchers', 'by researchers from', 'by rewarding', 'by rewarding a', 'by scoring', 'by scoring job', 'by similarity', 'by similarity to', 'by some', 'by some nonlinear', 'by some similarity', 'by space', 'by space instead', 'by taking', 'by taking advantage', 'by the', 'by the ai', 'by the biological', 'by the centroid', 'by the computing', 'by the corresponding', 'by the early', 'by the fact', 'by the interaction', 'by the model', 'by the same', 'by the system', 'by theoretical', 'by theoretical and', 'by these', 'by these patterns', 'by third', 'by third parties', 'by using', 'by using arithmetic', 'c', 'c maps', 'c maps an', 'c we', 'c we define', 'caa', 'caa exists', 'caa exists in', 'caa it', 'caa it gives', 'caa learns', 'caa learns a', 'caa selflearning', 'caa selflearning algorithm', 'calculated', 'calculated the', 'calculated the winning', 'call', 'call statistical', 'call statistical learning', 'call the', 'call the overall', 'called', 'called a', 'called a feature', 'called artificial', 'called artificial neurons', 'called classification', 'called classification trees', 'called clusters', 'called clusters so', 'called cybertron', 'called cybertron had', 'called dynamic', 'called dynamic bayesian', 'called edges', 'called edges artificial', 'called influence', 'called influence diagrams', 'called model', 'called model selection', 'called regression', 'called regression trees', 'called representation', 'called representation learning', 'called selfsupervised', 'called selfsupervised learning', 'called the', 'called the kernel', 'called the number', 'came', 'came in', 'came in the', 'can', 'can also', 'can also disappoint', 'can also result', 'can be', 'can be achieved', 'can be an', 'can be as', 'can be considered', 'can be directly', 'can be done', 'can be either', 'can be extended', 'can be learned', 'can be placed', 'can be sparsely', 'can be thought', 'can be universally', 'can be used', 'can be utilized', 'can be validated', 'can change', 'can change the', 'can do', 'can efficiently', 'can efficiently perform', 'can generate', 'can generate results', 'can lead', 'can lead to', 'can learn', 'can learn from', 'can machines', 'can machines do', 'can machines think', 'can not', 'can not unzip', 'can perform', 'can perform aipowered', 'can process', 'can process it', 'can produce', 'can produce a', 'can refer', 'can refer to', 'can represent', 'can represent and', 'can result', 'can result in', 'can show', 'can show compression', 'can suffer', 'can suffer from', 'can take', 'can take a', 'can take any', 'can take continuous', 'can transmit', 'can transmit information', 'can understand', 'can understand the', 'can utilise', 'can utilise a', 'can work', 'can work on', 'canadian', 'canadian psychologist', 'canadian psychologist donald', 'cancerous', 'cancerous moles', 'cancerous moles a', 'candidates', 'candidates who', 'candidates who were', 'cannot', 'cannot audit', 'cannot audit the', 'cannot be', 'cannot be learned', 'cannot be used', 'cannot explain', 'cannot explain why', 'cannot recognise', 'cannot recognise gorillas', 'capable', 'capable of', 'capable of selflearning', 'captured', 'captured by', 'captured by the', 'car', 'car from', 'car from uber', 'care', 'care but', 'care but also', 'care professionals', 'care professionals that', 'care to', 'care to provide', 'carried', 'carried out', 'carried out by', 'cases', 'cases for', 'cases for which', 'categories', 'categories an', 'categories an svm', 'categories of', 'categories of anomaly', 'categories spam', 'categories spam and', 'categories which', 'categories which correspond', 'categorisation', 'categorisation and', 'categorisation and sometimes', 'categorised', 'categorised instead', 'categorised instead of', 'category', 'category an', 'category an svm', 'cats', 'cats might', 'cats might conclude', 'cause', 'cause it', 'cause it to', 'caused', 'caused a', 'caused a rift', 'caused controversy', 'caused controversy the', 'caveats', 'caveats to', 'caveats to these', 'cells', 'cells hebbs', 'cells hebbs model', 'central', 'central applications', 'central applications of', 'centralised', 'centralised server', 'centralised server this', 'centroid', 'centroid of', 'centroid of its', 'centroids', 'centroids thereby', 'centroids thereby preserving', 'certain', 'certain ai', 'certain ai systems', 'certain class', 'certain class of', 'certain classes', 'certain classes cannot', 'certain interactions', 'certain interactions among', 'certain types', 'certain types of', 'challenge', 'challenge black', 'challenge black box', 'challenges', 'challenges such', 'challenges such as', 'challenges the', 'challenges the effective', 'chance', 'chance in', 'chance in checkers', 'change', 'change the', 'change the classification', 'change the output', 'changed', 'changed its', 'changed its goal', 'changed their', 'changed their recommendation', 'changing', 'changing a', 'changing a single', 'changing higherdimensional', 'changing higherdimensional data', 'chaos', 'chaos and', 'chaos and pragmatic', 'characteristic', 'characteristic of', 'characteristic of a', 'characteristic roc', 'characteristic roc along', 'characteristics', 'characteristics to', 'characteristics to predict', 'characterization', 'characterization recent', 'characterization recent research', 'characterizing', 'characterizing the', 'characterizing the generalisation', 'characters', 'characters letters', 'characters letters digits', 'chat', 'chat chatbot', 'chat chatbot has', 'chatbot', 'chatbot has', 'chatbot has been', 'chatbot that', 'chatbot that learned', 'cheaper', 'cheaper to', 'cheaper to obtain', 'checkers', 'checkers for', 'checkers for each', 'chemical', 'chemical reactions', 'chemical reactions thereby', 'chemistry', 'chemistry where', 'chemistry where novel', 'chemists', 'chemists to', 'chemists to tailor', 'chooses', 'chooses to', 'chooses to examine', 'chosen', 'chosen pixel', 'chosen pixel machine', 'chosen tasks', 'chosen tasks and', 'cinematch', 'cinematch movie', 'cinematch movie recommendation', 'claimed', 'claimed that', 'claimed that such', 'class', 'class has', 'class has already', 'class issues', 'class issues that', 'class labels', 'class labels and', 'class labels decision', 'class of', 'class of computing', 'class of functions', 'class of models', 'class of statistical', 'class of tasks', 'class that', 'class that is', 'class to', 'class to which', 'classes', 'classes and', 'classes and can', 'classes cannot', 'classes cannot be', 'classic', 'classic examples', 'classic examples include', 'classification', 'classification algorithm', 'classification algorithm that', 'classification algorithms', 'classification algorithms are', 'classification and', 'classification and regression', 'classification but', 'classification but the', 'classification hazard', 'classification hazard prediction', 'classification interest', 'classification interest related', 'classification model', 'classification model assessment', 'classification of', 'classification of any', 'classification of machine', 'classification often', 'classification often require', 'classification one', 'classification one wants', 'classification or', 'classification or even', 'classification or predictions', 'classification problems', 'classification problems is', 'classification setting', 'classification setting in', 'classification svms', 'classification svms can', 'classification the', 'classification the problem', 'classification tree', 'classification tree can', 'classification trees', 'classification trees in', 'classification using', 'classification using what', 'classifications', 'classifications on', 'classifications on new', 'classified', 'classified or', 'classified or categorised', 'classifier', 'classifier although', 'classifier although methods', 'classifier systems', 'classifier systems association', 'classifier systems lcs', 'classifier the', 'classifier the key', 'classifier trained', 'classifier trained only', 'classifiers', 'classifiers often', 'classifiers often do', 'classify', 'classify data', 'classify data based', 'classify the', 'classify the cancerous', 'classifying', 'classifying data', 'classifying data may', 'classifying eg', 'classifying eg for', 'clean', 'clean image', 'clean image patch', 'close', 'close connection', 'close connection between', 'closely', 'closely related', 'closely related fields', 'closely related to', 'cloud', 'cloud ai', 'cloud ai openai', 'cloud ai services', 'cloud servers', 'cloud servers for', 'cloudbased', 'cloudbased environments', 'cluster', 'cluster analysis', 'cluster analysis algorithm', 'cluster analysis feature', 'cluster analysis is', 'cluster and', 'cluster and separation', 'cluster are', 'cluster are similar', 'clustering', 'clustering aids', 'clustering aids in', 'clustering an', 'clustering an unsupervised', 'clustering can', 'clustering can be', 'clustering dimensionality', 'clustering dimensionality reduction', 'clustering techniques', 'clustering techniques make', 'clusters', 'clusters are', 'clusters are dissimilar', 'clusters k', 'clusters k each', 'clusters other', 'clusters other methods', 'clusters so', 'clusters so that', 'clusters this', 'clusters this technique', 'coders', 'coders of', 'coders of the', 'coding', 'coding algorithms', 'coding algorithms attempt', 'coding on', 'coding on the', 'cofounder', 'cofounder of', 'cofounder of sun', 'cognition', 'cognition and', 'cognition and emotionthe', 'cognitive', 'cognitive processes', 'cognitive processes in', 'cognitive systems', 'cognitive systems contributed', 'cognitive terms', 'cognitive terms this', 'coined', 'coined in', 'coined in by', 'collaboration', 'collaboration with', 'collaboration with the', 'collect', 'collect a', 'collect a large', 'collected', 'collected from', 'collected from individual', 'collected with', 'collected with biases', 'collection', 'collection of', 'collection of connected', 'collection of data', 'collection of images', 'collection of the', 'collectively', 'collectively represent', 'collectively represent the', 'collectively store', 'collectively store and', 'collision', 'collision attempts', 'collision attempts to', 'combination', 'combination just', 'combination just like', 'combination of', 'combination of basis', 'combine', 'combine a', 'combine a discovery', 'combine probabilities', 'combine probabilities however', 'combined', 'combined eg', 'combined eg dempsters', 'combined field', 'combined field that', 'combined form', 'combining', 'combining forecasts', 'combining forecasts mlas', 'come', 'come from', 'come from some', 'come to', 'come to dominate', 'come up', 'come up with', 'comes', 'comes from', 'comes from the', 'coming', 'coming from', 'coming from the', 'commercial', 'commercial cloud', 'commercial cloud ai', 'commission', 'commission for', 'commission for racial', 'committee', 'committee which', 'committee which claimed', 'common', 'common ann', 'common ann implementations', 'common form', 'common form is', 'common optimisation', 'common optimisation techniques', 'common statistical', 'common statistical definition', 'common the', 'common the biasvariance', 'commonalities', 'commonalities in', 'commonalities in each', 'commonalities in the', 'commonly', 'commonly identify', 'commonly identify a', 'communicate', 'communicate data', 'communicate data other', 'communities', 'communities after', 'communities after being', 'communities which', 'communities which do', 'compact', 'compact set', 'compact set of', 'compactness', 'compactness or', 'compactness or the', 'company', 'company characteristics', 'company characteristics to', 'company geoliticas', 'company geoliticas predictive', 'company to', 'company to analyse', 'compared', 'compared to', 'compared to bayesian', 'compared to other', 'comparison', 'comparison the', 'comparison the kfoldcrossvalidation', 'compatible', 'compatible to', 'compatible to be', 'competition', 'competition to', 'competition to find', 'completely', 'completely labelled', 'completely labelled training', 'complex', 'complex than', 'complex than the', 'complex the', 'complex the theory', 'complex then', 'complex then the', 'complex theory', 'complex theory gerrymandered', 'complexity', 'complexity and', 'complexity and feasibility', 'complexity of', 'complexity of the', 'complexity of these', 'complexity results', 'complexity results positive', 'component', 'component analysis', 'component analysis and', 'component analysis autoencoders', 'component analysis pca', 'component of', 'component of ai', 'component performing', 'component performing either', 'component typically', 'component typically a', 'components', 'components of', 'components of the', 'compress', 'compress data', 'compress data by', 'compressed', 'compressed size', 'compressed size includes', 'compresses', 'compresses best', 'compresses best given', 'compression', 'compression a', 'compression a system', 'compression aims', 'compression aims to', 'compression algorithms', 'compression algorithms implicitly', 'compression algorithms is', 'compression as', 'compression as a', 'compression by', 'compression by using', 'compression include', 'compression include opencv', 'compression methods', 'compression methods lzw', 'compression of', 'compression of x', 'compression software', 'compression software include', 'compressionbased', 'compressionbased similarity', 'compressionbased similarity measures', 'compressor', 'compressor c', 'compressor c we', 'compressor can', 'compressor can be', 'comprise', 'comprise the', 'comprise the foundations', 'computation', 'computation as', 'computation as opposed', 'computation is', 'computation is considered', 'computation time', 'computation time when', 'computational', 'computational analysis', 'computational analysis of', 'computational complexity', 'computational complexity of', 'computational learning', 'computational learning theory', 'computational techniques', 'computational techniques derived', 'computationally', 'computationally convenient', 'computationally convenient to', 'computations', 'computations making', 'computations making them', 'computations while', 'computations while maintaining', 'compute', 'compute required', 'compute required with', 'compute similarity', 'compute similarity within', 'compute the', 'compute the probabilities', 'compute used', 'compute used in', 'computed', 'computed by', 'computed by looking', 'computed by some', 'computer', 'computer gaming', 'computer gaming and', 'computer hardware', 'computer hardware have', 'computer program', 'computer program is', 'computer program trained', 'computer science', 'computer science around', 'computer science known', 'computer terminal', 'computer vision', 'computer vision and', 'computer vision of', 'computer vision speech', 'computers', 'computers edge', 'computers edge devices', 'computers to', 'computers to communicate', 'computers was', 'computers was also', 'computes', 'computes in', 'computes in a', 'computing', 'computing and', 'computing and model', 'computing machinery', 'computing machinery and', 'computing refers', 'computing refers to', 'computing research', 'computing research association', 'computing resources', 'computing resources such', 'computing systems', 'computing systems designed', 'computing systems vaguely', 'concept', 'concept in', 'concept in machine', 'concept of', 'concept of linear', 'concept of strong', 'concern', 'concern for', 'concern for fairness', 'concerned', 'concerned offers', 'concerned offers a', 'concerned with', 'concerned with how', 'concerned with the', 'concerns', 'concerns among', 'concerns among health', 'conclude', 'conclude that', 'conclude that all', 'conclusions', 'conclusions about', 'conclusions about the', 'condenses', 'condenses extensive', 'condenses extensive datasets', 'conditional', 'conditional independence', 'conditional independence with', 'conditions', 'conditions for', 'conditions for optimal', 'conferences', 'conferences and', 'conferences and separate', 'configurations', 'configurations that', 'configurations that are', 'confusion', 'confusion between', 'confusion between these', 'conjunction', 'conjunction with', 'conjunction with a', 'conjunctions', 'conjunctions of', 'conjunctions of features', 'connected', 'connected to', 'connected to it', 'connected units', 'connected units or', 'connection', 'connection artificial', 'connection artificial neurons', 'connection between', 'connection between artificial', 'connection between machine', 'connection like', 'connection like the', 'connection more', 'connection more directly', 'connectionism', 'connectionism by', 'connectionism by researchers', 'connectionist', 'connectionist systems', 'connectionist systems are', 'connections', 'connections between', 'connections between artificial', 'connections to', 'connections to other', 'connectivity', 'consequence', 'consequence situation', 'consequence situation the', 'consequence situations', 'consequence situations the', 'consider', 'consider the', 'consider the order', 'considerable', 'considerable improvement', 'considerable improvement in', 'consideration', 'consideration by', 'consideration by obtaining', 'considered', 'considered a', 'considered a critical', 'considered acceptable', 'considered acceptable unless', 'considered as', 'considered as either', 'considered feasible', 'considered feasible if', 'considered representative', 'considered representative of', 'considered to', 'considered to have', 'considering', 'considering examples', 'considering examples generally', 'considering subset', 'considering subset for', 'considers', 'considers any', 'considers any kind', 'consists', 'consists of', 'consists of a', 'consists of multiple', 'constitute', 'constitute animal', 'constitute animal brains', 'constitutional', 'constitutional and', 'constitutional and unconscious', 'constraint', 'constraint that', 'constraint that the', 'construct', 'construct a', 'construct a model', 'contain', 'contain biases', 'contain biases machines', 'contain humanlike', 'contain humanlike biases', 'contain many', 'contain many layers', 'containing', 'containing a', 'containing a variety', 'contains', 'contains both', 'contains both desirable', 'contains both the', 'context', 'context is', 'context is the', 'context of', 'context of abuse', 'context of generalisation', 'contextdependent', 'contextdependent rules', 'contextdependent rules that', 'contexts', 'contexts in', 'contexts in classification', 'continue', 'continue within', 'continue within ai', 'continued', 'continued into', 'continued into the', 'continued outside', 'continued outside the', 'continuous', 'continuous production', 'continuous production and', 'continuous values', 'continuous values typically', 'contrast', 'contrast machine', 'contrast machine learning', 'contrast regression', 'contrast regression is', 'contrast to', 'contrast to other', 'contrast with', 'contrast with sequence', 'contrasts', 'contrasts with', 'contrasts with the', 'contributed', 'contributed to', 'contributed to the', 'control', 'control theory', 'control theory operations', 'controversy', 'controversy the', 'controversy the gorilla', 'convenient', 'convenient to', 'convenient to process', 'conventional', 'conventional hardware', 'conventional hardware or', 'conventional statistical', 'conventional statistical analyses', 'conventionally', 'conventionally training', 'conventionally training set', 'conversely', 'conversely an', 'conversely an optimal', 'conversely machine', 'conversely machine learning', 'core', 'core information', 'core information of', 'core objective', 'core objective of', 'corpora', 'corpora will', 'corpora will necessarily', 'corpus', 'corpus of', 'corpus of text', 'correct', 'correct learning', 'correct learning model', 'correct learning provides', 'correctly', 'correctly determine', 'correctly determine the', 'correctly machine', 'correctly machine learning', 'correctly predict', 'correctly predict the', 'correlate', 'correlate with', 'correlate with images', 'correspond', 'correspond to', 'correspond to learning', 'corresponding', 'corresponding dictionary', 'corresponding dictionary sparse', 'corresponding to', 'corresponding to the', 'could', 'could be', 'could be designed', 'could have', 'could have a', 'could represent', 'could represent the', 'couple', 'couple of', 'couple of black', 'coupled', 'coupled with', 'coupled with supervised', 'covariance', 'covariance function', 'covariance function or', 'covariances', 'covariances between', 'covariances between those', 'covers', 'covers a', 'covers a broad', 'covers various', 'covers various emerging', 'covid', 'covid machine', 'covid machine learning', 'cpus', 'cpus as', 'cpus as the', 'cra', 'cra in', 'cra in female', 'created', 'created by', 'created by people', 'created using', 'created using machine', 'crime', 'crime data', 'crisis', 'crisis in', 'crisis in cofounder', 'criteria', 'criteria while', 'criteria while observations', 'criterion', 'criterion such', 'criterion such as', 'critical', 'critical part', 'critical part of', 'crossbar', 'crossbar adaptive', 'crossbar adaptive array', 'crossbar fashion', 'crossbar fashion both', 'crosses', 'crosses that', 'crosses that threshold', 'crossover', 'crossover to', 'crossover to generate', 'crossvalidation', 'crossvalidation methods', 'crossvalidation methods bootstrap', 'cultural', 'cultural prejudices', 'cultural prejudices for', 'cumulative', 'cumulative reward', 'cumulative reward due', 'cure', 'cure for', 'cure for covid', 'current', 'current customers', 'current customers may', 'current image', 'current image classifiers', 'current research', 'current research especially', 'curve', 'curve auc', 'curve auc offer', 'customer', 'customer buys', 'customer buys onions', 'customer groups', 'customer groups that', 'customers', 'customers may', 'customers may not', 'cybersecurity', 'cybersecurity key', 'cybersecurity key rbml', 'cybertron', 'cybertron had', 'cybertron had been', 'd', 'd to', 'd to a', 'dag', 'dag for', 'dag for example', 'data', 'data according', 'data according to', 'data acquisition', 'data acquisition and', 'data an', 'data an algorithm', 'data analysis', 'data analysis eda', 'data and', 'data and business', 'data and data', 'data and documentation', 'data and evolve', 'data and generalise', 'data and patterns', 'data and react', 'data and supervised', 'data and thus', 'data as', 'data as well', 'data based', 'data based on', 'data bias', 'data bias privacy', 'data biases', 'data biases a', 'data breaches', 'data breaches privacy', 'data but', 'data but penalising', 'data but the', 'data by', 'data by grouping', 'data can', 'data can be', 'data can produce', 'data can result', 'data central', 'data central applications', 'data collected', 'data collected from', 'data compression', 'data compression aims', 'data compression as', 'data compression by', 'data consists', 'data consists of', 'data data', 'data data bias', 'data data from', 'data data mining', 'data during', 'data during training', 'data eg', 'data eg d', 'data examples', 'data examples include', 'data files', 'data files enhancing', 'data from', 'data from a', 'data from the', 'data has', 'data has not', 'data have', 'data have been', 'data if', 'data if the', 'data in', 'data in a', 'data into', 'data into k', 'data is', 'data is known', 'data is represented', 'data it', 'data it provides', 'data itself', 'data known', 'data known as', 'data lack', 'data lack of', 'data machine', 'data machine learning', 'data may', 'data may use', 'data mining', 'data mining a', 'data mining and', 'data mining anomaly', 'data mining focuses', 'data mining is', 'data mining kdd', 'data mining methods', 'data mining often', 'data mining uses', 'data model', 'data model and', 'data not', 'data not being', 'data of', 'data of a', 'data of from', 'data of previous', 'data often', 'data often defined', 'data on', 'data on cloud', 'data other', 'data other researchers', 'data points', 'data points into', 'data points with', 'data recorded', 'data recorded by', 'data reduction', 'data reduction by', 'data science', 'data science as', 'data set', 'data set and', 'data set are', 'data set in', 'data set supervised', 'data set that', 'data set the', 'data set under', 'data sets', 'data sets lie', 'data shape', 'data shape the', 'data some', 'data some of', 'data such', 'data such as', 'data that', 'data that contains', 'data that has', 'data the', 'data the house', 'data they', 'data they attempted', 'data this', 'data this is', 'data to', 'data to a', 'data to perform', 'data transmission', 'data transmission kmeans', 'data typically', 'data typically the', 'data unless', 'data unless aggregated', 'data when', 'data when trained', 'data when used', 'data while', 'data while significantly', 'data without', 'data without reshaping', 'database', 'database of', 'database of facts', 'databases', 'databases data', 'databases data mining', 'databases it', 'databases it is', 'databases using', 'databases using some', 'datacentric', 'datacentric methods', 'datacentric methods in', 'datagenerating', 'datagenerating distribution', 'datagenerating distribution while', 'dataset', 'dataset can', 'dataset can be', 'dataset into', 'dataset into a', 'datasets', 'datasets collected', 'datasets collected with', 'datasets into', 'datasets into a', 'datasets that', 'datasets that lack', 'datasoftware', 'datasoftware transparency', 'datasoftware transparency is', 'david', 'david rumelhart', 'david rumelhart and', 'days', 'days of', 'days of ai', 'dealing', 'dealing mostly', 'dealing mostly with', 'dealing with', 'dealing with nonlinear', 'decades', 'decades of', 'decades of human', 'decades to', 'decades to automated', 'decentralises', 'decentralises the', 'decentralises the training', 'decentralising', 'decentralising the', 'decentralising the training', 'decide', 'decide to', 'decide to evacuate', 'decision', 'decision analysis', 'decision analysis a', 'decision boundary', 'decision boundary low', 'decision by', 'decision by refining', 'decision making', 'decision making in', 'decision problems', 'decision problems under', 'decision process', 'decision process mdp', 'decision tree', 'decision tree as', 'decision tree can', 'decision tree describes', 'decision tree is', 'decision tree learning', 'decision treebased', 'decision treebased models', 'decision trees', 'decision trees and', 'decision trees rfr', 'decision trees where', 'decisionmaking', 'decisionmaking accountability', 'decisionmaking accountability privacy', 'decisionmaking in', 'decisionmaking in fields', 'decisions', 'decisions a', 'decisions a representative', 'decisions about', 'decisions about actions', 'decisions about marketing', 'decisions and', 'decisions and decision', 'decisions in', 'decisions in building', 'decisions it', 'decisions it makes', 'decisions or', 'decisions or predictions', 'decomposition', 'decomposition is', 'decomposition is one', 'decreases', 'decreases but', 'decreases but if', 'decreases the', 'decreases the strength', 'decreasing', 'decreasing the', 'decreasing the required', 'deep', 'deep learning', 'deep learning algorithms', 'deep learning are', 'deep learning consists', 'deep learning have', 'deep learning projects', 'deep learning tasks', 'deep neural', 'deep neural networks', 'deepmind', 'deepmind alphafold', 'deepmind alphafold and', 'deeprooted', 'deeprooted physics', 'deeprooted physics of', 'defect', 'defect medical', 'defect medical problems', 'defendants', 'defendants high', 'defendants high risk', 'defendants in', 'defendants in google', 'define', 'define an', 'define an associated', 'define specific', 'define specific features', 'defined', 'defined by', 'defined by some', 'defined in', 'defined in terms', 'defining', 'defining characteristic', 'defining characteristic of', 'defining the', 'defining the field', 'definition', 'definition of', 'definition of an', 'definition of the', 'definition rather', 'definition rather than', 'deliver', 'deliver even', 'deliver even after', 'deliver expected', 'deliver expected results', 'demonstrated', 'demonstrated how', 'demonstrated how backdoors', 'demonstrates', 'demonstrates a', 'demonstrates a lack', 'dempsters', 'dempsters rule', 'dempsters rule of', 'dempstershafer', 'dempstershafer theory', 'dempstershafer theory is', 'denied', 'denied nearly', 'denied nearly candidates', 'denoising', 'denoising the', 'denoising the key', 'denominators', 'denominators receiver', 'denominators receiver operating', 'density', 'density and', 'density and graph', 'density estimation', 'dependent', 'dependent on', 'dependent on the', 'dependent variables', 'dependent variables simultaneously', 'depending', 'depending on', 'depending on the', 'depending on their', 'deployed', 'deployed on', 'deployed on embedded', 'derive', 'derive a', 'derive a hypothesized', 'derived', 'derived from', 'derived from biased', 'derived from deeprooted', 'described', 'described by', 'described by duda', 'describes', 'describes data', 'describes data but', 'describing', 'describing machine', 'describing machine learning', 'designation', 'designation and', 'designation and evaluates', 'designed', 'designed in', 'designed in the', 'designed to', 'designed to emulate', 'designed to provide', 'designers', 'designers cannot', 'designers cannot explain', 'desirable', 'desirable and', 'desirable and undesirable', 'desire', 'desire and', 'desire and effort', 'desired', 'desired output', 'desired output also', 'desired outputs', 'desired outputs the', 'detect', 'detect a', 'detect a pedestrian', 'detect anomalies', 'detect anomalies in', 'detect the', 'detect the microclusters', 'detecting', 'detecting underlying', 'detecting underlying patterns', 'detection', 'detection also', 'detection also known', 'detection and', 'detection and cybersecurity', 'detection continuous', 'detection continuous production', 'detection is', 'detection is the', 'detection methods', 'detection methods in', 'detection semisupervised', 'detection semisupervised anomaly', 'detection techniques', 'detection techniques construct', 'detection techniques detect', 'detection techniques exist', 'detection techniques require', 'detection the', 'detection the interesting', 'determine', 'determine the', 'determine the class', 'determine the output', 'detrimental', 'detrimental outcomes', 'detrimental outcomes thereby', 'developed', 'developed by', 'developed by google', 'developed by raytheon', 'developed or', 'developed or trained', 'developed sufficiently', 'developed sufficiently to', 'developed the', 'developed the other', 'developed which', 'developed which do', 'developing', 'developing a', 'developing a cure', 'development', 'development and', 'development and study', 'deviations', 'deviations and', 'deviations and exceptions', 'deviations from', 'deviations from biology', 'devices', 'devices and', 'devices and microcontrollers', 'devices eliminates', 'devices eliminates the', 'devices for', 'devices for example', 'diagnose', 'diagnose medicate', 'diagnose medicate and', 'diagnoses', 'diagnoses and', 'diagnoses and aid', 'diagnosis', 'diagnostic', 'diagnostic software', 'diagnostic software in', 'diagnostics', 'diagrams', 'dictionary', 'dictionary but', 'dictionary but the', 'dictionary learning', 'dictionary learning has', 'dictionary learning in', 'dictionary learning independent', 'dictionary learning is', 'dictionary sparse', 'dictionary sparse dictionary', 'dictionary where', 'dictionary where each', 'did', 'did continue', 'did continue within', 'difference', 'difference between', 'difference between clusters', 'difference from', 'difference from many', 'different', 'different assumptions', 'different assumptions on', 'different clustering', 'different clustering techniques', 'different clusters', 'different clusters are', 'different data', 'different data biases', 'different goals', 'different goals on', 'different kinds', 'different kinds of', 'different layers', 'different layers may', 'different machine', 'different machine learning', 'different solutions', 'different solutions have', 'differing', 'differing significantly', 'differing significantly from', 'difficult', 'difficult to', 'difficult to solve', 'difficulty', 'difficulty resolving', 'difficulty resolving however', 'digitising', 'digitising cultural', 'digitising cultural prejudices', 'digits', 'digits and', 'digits and special', 'dilemma', 'dilemma of', 'dilemma of improving', 'dimension', 'dimension of', 'dimension of the', 'dimensionality', 'dimensionality reduction', 'dimensionality reduction and', 'dimensionality reduction is', 'dimensionality reduction techniques', 'directed', 'directed acyclic', 'directed acyclic graph', 'directed acyclic graphical', 'directly', 'directly computed', 'directly computed by', 'directly explained', 'directly explained in', 'directly from', 'directly from tensor', 'directly on', 'directly on these', 'disappoint', 'disappoint by', 'disappoint by learning', 'disasters', 'disasters different', 'disasters different solutions', 'discipline', 'discipline some', 'discipline some researchers', 'disciplines', 'disciplines including', 'disciplines including john', 'disciplines such', 'disciplines such as', 'discover', 'discover multiple', 'discover multiple levels', 'discover such', 'discover such features', 'discovered', 'discovered in', 'discovered in databases', 'discovering', 'discovering better', 'discovering better representations', 'discovering regularities', 'discovering regularities between', 'discovering relationships', 'discovering relationships between', 'discovers', 'discovers and', 'discovers and learns', 'discovery', 'discovery and', 'discovery and data', 'discovery component', 'discovery component typically', 'discovery in', 'discovery in databases', 'discovery of', 'discovery of previously', 'discrepancy', 'discrepancy between', 'discrepancy between the', 'discrete', 'discrete set', 'discrete set of', 'diseases', 'diseases and', 'diseases and symptoms', 'diseases efficient', 'diseases efficient algorithms', 'disentangles', 'disentangles the', 'disentangles the underlying', 'dismantling', 'dismantling their', 'dismantling their misconceptions', 'disordered', 'disordered systems', 'disordered systems can', 'displaced', 'displaced cpus', 'displaced cpus as', 'disproportionately', 'disproportionately high', 'disproportionately high levels', 'dissimilar', 'dissimilar different', 'dissimilar different clustering', 'distillation', 'distillation lowrank', 'distillation lowrank factorisation', 'distinct', 'distinct in', 'distinct in their', 'distinguished', 'distinguished two', 'distinguished two statistical', 'distributed', 'distributed artificial', 'distributed artificial intelligence', 'distribution', 'distribution and', 'distribution and it', 'distribution considered', 'distribution considered representative', 'distribution conversely', 'distribution conversely an', 'distribution of', 'distribution of the', 'distribution this', 'distribution this replaces', 'distribution while', 'distribution while not', 'diversity', 'diversity in', 'diversity in the', 'divided', 'divided into', 'divided into three', 'do', 'do hyperparameter', 'do hyperparameter optimisation', 'do not', 'do not assume', 'do not fit', 'do not primarily', 'do often', 'do often have', 'do so', 'do so under', 'do what', 'do what we', 'doctors', 'doctors jobs', 'doctors jobs would', 'documentation', 'documentation of', 'documentation of algorithmic', 'does', 'does not', 'does not adhere', 'does not consider', 'does not yield', 'dollars', 'dollars invested', 'dollars invested microsofts', 'domain', 'domain typically', 'domain typically leverage', 'domains', 'domains concern', 'domains concern for', 'dominant', 'dominant method', 'dominant method of', 'dominate', 'dominate ai', 'dominate ai and', 'donald', 'donald hebb', 'donald hebb published', 'done', 'done in', 'done in polynomial', 'doublingtime', 'doublingtime trendline', 'doublingtime trendline of', 'drawn', 'drawn from', 'drawn from different', 'drawn to', 'drawn to best', 'draws', 'draws population', 'draws population inferences', 'driven', 'driven by', 'driven by the', 'dthe', 'dthe manifold', 'dthe manifold hypothesis', 'duda', 'duda and', 'duda and hart', 'due', 'due to', 'due to its', 'due to the', 'duplicating', 'duplicating the', 'duplicating the bias', 'during', 'during the', 'during the s', 'during training', 'during training a', 'during training classic', 'during wildfires', 'during wildfires and', 'dynamic', 'dynamic bayesian', 'dynamic bayesian networks', 'dynamic programming', 'dynamic programming techniques', 'dynamics', 'dynamics ai', 'dynamics ai safety', 'e', 'e this', 'e this definition', 'e with', 'e with respect', 'each', 'each algorithm', 'each algorithm has', 'each artificial', 'each artificial neuron', 'each class', 'each class has', 'each compressor', 'each compressor c', 'each connection', 'each connection like', 'each decision', 'each decision tree', 'each iteration', 'each iteration executes', 'each marked', 'each marked as', 'each new', 'each new piece', 'each other', 'each other depending', 'each represented', 'each represented by', 'each respectively', 'each respectively considering', 'each side', 'each side the', 'each training', 'each training example', 'earliest', 'earliest machine', 'earliest machine learning', 'early', 'early days', 'early days of', 'early mathematical', 'early mathematical models', 'early s', 'early s an', 'easily', 'easily be', 'easily be outperformed', 'ecml', 'ecml pkdd', 'ecml pkdd being', 'economic', 'economic indicators', 'economic indicators or', 'eda', 'eda via', 'eda via unsupervised', 'edge', 'edge devices', 'edge devices and', 'edges', 'edges artificial', 'edges artificial neurons', 'edges typically', 'edges typically have', 'effective', 'effective feature', 'effective feature engineering', 'effective training', 'effective training sets', 'effective use', 'effective use of', 'effectively', 'effectively xai', 'effectively xai may', 'effects', 'effects on', 'effects on chemical', 'efficiency', 'efficiency and', 'efficiency and speeding', 'efficiency by', 'efficiency by decentralising', 'efficiency since', 'efficiency since their', 'efficient', 'efficient algorithms', 'efficient algorithms exist', 'efficient for', 'efficient for deep', 'efficient methods', 'efficient methods for', 'efficiently', 'efficiently perform', 'efficiently perform a', 'effort', 'effort to', 'effort to study', 'eg', 'eg d', 'eg d to', 'eg dempsters', 'eg dempsters rule', 'eg dthe', 'eg dthe manifold', 'eg for', 'eg for categories', 'eg maml', 'eg to', 'eg to analyse', 'ehud', 'ehud shapiro', 'ehud shapiro laid', 'either', 'either be', 'either be women', 'either feature', 'either feature elimination', 'either supervised', 'either supervised learning', 'either supervised or', 'either within', 'either within a', 'electrically', 'electrically adjustable', 'electrically adjustable materials', 'electrocardiograms', 'electrocardiograms and', 'electrocardiograms and speech', 'eliminates', 'eliminates the', 'eliminates the need', 'elimination', 'elimination or', 'elimination or extraction', 'email', 'email and', 'email and the', 'email filtering', 'email filtering agriculture', 'email in', 'email in contrast', 'emails', 'emails the', 'emails the input', 'embedded', 'embedded machine', 'embedded machine learning', 'embedded systems', 'embedded systems with', 'emerging', 'emerging as', 'emerging as a', 'emerging or', 'emerging or potential', 'emotion', 'emotion as', 'emotion as an', 'emotion is', 'emotion is used', 'emotion toward', 'emotion toward the', 'emotions', 'emotions about', 'emotions about situations', 'emotions feelings', 'emotions feelings about', 'emotionthe', 'emotionthe selflearning', 'emotionthe selflearning algorithm', 'emphasis', 'emphasis on', 'emphasis on the', 'emphasizes', 'emphasizes a', 'emphasizes a move', 'employ', 'employ the', 'employ the same', 'employed', 'employed especially', 'employed especially in', 'employed to', 'employed to partition', 'employed today', 'employed today in', 'employee', 'employee and', 'employee and pioneer', 'employing', 'employing effective', 'employing effective feature', 'employs', 'employs data', 'employs data mining', 'emulate', 'emulate the', 'emulate the function', 'emulate the structure', 'enable', 'enable the', 'enable the prediction', 'enables', 'enables it', 'enables it to', 'enables model', 'enables model to', 'encoding', 'encoding of', 'encoding of the', 'encompasses', 'encompasses a', 'encompasses a large', 'encountered', 'encountered in', 'encountered in the', 'endeavour', 'endeavour machine', 'endeavour machine learning', 'energy', 'energy efficiency', 'energy efficiency since', 'engine', 'engine accordingly', 'engine accordingly in', 'engineering', 'engineering and', 'engineering and allows', 'engineering and combining', 'engineering judgment', 'engineering judgment but', 'engineering teams', 'engineering where', 'engineering where it', 'engineers', 'engineers need', 'engineers need to', 'enhance', 'enhance it', 'enhance it using', 'enhancements', 'enhancements had', 'enhancements had displaced', 'enhancing', 'enhancing storage', 'enhancing storage efficiency', 'ensemble', 'ensemble learning', 'ensemble learning method', 'ensemble methods', 'ensemble methods to', 'ensemble model', 'ensemble model to', 'entails', 'entails all', 'entails all positive', 'entire', 'entire history', 'entire history can', 'entirely', 'entirely opaque', 'entirely opaque meaning', 'entities', 'entities can', 'entities can do', 'environment', 'environment after', 'environment after receiving', 'environment is', 'environment is typically', 'environment so', 'environment so as', 'environment that', 'environment that contains', 'environment the', 'environment the backpropagated', 'environment the caa', 'environment where', 'environment where it', 'environment wherefrom', 'environment wherefrom it', 'environments', 'environments one', 'environments one is', 'equality', 'equality found', 'equality found that', 'equipped', 'equipped with', 'equipped with a', 'equivalence', 'equivalence has', 'equivalence has been', 'error', 'error decreases', 'error decreases but', 'errors', 'errors in', 'errors in a', 'errors in its', 'especially', 'especially for', 'especially for deep', 'especially in', 'especially in automated', 'especially in cloudbased', 'especially true', 'especially true in', 'estimate', 'estimate the', 'estimate the relationship', 'estimated', 'estimated density', 'estimated density and', 'estimated the', 'estimated the hardware', 'estimates', 'estimates the', 'estimates the relationships', 'estimation', 'estimation techniques', 'estimation techniques like', 'ethical', 'ethical dilemma', 'ethical dilemma of', 'ethical stakes', 'ethical stakes this', 'ethically', 'ethically lethal', 'ethically lethal autonomous', 'ethics', 'ethics how', 'ethics how to', 'ethics is', 'ethics is becoming', 'ethics of', 'ethics of artificial', 'evacuate', 'evacuate during', 'evacuate during wildfires', 'evacuation', 'evacuation decision', 'evacuation decision making', 'evacuation decisions', 'evacuation decisions in', 'evaluated', 'evaluated for', 'evaluated for example', 'evaluated with', 'evaluated with respect', 'evaluates', 'evaluates the', 'evaluates the performance', 'evaluation', 'evaluation and', 'evaluation and the', 'evaluation of', 'evaluation of a', 'evaluation problems', 'evasion', 'evasion via', 'evasion via adversarial', 'even', 'even after', 'even after years', 'even its', 'even its designers', 'even kernel', 'even kernel regression', 'even smaller', 'even smaller combined', 'even the', 'even the coders', 'events', 'events or', 'events or observations', 'every', 'every finite', 'every finite collection', 'everything', 'everything is', 'everything is a', 'evidence', 'evidence is', 'evidence is combined', 'evidence related', 'evidence related to', 'evidence theory', 'evidence theory or', 'evolutionary', 'evolutionary algorithms', 'evolve', 'evolve rules', 'evolve rules over', 'evolves', 'evolves rules', 'evolves rules to', 'exact', 'exact mathematical', 'exact mathematical model', 'exact models', 'exact models are', 'examination', 'examination of', 'examination of the', 'examination without', 'examination without relying', 'examine', 'examine three', 'examine three representative', 'example', 'example a', 'example a bayesian', 'example belongs', 'example belongs for', 'example by', 'example by internal', 'example falls', 'example falls into', 'example gboard', 'example gboard uses', 'example has', 'example has one', 'example in', 'example in a', 'example in classification', 'example in that', 'example in the', 'example includes', 'example includes predictive', 'example is', 'example is associated', 'example is represented', 'example is that', 'example the', 'example the algorithms', 'example the rule', 'example topic', 'example topic modelling', 'example used', 'example used for', 'examples', 'examples are', 'examples are missing', 'examples background', 'examples background knowledge', 'examples come', 'examples come from', 'examples each', 'examples each marked', 'examples each training', 'examples generally', 'examples generally without', 'examples include', 'examples include artificial', 'examples include dictionary', 'examples include principal', 'examples inductive', 'examples inductive programming', 'examples loss', 'examples loss functions', 'examples of', 'examples of aipowered', 'examples of software', 'examples represented', 'examples represented as', 'examples the', 'examples the distribution', 'examples the term', 'examples using', 'examples using a', 'examplestasks', 'examplestasks after', 'examplestasks after having', 'excel', 'excel logistic', 'excel logistic regression', 'exception', 'exception comes', 'exception comes from', 'exceptions', 'executes', 'executes the', 'executes the following', 'exhaustive', 'exhaustive examination', 'exhaustive examination of', 'exhibit', 'exhibit these', 'exhibit these biases', 'exist', 'exist that', 'exist that perform', 'exist to', 'exist to use', 'exist unsupervised', 'exist unsupervised anomaly', 'existential', 'existential risks', 'existing', 'existing cinematch', 'existing cinematch movie', 'exists', 'exists in', 'exists in two', 'expected', 'expected results', 'expected results reasons', 'experience', 'experience are', 'experience are included', 'experience e', 'experience e this', 'experience e with', 'experience generalisation', 'experience generalisation in', 'experienced', 'experienced a', 'experienced a learning', 'experiment', 'experiment carried', 'experiment carried out', 'experimental', 'experimental conditions', 'experimental conditions for', 'experimental learning', 'experimental learning machine', 'experiments', 'experiments are', 'experiments are performed', 'expert', 'expert systems', 'expert systems had', 'explain', 'explain observed', 'explain observed facts', 'explain the', 'explain the observed', 'explain why', 'explain why an', 'explainable', 'explainable ai', 'explainable ai xai', 'explainable machine', 'explainable machine learning', 'explained', 'explained in', 'explained in hutter', 'explanation', 'explanation for', 'explanation for the', 'explicit', 'explicit algorithms', 'explicit instructions', 'explicit instructions within', 'explicitly', 'explicitly represent', 'explicitly represent decisions', 'exploratory', 'exploratory data', 'exploratory data analysis', 'express', 'express the', 'express the discrepancy', 'expressed', 'expressed by', 'expressed by artificial', 'extended', 'extended by', 'extended by regularisation', 'extended into', 'extended into the', 'extended to', 'extended to largescale', 'extends', 'extends the', 'extends the concept', 'extension', 'extension the', 'extension the term', 'extensive', 'extensive datasets', 'extensive datasets into', 'extensive datasets that', 'external', 'external reward', 'external reward by', 'extract', 'extract patterns', 'extract patterns from', 'extracted', 'extracted out', 'extracted out of', 'extraction', 'extraction one', 'extraction one of', 'face', 'face verification', 'face verification and', 'fact', 'fact according', 'fact according to', 'fact that', 'fact that machine', 'factorisation', 'factorisation and', 'factorisation and various', 'factorisation network', 'factorisation network architecture', 'factors', 'factors like', 'factors like age', 'factors of', 'factors of variation', 'facts', 'facts an', 'facts an ilp', 'facts rather', 'facts rather than', 'faculty', 'faculty members', 'faculty members who', 'faculty merely', 'faculty merely make', 'fail', 'fail on', 'fail on such', 'fail to', 'fail to deliver', 'fail to reveal', 'failed', 'failed to', 'failed to deliver', 'failed to detect', 'fairness', 'fairness automated', 'fairness automated decisionmaking', 'fairness in', 'fairness in machine', 'faithful', 'faithful to', 'faithful to configurations', 'falls', 'falls between', 'falls between unsupervised', 'falls into', 'falls into one', 'falls under', 'falls under umbrella', 'false', 'false negative', 'false negative rate', 'false positive', 'false positive rate', 'falsely', 'falsely flagged', 'falsely flagged black', 'family', 'family of', 'family of rulebased', 'far', 'far surpass', 'far surpass those', 'fashion', 'fashion both', 'fashion both decisions', 'favour', 'favour work', 'favour work on', 'feasibility', 'feasibility of', 'feasibility of learning', 'feasible', 'feasible if', 'feasible if it', 'feature', 'feature elimination', 'feature elimination or', 'feature engineering', 'feature engineering and', 'feature learning', 'feature learning algorithms', 'feature learning can', 'feature learning features', 'feature learning is', 'feature learning method', 'feature set', 'feature set also', 'feature space', 'feature space vectors', 'feature spaces', 'feature spaces for', 'feature spaces underlying', 'feature vector', 'feature vector and', 'feature vectors', 'feature vectors chooses', 'features', 'features an', 'features an alternative', 'features and', 'features and use', 'features are', 'features are learned', 'features defined', 'features defined in', 'features it', 'features it has', 'features its', 'features its most', 'features most', 'features most of', 'features or', 'features or representations', 'features that', 'features that lead', 'features with', 'features with higherlevel', 'federated', 'federated learning', 'federated learning is', 'federated machine', 'federated machine learning', 'feedback', 'feedback available', 'feedback available to', 'feedback unsupervised', 'feedback unsupervised learning', 'feelings', 'feelings about', 'feelings about consequence', 'feifei', 'feifei li', 'feifei li who', 'female', 'female faculty', 'female faculty merely', 'field', 'field a', 'field a computer', 'field as', 'field as connectionism', 'field changed', 'field changed its', 'field in', 'field in cognitive', 'field is', 'field is studied', 'field of', 'field of ai', 'field of art', 'field of computer', 'field of deep', 'field of quantum', 'field of study', 'field started', 'field started to', 'field that', 'field that considers', 'field that they', 'field where', 'field where machine', 'fields', 'fields in', 'fields in terms', 'fields including', 'fields including natural', 'fields like', 'fields like healthcare', 'fields machinelearning', 'fields machinelearning programs', 'fields such', 'fields such as', 'file', 'file and', 'file and the', 'file the', 'file the email', 'files', 'files compressed', 'files compressed size', 'files enhancing', 'files enhancing storage', 'filtering', 'filtering agriculture', 'filtering agriculture and', 'filtering playing', 'filtering playing board', 'filters', 'filters emails', 'filters emails the', 'finally', 'finally metalearning', 'finally metalearning eg', 'financial', 'financial crisis', 'financial crisis in', 'find', 'find a', 'find a program', 'find structures', 'find structures in', 'finding', 'finding applications', 'finding applications in', 'finding good', 'finding good solutions', 'finding the', 'finding the symbol', 'findings', 'findings research', 'findings research themselves', 'finds', 'finds application', 'finds application in', 'finds generalisable', 'finds generalisable predictive', 'finds widespread', 'finds widespread use', 'fine', 'fine art', 'fine art paintings', 'finite', 'finite and', 'finite and the', 'finite collection', 'finite collection of', 'fires', 'firm', 'firm rebellion', 'firm rebellion research', 'firm with', 'firm with racist', 'first', 'first implementation', 'first implementation model', 'first layer', 'first layer the', 'first netflix', 'first netflix prize', 'first research', 'first research book', 'fit', 'fit all', 'fit all the', 'fit neatly', 'fit neatly into', 'fit the', 'fit the given', 'fit the least', 'fits', 'fits the', 'fits the data', 'fitted', 'fitted the', 'fitted the data', 'fitting', 'fitting a', 'fitting a multidimensional', 'fitting in', 'fitting in microsoft', 'flagged', 'flagged black', 'flagged black defendants', 'flourish', 'flourish in', 'flourish in the', 'fnr', 'fnr however', 'fnr however these', 'focus', 'focus away', 'focus away from', 'focus on', 'focus on ai', 'focuses', 'focuses on', 'focuses on prediction', 'focuses on the', 'focusing', 'focusing on', 'focusing on exploratory', 'focusing on pre', 'fold', 'fold increase', 'fold increase in', 'folder', 'folder in', 'folder in which', 'following', 'following machine', 'following machine learning', 'follows', 'follows alan', 'follows alan turings', 'for', 'for a', 'for a dictionary', 'for a task', 'for all', 'for all members', 'for all problems', 'for analysis', 'for analysis in', 'for any', 'for any machine', 'for artificial', 'for artificial intelligence', 'for categories', 'for categories spam', 'for chemists', 'for chemists to', 'for classification', 'for classification and', 'for classification model', 'for computation', 'for computation as', 'for covid', 'for covid machine', 'for decisionmaking', 'for decisionmaking in', 'for decisions', 'for decisions about', 'for deep', 'for deep learning', 'for describing', 'for describing machine', 'for discovering', 'for discovering regularities', 'for discovering relationships', 'for each', 'for each compressor', 'for each side', 'for engineering', 'for engineering judgment', 'for evaluation', 'for evaluation and', 'for example', 'for example a', 'for example by', 'for example gboard', 'for example in', 'for example the', 'for example topic', 'for example used', 'for fairness', 'for fairness in', 'for further', 'for further processing', 'for future', 'for future outcomes', 'for general', 'for general intelligence', 'for how', 'for how ais', 'for human', 'for human good', 'for inductive', 'for inductive machine', 'for input', 'for input examples', 'for inputs', 'for inputs that', 'for instance', 'for instance each', 'for instances', 'for instances that', 'for machine', 'for machine learning', 'for machine learnings', 'for million', 'for million shortly', 'for multidimensional', 'for multidimensional data', 'for optimal', 'for optimal data', 'for optimal outcomes', 'for patients', 'for patients but', 'for pattern', 'for pattern classification', 'for prediction', 'for prediction by', 'for racial', 'for racial equality', 'for reasoning', 'for reasoning with', 'for representing', 'for representing hypotheses', 'for some', 'for some systems', 'for sparse', 'for sparse dictionary', 'for stock', 'for stock trading', 'for tasks', 'for tasks such', 'for tensor', 'for tensor computations', 'for the', 'for the best', 'for the decisions', 'for the findings', 'for the study', 'for this', 'for this are', 'for training', 'for training deep', 'for training enables', 'for training machine', 'for training the', 'for trendline', 'for trendline fitting', 'for users', 'for users privacy', 'for using', 'for using data', 'for when', 'for when training', 'for which', 'for which a', 'forecasting', 'forecasting future', 'forecasting future temperatures', 'forecasts', 'forecasts mlas', 'forecasts mlas can', 'forest', 'forest regression', 'forest regression rfr', 'form', 'form is', 'form is linear', 'form of', 'form of distributed', 'formal', 'formal definition', 'formal definition of', 'formed', 'formed by', 'formed by certain', 'formed by these', 'forms', 'forms of', 'forms of clustering', 'formulated', 'formulated as', 'formulated as minimisation', 'found', 'found a', 'found a fold', 'found in', 'found in many', 'found in the', 'found that', 'found that st', 'found that unlabelled', 'found to', 'found to be', 'found to either', 'foundation', 'foundation for', 'foundation for inductive', 'foundations', 'foundations of', 'foundations of machine', 'fpgas', 'fpgas tpus', 'fpgas tpus are', 'fpr', 'fpr as', 'fpr as well', 'framework', 'framework for', 'framework for describing', 'framework for reasoning', 'frameworks', 'frameworks can', 'frameworks can be', 'frameworks such', 'frameworks such as', 'fraud', 'fraud a', 'fraud a structural', 'fraud detection', 'fraud detection and', 'frequently', 'frequently report', 'frequently report sensitivity', 'from', 'from a', 'from a computer', 'from a firm', 'from a general', 'from a given', 'from a sample', 'from a theoretical', 'from achieving', 'from achieving artificial', 'from ai', 'from ai and', 'from alexnet', 'from alexnet to', 'from att', 'from att labsresearch', 'from basic', 'from basic linear', 'from biased', 'from biased or', 'from biology', 'from biology artificial', 'from data', 'from data and', 'from data have', 'from data it', 'from data of', 'from data they', 'from deeprooted', 'from deeprooted physics', 'from different', 'from different clusters', 'from different data', 'from examples', 'from examples using', 'from experience', 'from experience e', 'from individual', 'from individual users', 'from its', 'from its experience', 'from machine', 'from machine learning', 'from many', 'from many other', 'from methodological', 'from methodological principles', 'from nonpattern', 'from nonpattern perturbations', 'from observations', 'from observations about', 'from one', 'from one artificial', 'from other', 'from other disciplines', 'from positive', 'from positive and', 'from some', 'from some generally', 'from statistics', 'from statistics fuzzy', 'from supervised', 'from supervised learning', 'from tensor', 'from tensor representations', 'from the', 'from the basic', 'from the data', 'from the dataset', 'from the environment', 'from the first', 'from the genetic', 'from the majority', 'from the spatial', 'from the symbolic', 'from the training', 'from the unknown', 'from training', 'from training set', 'from twitter', 'from twitter and', 'from uber', 'from uber failed', 'full', 'full and', 'full and satisfactory', 'fully', 'fully prepared', 'fully prepared for', 'fully trained', 'fully trained model', 'function', 'function allows', 'function allows the', 'function approaches', 'function approaches that', 'function of', 'function of its', 'function of neural', 'function of the', 'function on', 'function on a', 'function or', 'function or kernel', 'function supervised', 'function supervised learning', 'function that', 'function that can', 'function that measures', 'function then', 'function then the', 'function underlying', 'function underlying the', 'functional', 'functional programs', 'functionality', 'functionality of', 'functionality of biological', 'functions', 'functions also', 'functions also referred', 'functions and', 'functions and assumed', 'functions can', 'functions can be', 'functions express', 'functions express the', 'functions when', 'functions when compared', 'fundamentally', 'fundamentally operational', 'fundamentally operational definition', 'further', 'further demonstrates', 'further demonstrates a', 'further processing', 'further processing thereby', 'furthering', 'furthering the', 'furthering the negative', 'furthermore', 'furthermore among', 'furthermore among the', 'fusion', 'fusion approach', 'fusion approach of', 'future', 'future challenges', 'future challenges such', 'future is', 'future is uncertain', 'future outcomes', 'future outcomes based', 'future potential', 'future potential predictions', 'future temperatures', 'future temperatures based', 'fuzzy', 'fuzzy logic', 'fuzzy logic and', 'ga', 'ga is', 'ga is a', 'game', 'game against', 'game against a', 'game theory', 'game theory control', 'games', 'games and', 'games and medical', 'gaming', 'gaming and', 'gaming and artificial', 'gaussian', 'gaussian process', 'gaussian process is', 'gaussian processes', 'gaussian processes are', 'gboard', 'gboard uses', 'gboard uses federated', 'general', 'general class', 'general class of', 'general framework', 'general framework for', 'general intelligence', 'general model', 'general model about', 'general term', 'general term for', 'generalisable', 'generalisable predictive', 'generalisable predictive patterns', 'generalisation', 'generalisation error', 'generalisation in', 'generalisation in this', 'generalisation of', 'generalisation of various', 'generalisation the', 'generalisation the complexity', 'generalisation will', 'generalisation will be', 'generalisations', 'generalisations of', 'generalisations of bayesian', 'generalise', 'generalise from', 'generalise from its', 'generalise to', 'generalise to unseen', 'generalised', 'generalised linear', 'generalised linear models', 'generality', 'generality the', 'generality the field', 'generally', 'generally unknown', 'generally unknown probability', 'generally without', 'generally without being', 'generalpurpose', 'generalpurpose gpus', 'generalpurpose gpus and', 'generate', 'generate new', 'generate new genotypes', 'generate results', 'generate results that', 'generated', 'generated by', 'generated by the', 'generates', 'generates independent', 'generates independent decision', 'generates x', 'generates x for', 'generating', 'generating lowerlevel', 'generating lowerlevel features', 'generating the', 'generating the supervisory', 'generative', 'generative image', 'generative image compression', 'genetic', 'genetic algorithm', 'genetic algorithm ga', 'genetic algorithm with', 'genetic algorithms', 'genetic algorithms in', 'genetic algorithms were', 'genetic and', 'genetic and evolutionary', 'genetic environment', 'genetic environment the', 'genetic environment wherefrom', 'genetics', 'genetics or', 'genetics or forecasting', 'genome', 'genome species', 'genome species vector', 'genotypes', 'genotypes in', 'genotypes in the', 'geoffrey', 'geoffrey hinton', 'geoffrey hinton their', 'geoliticas', 'geoliticas predictive', 'geoliticas predictive algorithm', 'georges', 'georges medical', 'georges medical school', 'geotechnical', 'geotechnical engineering', 'geotechnical engineering where', 'gerrymandered', 'gerrymandered to', 'gerrymandered to fit', 'given', 'given a', 'given a set', 'given an', 'given an encoding', 'given data', 'given data according', 'given dataset', 'given dataset can', 'given its', 'given its entire', 'given normal', 'given normal training', 'given on', 'given on using', 'given problem', 'given problem in', 'given symptoms', 'given symptoms the', 'given the', 'given the previous', 'gives', 'gives a', 'gives a solution', 'go', 'go from', 'go from observations', 'goal', 'goal from', 'goal from achieving', 'goal is', 'goal is to', 'goal of', 'goal of the', 'goal statistics', 'goal statistics draws', 'goals', 'goals on', 'goals on the', 'goalseeking', 'goalseeking behaviour', 'goalseeking behaviour in', 'good', 'good is', 'good is increasingly', 'good solutions', 'good solutions to', 'goof', 'goof button', 'goof button to', 'google', 'google cloud', 'google cloud ai', 'google photos', 'google photos once', 'google specifically', 'google specifically for', 'googles', 'googles deepmind', 'googles deepmind alphafold', 'gordon', 'gordon plotkin', 'gordon plotkin and', 'gorilla', 'gorilla label', 'gorilla label was', 'gorillas', 'gorillas similar', 'gorillas similar issues', 'gorillas which', 'gorillas which caused', 'goto', 'goto models', 'goto models include', 'gpus', 'gpus and', 'gpus and fpgas', 'gpus often', 'gpus often with', 'graduates', 'graduates identified', 'graduates identified as', 'grand', 'grand prize', 'grand prize in', 'graph', 'graph connectivity', 'graph dag', 'graph dag for', 'graphical', 'graphical model', 'graphical model is', 'graphical model that', 'graphics', 'graphics processing', 'graphics processing units', 'grew', 'grew out', 'grew out of', 'ground', 'ground classification', 'ground classification hazard', 'groundwork', 'groundwork for', 'groundwork for how', 'group', 'group of', 'group of new', 'grouping', 'grouping similar', 'grouping similar data', 'groups', 'groups of', 'groups of data', 'groups that', 'groups that are', 'growth', 'growth of', 'growth of biomedical', 'guarantees', 'guarantees of', 'guarantees of the', 'had', 'had a', 'had a long', 'had been', 'had been abandoned', 'had been applied', 'had been developed', 'had been using', 'had come', 'had come to', 'had denied', 'had denied nearly', 'had displaced', 'had displaced cpus', 'had inherited', 'had inherited from', 'hamburger', 'hamburger meat', 'hamburger meat such', 'hand', 'hand machine', 'hand machine learning', 'handle', 'handle multiple', 'handle multiple dependent', 'handle the', 'handle the learners', 'handling', 'handling extensive', 'handling extensive datasets', 'hardware', 'hardware acceleration', 'hardware acceleration approximate', 'hardware accelerators', 'hardware accelerators developed', 'hardware architectures', 'hardware compute', 'hardware compute used', 'hardware for', 'hardware for computation', 'hardware have', 'hardware have led', 'hardware or', 'hardware or through', 'hardware that', 'hardware that relies', 'hart', 'hart in', 'hart in in', 'has', 'has a', 'has a multivariate', 'has advantages', 'has advantages and', 'has already', 'has already been', 'has also', 'has also been', 'has applications', 'has applications in', 'has been', 'has been applied', 'has been argued', 'has been labelled', 'has been reported', 'has been transformative', 'has been used', 'has improved', 'has improved with', 'has intimate', 'has intimate ties', 'has many', 'has many zeros', 'has not', 'has not been', 'has not yet', 'has not yielded', 'has one', 'has one or', 'has to', 'has to build', 'has two', 'has two objectives', 'has under', 'has under fitted', 'have', 'have a', 'have a moral', 'have a substantial', 'have a threshold', 'have a weight', 'have adopted', 'have adopted methods', 'have allowed', 'have allowed neural', 'have become', 'have become a', 'have been', 'have been developed', 'have been focusing', 'have been found', 'have been shown', 'have been tested', 'have been used', 'have demonstrated', 'have demonstrated how', 'have difficulty', 'have difficulty resolving', 'have extended', 'have extended into', 'have found', 'have found that', 'have had', 'have had a', 'have learned', 'have learned to', 'have led', 'have led to', 'have noneuropean', 'have noneuropean sounding', 'have particular', 'have particular ethical', 'have revealed', 'have revealed previously', 'have separate', 'have separate conferences', 'have some', 'have some analogous', 'have studied', 'have studied human', 'having', 'having experienced', 'having experienced a', 'having machines', 'having machines learn', 'having to', 'having to send', 'hazard', 'hazard prediction', 'hazard prediction and', 'he', 'he also', 'he also suggested', 'he introduced', 'he introduced a', 'health', 'health care', 'health care but', 'health care professionals', 'health care to', 'healthcare', 'healthcare fraud', 'healthcare fraud detection', 'healthcare with', 'healthcare with the', 'hearing', 'hearing some', 'hearing some successful', 'hebb', 'hebb published', 'hebb published the', 'hebbs', 'hebbs model', 'hebbs model of', 'height', 'height based', 'height based on', 'held', 'held the', 'held the first', 'help', 'help make', 'help make diagnoses', 'help users', 'help users perform', 'here', 'here refers', 'here refers to', 'heuristic', 'heuristic method', 'heuristic method for', 'heuristic technique', 'heuristic technique that', 'hidden', 'hidden layers', 'hidden layers in', 'hidden units', 'hidden units by', 'hierarchy', 'hierarchy of', 'hierarchy of features', 'high', 'high levels', 'high levels of', 'high quantity', 'high quantity of', 'high risk', 'high risk twice', 'highbandwidth', 'highbandwidth memory', 'highbandwidth memory to', 'highdimensional', 'highdimensional data', 'highdimensional data sets', 'highdimensional feature', 'highdimensional feature spaces', 'higher', 'higher auc', 'higher auc is', 'higher computation', 'higher computation time', 'higherdimensional', 'higherdimensional data', 'higherdimensional data eg', 'higherdimensional space', 'higherdimensional vectors', 'higherdimensional vectors deep', 'higherlevel', 'higherlevel more', 'higherlevel more abstract', 'highfidelity', 'highfidelity generative', 'highfidelity generative image', 'highlights', 'highlights the', 'highlights the use', 'hinton', 'hinton their', 'hinton their main', 'hiring', 'hiring data', 'hiring data from', 'hiring policies', 'hiring policies may', 'his', 'his paper', 'his paper computing', 'hispanic', 'hispanic and', 'hispanic and as', 'historical', 'historical crime', 'historical crime data', 'historical data', 'history', 'history can', 'history can be', 'history of', 'history of machine', 'history this', 'history this equivalence', 'history to', 'history to study', 'hold', 'hold stakes', 'hold stakes there', 'holdout', 'holdout and', 'holdout and crossvalidation', 'holdout method', 'holdout method which', 'hope', 'hope of', 'hope of finding', 'hopfield', 'hopfield david', 'hopfield david rumelhart', 'horses', 'horses a', 'horses a realworld', 'horses and', 'horses and black', 'hostile', 'hostile and', 'hostile and offensive', 'house', 'house of', 'house of lords', 'householders', 'householders decide', 'householders decide to', 'how', 'how ais', 'how ais and', 'how backdoors', 'how backdoors can', 'how complex', 'how complex the', 'how evidence', 'how evidence is', 'how in', 'how in a', 'how pairs', 'how pairs of', 'how similar', 'how similar or', 'how software', 'how software agents', 'how to', 'how to make', 'how to treat', 'how well', 'how well it', 'however', 'however an', 'however an increasing', 'however over', 'however over time', 'however realworld', 'however realworld data', 'however the', 'however the computational', 'however there', 'however there are', 'however these', 'however these labels', 'however these rates', 'human', 'human brain', 'human brain processes', 'human brain would', 'human cognitive', 'human cognitive processes', 'human cognitive systems', 'human desire', 'human desire and', 'human good', 'human good is', 'human languages', 'human languages contain', 'human operatorteacher', 'human operatorteacher to', 'human opponent', 'human thought', 'human thought processes', 'humanlike', 'humanlike biases', 'humanlike biases because', 'humanmade', 'humanmade data', 'humanmade data machine', 'humans', 'humans are', 'humans are oblivious', 'humans can', 'humans can understand', 'humans current', 'humans current image', 'hurricanes', 'hurricanes other', 'hurricanes other applications', 'hutter', 'hutter prize', 'hutter prize the', 'hyperparameter', 'hyperparameter optimisation', 'hypotheses', 'hypotheses and', 'hypotheses and not', 'hypotheses given', 'hypotheses given an', 'hypothesis', 'hypothesis is', 'hypothesis is less', 'hypothesis is too', 'hypothesis proposes', 'hypothesis proposes that', 'hypothesis should', 'hypothesis should match', 'hypothesized', 'hypothesized logic', 'hypothesized logic program', 'hypothetical', 'hypothetical algorithm', 'hypothetical algorithm specific', 'i', 'i jordan', 'i jordan the', 'ibm', 'ibm employee', 'ibm employee and', 'ibm watson', 'ibm watson system', 'idea', 'idea is', 'idea is that', 'ideas', 'ideas of', 'ideas of machine', 'identification', 'identification and', 'identification and utilisation', 'identification of', 'identification of rare', 'identified', 'identified as', 'identified as white', 'identifies', 'identifies learns', 'identifies learns or', 'identify', 'identify a', 'identify a set', 'identify a singular', 'identify commonalities', 'identify commonalities in', 'identify strong', 'identify strong rules', 'identity', 'identity tracking', 'identity tracking face', 'if', 'if a', 'if a customer', 'if and', 'if and when', 'if it', 'if it can', 'if its', 'if its performance', 'if the', 'if the aggregate', 'if the complexity', 'if the hypothesis', 'if they', 'if they have', 'ignorance', 'ignorance and', 'ignorance and uncertainty', 'ilp', 'ilp is', 'ilp is an', 'ilp system', 'ilp system will', 'image', 'image and', 'image and signal', 'image can', 'image can result', 'image classifier', 'image classifier trained', 'image classifiers', 'image classifiers often', 'image compression', 'image compression include', 'image denoising', 'image denoising the', 'image dictionary', 'image dictionary but', 'image patch', 'image patch can', 'image processing', 'image processing toolbox', 'images', 'images of', 'images of certain', 'images sensor', 'images sensor data', 'images that', 'images that the', 'images video', 'images video and', 'images which', 'images which are', 'imieliÅ„ski', 'imieliÅ„ski and', 'imieliÅ„ski and arun', 'immune', 'immune systems', 'immune systems and', 'impact', 'impact on', 'impact on an', 'impacts', 'impacts on', 'impacts on society', 'impacts people', 'impacts people it', 'implausible', 'implausible under', 'implausible under that', 'implementation', 'implementation model', 'implementation model inference', 'implementation of', 'implementation of the', 'implementations', 'implementations it', 'implementations it broadly', 'implementations the', 'implementations the signal', 'implemented', 'implemented through', 'implemented through softwarebased', 'implemented within', 'implemented within the', 'implicit', 'implicit feature', 'implicit feature space', 'implicitly', 'implicitly map', 'implicitly map input', 'implicitly map strings', 'implicitly mapping', 'implicitly mapping their', 'importantlyit', 'importantlyit impacts', 'importantlyit impacts people', 'imprecise', 'imprecise however', 'imprecise however these', 'imprecise probability', 'imprecise probability theories', 'improve', 'improve accuracy', 'improve accuracy and', 'improve learner', 'improve learner accuracy', 'improve the', 'improve the accuracy', 'improve the performance', 'improved', 'improved with', 'improved with training', 'improvement', 'improvement in', 'improvement in learning', 'improves', 'improves the', 'improves the accuracy', 'improves with', 'improves with experience', 'improving', 'improving health', 'improving health care', 'in', 'in a', 'in a biological', 'in a classification', 'in a crossbar', 'in a logical', 'in a piecewise', 'in a pmfbased', 'in a probabilistic', 'in a prolog', 'in a report', 'in a selfdriving', 'in a text', 'in a training', 'in a typical', 'in a way', 'in accordance', 'in accordance with', 'in addition', 'in addition only', 'in addition to', 'in adversarial', 'in adversarial images', 'in along', 'in along with', 'in an', 'in an artificial', 'in an environment', 'in an experiment', 'in an unlabelled', 'in application', 'in application areas', 'in artificial', 'in artificial intelligence', 'in automated', 'in automated medical', 'in autonomous', 'in autonomous vehicles', 'in bayesian', 'in bayesian optimisation', 'in bioinformatics', 'in bioinformatics and', 'in both', 'in both machine', 'in building', 'in building fires', 'in by', 'in by arthur', 'in canadian', 'in canadian psychologist', 'in cases', 'in cases for', 'in checkers', 'in checkers for', 'in classification', 'in classification one', 'in classification the', 'in cloudbased', 'in cloudbased environments', 'in cofounder', 'in cofounder of', 'in cognitive', 'in cognitive terms', 'in collaboration', 'in collaboration with', 'in common', 'in common ann', 'in comparison', 'in comparison the', 'in computational', 'in computational learning', 'in conjunction', 'in conjunction with', 'in contrast', 'in contrast machine', 'in contrast regression', 'in contrast to', 'in contrast with', 'in data', 'in data mining', 'in data reduction', 'in data that', 'in databases', 'in databases data', 'in databases using', 'in decision', 'in decision analysis', 'in detrimental', 'in detrimental outcomes', 'in developing', 'in developing a', 'in disproportionately', 'in disproportionately high', 'in each', 'in each iteration', 'in each new', 'in fact', 'in fact according', 'in female', 'in female faculty', 'in fields', 'in fields like', 'in fields such', 'in for', 'in for million', 'in geotechnical', 'in geotechnical engineering', 'in google', 'in google cloud', 'in google photos', 'in having', 'in having machines', 'in health', 'in health care', 'in healthcare', 'in healthcare with', 'in his', 'in his paper', 'in hutter', 'in hutter prize', 'in image', 'in image and', 'in image denoising', 'in in', 'in in a', 'in it', 'in it still', 'in it was', 'in its', 'in its predictions', 'in knowledge', 'in knowledge discovery', 'in large', 'in large databases', 'in large scale', 'in larger', 'in larger effective', 'in largescale', 'in largescale transaction', 'in learning', 'in learning accuracy', 'in learning to', 'in lowincome', 'in lowincome and', 'in machine', 'in machine learning', 'in many', 'in many fields', 'in many other', 'in microsoft', 'in microsoft excel', 'in microsoft tested', 'in new', 'in new cases', 'in nonlinear', 'in nonlinear systems', 'in order', 'in order to', 'in other', 'in other domains', 'in other words', 'in particular', 'in particular in', 'in particular unsupervised', 'in pattern', 'in pattern recognition', 'in performance', 'in polynomial', 'in polynomial time', 'in ranking', 'in ranking recommendation', 'in reinforcement', 'in reinforcement learning', 'in response', 'in response then', 'in ridge', 'in ridge regression', 'in scenarios', 'in scenarios where', 'in several', 'in several contexts', 'in skewed', 'in skewed or', 'in society', 'in some', 'in some fields', 'in springer', 'in springer nature', 'in statistical', 'in statistical classification', 'in statistics', 'in statistics data', 'in statistics he', 'in supermarkets', 'in supermarkets for', 'in supervised', 'in supervised feature', 'in t', 'in t as', 'in terms', 'in terms of', 'in that', 'in that model', 'in the', 'in the amount', 'in the area', 'in the behavioural', 'in the branches', 'in the context', 'in the data', 'in the early', 'in the field', 'in the hope', 'in the largest', 'in the leaves', 'in the machine', 'in the mathematical', 'in the mediaservices', 'in the mids', 'in the next', 'in the process', 'in the publics', 'in the s', 'in the sales', 'in the same', 'in the training', 'in the uks', 'in the united', 'in the wall', 'in their', 'in their input', 'in their principal', 'in these', 'in these tree', 'in this', 'in this context', 'in this field', 'in this time', 'in tpus', 'in tpus have', 'in two', 'in two environments', 'in unsupervised', 'in unsupervised feature', 'in unsupervised machine', 'in various', 'in various application', 'in weakly', 'in weakly supervised', 'in which', 'in which every', 'in which he', 'in which humans', 'in which machine', 'in which the', 'in which to', 'inactivity', 'inactivity this', 'inactivity this pattern', 'include', 'include active', 'include active learning', 'include artificial', 'include artificial neural', 'include clustering', 'include clustering dimensionality', 'include dictionary', 'include dictionary learning', 'include learning', 'include learning classifier', 'include nvidia', 'include nvidia maxine', 'include opencv', 'include opencv tensorflow', 'include polynomial', 'include polynomial regression', 'include principal', 'include principal component', 'include pruning', 'include pruning quantisation', 'include the', 'include the following', 'included', 'included for', 'included for analysis', 'includes', 'includes algorithmic', 'includes algorithmic biases', 'includes both', 'includes both the', 'includes learning', 'includes learning classifier', 'includes predictive', 'includes predictive policing', 'including', 'including computer', 'including computer vision', 'including feifei', 'including feifei li', 'including in', 'including in cases', 'including john', 'including john hopfield', 'including logician', 'including logician walter', 'including machine', 'including machine learning', 'including natural', 'including natural language', 'including web', 'including web usage', 'including whitebox', 'including whitebox access', 'incomegenerating', 'incomegenerating machines', 'incomegenerating machines this', 'incoming', 'incoming email', 'incoming email and', 'incorporate', 'incorporate ignorance', 'incorporate ignorance and', 'incorrect', 'incorrect decisions', 'incorrect decisions a', 'increase', 'increase in', 'increase in the', 'increased', 'increased in', 'increased in response', 'increased reviewer', 'increased reviewer burden', 'increases', 'increases efficiency', 'increases efficiency by', 'increases or', 'increases or decreases', 'increasing', 'increasing emphasis', 'increasing emphasis on', 'increasing profits', 'increasing profits for', 'increasingly', 'increasingly expressed', 'increasingly expressed by', 'independence', 'independence with', 'independence with a', 'independent', 'independent component', 'independent component analysis', 'independent decision', 'independent decision trees', 'indicate', 'indicate that', 'indicate that if', 'indicators', 'indicators of', 'indicators of their', 'indicators or', 'indicators or reconstructing', 'individual', 'individual searches', 'individual searches back', 'individual users', 'individual users of', 'individuals', 'individuals life', 'individuals life would', 'induction', 'induction proving', 'induction proving a', 'induction suggesting', 'induction suggesting a', 'inductive', 'inductive here', 'inductive here refers', 'inductive logic', 'inductive logic programming', 'inductive logic programmingilp', 'inductive machine', 'inductive machine learning', 'inductive programming', 'inductive programming is', 'inductively', 'inductively inferred', 'inductively inferred logic', 'infeasible', 'infeasible reinforcement', 'infeasible reinforcement learning', 'inference', 'inference and', 'inference and learning', 'inference system', 'inference system in', 'inference they', 'inference they are', 'inferences', 'inferences from', 'inferences from a', 'inferred', 'inferred logic', 'inferred logic programs', 'influence', 'influence diagrams', 'influences', 'influences among', 'influences among artists', 'inform', 'inform the', 'inform the trader', 'information', 'information a', 'information a signal', 'information can', 'information can be', 'information in', 'information in their', 'information of', 'information of the', 'information retrieval', 'information retrieval neural', 'information theory', 'information theory simulationbased', 'infrastructure', 'infrastructure especially', 'infrastructure especially in', 'inherently', 'inherently multidimensional', 'inherently unbalanced', 'inherently unbalanced nature', 'inherited', 'inherited from', 'inherited from ai', 'initial', 'initial emotions', 'initial emotions about', 'initial theoretical', 'initial theoretical foundation', 'initially', 'initially and', 'initially and only', 'input', 'input but', 'input but also', 'input data', 'input data can', 'input data examples', 'input examples', 'input examples background', 'input for', 'input for decisionmaking', 'input from', 'input from the', 'input including', 'input including in', 'input is', 'input is an', 'input layer', 'input layer to', 'input nor', 'input nor an', 'input situation', 'input situation and', 'input string', 'input string x', 'input that', 'input that is', 'input used', 'input used to', 'input variables', 'input variables and', 'input variables to', 'inputoutput', 'inputoutput examples', 'inputoutput examples the', 'inputs', 'inputs an', 'inputs an optimal', 'inputs and', 'inputs and the', 'inputs coming', 'inputs coming from', 'inputs into', 'inputs into highdimensional', 'inputs provided', 'inputs provided during', 'inputs signals', 'inputs signals travel', 'inputs that', 'inputs that were', 'inputs the', 'inputs the connections', 'insight', 'insight into', 'insight into the', 'inspired', 'inspired by', 'inspired by a', 'inspired by people', 'inspired by the', 'instance', 'instance each', 'instance each decision', 'instance in', 'instance in order', 'instance to', 'instance to be', 'instances', 'instances and', 'instances and models', 'instances for', 'instances for example', 'instances in', 'instances in the', 'instances that', 'instances that seem', 'instances with', 'instances with replacement', 'instead', 'instead a', 'instead a cluster', 'instead feature', 'instead feature vectors', 'instead of', 'instead of responding', 'instead probabilistic', 'instead probabilistic bounds', 'instructions', 'instructions within', 'instructions within a', 'integrated', 'integrated within', 'integrated within machine', 'intellectual', 'intellectual property', 'intellectual property personal', 'intelligence', 'intelligence ai', 'intelligence ai in', 'intelligence concerned', 'intelligence concerned with', 'intelligence covers', 'intelligence covers a', 'intelligence in', 'intelligence in which', 'intelligence scientists', 'intelligence scientists including', 'intelligence statistics', 'intelligence statistics and', 'intelligence system', 'intelligence system that', 'intelligence the', 'intelligence the synonym', 'intelligence to', 'intelligence to tackling', 'intelligence to training', 'intelligent', 'intelligent machine', 'intelligent machine is', 'intended', 'intended to', 'intended to identify', 'interacting', 'interacting with', 'interacting with one', 'interaction', 'interaction between', 'interaction between cognition', 'interaction with', 'interaction with the', 'interactions', 'interactions among', 'interactions among nerve', 'interdependent', 'interdependent or', 'interdependent or share', 'interest', 'interest but', 'interest but as', 'interest related', 'interest related to', 'interested', 'interested in', 'interested in having', 'interesting', 'interesting objects', 'interesting objects are', 'interestingness', 'internal', 'internal compactness', 'internal compactness or', 'internal parameters', 'internal parameters to', 'internal parameters tuned', 'internal reward', 'internal reward emotion', 'interpretable', 'interpretable ai', 'interpretable ai or', 'interpretable models', 'interpretable models making', 'intimate', 'intimate ties', 'intimate ties to', 'into', 'into a', 'into a more', 'into a specified', 'into classifying', 'into classifying eg', 'into clusters', 'into clusters this', 'into highdimensional', 'into highdimensional feature', 'into higherdimensional', 'into higherdimensional vectors', 'into implicit', 'into implicit feature', 'into k', 'into k subsets', 'into layers', 'into layers different', 'into machine', 'into machine learning', 'into one', 'into one category', 'into subsets', 'into subsets called', 'into the', 'into the field', 'into the recidivism', 'into the s', 'into this', 'into this threefold', 'into three', 'into three broad', 'into vision', 'into vision and', 'introduced', 'introduced a', 'introduced a theoretical', 'introduced association', 'introduced association rules', 'introduced in', 'introduced in along', 'introduced in the', 'introduces', 'introduces nonlinearity', 'introduces nonlinearity by', 'introducing', 'introducing emotion', 'introducing emotion as', 'introduction', 'introduction in', 'introduction in tpus', 'intrusion', 'intrusion detection', 'intrusion detection continuous', 'intrusion detection the', 'invented', 'invented a', 'invented a program', 'invested', 'invested microsofts', 'invested microsofts bing', 'investigate', 'investigate and', 'investigate and predict', 'investigative', 'investigative journalism', 'investigative journalism organisation', 'investigators', 'investigators frequently', 'investigators frequently report', 'investigators sometimes', 'investigators sometimes report', 'involves', 'involves changing', 'involves changing higherdimensional', 'involves training', 'involves training a', 'ipt', 'ipt and', 'ipt and highfidelity', 'is', 'is a', 'is a branch', 'is a close', 'is a feature', 'is a field', 'is a general', 'is a longstanding', 'is a model', 'is a nonprobabilistic', 'is a potential', 'is a powerful', 'is a probabilistic', 'is a process', 'is a profound', 'is a real', 'is a recommendation', 'is a related', 'is a rulebased', 'is a search', 'is a specific', 'is a stochastic', 'is a subfield', 'is a system', 'is a type', 'is also', 'is also emerging', 'is an', 'is an active', 'is an adapted', 'is an approach', 'is an area', 'is an ensemble', 'is an incoming', 'is artificial', 'is artificial intelligence', 'is associated', 'is associated with', 'is becoming', 'is becoming a', 'is best', 'is best sparsely', 'is called', 'is called model', 'is called the', 'is combined', 'is combined eg', 'is computed', 'is computed by', 'is concerned', 'is concerned offers', 'is considered', 'is considered a', 'is considered feasible', 'is drawn', 'is drawn to', 'is driven', 'is driven by', 'is employed', 'is employed to', 'is entirely', 'is entirely opaque', 'is especially', 'is especially true', 'is in', 'is in contrast', 'is increased', 'is increased in', 'is increasingly', 'is increasingly expressed', 'is inspired', 'is inspired by', 'is intended', 'is intended to', 'is known', 'is known as', 'is less', 'is less complex', 'is likely', 'is likely to', 'is linear', 'is linear regression', 'is lowdimensional', 'is lowdimensional sparse', 'is mathematically', 'is mathematically and', 'is motivated', 'is motivated by', 'is neither', 'is neither a', 'is not', 'is not a', 'is not built', 'is often', 'is often extended', 'is one', 'is one of', 'is one that', 'is one way', 'is only', 'is only sent', 'is particularly', 'is particularly useful', 'is possible', 'is possible to', 'is potential', 'is potential for', 'is precluded', 'is precluded by', 'is principal', 'is principal component', 'is provided', 'is provided possibly', 'is reducing', 'is reducing bias', 'is replaced', 'is replaced with', 'is represented', 'is represented as', 'is represented by', 'is said', 'is said to', 'is something', 'is something to', 'is sparse', 'is sparse meaning', 'is strongly', 'is strongly nphard', 'is studied', 'is studied in', 'is subject', 'is subject to', 'is that', 'is that a', 'is that an', 'is that unlike', 'is the', 'is the ability', 'is the analysis', 'is the assignment', 'is the behavioural', 'is the discovery', 'is the emotion', 'is the folder', 'is the genetic', 'is the identification', 'is the inherently', 'is the ksvd', 'is the smallest', 'is thus', 'is thus finding', 'is to', 'is to classify', 'is to determine', 'is to discover', 'is to generalise', 'is to learn', 'is to make', 'is too', 'is too complex', 'is trained', 'is trained on', 'is typically', 'is typically represented', 'is uncertain', 'is uncertain learning', 'is used', 'is used as', 'is used by', 'is used for', 'is used to', 'is usually', 'is usually evaluated', 'issue', 'issue such', 'issue such as', 'issues', 'issues that', 'issues that standard', 'issues with', 'issues with recognising', 'it', 'it also', 'it also covers', 'it and', 'it and then', 'it behaves', 'it behaves and', 'it broadly', 'it broadly refers', 'it can', 'it can be', 'it can work', 'it contrasts', 'it contrasts with', 'it fits', 'it fits the', 'it gives', 'it gives a', 'it had', 'it had inherited', 'it has', 'it has applications', 'it has been', 'it has improved', 'it has not', 'it in', 'it in a', 'it in common', 'it initially', 'it initially and', 'it is', 'it is a', 'it is intended', 'it is one', 'it is particularly', 'it is possible', 'it is used', 'it makes', 'it may', 'it may have', 'it provided', 'it provided a', 'it provides', 'it provides interpretable', 'it quickly', 'it quickly picked', 'it relies', 'it relies on', 'it shifted', 'it shifted focus', 'it still', 'it still cannot', 'it to', 'it to classify', 'it to produce', 'it to reevaluate', 'it useful', 'it useful for', 'it useful often', 'it using', 'it using sitespecific', 'it was', 'it was repetitively', 'it was reported', 'it without', 'it without both', 'item', 'item represented', 'item represented in', 'items', 'items either', 'items either within', 'items events', 'items events or', 'items represent', 'items represent an', 'items target', 'items target value', 'iteration', 'iteration executes', 'iteration executes the', 'iterative', 'iterative optimisation', 'iterative optimisation of', 'iteratively', 'iteratively adjusts', 'iteratively adjusts the', 'its', 'its created', 'its created by', 'its designers', 'its designers cannot', 'its entire', 'its entire history', 'its existing', 'its existing cinematch', 'its experience', 'its experience generalisation', 'its generality', 'its generality the', 'its goal', 'its goal from', 'its input', 'its input data', 'its inputs', 'its inputs the', 'its inspired', 'its inspired by', 'its internal', 'its internal parameters', 'its most', 'its most common', 'its outputs', 'its outputs or', 'its own', 'its own field', 'its performance', 'its performance at', 'its points', 'its points this', 'its predictions', 'its predictions by', 'its use', 'its use for', 'its users', 'itself', 'job', 'job applicants', 'job applicants by', 'job hiring', 'job hiring data', 'jobs', 'jobs would', 'jobs would be', 'john', 'john hopfield', 'john hopfield david', 'joint', 'joint team', 'joint team made', 'jordan', 'jordan the', 'jordan the ideas', 'journal', 'journal wrote', 'journal wrote about', 'journalism', 'journalism organisation', 'journalism organisation a', 'journals', 'journals ecml', 'journals ecml pkdd', 'judgements', 'judgements from', 'judgements from the', 'judgment', 'judgment but', 'judgment but a', 'just', 'just beginning', 'just beginning to', 'just like', 'just like how', 'justification', 'justification for', 'justification for using', 'k', 'k each', 'k each represented', 'k experiments', 'k experiments are', 'k subsets', 'k subsets and', 'k subsets for', 'kdd', 'kdd task', 'kdd task supervised', 'kdd the', 'kdd the key', 'kernel', 'kernel regression', 'kernel regression which', 'kernel that', 'kernel that models', 'kernel trick', 'kernel trick implicitly', 'kernel trick to', 'key', 'key component', 'key component of', 'key difference', 'key difference from', 'key idea', 'key idea is', 'key rbml', 'key rbml techniques', 'key task', 'key task is', 'kfoldcrossvalidation', 'kfoldcrossvalidation method', 'kfoldcrossvalidation method randomly', 'khosla', 'khosla predicted', 'khosla predicted that', 'killed', 'killed after', 'killed after a', 'kind', 'kind of', 'kind of learner', 'kind of programming', 'kinds', 'kinds of', 'kinds of time', 'kinds of transformations', 'kmeans', 'kmeans clustering', 'kmeans clustering aids', 'kmeans clustering an', 'kmeans clustering can', 'knowledge', 'knowledge an', 'knowledge an uninformed', 'knowledge and', 'knowledge and a', 'knowledge and hypotheses', 'knowledge captured', 'knowledge captured by', 'knowledge discovery', 'knowledge discovery and', 'knowledge discovery in', 'knowledge distillation', 'knowledge distillation lowrank', 'knowledge evaluated', 'knowledge evaluated with', 'knowledge in', 'knowledge in a', 'knowledge of', 'knowledge of an', 'knowledge the', 'knowledge the defining', 'knowledge while', 'knowledge while in', 'knowledgebased', 'knowledgebased approach', 'knowledgebased approach caused', 'known', 'known as', 'known as a', 'known as computational', 'known as outlier', 'known as overfitting', 'known as predictive', 'known as supportvector', 'known as training', 'known background', 'known background knowledge', 'known knowledge', 'known knowledge an', 'known knowledge while', 'known properties', 'known properties learned', 'ksvd', 'ksvd algorithm', 'ksvd algorithm sparse', 'label', 'label to', 'label to instances', 'label was', 'label was subsequently', 'labelled', 'labelled as', 'labelled as normal', 'labelled classified', 'labelled classified or', 'labelled data', 'labelled data can', 'labelled input', 'labelled input data', 'labelled training', 'labelled training data', 'labels', 'labels and', 'labels and branches', 'labels and finds', 'labels are', 'labels are noisy', 'labels are often', 'labels decision', 'labels decision trees', 'labels of', 'labels of a', 'labels yet', 'labels yet many', 'labsresearch', 'labsresearch in', 'labsresearch in collaboration', 'lack', 'lack of', 'lack of access', 'lack of diversity', 'lack of participation', 'lack of resources', 'lack of suitable', 'lack predefined', 'lack predefined labels', 'laid', 'laid the', 'laid the initial', 'language', 'language corpora', 'language corpora will', 'language for', 'language for representing', 'language models', 'language models learned', 'language models tpus', 'language processing', 'language processing computer', 'language processing gordon', 'languages', 'languages contain', 'languages contain biases', 'large', 'large and', 'large and representative', 'large databases', 'large databases it', 'large language', 'large language models', 'large scale', 'large scale and', 'large variety', 'large variety of', 'larger', 'larger effective', 'larger effective training', 'largescale', 'largescale commercial', 'largescale commercial cloud', 'largescale machine', 'largescale machine learning', 'largescale problems', 'largescale problems including', 'largescale transaction', 'largescale transaction data', 'largest', 'largest deep', 'largest deep learning', 'last', 'last layer', 'last layer the', 'later', 'later found', 'later found to', 'latter', 'latter is', 'latter is often', 'layer', 'layer possibly', 'layer possibly after', 'layer the', 'layer the input', 'layer the output', 'layer to', 'layer to the', 'layers', 'layers different', 'layers different layers', 'layers in', 'layers in an', 'layers may', 'layers may perform', 'layers multiple', 'layers multiple times', 'layers of', 'layers of nonlinear', 'lcs', 'lcs are', 'lcs are a', 'lead', 'lead to', 'lead to a', 'lead to those', 'leading', 'leading to', 'leading to a', 'leading to deviations', 'leading to inductive', 'leading to the', 'leaks', 'leaks and', 'leaks and theft', 'learn', 'learn a', 'learn a function', 'learn from', 'learn from data', 'learn from examples', 'learn from experience', 'learn lowdimensional', 'learn lowdimensional representations', 'learn relationships', 'learn relationships between', 'learn the', 'learn the features', 'learn these', 'learn these biases', 'learn to', 'learn to perform', 'learned', 'learned from', 'learned from data', 'learned from the', 'learned from twitter', 'learned in', 'learned in polynomial', 'learned representation', 'learned representation is', 'learned to', 'learned to perform', 'learned using', 'learned using labelled', 'learned with', 'learned with unlabelled', 'learner', 'learner accuracy', 'learner accuracy much', 'learner and', 'learner and have', 'learner has', 'learner has to', 'learner is', 'learner is to', 'learners', 'learners can', 'learners can also', 'learners decision', 'learners decision boundary', 'learning', 'learning accuracy', 'learning advances', 'learning advances in', 'learning algorithm', 'learning algorithm for', 'learning algorithm had', 'learning algorithm is', 'learning algorithm iteratively', 'learning algorithms', 'learning algorithms aim', 'learning algorithms also', 'learning algorithms and', 'learning algorithms are', 'learning algorithms attempt', 'learning algorithms build', 'learning algorithms discover', 'learning algorithms do', 'learning algorithms find', 'learning algorithms identify', 'learning algorithms include', 'learning algorithms insight', 'learning algorithms is', 'learning algorithms learn', 'learning algorithms like', 'learning algorithms mlas', 'learning algorithms often', 'learning algorithms that', 'learning algorithms to', 'learning algorithms use', 'learning algorithms work', 'learning also', 'learning also employs', 'learning also has', 'learning and', 'learning and artificial', 'learning and compression', 'learning and data', 'learning and finally', 'learning and manifold', 'learning and propelling', 'learning and statistics', 'learning approach', 'learning approach tend', 'learning approaches', 'learning approaches are', 'learning approaches can', 'learning approaches in', 'learning approaches include', 'learning are', 'learning are computer', 'learning artificial', 'learning artificial immune', 'learning bayesian', 'learning bayesian networks', 'learning called', 'learning called selfsupervised', 'learning can', 'learning can be', 'learning classification', 'learning classification and', 'learning classifier', 'learning classifier systems', 'learning closely', 'learning closely related', 'learning component', 'learning component performing', 'learning concerned', 'learning concerned with', 'learning consists', 'learning consists of', 'learning data', 'learning data mining', 'learning data set', 'learning did', 'learning did continue', 'learning domain', 'learning domain typically', 'learning during', 'learning during the', 'learning eg', 'learning eg to', 'learning engineering', 'learning engineering teams', 'learning engineers', 'learning engineers need', 'learning ethics', 'learning ethics is', 'learning falls', 'learning falls between', 'learning features', 'learning features are', 'learning field', 'learning field a', 'learning finds', 'learning finds generalisable', 'learning focuses', 'learning focuses on', 'learning for', 'learning for pattern', 'learning from', 'learning from methodological', 'learning genetic', 'learning genetic algorithms', 'learning grew', 'learning grew out', 'learning has', 'learning has also', 'learning has been', 'learning has two', 'learning have', 'learning have allowed', 'learning have extended', 'learning in', 'learning in a', 'learning in computational', 'learning in health', 'learning in healthcare', 'learning in machine', 'learning in order', 'learning in unsupervised', 'learning include', 'learning include clustering', 'learning including', 'learning independent', 'learning independent component', 'learning involves', 'learning involves training', 'learning is', 'learning is a', 'learning is also', 'learning is an', 'learning is becoming', 'learning is concerned', 'learning is inspired', 'learning is likely', 'learning is motivated', 'learning is not', 'learning is the', 'learning it', 'learning it was', 'learning kmeans', 'learning kmeans clustering', 'learning leading', 'learning leading to', 'learning machine', 'learning machine to', 'learning machine with', 'learning machines', 'learning machines dealing', 'learning may', 'learning may take', 'learning medical', 'learning medical diagnostic', 'learning method', 'learning method for', 'learning method that', 'learning method where', 'learning methods', 'learning methods but', 'learning methods starting', 'learning methods used', 'learning ml', 'learning ml is', 'learning ml reorganised', 'learning model', 'learning model because', 'learning model is', 'learning model machine', 'learning model trained', 'learning model was', 'learning models', 'learning models are', 'learning models can', 'learning models like', 'learning models require', 'learning models that', 'learning or', 'learning or as', 'learning or unsupervised', 'learning paradigm', 'learning paradigm was', 'learning paradigms', 'learning paradigms depending', 'learning performance', 'learning performance is', 'learning probabilistic', 'learning probabilistic systems', 'learning problems', 'learning problems are', 'learning proceeds', 'learning proceeds the', 'learning projects', 'learning projects from', 'learning provides', 'learning provides a', 'learning rbml', 'learning rbml is', 'learning reinforcement', 'learning reinforcement learning', 'learning roots', 'learning roots back', 'learning routine', 'learning some', 'learning some researchers', 'learning system', 'learning system duplicating', 'learning system for', 'learning system trained', 'learning systems', 'learning systems picking', 'learning tasks', 'learning tasks such', 'learning techniques', 'learning techniques have', 'learning technologies', 'learning technologies as', 'learning technology', 'learning technology was', 'learning that', 'learning that automatically', 'learning that contain', 'learning that is', 'learning the', 'learning the environment', 'learning the training', 'learning the wrong', 'learning theorists', 'learning theorists study', 'learning theory', 'learning theory a', 'learning theory usually', 'learning theory via', 'learning they', 'learning they seek', 'learning to', 'learning to play', 'learning to predict', 'learning to train', 'learning tree', 'learning tree models', 'learning typically', 'learning typically does', 'learning uses', 'learning uses a', 'learning using', 'learning using logic', 'learning was', 'learning was coined', 'learning was recently', 'learning where', 'learning where even', 'learning where models', 'learning with', 'learning with completely', 'learning without', 'learning without any', 'learning workloads', 'learning workloads unlike', 'learning xml', 'learning xml is', 'learnings', 'learnings vulnerability', 'learnings vulnerability to', 'learns', 'learns a', 'learns a goalseeking', 'learns a representation', 'learns or', 'learns or evolves', 'learns rules', 'learns rules from', 'learns to', 'learns to recognise', 'least', 'least a', 'least a joint', 'least squares', 'least squares the', 'least to', 'least to the', 'leaves', 'leaves it', 'leaves it is', 'leaves represent', 'leaves represent class', 'led', 'led to', 'led to more', 'legitimate', 'legitimate image', 'legitimate image can', 'leo', 'leo breiman', 'leo breiman distinguished', 'less', 'less complex', 'less complex than', 'less the', 'less the machine', 'lesson', 'lesson a', 'lesson a toy', 'lethal', 'lethal autonomous', 'lethal autonomous weapon', 'letters', 'letters digits', 'letters digits and', 'levels', 'levels of', 'levels of overpolicing', 'levels of representation', 'levels of specificity', 'leverage', 'leverage a', 'leverage a fusion', 'leverage matrix', 'leverage matrix multiplication', 'li', 'li who', 'li who said', 'lie', 'lie along', 'lie along lowdimensional', 'life', 'life would', 'life would not', 'light', 'light and', 'light and sound', 'like', 'like age', 'like age and', 'like googles', 'like googles deepmind', 'like healthcare', 'like healthcare fraud', 'like how', 'like how in', 'like ols', 'like random', 'like random forest', 'like speech', 'like speech signals', 'like the', 'like the holdout', 'like the observed', 'like the synapses', 'likelihood', 'likelihood of', 'likelihood of a', 'likely', 'likely to', 'likely to also', 'likely to be', 'likely to pick', 'limitations', 'limitations no', 'limitations no single', 'limited', 'limited computing', 'limited computing resources', 'limited or', 'limited or imprecise', 'limited set', 'limited set of', 'limiting', 'limiting the', 'limiting the necessary', 'line', 'line is', 'line is drawn', 'line of', 'line of research', 'line too', 'line too was', 'linear', 'linear classification', 'linear classification svms', 'linear classifier', 'linear classifier although', 'linear combination', 'linear combination of', 'linear model', 'linear model it', 'linear models', 'linear models of', 'linear regression', 'linear regression extends', 'linear regression to', 'linear regression where', 'linear techniques', 'linear techniques like', 'literature', 'literature while', 'literature while it', 'locations', 'logic', 'logic and', 'logic and probability', 'logic program', 'logic program that', 'logic programming', 'logic programming as', 'logic programming ilp', 'logic programming is', 'logic programming such', 'logic programmingilp', 'logic programmingilp but', 'logic programs', 'logic programs from', 'logical', 'logical database', 'logical database of', 'logical knowledgebased', 'logical knowledgebased approach', 'logical setting', 'logical setting shapiro', 'logician', 'logician walter', 'logician walter pitts', 'logistic', 'logistic regression', 'logistic regression often', 'long', 'long prehistory', 'long prehistory in', 'longer', 'longer to', 'longer to be', 'longstanding', 'longstanding ethical', 'longstanding ethical dilemma', 'looking', 'looking for', 'looking for instances', 'looking like', 'looking like the', 'loosely', 'loosely model', 'loosely model the', 'lords', 'lords select', 'lords select committee', 'loss', 'loss function', 'loss function on', 'loss functions', 'loss functions express', 'lossless', 'lossless compression', 'lossless compression methods', 'lost', 'lost in', 'lost in the', 'low', 'low samples', 'low samples and', 'lowdimensional', 'lowdimensional manifolds', 'lowdimensional manifolds and', 'lowdimensional representations', 'lowdimensional representations directly', 'lowdimensional sparse', 'lowdimensional sparse coding', 'lowerlevel', 'lowerlevel features', 'lowerlevel features it', 'lowincome', 'lowincome and', 'lowincome and minority', 'lowrank', 'lowrank factorisation', 'lowrank factorisation network', 'lz', 'lz and', 'lz and ppm', 'lzw', 'lzw lz', 'lzw lz and', 'm', 'm mitchell', 'm mitchell provided', 'machine', 'machine ethics', 'machine ethics how', 'machine extracted', 'machine extracted out', 'machine is', 'machine is one', 'machine learning', 'machine learning advances', 'machine learning algorithm', 'machine learning algorithms', 'machine learning also', 'machine learning and', 'machine learning approach', 'machine learning approaches', 'machine learning can', 'machine learning closely', 'machine learning concerned', 'machine learning data', 'machine learning domain', 'machine learning during', 'machine learning eg', 'machine learning engineering', 'machine learning engineers', 'machine learning ethics', 'machine learning field', 'machine learning finds', 'machine learning focuses', 'machine learning for', 'machine learning from', 'machine learning genetic', 'machine learning grew', 'machine learning has', 'machine learning have', 'machine learning in', 'machine learning include', 'machine learning including', 'machine learning is', 'machine learning kmeans', 'machine learning leading', 'machine learning may', 'machine learning medical', 'machine learning method', 'machine learning methods', 'machine learning ml', 'machine learning model', 'machine learning models', 'machine learning paradigm', 'machine learning performance', 'machine learning probabilistic', 'machine learning rbml', 'machine learning roots', 'machine learning routine', 'machine learning some', 'machine learning system', 'machine learning systems', 'machine learning tasks', 'machine learning techniques', 'machine learning technologies', 'machine learning technology', 'machine learning that', 'machine learning to', 'machine learning tree', 'machine learning was', 'machine learning where', 'machine learning workloads', 'machine learning xml', 'machine learnings', 'machine learnings vulnerability', 'machine to', 'machine to both', 'machine to perform', 'machine translation', 'machine translation social', 'machine with', 'machine with punched', 'machinelearning', 'machinelearning programs', 'machinelearning programs often', 'machinelearning researchers', 'machinelearning researchers have', 'machinery', 'machinery and', 'machinery and intelligence', 'machines', 'machines dealing', 'machines dealing mostly', 'machines do', 'machines do what', 'machines learn', 'machines learn from', 'machines svms', 'machines svms also', 'machines that', 'machines that behave', 'machines think', 'machines think is', 'machines this', 'machines this is', 'machines trained', 'machines trained on', 'made', 'made by', 'made by the', 'made up', 'made up of', 'main', 'main success', 'main success came', 'maintained', 'maintained by', 'maintained by not', 'maintaining', 'maintaining energy', 'maintaining energy efficiency', 'major', 'major exception', 'major exception comes', 'majority', 'majority of', 'majority of the', 'make', 'make a', 'make a prediction', 'make diagnoses', 'make diagnoses and', 'make different', 'make different assumptions', 'make judgements', 'make judgements from', 'make machines', 'make machines that', 'make predictions', 'make predictions for', 'make predictions or', 'make this', 'make this assumption', 'make up', 'make up of', 'makes', 'makes it', 'makes it useful', 'makes rfr', 'makes rfr compatible', 'making', 'making in', 'making in data', 'making in large', 'making it', 'making it useful', 'making them', 'making them particularly', 'maml', 'manifold', 'manifold hypothesis', 'manifold hypothesis proposes', 'manifold learning', 'manifold learning algorithms', 'manifold learning and', 'manifold regularisation', 'manifolds', 'manifolds and', 'manifolds and many', 'manipulate', 'manipulate or', 'manipulate or apply', 'manipulation', 'manipulation or', 'manipulation or evasion', 'manner', 'manner in', 'manner in order', 'manual', 'manual feature', 'manual feature engineering', 'many', 'many applications', 'many applications for', 'many caveats', 'many caveats to', 'many devices', 'many devices for', 'many dimensionality', 'many dimensionality reduction', 'many fields', 'many fields including', 'many layers', 'many layers of', 'many learning', 'many learning problems', 'many machine', 'many machine learning', 'many machinelearning', 'many machinelearning researchers', 'many other', 'many other disciplines', 'many other statistical', 'many other systems', 'many outlier', 'many outlier detection', 'many previous', 'many previous machine', 'many reinforcement', 'many reinforcement learning', 'many systems', 'many systems attempt', 'many zeros', 'many zeros multilinear', 'map', 'map input', 'map input variables', 'map strings', 'map strings into', 'mapping', 'mapping their', 'mapping their inputs', 'maps', 'maps an', 'maps an input', 'marked', 'marked as', 'marked as belonging', 'market', 'market basket', 'market basket analysis', 'marketing', 'marketing activities', 'marketing activities such', 'markov', 'markov decision', 'markov decision process', 'match', 'match the', 'match the complexity', 'materials', 'materials such', 'materials such as', 'materials with', 'materials with adjustable', 'mathematical', 'mathematical criterion', 'mathematical criterion such', 'mathematical induction', 'mathematical induction proving', 'mathematical model', 'mathematical model each', 'mathematical model has', 'mathematical model of', 'mathematical model that', 'mathematical models', 'mathematical models of', 'mathematical optimisation', 'mathematical optimisation mathematical', 'mathematical programming', 'mathematical programming methods', 'mathematically', 'mathematically and', 'mathematically and computationally', 'mathrm', 'mathrm burger', 'mathrm burger found', 'mathrm onionspotatoes', 'mathrm onionspotatoes rightarrow', 'matlabs', 'matlabs image', 'matlabs image processing', 'matrix', 'matrix factorisation', 'matrix factorisation and', 'matrix multiplication', 'matrix multiplication units', 'matrix the', 'matrix the method', 'matrix through', 'matrix through iterative', 'matrix w', 'matrix w was', 'maximise', 'maximise some', 'maximise some notion', 'maxine', 'maxine aivc', 'maxine aivc examples', 'may', 'may be', 'may be able', 'may be an', 'may be implemented', 'may exhibit', 'may exhibit these', 'may have', 'may have a', 'may have revealed', 'may inform', 'may inform the', 'may lead', 'may lead to', 'may not', 'may not be', 'may perform', 'may perform different', 'may result', 'may result in', 'may take', 'may take longer', 'may use', 'may use computer', 'mcculloch', 'mcculloch who', 'mcculloch who proposed', 'mdp', 'mdp and', 'mdp and are', 'mdp many', 'mdp many reinforcement', 'meaning', 'meaning that', 'meaning that even', 'meaning that the', 'meaning true', 'meaning true positive', 'means', 'means more', 'means more or', 'measure', 'measure of', 'measure of interestingness', 'measure p', 'measure p if', 'measured', 'measured by', 'measured by p', 'measures', 'measures compute', 'measures compute similarity', 'measures how', 'measures how similar', 'meat', 'meat such', 'meat such information', 'mediaservices', 'mediaservices provider', 'mediaservices provider netflix', 'medical', 'medical diagnosis', 'medical diagnostic', 'medical diagnostic software', 'medical diagnostics', 'medical doctors', 'medical doctors jobs', 'medical problems', 'medical problems or', 'medical school', 'medical school had', 'medicate', 'medicate and', 'medicate and plan', 'medication', 'medication in', 'medication in which', 'medicine', 'medicine the', 'medicine the application', 'members', 'members of', 'members of a', 'members of the', 'members who', 'members who focus', 'memory', 'memory called', 'memory called cybertron', 'memory matrix', 'memory matrix w', 'memory to', 'memory to accelerate', 'memristors', 'memristors to', 'memristors to emulate', 'mental', 'mental models', 'mental models of', 'merely', 'merely make', 'merely make up', 'metalearning', 'metalearning eg', 'metalearning eg maml', 'method', 'method for', 'method for discovering', 'method for sparse', 'method is', 'method is strongly', 'method of', 'method of training', 'method randomly', 'method randomly partitions', 'method that', 'method that builds', 'method that identifies', 'method where', 'method where a', 'method which', 'method which splits', 'method will', 'method will easily', 'methodological', 'methodological principles', 'methodological principles to', 'methods', 'methods and', 'methods and models', 'methods and overlap', 'methods are', 'methods are based', 'methods as', 'methods as unsupervised', 'methods as well', 'methods bootstrap', 'methods bootstrap which', 'methods but', 'methods but distinct', 'methods but with', 'methods cannot', 'methods cannot be', 'methods comprise', 'methods comprise the', 'methods extract', 'methods extract patterns', 'methods for', 'methods for training', 'methods from', 'methods from machine', 'methods in', 'methods in particular', 'methods in this', 'methods lzw', 'methods lzw lz', 'methods of', 'methods of dimensionality', 'methods starting', 'methods starting from', 'methods such', 'methods such as', 'methods to', 'methods to better', 'methods to estimate', 'methods to mitigate', 'methods used', 'methods used for', 'methods while', 'methods while in', 'metric', 'metric and', 'metric and evaluated', 'michael', 'michael i', 'michael i jordan', 'microclusters', 'microclusters formed', 'microclusters formed by', 'microcontrollers', 'microcontrollers running', 'microcontrollers running models', 'microsoft', 'microsoft excel', 'microsoft excel logistic', 'microsoft tested', 'microsoft tested tay', 'microsofts', 'microsofts bing', 'microsofts bing chat', 'microsystems', 'microsystems vinod', 'microsystems vinod khosla', 'mids', 'mids with', 'mids with the', 'might', 'might conclude', 'might conclude that', 'might not', 'might not be', 'million', 'million shortly', 'million shortly after', 'mimics', 'mimics the', 'mimics the process', 'minimisation', 'minimisation of', 'minimisation of some', 'minimise', 'minimise errors', 'minimise errors in', 'mining', 'mining a', 'mining a decision', 'mining and', 'mining and machine', 'mining anomaly', 'mining anomaly detection', 'mining association', 'mining association rule', 'mining focuses', 'mining focuses on', 'mining intrusion', 'mining intrusion detection', 'mining is', 'mining is a', 'mining kdd', 'mining kdd the', 'mining methods', 'mining methods as', 'mining often', 'mining often employ', 'mining uses', 'mining uses many', 'minority', 'minority communities', 'minority communities after', 'minority population', 'minority population in', 'mirror', 'mirror human', 'mirror human thought', 'misclassifies', 'misconceptions', 'misconceptions xai', 'misconceptions xai promises', 'misinformation', 'misinformation how', 'misinformation how to', 'missing', 'missing training', 'missing training labels', 'mitchell', 'mitchell provided', 'mitchell provided a', 'mitigate', 'mitigate overfitting', 'mitigate overfitting and', 'mitigated', 'ml', 'ml finds', 'ml finds application', 'ml is', 'ml is a', 'ml reorganised', 'ml reorganised and', 'ml to', 'ml to business', 'mlas', 'mlas can', 'mlas can generate', 'mlas can utilise', 'mobile', 'mobile phones', 'mobile phones without', 'model', 'model a', 'model a zip', 'model about', 'model about this', 'model accuracy', 'model and', 'model and algorithmic', 'model assessment', 'model assessment higher', 'model based', 'model based on', 'model because', 'model because training', 'model being', 'model being trained', 'model by', 'model by detecting', 'model by generating', 'model can', 'model can refer', 'model each', 'model each training', 'model for', 'model for a', 'model has', 'model has many', 'model has under', 'model in', 'model in addition', 'model inference', 'model inference system', 'model is', 'model is a', 'model is increased', 'model is subject', 'model it', 'model it is', 'model machine', 'model machine learning', 'model means', 'model means more', 'model most', 'model most suitable', 'model of', 'model of a', 'model of neurons', 'model of the', 'model on', 'model on the', 'model optimisation', 'model optimisation common', 'model rather', 'model rather the', 'model representing', 'model representing normal', 'model selection', 'model sequences', 'model sequences of', 'model that', 'model that can', 'model that once', 'model that predicts', 'model that represents', 'model the', 'model the more', 'model the neurons', 'model the way', 'model to', 'model to go', 'model to reduce', 'model to win', 'model trained', 'model trained models', 'model was', 'model was introduced', 'model wherein', 'model wherein algorithmic', 'model will', 'model will be', 'model with', 'model with all', 'modelling', 'modelling approaches', 'modelling approaches used', 'modelling metalearning', 'modelling paradigms', 'modelling paradigms data', 'models', 'models a', 'models a hypothetical', 'models and', 'models and their', 'models are', 'models are deployed', 'models are infeasible', 'models are often', 'models are trained', 'models borrowed', 'models borrowed from', 'models can', 'models can be', 'models derived', 'models derived from', 'models directly', 'models directly on', 'models have', 'models have been', 'models how', 'models how pairs', 'models in', 'models in bayesian', 'models include', 'models include polynomial', 'models internal', 'models internal parameters', 'models learned', 'models learned from', 'models like', 'models like googles', 'models making', 'models making it', 'models may', 'models may result', 'models of', 'models of neural', 'models of statistics', 'models of users', 'models on', 'models on users', 'models require', 'models require a', 'models rfr', 'models rfr is', 'models that', 'models that are', 'models that decentralises', 'models that were', 'models these', 'models these methods', 'models tpus', 'models tpus leverage', 'models where', 'models where the', 'models which', 'models which have', 'modern', 'modern machine', 'modern machine learning', 'modernday', 'modernday machine', 'modernday machine learning', 'modifying', 'modifying these', 'modifying these patterns', 'moles', 'moles a', 'moles a machine', 'moles coupled', 'moles coupled with', 'months', 'moral', 'moral status', 'moral status ai', 'more', 'more abstract', 'more abstract features', 'more accurate', 'more accurate the', 'more compact', 'more compact set', 'more directly', 'more directly explained', 'more effectively', 'more effectively xai', 'more efficient', 'more efficient methods', 'more formal', 'more formal definition', 'more inputs', 'more inputs and', 'more or', 'more or less', 'more predesignated', 'more predesignated criteria', 'more statistical', 'more statistical line', 'more than', 'more than one', 'more variables', 'more variables input', 'most', 'most common', 'most common form', 'most of', 'most of the', 'most suitable', 'most suitable for', 'mostly', 'mostly perceptrons', 'mostly perceptrons and', 'mostly with', 'mostly with machine', 'motivated', 'motivated by', 'motivated by the', 'move', 'move toward', 'move toward datacentric', 'moved', 'moved to', 'moved to performing', 'movie', 'movie recommendation', 'movie recommendation algorithm', 'much', 'much higher', 'much higher computation', 'much of', 'much of the', 'multiagent', 'multiagent systems', 'multiagent systems swarm', 'multidimensional', 'multidimensional data', 'multidimensional data without', 'multidimensional linear', 'multidimensional linear model', 'multilayer', 'multilayer perceptrons', 'multilayer perceptrons and', 'multilinear', 'multilinear subspace', 'multilinear subspace learning', 'multiple', 'multiple decision', 'multiple decision trees', 'multiple dependent', 'multiple dependent variables', 'multiple economic', 'multiple economic indicators', 'multiple hidden', 'multiple hidden layers', 'multiple levels', 'multiple levels of', 'multiple regressor', 'multiple regressor task', 'multiple times', 'multiplication', 'multiplication units', 'multiplication units and', 'multitude', 'multitude of', 'multitude of machine', 'multivariate', 'multivariate linear', 'multivariate linear regression', 'multivariate normal', 'multivariate normal distribution', 'mutation', 'mutation and', 'mutation and crossover', 'n', 'n instances', 'n instances with', 'named', 'named crossbar', 'named crossbar adaptive', 'names', 'names using', 'names using job', 'narrow', 'narrow subdomain', 'narrow subdomain of', 'natural', 'natural language', 'natural language processing', 'natural selection', 'natural selection using', 'nature', 'nature it', 'nature it shifted', 'nature of', 'nature of outlier', 'nature of the', 'nature published', 'nature published the', 'nearly', 'nearly candidates', 'nearly candidates who', 'neatly', 'neatly into', 'neatly into this', 'necessarily', 'necessarily also', 'necessarily also learn', 'necessarily faithful', 'necessarily faithful to', 'necessary', 'necessary sensitivity', 'necessary sensitivity for', 'need', 'need to', 'need to target', 'need to transfer', 'needing', 'needing to', 'needing to send', 'needs', 'needs of', 'needs of new', 'negative', 'negative examples', 'negative examples inductive', 'negative examples the', 'negative impacts', 'negative impacts on', 'negative rate', 'negative rate fnr', 'negative rate tnr', 'negative results', 'negative results show', 'neither', 'neither a', 'neither a separate', 'nerve', 'nerve cells', 'nerve cells hebbs', 'netflix', 'netflix held', 'netflix held the', 'netflix prize', 'netflix prize competition', 'netflix realised', 'netflix realised that', 'network', 'network architecture', 'network architecture search', 'network belief', 'network belief network', 'network can', 'network can be', 'network capable', 'network capable of', 'network could', 'network could represent', 'network filtering', 'network filtering playing', 'network highlights', 'network highlights the', 'network intrusion', 'network intrusion detection', 'network is', 'network is a', 'network learns', 'network learns to', 'network or', 'network or directed', 'network this', 'network this approach', 'networks', 'networks a', 'networks a class', 'networks a particular', 'networks anns', 'networks anns or', 'networks are', 'networks are a', 'networks generalisations', 'networks generalisations of', 'networks have', 'networks have been', 'networks multilayer', 'networks multilayer perceptrons', 'networks research', 'networks research had', 'networks statistical', 'networks statistical physics', 'networks that', 'networks that can', 'networks that constitute', 'networks that model', 'networks that use', 'networks these', 'networks these systems', 'networks these were', 'networks to', 'networks to come', 'neural', 'neural network', 'neural network capable', 'neural network highlights', 'neural network is', 'neural network learns', 'neural network this', 'neural networks', 'neural networks a', 'neural networks anns', 'neural networks have', 'neural networks multilayer', 'neural networks research', 'neural networks statistical', 'neural networks that', 'neural networks these', 'neural networks to', 'neural structure', 'neural structure formed', 'neural synapses', 'neural synapses the', 'neuromorphic', 'neuromorphic computing', 'neuromorphic computing refers', 'neuromorphic hardware', 'neuromorphic hardware that', 'neuron', 'neuron is', 'neuron is computed', 'neuron that', 'neuron that receives', 'neuron to', 'neuron to another', 'neurons', 'neurons and', 'neurons and edges', 'neurons are', 'neurons are aggregated', 'neurons are called', 'neurons connected', 'neurons connected to', 'neurons in', 'neurons in a', 'neurons interacting', 'neurons interacting with', 'neurons is', 'neurons is a', 'neurons may', 'neurons may have', 'neurons used', 'neurons used by', 'neurons which', 'neurons which loosely', 'new', 'new cases', 'new customer', 'new customer groups', 'new data', 'new data during', 'new example', 'new example falls', 'new genotypes', 'new genotypes in', 'new inputs', 'new inputs an', 'new piece', 'new piece of', 'new point', 'new point as', 'new tools', 'new tools for', 'new training', 'new training example', 'new unobserved', 'new unobserved point', 'new unseen', 'new unseen examplestasks', 'new us', 'new us resident', 'next', 'next two', 'next two decades', 'nilssons', 'nilssons book', 'nilssons book on', 'no', 'no negative', 'no negative examples', 'no single', 'no single algorithm', 'nodes', 'nodes called', 'nodes called artificial', 'nodes or', 'nodes or artificial', 'noise', 'noise cannot', 'noise deviations', 'noise deviations and', 'noisy', 'noisy limited', 'noisy limited or', 'noneuropean', 'noneuropean sounding', 'noneuropean sounding names', 'nonevaluated', 'nonevaluated data', 'nonevaluated data can', 'nonlinear', 'nonlinear classification', 'nonlinear classification using', 'nonlinear function', 'nonlinear function of', 'nonlinear hidden', 'nonlinear hidden units', 'nonlinear problems', 'nonlinear problems goto', 'nonlinear systems', 'nonlinear systems or', 'nonlinearity', 'nonlinearity by', 'nonlinearity by taking', 'nonpattern', 'nonpattern perturbations', 'nonpattern perturbations for', 'nonprobabilistic', 'nonprobabilistic binary', 'nonprobabilistic binary linear', 'nonwhite', 'nonwhite people', 'nonwhite people have', 'nor', 'nor an', 'nor an advice', 'norm', 'norm x', 'norm x an', 'normal', 'normal and', 'normal and abnormal', 'normal behaviour', 'normal behaviour from', 'normal by', 'normal by looking', 'normal distribution', 'normal distribution and', 'normal training', 'normal training data', 'not', 'not a', 'not a part', 'not a replacement', 'not adhere', 'not adhere to', 'not assume', 'not assume knowledge', 'not be', 'not be able', 'not be considered', 'not be designed', 'not been', 'not been labelled', 'not being', 'not being fully', 'not being necessarily', 'not built', 'not built on', 'not consider', 'not consider the', 'not fit', 'not fit neatly', 'not needing', 'not needing to', 'not only', 'not only logic', 'not primarily', 'not primarily make', 'not rare', 'not rare objects', 'not represented', 'not represented in', 'not spam', 'not spam of', 'not the', 'not the best', 'not unzip', 'not unzip it', 'not yet', 'not yet developed', 'not yield', 'not yield guarantees', 'not yielded', 'not yielded attempts', 'notably', 'notably becoming', 'notably becoming integrated', 'nothing', 'nothing artificial', 'nothing artificial about', 'notion', 'notion of', 'notion of cumulative', 'novel', 'novel algorithms', 'novel algorithms now', 'novelties', 'novelties noise', 'novelties noise deviations', 'now', 'now enable', 'now enable the', 'now outside', 'now outside the', 'nphard', 'nphard and', 'nphard and difficult', 'number', 'number and', 'number and the', 'number of', 'number of clusters', 'number of features', 'number of propositions', 'number of random', 'numbers', 'numbers are', 'numbers are called', 'numerators', 'numerators and', 'numerators and denominators', 'numerical', 'numerical value', 'numerical value within', 'numerous', 'numerous lack', 'numerous lack of', 'nvidia', 'nvidia maxine', 'nvidia maxine aivc', 'object', 'object many', 'object many outlier', 'objective', 'objective function', 'objective function supervised', 'objective of', 'objective of a', 'objectives', 'objectives algorithmic', 'objectives algorithmic bias', 'objectives one', 'objectives one is', 'objects', 'objects are', 'objects are it', 'objects are often', 'objects but', 'objects but unexpected', 'objects modifying', 'objects modifying these', 'oblivious', 'oblivious to', 'oblivious to but', 'observations', 'observations about', 'observations about an', 'observations drawn', 'observations drawn from', 'observations into', 'observations into subsets', 'observations which', 'observations which raise', 'observations within', 'observations within the', 'observed', 'observed data', 'observed facts', 'observed facts rather', 'observed points', 'observed points and', 'observed points or', 'obtain', 'obtain resulting', 'obtain resulting in', 'obtained', 'obtained from', 'obtained from basic', 'obtaining', 'obtaining a', 'obtaining a set', 'occurrences', 'occurrences and', 'occurrences and the', 'of', 'of a', 'of a learner', 'of a learning', 'of a model', 'of a new', 'of a practical', 'of a rulebased', 'of a selflearning', 'of a sequence', 'of a service', 'of a set', 'of a supermarket', 'of a test', 'of a wellordered', 'of abuse', 'of abuse and', 'of access', 'of access to', 'of ai', 'of ai as', 'of ai for', 'of ai infrastructure', 'of ai proper', 'of aipowered', 'of aipowered audiovideo', 'of aipowered systems', 'of algorithmic', 'of algorithmic rules', 'of algorithms', 'of algorithms instead', 'of all', 'of all faculty', 'of an', 'of an exact', 'of an objective', 'of an outlier', 'of anomaly', 'of anomaly detection', 'of any', 'of any input', 'of art', 'of art history', 'of artificial', 'of artificial intelligence', 'of as', 'of as a', 'of backpropagation', 'of basis', 'of basis functions', 'of bayesian', 'of bayesian networks', 'of behavior', 'of behavior in', 'of belief', 'of belief functions', 'of biological', 'of biological neural', 'of biomedical', 'of biomedical literature', 'of black', 'of black people', 'of brown', 'of brown horses', 'of certain', 'of certain types', 'of clustering', 'of clusters', 'of clusters k', 'of combination', 'of combination just', 'of company', 'of company characteristics', 'of compute', 'of compute required', 'of computer', 'of computer gaming', 'of computing', 'of computing systems', 'of connected', 'of connected units', 'of contextdependent', 'of contextdependent rules', 'of cumulative', 'of cumulative reward', 'of current', 'of current research', 'of data', 'of data acquisition', 'of data and', 'of data breaches', 'of data central', 'of data data', 'of data files', 'of data not', 'of data points', 'of data that', 'of datasoftware', 'of datasoftware transparency', 'of decision', 'of decision treebased', 'of deep', 'of deep learning', 'of deep neural', 'of dimensionality', 'of dimensionality reduction', 'of disordered', 'of disordered systems', 'of distributed', 'of distributed artificial', 'of diversity', 'of diversity in', 'of dollars', 'of dollars invested', 'of each', 'of each artificial', 'of examples', 'of examples loss', 'of examples represented', 'of facts', 'of facts an', 'of favour', 'of favour work', 'of features', 'of features most', 'of features that', 'of features with', 'of finding', 'of finding good', 'of from', 'of from training', 'of functions', 'of functions can', 'of future', 'of future potential', 'of generalisation', 'of generalisation the', 'of genetic', 'of genetic and', 'of how', 'of how evidence', 'of human', 'of human desire', 'of images', 'of images sensor', 'of improving', 'of improving health', 'of inactivity', 'of inactivity this', 'of input', 'of input variables', 'of intellectual', 'of intellectual property', 'of interestingness', 'of items', 'of items either', 'of its', 'of its existing', 'of its input', 'of its inputs', 'of its outputs', 'of its points', 'of knowledge', 'of knowledge discovery', 'of labelled', 'of labelled data', 'of learner', 'of learner and', 'of learning', 'of learning in', 'of linear', 'of linear regression', 'of lords', 'of lords select', 'of machine', 'of machine learning', 'of manifold', 'of manifold learning', 'of mathematical', 'of mathematical model', 'of medical', 'of medical diagnostics', 'of medical doctors', 'of methods', 'of methods but', 'of minority', 'of minority population', 'of ml', 'of ml to', 'of models', 'of models and', 'of models have', 'of moles', 'of moles coupled', 'of months', 'of multiple', 'of multiple hidden', 'of natural', 'of natural selection', 'of neural', 'of neural networks', 'of neural synapses', 'of neuromorphic', 'of neuromorphic hardware', 'of neurons', 'of neurons interacting', 'of new', 'of new customer', 'of new us', 'of nonlinear', 'of nonlinear hidden', 'of observations', 'of observations into', 'of observed', 'of observed points', 'of occurrences', 'of occurrences and', 'of or', 'of or generating', 'of outlier', 'of outlier detection', 'of overpolicing', 'of overpolicing in', 'of participation', 'of participation and', 'of physical', 'of physical hardware', 'of points', 'of points relate', 'of posts', 'of posts machine', 'of previous', 'of previous admissions', 'of previously', 'of previously unknown', 'of principal', 'of principal variables', 'of producing', 'of producing an', 'of programming', 'of programming language', 'of propositions', 'of propositions classes', 'of quantum', 'of quantum chemistry', 'of random', 'of random variables', 'of rare', 'of rare items', 'of real', 'of real objects', 'of reducing', 'of reducing the', 'of related', 'of related supervised', 'of relational', 'of relational rules', 'of reliable', 'of reliable data', 'of representation', 'of representation or', 'of representative', 'of representative points', 'of research', 'of research was', 'of researchers', 'of researchers from', 'of resources', 'of resources and', 'of responding', 'of responding to', 'of rfr', 'of rfr for', 'of rulebased', 'of rulebased machine', 'of selflearning', 'of selflearning named', 'of software', 'of software that', 'of solvent', 'of solvent effects', 'of some', 'of some loss', 'of specificity', 'of specificity from', 'of statistical', 'of statistical algorithms', 'of statistical methods', 'of statistics', 'of statistics probabilistic', 'of strong', 'of strong rules', 'of study', 'of study and', 'of study focusing', 'of study in', 'of such', 'of such challenges', 'of such commonalities', 'of suitable', 'of suitable data', 'of sun', 'of sun microsystems', 'of supervised', 'of supervised machine', 'of supervisedlearning', 'of supervisedlearning algorithms', 'of tasks', 'of tasks including', 'of tasks t', 'of text', 'of text a', 'of the', 'of the algorithm', 'of the algorithms', 'of the ann', 'of the confusion', 'of the data', 'of the dimensionality', 'of the feature', 'of the function', 'of the generalised', 'of the hypothesis', 'of the inputs', 'of the instances', 'of the kernel', 'of the known', 'of the mdp', 'of the model', 'of the original', 'of the performance', 'of the picture', 'of the popular', 'of the predictive', 'of the presence', 'of the quest', 'of the random', 'of the same', 'of the signal', 'of the social', 'of the space', 'of the sum', 'of the tasks', 'of the training', 'of the unobserved', 'of their', 'of their viewing', 'of theoretical', 'of theoretical computer', 'of these', 'of these algorithms', 'of time', 'of time and', 'of time complexity', 'of topics', 'of topics within', 'of training', 'of training data', 'of training examples', 'of training largescale', 'of transformations', 'of transformations on', 'of travellers', 'of travellers recently', 'of two', 'of two categories', 'of unsupervised', 'of unsupervised learning', 'of unsupervised machine', 'of users', 'of users of', 'of values', 'of values are', 'of values while', 'of variables', 'of variables like', 'of variation', 'of variation that', 'of various', 'of various diseases', 'of various ensemble', 'of various learning', 'of x', 'of x is', 'offensive', 'offensive response', 'offensive response against', 'offer', 'offer additional', 'offer additional tools', 'offering', 'offering new', 'offering new tools', 'offers', 'offers a', 'offers a fundamentally', 'often', 'often as', 'often as a', 'often as white', 'often attempt', 'often attempt to', 'often cheaper', 'often cheaper to', 'often defined', 'often defined by', 'often developed', 'often developed or', 'often do', 'often do not', 'often employ', 'often employ the', 'often extended', 'often extended by', 'often fail', 'often fail to', 'often have', 'often have separate', 'often not', 'often not rare', 'often require', 'often require input', 'often used', 'often used in', 'often vulnerable', 'often vulnerable to', 'often with', 'often with aispecific', 'ols', 'on', 'on a', 'on a bad', 'on a collection', 'on a given', 'on a legitimate', 'on a predefined', 'on a prestructured', 'on a training', 'on a variety', 'on ai', 'on ai among', 'on an', 'on an individuals', 'on chemical', 'on chemical reactions', 'on cloud', 'on cloud servers', 'on conventional', 'on conventional hardware', 'on current', 'on current customers', 'on datasets', 'on datasets collected', 'on electrically', 'on electrically adjustable', 'on embedded', 'on embedded systems', 'on estimated', 'on estimated density', 'on explicit', 'on explicit algorithms', 'on exploratory', 'on exploratory data', 'on factors', 'on factors like', 'on historical', 'on historical data', 'on humanmade', 'on humanmade data', 'on known', 'on known properties', 'on language', 'on language corpora', 'on learning', 'on learning machines', 'on models', 'on models which', 'on new', 'on new data', 'on new unseen', 'on pictures', 'on pictures of', 'on pre', 'on pre evacuation', 'on prediction', 'on prediction based', 'on previous', 'on previous experience', 'on random', 'on random data', 'on research', 'on research into', 'on single', 'on single output', 'on society', 'on society or', 'on such', 'on such data', 'on symbolicknowledgebased', 'on symbolicknowledgebased learning', 'on the', 'on the concept', 'on the discovery', 'on the logical', 'on the nature', 'on the number', 'on the other', 'on the output', 'on the performance', 'on the presence', 'on the structure', 'on the test', 'on the users', 'on their', 'on their inputs', 'on their locations', 'on these', 'on these devices', 'on these models', 'on users', 'on users mobile', 'on using', 'on using teaching', 'once', 'once receives', 'once receives initial', 'once tagged', 'once tagged a', 'once trained', 'once trained on', 'one', 'one another', 'one another set', 'one artificial', 'one artificial neuron', 'one category', 'one category an', 'one input', 'one input situation', 'one is', 'one is the', 'one is to', 'one is used', 'one of', 'one of the', 'one of two', 'one or', 'one or more', 'one output', 'one output action', 'one that', 'one that learns', 'one wants', 'one wants to', 'one way', 'one way to', 'onions', 'onions and', 'onions and potatoes', 'onionspotatoes', 'onionspotatoes rightarrow', 'onionspotatoes rightarrow mathrm', 'onionspotatoesburgerdisplaystyle', 'onionspotatoesburgerdisplaystyle mathrm', 'onionspotatoesburgerdisplaystyle mathrm onionspotatoes', 'only', 'only changing', 'only changing a', 'only just', 'only just beginning', 'only logic', 'only logic programming', 'only on', 'only on pictures', 'only once', 'only once receives', 'only one', 'only one input', 'only one output', 'only sent', 'only sent if', 'only significant', 'only significant or', 'opaque', 'opaque meaning', 'opaque meaning that', 'openai', 'openai estimated', 'openai estimated the', 'opencv', 'opencv tensorflow', 'opencv tensorflow matlabs', 'operating', 'operating characteristic', 'operating characteristic roc', 'operational', 'operational definition', 'operational definition rather', 'operations', 'operations research', 'operations research information', 'operatorteacher', 'operatorteacher to', 'operatorteacher to recognise', 'opponent', 'opposed', 'opposed to', 'opposed to softwarebased', 'optimal', 'optimal compressor', 'optimal compressor can', 'optimal data', 'optimal data compression', 'optimal function', 'optimal function allows', 'optimal outcomes', 'optimisation', 'optimisation common', 'optimisation common optimisation', 'optimisation many', 'optimisation many learning', 'optimisation mathematical', 'optimisation mathematical programming', 'optimisation multiagent', 'optimisation multiagent systems', 'optimisation of', 'optimisation of an', 'optimisation techniques', 'optimisation techniques include', 'optimisation used', 'optimisation used to', 'optimise', 'optimise smartphones', 'optimise smartphones performance', 'optimised', 'optimised for', 'optimised for tensor', 'or', 'or a', 'or a hierarchy', 'or absence', 'or absence of', 'or across', 'or across transactions', 'or apply', 'or apply knowledge', 'or artificial', 'or artificial neurons', 'or as', 'or as a', 'or behaviour', 'or behaviour a', 'or categorised', 'or categorised instead', 'or classifications', 'or classifications on', 'or connectionist', 'or connectionist systems', 'or decreases', 'or decreases the', 'or dempstershafer', 'or dempstershafer theory', 'or directed', 'or directed acyclic', 'or errors', 'or errors in', 'or evasion', 'or evasion via', 'or even', 'or even kernel', 'or evolves', 'or evolves rules', 'or explainable', 'or explainable machine', 'or extraction', 'or extraction one', 'or feedback', 'or feedback available', 'or forecasting', 'or forecasting future', 'or from', 'or from nonpattern', 'or generating', 'or generating lowerlevel', 'or have', 'or have noneuropean', 'or imprecise', 'or imprecise however', 'or in', 'or in learning', 'or inputoutput', 'or inputoutput examples', 'or interpretable', 'or interpretable ai', 'or kernel', 'or kernel that', 'or less', 'or less the', 'or medication', 'or medication in', 'or more', 'or more inputs', 'or more predesignated', 'or nodes', 'or nodes called', 'or nonevaluated', 'or nonevaluated data', 'or objectives', 'or objectives algorithmic', 'or observations', 'or observations which', 'or potential', 'or potential future', 'or predictions', 'or predictions made', 'or predictions over', 'or predictions this', 'or product', 'or product placements', 'or protein', 'or protein sequences', 'or reconstructing', 'or reconstructing images', 'or related', 'or related two', 'or representations', 'or representations through', 'or share', 'or share underlying', 'or the', 'or the process', 'or the similarity', 'or theoretically', 'or theoretically relevant', 'or through', 'or through specialised', 'or trained', 'or trained by', 'or undesired', 'or undesired predictions', 'or unsupervised', 'or unsupervised in', 'or unsupervised learning', 'or vector', 'or vector sometimes', 'order', 'order of', 'order of items', 'order to', 'order to incorporate', 'order to make', 'order to train', 'ordinary', 'ordinary least', 'ordinary least squares', 'organisation', 'organisation a', 'organisation a machine', 'organization', 'organization of', 'organization of behavior', 'original', 'original data', 'original data while', 'original goal', 'original goal of', 'other', 'other applications', 'other applications have', 'other approaches', 'other approaches have', 'other depending', 'other depending on', 'other disciplines', 'other disciplines including', 'other disciplines such', 'other domains', 'other domains concern', 'other frameworks', 'other frameworks such', 'other hand', 'other hand machine', 'other is', 'other is the', 'other machine', 'other machine learning', 'other methods', 'other methods are', 'other models', 'other models that', 'other purpose', 'other purpose is', 'other researchers', 'other researchers who', 'other similar', 'other similar models', 'other statistical', 'other statistical classification', 'other supervised', 'other supervised methods', 'other systems', 'other words', 'other words it', 'ought', 'ought to', 'ought to take', 'out', 'out by', 'out by propublica', 'out by the', 'out for', 'out for when', 'out of', 'out of favour', 'out of the', 'outcomes', 'outcomes based', 'outcomes based on', 'outcomes thereby', 'outcomes thereby furthering', 'outlier', 'outlier as', 'outlier as a', 'outlier detection', 'outlier detection is', 'outlier detection methods', 'outlier detection semisupervised', 'outliers', 'outliers novelties', 'outliers novelties noise', 'outperformed', 'outperformed by', 'outperformed by other', 'output', 'output action', 'output action or', 'output also', 'output also known', 'output associated', 'output associated with', 'output by', 'output by only', 'output data', 'output data as', 'output distribution', 'output distribution conversely', 'output for', 'output for inputs', 'output is', 'output is entirely', 'output is the', 'output layer', 'output layer possibly', 'output of', 'output of a', 'output of each', 'output variables', 'output variables by', 'outputs', 'outputs are', 'outputs are interdependent', 'outputs are restricted', 'outputs can', 'outputs can take', 'outputs or', 'outputs or predictions', 'outputs the', 'outputs the data', 'outside', 'outside the', 'outside the aics', 'outside the field', 'over', 'over time', 'over time attention', 'over time is', 'overall', 'overall accuracy', 'overall accuracy investigators', 'overall field', 'overfitting', 'overfitting and', 'overfitting and bias', 'overfitting and generalisation', 'overfitting by', 'overfitting by employing', 'overfitting by rewarding', 'overfitting is', 'overfitting is something', 'overfitting many', 'overfitting many systems', 'overfitting to', 'overfitting to build', 'overlap', 'overlap significantly', 'overlap significantly but', 'overly', 'overly complex', 'overly complex theory', 'overpolicing', 'overpolicing in', 'overpolicing in lowincome', 'own', 'own field', 'own field started', 'owners', 'owners hold', 'owners hold stakes', 'p', 'p if', 'p if its', 'p improves', 'p improves with', 'paintings', 'paintings and', 'paintings and that', 'pairs', 'pairs of', 'pairs of points', 'paper', 'paper computing', 'paper computing machinery', 'paradigm', 'paradigm was', 'paradigm was introduced', 'paradigms', 'paradigms data', 'paradigms data model', 'paradigms depending', 'paradigms depending on', 'parameter', 'parameter sharing', 'parameters', 'parameters to', 'parameters to minimise', 'parameters tuned', 'part', 'part of', 'part of machine', 'part of the', 'participation', 'participation and', 'participation and representation', 'particular', 'particular ethical', 'particular ethical stakes', 'particular in', 'particular in the', 'particular narrow', 'particular narrow subdomain', 'particular unsupervised', 'particular unsupervised algorithms', 'particularly', 'particularly beneficial', 'particularly beneficial in', 'particularly efficient', 'particularly efficient for', 'particularly useful', 'particularly useful in', 'parties', 'parties can', 'parties can change', 'parties parties', 'parties parties can', 'partition', 'partition a', 'partition a dataset', 'partitions', 'partitions the', 'partitions the data', 'past', 'past training', 'past training data', 'patch', 'patch can', 'patch can be', 'patches', 'patches are', 'patches are likely', 'paths', 'paths for', 'paths for patients', 'patients', 'patients but', 'patients but this', 'patients with', 'patients with unnecessary', 'pattern', 'pattern classification', 'pattern classification interest', 'pattern does', 'pattern does not', 'pattern recognition', 'pattern recognition and', 'pattern recognition continued', 'pattern that', 'pattern that the', 'patterns', 'patterns according', 'patterns according to', 'patterns and', 'patterns and equipped', 'patterns everything', 'patterns everything is', 'patterns from', 'patterns from data', 'patterns on', 'patterns on a', 'patterns such', 'patterns such as', 'patterns the', 'patterns the more', 'patterns using', 'patterns using rudimentary', 'pca', 'pca involves', 'pca involves changing', 'pca pca', 'pca pca involves', 'pedestrian', 'pedestrian who', 'pedestrian who was', 'penalising', 'penalising the', 'penalising the theory', 'people', 'people andmost', 'people andmost importantlyit', 'people as', 'people as gorillas', 'people have', 'people have been', 'people it', 'people it is', 'people its', 'people its created', 'people lack', 'people lack of', 'perceptrons', 'perceptrons and', 'perceptrons and other', 'perceptrons and supervised', 'perform', 'perform a', 'perform a nonlinear', 'perform a specific', 'perform accurate', 'perform accurate predictions', 'perform accurately', 'perform accurately on', 'perform aipowered', 'perform aipowered image', 'perform different', 'perform different kinds', 'perform inference', 'perform inference and', 'perform more', 'perform more effectively', 'perform tasks', 'perform tasks by', 'perform tasks without', 'perform that', 'perform that task', 'performance', 'performance and', 'performance and thermal', 'performance are', 'performance are quite', 'performance at', 'performance at tasks', 'performance bounds', 'performance bounds learning', 'performance in', 'performance in the', 'performance is', 'performance is a', 'performance is usually', 'performance measure', 'performance measure p', 'performance of', 'performance of algorithms', 'performance of genetic', 'performance of the', 'performed', 'performed each', 'performed each respectively', 'performing', 'performing classification', 'performing classification or', 'performing either', 'performing either supervised', 'performing linear', 'performing linear classification', 'performing model', 'performing specific', 'performing specific tasks', 'period', 'personal', 'personal data', 'personal data and', 'persons', 'persons height', 'persons height based', 'perturbations', 'perturbations for', 'perturbations for some', 'phd', 'phd graduates', 'phd graduates identified', 'philosophical', 'philosophical induction', 'philosophical induction suggesting', 'phone', 'phone when', 'phone when applied', 'phones', 'phones without', 'phones without having', 'photos', 'photos once', 'photos once tagged', 'physical', 'physical hardware', 'physical hardware for', 'physical neural', 'physical neural network', 'physics', 'physics is', 'physics is thus', 'physics of', 'physics of disordered', 'pick', 'pick up', 'pick up the', 'picked', 'picked up', 'picked up racist', 'picking', 'picking the', 'picking the best', 'picture', 'picture and', 'picture and they', 'pictures', 'pictures of', 'pictures of brown', 'piece', 'piece of', 'piece of data', 'piecewise', 'piecewise manner', 'piecewise manner in', 'pioneer', 'pioneer in', 'pioneer in the', 'pitts', 'pitts and', 'pitts and warren', 'pixel', 'pixel machine', 'pixel machine learning', 'pixels', 'pixels that', 'pixels that humans', 'pkdd', 'pkdd being', 'pkdd being a', 'placed', 'placed undetectably', 'placed undetectably into', 'placeholder', 'placeholder to', 'placeholder to call', 'placements', 'placements in', 'placements in addition', 'plagued', 'plagued by', 'plagued by theoretical', 'plan', 'plan recovery', 'plan recovery paths', 'platt', 'platt scaling', 'platt scaling exist', 'play', 'play a', 'play a game', 'playing', 'playing board', 'playing board and', 'plotkin', 'plotkin and', 'plotkin and ehud', 'pmfbased', 'pmfbased bayesian', 'pmfbased bayesian approach', 'point', 'point as', 'point as function', 'pointofsale', 'pointofsale pos', 'pointofsale pos systems', 'points', 'points and', 'points and the', 'points into', 'points into clusters', 'points or', 'points or inputoutput', 'points particularly', 'points particularly beneficial', 'points relate', 'points relate to', 'points this', 'points this process', 'points with', 'points with their', 'policies', 'policies may', 'policies may lead', 'policing', 'policing company', 'policing company geoliticas', 'polynomial', 'polynomial regression', 'polynomial regression for', 'polynomial time', 'polynomial time negative', 'polynomial time there', 'poorer', 'popular', 'popular heuristic', 'popular heuristic method', 'popular methods', 'popular methods of', 'popular surrogate', 'popular surrogate models', 'population', 'population in', 'population in the', 'population inferences', 'population inferences from', 'pos', 'pos systems', 'pos systems in', 'poses', 'poses another', 'poses another yet', 'positive', 'positive and', 'positive and negative', 'positive and no', 'positive rate', 'positive rate fpr', 'positive rate tpr', 'positive results', 'positive results show', 'possibility', 'possibility and', 'possibility and imprecise', 'possible', 'possible compression', 'possible compression of', 'possible software', 'possible software that', 'possible to', 'possible to change', 'possibly', 'possibly after', 'possibly after traversing', 'possibly including', 'possibly including whitebox', 'posterior', 'posterior probabilities', 'posterior probabilities of', 'posts', 'posts machine', 'posts machine learning', 'potatoes', 'potatoes together', 'potatoes together they', 'potential', 'potential for', 'potential for machine', 'potential future', 'potential future challenges', 'potential predictions', 'potential result', 'potential result of', 'powerful', 'powerful tool', 'powerful tool we', 'ppm', 'practical', 'practical nature', 'practical nature it', 'practical problems', 'practical problems of', 'pragmatic', 'pragmatic theory', 'pragmatic theory built', 'pre', 'pre evacuation', 'pre evacuation decisions', 'preassigned', 'preassigned labels', 'preassigned labels of', 'precluded', 'precluded by', 'precluded by space', 'predefined', 'predefined covariance', 'predefined covariance function', 'predefined labels', 'predefined labels and', 'predesignated', 'predesignated criteria', 'predesignated criteria while', 'predict', 'predict evacuation', 'predict evacuation decision', 'predict if', 'predict if and', 'predict stock', 'predict stock returns', 'predict the', 'predict the financial', 'predict the needs', 'predict the output', 'predict the preassigned', 'predict the proenvironmental', 'predict user', 'predict user preferences', 'predicted', 'predicted that', 'predicted that of', 'predicting', 'predicting a', 'predicting a persons', 'predicting multiple', 'predicting multiple economic', 'prediction', 'prediction and', 'prediction and site', 'prediction based', 'prediction based on', 'prediction by', 'prediction by finding', 'prediction models', 'prediction models on', 'prediction of', 'prediction of solvent', 'prediction rulebased', 'prediction rulebased machine', 'predictions', 'predictions and', 'predictions and achieve', 'predictions biased', 'predictions biased models', 'predictions by', 'predictions by extension', 'predictions for', 'predictions for future', 'predictions in', 'predictions in new', 'predictions made', 'predictions made by', 'predictions of', 'predictions of the', 'predictions or', 'predictions or classifications', 'predictions over', 'predictions over time', 'predictions this', 'predictions this technique', 'predictions to', 'predictions to improve', 'predictions when', 'predictions when training', 'predictive', 'predictive algorithm', 'predictive algorithm that', 'predictive analytics', 'predictive model', 'predictive model to', 'predictive modelling', 'predictive modelling approaches', 'predictive patterns', 'predictive patterns according', 'predictive policing', 'predictive policing company', 'predicts', 'predicts the', 'predicts the posterior', 'predicts whether', 'predicts whether a', 'preferences', 'preferences and', 'preferences and improve', 'prehistory', 'prehistory in', 'prehistory in statistics', 'prejudices', 'prejudices for', 'prejudices for example', 'prepared', 'prepared for', 'prepared for training', 'preprocessing', 'preprocessing step', 'preprocessing step before', 'preprocessing step to', 'presence', 'presence of', 'presence of various', 'presence or', 'presence or absence', 'present', 'present in', 'present in society', 'preserve', 'preserve the', 'preserve the information', 'preserving', 'preserving the', 'preserving the core', 'prestructured', 'prestructured model', 'prestructured model rather', 'previous', 'previous admissions', 'previous admissions staff', 'previous experience', 'previous experience are', 'previous history', 'previous history this', 'previous machine', 'previous machine learning', 'previous successful', 'previous successful applicants', 'previously', 'previously unknown', 'previously unknown knowledge', 'previously unknown properties', 'previously unrecognised', 'previously unrecognised influences', 'previously unseen', 'previously unseen training', 'pricing', 'pricing or', 'pricing or product', 'primarily', 'primarily make', 'primarily make judgements', 'principal', 'principal component', 'principal component analysis', 'principal goal', 'principal goal statistics', 'principal variables', 'principal variables in', 'principles', 'principles to', 'principles to theoretical', 'priori', 'priori selection', 'priori selection of', 'prisoners', 'prisoners falsely', 'prisoners falsely flagged', 'privacy', 'privacy and', 'privacy and regulation', 'privacy leaks', 'privacy leaks and', 'privacy problems', 'privacy problems badly', 'privacy to', 'privacy to be', 'prize', 'prize competition', 'prize competition to', 'prize in', 'prize in for', 'prize the', 'prize the best', 'prize was', 'prize was awarded', 'probabilistic', 'probabilistic bounds', 'probabilistic bounds on', 'probabilistic classification', 'probabilistic classification setting', 'probabilistic graphical', 'probabilistic graphical model', 'probabilistic reasoning', 'probabilistic reasoning was', 'probabilistic relationships', 'probabilistic relationships between', 'probabilistic systems', 'probabilistic systems were', 'probabilities', 'probabilities however', 'probabilities however there', 'probabilities of', 'probabilities of a', 'probabilities of the', 'probability', 'probability distribution', 'probability distribution considered', 'probability possibility', 'probability possibility and', 'probability theories', 'probability theories these', 'probability theory', 'probably', 'probably approximately', 'probably approximately correct', 'problem', 'problem in', 'problem in machine', 'problem instances', 'problem instances for', 'problem is', 'problem is to', 'problem learning', 'problem learning without', 'problem with', 'problem with various', 'problems', 'problems are', 'problems are formulated', 'problems badly', 'problems badly chosen', 'problems goto', 'problems goto models', 'problems in', 'problems in the', 'problems including', 'problems including machine', 'problems is', 'problems is known', 'problems is the', 'problems of', 'problems of a', 'problems of data', 'problems or', 'problems or errors', 'problems under', 'problems under uncertainty', 'proceeds', 'proceeds the', 'proceeds the weight', 'process', 'process allowing', 'process allowing for', 'process condenses', 'process condenses extensive', 'process has', 'process has a', 'process however', 'process however realworld', 'process in', 'process in which', 'process is', 'process is a', 'process it', 'process it and', 'process mdp', 'process mdp many', 'process of', 'process of natural', 'process of producing', 'process of reducing', 'process to', 'process to many', 'processes', 'processes are', 'processes are popular', 'processes in', 'processes in canadian', 'processes light', 'processes light and', 'processing', 'processing computer', 'processing computer vision', 'processing gordon', 'processing gordon plotkin', 'processing kmeans', 'processing kmeans clustering', 'processing thereby', 'processing thereby reducing', 'processing toolbox', 'processing toolbox ipt', 'processing units', 'processing units gpus', 'processing units tpus', 'produce', 'produce a', 'produce a considerable', 'produce hostile', 'produce hostile and', 'produce sufficiently', 'produce sufficiently accurate', 'producing', 'producing an', 'producing an output', 'product', 'product placements', 'product placements in', 'production', 'production and', 'production and bioinformatics', 'products', 'products in', 'products in largescale', 'proenvironmental', 'proenvironmental behaviour', 'proenvironmental behaviour of', 'professionals', 'professionals an', 'professionals an additional', 'professionals that', 'professionals that these', 'profits', 'profits for', 'profits for example', 'profound', 'profound responsibility', 'program', 'program had', 'program had denied', 'program is', 'program is said', 'program that', 'program that calculated', 'program that entails', 'program that inductively', 'program to', 'program to better', 'program trained', 'program trained from', 'programmed', 'programmed with', 'programmed with any', 'programming', 'programming as', 'programming as a', 'programming ilp', 'programming ilp is', 'programming is', 'programming is a', 'programming is particularly', 'programming language', 'programming language for', 'programming methods', 'programming methods comprise', 'programming such', 'programming such as', 'programming techniques', 'programming techniques reinforcement', 'programmingilp', 'programmingilp but', 'programmingilp but the', 'programs', 'programs from', 'programs from positive', 'programs often', 'programs often fail', 'projects', 'projects from', 'projects from alexnet', 'prolog', 'prolog program', 'prolog program that', 'promises', 'promises to', 'promises to help', 'promising', 'promising tool', 'promising tool in', 'promotional', 'promotional pricing', 'promotional pricing or', 'propelling', 'propelling its', 'propelling its use', 'proper', 'proper in', 'proper in pattern', 'properties', 'properties in', 'properties in the', 'properties learned', 'properties learned from', 'properties of', 'properties of how', 'property', 'property for', 'property for all', 'property personal', 'property personal data', 'proposal', 'proposal in', 'proposal in his', 'proposed', 'proposed the', 'proposed the early', 'proposes', 'proposes that', 'proposes that highdimensional', 'propositions', 'propositions classes', 'propositions classes and', 'proprietary', 'proprietary owners', 'proprietary owners hold', 'propublica', 'propublica an', 'propublica an investigative', 'protein', 'protein sequences', 'protein sequences are', 'provide', 'provide patients', 'provide patients with', 'provide professionals', 'provide professionals an', 'provided', 'provided a', 'provided a full', 'provided a widely', 'provided during', 'provided during training', 'provided possibly', 'provided possibly including', 'provider', 'provider netflix', 'provider netflix held', 'provides', 'provides a', 'provides a framework', 'provides interpretable', 'provides interpretable models', 'proving', 'proving a', 'proving a property', 'pruning', 'pruning quantisation', 'pruning quantisation knowledge', 'psychologist', 'psychologist donald', 'psychologist donald hebb', 'publics', 'publics interest', 'publics interest but', 'published', 'published the', 'published the book', 'published the first', 'punched', 'punched tape', 'punched tape memory', 'purpose', 'purpose is', 'purpose is to', 'quantification', 'quantification these', 'quantification these belief', 'quantify', 'quantify generalisation', 'quantify generalisation error', 'quantisation', 'quantisation knowledge', 'quantisation knowledge distillation', 'quantity', 'quantity of', 'quantity of reliable', 'quantum', 'quantum chemistry', 'quantum chemistry where', 'query', 'query prediction', 'query prediction models', 'quest', 'quest for', 'quest for artificial', 'question', 'question can', 'question can machines', 'quickly', 'quickly picked', 'quickly picked up', 'quite', 'quite common', 'quite common the', 'quoted', 'quoted more', 'quoted more formal', 'race', 'race dynamics', 'race dynamics ai', 'racial', 'racial equality', 'racial equality found', 'racist', 'racist and', 'racist and sexist', 'racist hiring', 'racist hiring policies', 'raise', 'raise suspicions', 'raise suspicions by', 'rakesh', 'rakesh agrawal', 'rakesh agrawal tomasz', 'random', 'random data', 'random data of', 'random forest', 'random forest regression', 'random selection', 'random selection of', 'random variables', 'random variables and', 'random variables in', 'random variables under', 'randomly', 'randomly partitions', 'randomly partitions the', 'range', 'range for', 'range for example', 'range of', 'range of company', 'range of topics', 'ranking', 'ranking recommendation', 'ranking recommendation systems', 'rare', 'rare items', 'rare items events', 'rare object', 'rare object many', 'rare objects', 'rare objects but', 'rate', 'rate fnr', 'rate fnr however', 'rate fpr', 'rate fpr as', 'rate tnr', 'rate tnr respectively', 'rate tpr', 'rate tpr and', 'rates', 'rates among', 'rates among prisoners', 'rates are', 'rates are ratios', 'rather', 'rather than', 'rather than defining', 'rather than mathematical', 'rather the', 'rather the data', 'ratings', 'ratings were', 'ratings were not', 'ratios', 'ratios that', 'ratios that fail', 'raytheon', 'raytheon company', 'raytheon company to', 'rbml', 'rbml is', 'rbml is a', 'rbml techniques', 'rbml techniques includes', 'react', 'react based', 'react based on', 'reactions', 'reactions thereby', 'reactions thereby offering', 'real', 'real number', 'real number and', 'real numbers', 'real numbers are', 'real objects', 'real objects modifying', 'realised', 'realised that', 'realised that viewers', 'realworld', 'realworld data', 'realworld data such', 'realworld example', 'realworld example is', 'reasoning', 'reasoning was', 'reasoning was also', 'reasoning with', 'reasoning with uncertainty', 'reasons', 'reasons for', 'reasons for this', 'rebellion', 'rebellion research', 'rebellion research and', 'receiver', 'receiver operating', 'receiver operating characteristic', 'receives', 'receives a', 'receives a signal', 'receives initial', 'receives initial emotions', 'receiving', 'receiving the', 'receiving the genome', 'recent', 'recent advancements', 'recent advancements in', 'recent research', 'recent research emphasizes', 'recently', 'recently applied', 'recently applied to', 'recently machine', 'recently machine learning', 'recidivism', 'recidivism rates', 'recidivism rates among', 'recognise', 'recognise characters', 'recognise characters letters', 'recognise gorillas', 'recognise gorillas similar', 'recognise patterns', 'recognise patterns and', 'recognised', 'recognised as', 'recognised as its', 'recognising', 'recognising nonwhite', 'recognising nonwhite people', 'recognition', 'recognition and', 'recognition and information', 'recognition continued', 'recognition continued into', 'recognition email', 'recognition email filtering', 'recognition machine', 'recognition machine translation', 'recommendation', 'recommendation algorithm', 'recommendation algorithm by', 'recommendation and', 'recommendation and they', 'recommendation engine', 'recommendation engine accordingly', 'recommendation systems', 'recommendation systems visual', 'reconstructing', 'reconstructing images', 'reconstructing images which', 'reconstruction', 'reconstruction of', 'reconstruction of the', 'recorded', 'recorded by', 'recorded by pointofsale', 'recovery', 'recovery paths', 'recovery paths for', 'reduce', 'reduce bias', 'reduce bias predictions', 'reduce overfitting', 'reduce overfitting by', 'reduce the', 'reduce the size', 'reduce the workload', 'reducing', 'reducing bias', 'reducing bias in', 'reducing the', 'reducing the dimension', 'reducing the number', 'reducing the risk', 'reduction', 'reduction and', 'reduction and density', 'reduction by', 'reduction by replacing', 'reduction is', 'reduction is a', 'reduction is principal', 'reduction techniques', 'reduction techniques can', 'reduction techniques make', 'reevaluate', 'reevaluate incorrect', 'reevaluate incorrect decisions', 'refer', 'refer to', 'refer to several', 'referred', 'referred to', 'referred to as', 'refers', 'refers to', 'refers to a', 'refers to artificial', 'refers to philosophical', 'refining', 'refining the', 'refining the mental', 'regression', 'regression algorithms', 'regression algorithms are', 'regression analysis', 'regression analysis encompasses', 'regression and', 'regression and classification', 'regression classification', 'regression classification algorithms', 'regression extends', 'regression extends the', 'regression for', 'regression for example', 'regression given', 'regression given a', 'regression is', 'regression is used', 'regression often', 'regression often used', 'regression rfr', 'regression rfr falls', 'regression to', 'regression to handle', 'regression trees', 'regression trees in', 'regression when', 'regression when dealing', 'regression where', 'regression where a', 'regression which', 'regression which introduces', 'regressor', 'regressor task', 'regressor task this', 'regularisation', 'regularisation methods', 'regularisation methods to', 'regularities', 'regularities between', 'regularities between products', 'regulation', 'regulation it', 'regulation it also', 'reinforcement', 'reinforcement input', 'reinforcement input nor', 'reinforcement is', 'reinforcement is the', 'reinforcement learning', 'reinforcement learning algorithms', 'reinforcement learning and', 'reinforcement learning is', 'reinforcement learning it', 'reinforcement learning or', 'reinforcement learning the', 'reinvention', 'reinvention of', 'reinvention of backpropagation', 'reinventions', 'reinventions of', 'reinventions of the', 'relate', 'relate to', 'relate to each', 'related', 'related field', 'related field of', 'related field that', 'related fields', 'related fields in', 'related supervised', 'related supervised learning', 'related to', 'related to a', 'related to pattern', 'related to regression', 'related to the', 'related two', 'related two objects', 'relational', 'relational rules', 'relational rules that', 'relationship', 'relationship between', 'relationship between components', 'relationship between input', 'relationships', 'relationships between', 'relationships between a', 'relationships between diseases', 'relationships between pixels', 'relationships between variables', 'relevant', 'relevant variables', 'relevant variables based', 'reliable', 'reliable data', 'reliable data to', 'relies', 'relies on', 'relies on a', 'relies on electrically', 'relying', 'relying on', 'relying on explicit', 'remainder', 'remainder of', 'remainder of the', 'remaining', 'remaining k', 'remaining k subsets', 'removed', 'removed and', 'removed and in', 'reorganised', 'reorganised and', 'reorganised and recognised', 'repetitively', 'repetitively trained', 'repetitively trained by', 'replaced', 'replaced with', 'replaced with the', 'replacement', 'replacement for', 'replacement for engineering', 'replacement from', 'replacement from the', 'replaces', 'replaces manual', 'replaces manual feature', 'replacing', 'replacing groups', 'replacing groups of', 'replicate', 'replicate neural', 'replicate neural synapses', 'report', 'report sensitivity', 'report sensitivity and', 'report the', 'report the false', 'report was', 'report was given', 'reported', 'reported that', 'reported that a', 'reported to', 'reported to produce', 'represent', 'represent an', 'represent an issue', 'represent and', 'represent and solve', 'represent class', 'represent class labels', 'represent conjunctions', 'represent conjunctions of', 'represent decisions', 'represent decisions and', 'represent the', 'represent the knowledge', 'represent the probabilistic', 'representation', 'representation by', 'representation by expert', 'representation for', 'representation for input', 'representation is', 'representation is lowdimensional', 'representation is sparse', 'representation learning', 'representation learning algorithms', 'representation of', 'representation of minority', 'representation or', 'representation or a', 'representation that', 'representation that disentangles', 'representations', 'representations directly', 'representations directly from', 'representations for', 'representations for multidimensional', 'representations of', 'representations of the', 'representations through', 'representations through examination', 'representative', 'representative book', 'representative book on', 'representative lossless', 'representative lossless compression', 'representative of', 'representative of the', 'representative points', 'representative points particularly', 'representative sample', 'representative sample of', 'represented', 'represented as', 'represented as a', 'represented by', 'represented by a', 'represented by an', 'represented by the', 'represented in', 'represented in the', 'representing', 'representing hypotheses', 'representing hypotheses and', 'representing normal', 'representing normal behaviour', 'represents', 'represents a', 'represents a set', 'reproduce', 'reproduce known', 'reproduce known knowledge', 'require', 'require a', 'require a data', 'require a high', 'require input', 'require input that', 'require the', 'require the a', 'required', 'required storage', 'required storage space', 'required with', 'required with a', 'requires', 'requires these', 'requires these biases', 'research', 'research and', 'research and their', 'research association', 'research association cra', 'research book', 'research book created', 'research carried', 'research carried out', 'research communities', 'research communities which', 'research emphasizes', 'research emphasizes a', 'research especially', 'research especially for', 'research had', 'research had been', 'research information', 'research information theory', 'research into', 'research into machine', 'research themselves', 'research was', 'research was now', 'researched', 'researched for', 'researched for machine', 'researchers', 'researchers blame', 'researchers blame lack', 'researchers from', 'researchers from att', 'researchers from other', 'researchers have', 'researchers have demonstrated', 'researchers have found', 'researchers in', 'researchers in developing', 'researchers were', 'researchers were interested', 'researchers who', 'researchers who have', 'reshaping', 'reshaping them', 'reshaping them into', 'resident', 'resident ai', 'resident ai phd', 'resistance', 'resistance to', 'resistance to replicate', 'resolving', 'resolving however', 'resolving however the', 'resources', 'resources and', 'resources and evaluation', 'resources such', 'resources such as', 'respect', 'respect to', 'respect to known', 'respect to some', 'respect to the', 'respectively', 'respectively considering', 'respectively considering subset', 'respectively similarly', 'respectively similarly investigators', 'responding', 'responding to', 'responding to feedback', 'response', 'response against', 'response against its', 'response then', 'response then the', 'responsibility', 'responsible', 'responsible collection', 'responsible collection of', 'restricted', 'restricted to', 'restricted to a', 'result', 'result in', 'result in adversarial', 'result in detrimental', 'result in nonlinear', 'result in skewed', 'result of', 'result of data', 'resulted', 'resulted in', 'resulted in disproportionately', 'resulting', 'resulting classification', 'resulting classification tree', 'resulting in', 'resulting in larger', 'results', 'results positive', 'results positive results', 'results reasons', 'results reasons for', 'results show', 'results show that', 'results that', 'results that far', 'retrieval', 'retrieval neural', 'retrieval neural networks', 'returns', 'returns without', 'returns without overfitting', 'reveal', 'reveal their', 'reveal their numerators', 'revealed', 'revealed previously', 'revealed previously unrecognised', 'review', 'review and', 'review and increased', 'reviewer', 'reviewer burden', 'reviewer burden related', 'reward', 'reward by', 'reward by introducing', 'reward due', 'reward due to', 'reward emotion', 'reward emotion is', 'rewarding', 'rewarding a', 'rewarding a theory', 'rfr', 'rfr compatible', 'rfr compatible to', 'rfr falls', 'rfr falls under', 'rfr for', 'rfr for training', 'rfr generates', 'rfr generates independent', 'rfr is', 'rfr is an', 'rfr uses', 'rfr uses bootstrapped', 'ridge', 'ridge regression', 'ridge regression when', 'rift', 'rift between', 'rift between ai', 'right', 'right to', 'right to explanation', 'rightarrow', 'rightarrow mathrm', 'rightarrow mathrm burger', 'rights', 'rights artificial', 'rights artificial superintelligence', 'risk', 'risk of', 'risk of data', 'risk twice', 'risk twice as', 'risks', 'robot', 'robot learning', 'robot learning is', 'roc', 'roc along', 'roc along with', 'roc curve', 'roc curve auc', 'roots', 'roots back', 'roots back to', 'routine', 'rudimentary', 'rudimentary reinforcement', 'rudimentary reinforcement learning', 'rule', 'rule learning', 'rule learning and', 'rule learning artificial', 'rule learning is', 'rule learning typically', 'rule learning using', 'rule of', 'rule of combination', 'rule onionspotatoesburgerdisplaystyle', 'rule onionspotatoesburgerdisplaystyle mathrm', 'rulebased', 'rulebased machine', 'rulebased machine learning', 'rules', 'rules are', 'rules are employed', 'rules discovered', 'rules discovered in', 'rules for', 'rules for discovering', 'rules from', 'rules from data', 'rules over', 'rules over time', 'rules rakesh', 'rules rakesh agrawal', 'rules that', 'rules that collectively', 'rules to', 'rules to store', 'rules used', 'rules used by', 'rumelhart', 'rumelhart and', 'rumelhart and geoffrey', 'running', 'running models', 'running models directly', 's', 's advances', 's advances in', 's an', 's an experimental', 's and', 's and s', 's as', 's as described', 's conversely', 's conversely machine', 's the', 's the field', 's was', 's was nilssons', 's when', 's when arthur', 'safety', 'safety and', 'safety and alignment', 'said', 'said that', 'said that theres', 'said to', 'said to have', 'said to learn', 'sales', 'sales data', 'sales data of', 'same', 'same cluster', 'same cluster and', 'same cluster are', 'same machine', 'same machine learning', 'same methods', 'same methods and', 'same time', 'same time this', 'same way', 'same way that', 'sample', 'sample of', 'sample of data', 'sample while', 'sample while machine', 'samples', 'samples and', 'samples and ambiguous', 'samples n', 'samples n instances', 'sampling', 'sampling for', 'sampling for instance', 'samuel', 'samuel an', 'samuel an ibm', 'samuel invented', 'samuel invented a', 'satisfactory', 'satisfactory explanation', 'satisfactory explanation for', 'scale', 'scale and', 'scale and small', 'scale disasters', 'scale disasters different', 'scaling', 'scaling exist', 'scaling exist to', 'scenarios', 'scenarios where', 'scenarios where outputs', 'school', 'school had', 'school had been', 'science', 'science around', 'science around the', 'science as', 'science as a', 'science known', 'science known as', 'scientific', 'scientific endeavour', 'scientific endeavour machine', 'scientists', 'scientists including', 'scientists including feifei', 'scoring', 'scoring job', 'scoring job applicants', 'search', 'search algorithm', 'search algorithm and', 'search and', 'search and parameter', 'search query', 'search query prediction', 'searches', 'searches back', 'searches back to', 'secondary', 'secondary reinforcement', 'secondary reinforcement is', 'secrets', 'secrets embedded', 'secrets embedded machine', 'seek', 'seek to', 'seek to identify', 'seem', 'seem to', 'seem to fit', 'select', 'select committee', 'select committee which', 'selection', 'selection of', 'selection of a', 'selection of rfr', 'selection using', 'selection using methods', 'selfdriving', 'selfdriving car', 'selfdriving car from', 'selflearning', 'selflearning agent', 'selflearning agent the', 'selflearning algorithm', 'selflearning algorithm computes', 'selflearning algorithm updates', 'selflearning as', 'selflearning as a', 'selflearning named', 'selflearning named crossbar', 'selfsupervised', 'selfsupervised learning', 'selfsupervised learning involves', 'selfteaching', 'selfteaching computers', 'selfteaching computers was', 'semisupervised', 'semisupervised anomaly', 'semisupervised anomaly detection', 'semisupervised learning', 'semisupervised learning falls', 'send', 'send individual', 'send individual searches', 'send their', 'send their data', 'sensitivity', 'sensitivity and', 'sensitivity and specificity', 'sensitivity for', 'sensitivity for the', 'sensor', 'sensor data', 'sensor data and', 'sensory', 'sensory data', 'sensory data has', 'sent', 'sent if', 'sent if the', 'separate', 'separate conferences', 'separate conferences and', 'separate journals', 'separate journals ecml', 'separate reinforcement', 'separate reinforcement input', 'separation', 'separation the', 'separation the difference', 'sequence', 'sequence given', 'sequence given its', 'sequence mining', 'sequence mining association', 'sequences', 'sequences are', 'sequences are called', 'sequences of', 'sequences of variables', 'server', 'server this', 'server this also', 'servers', 'servers for', 'servers for further', 'service', 'service overfitting', 'service overfitting is', 'services', 'services and', 'services and largescale', 'set', 'set a', 'set a groundwork', 'set also', 'set also called', 'set and', 'set and test', 'set and then', 'set are', 'set are normal', 'set can', 'set can be', 'set conventionally', 'set conventionally training', 'set designation', 'set designation and', 'set in', 'set in addition', 'set in comparison', 'set of', 'set of contextdependent', 'set of data', 'set of examples', 'set of input', 'set of observations', 'set of observed', 'set of principal', 'set of random', 'set of related', 'set of relational', 'set of representative', 'set of training', 'set of values', 'set supervised', 'set supervised anomaly', 'set that', 'set that has', 'set the', 'set the training', 'set this', 'set this random', 'set under', 'set under the', 'sets', 'sets are', 'sets are finite', 'sets it', 'sets it has', 'sets lie', 'sets lie along', 'setting', 'setting in', 'setting in addition', 'setting shapiro', 'setting shapiro built', 'settling', 'settling on', 'settling on a', 'several', 'several contexts', 'several contexts in', 'several learning', 'several learning algorithms', 'several levels', 'several levels of', 'several output', 'several output variables', 'several universities', 'several universities around', 'sexist', 'sexist language', 'shape', 'shape the', 'shape the model', 'shapiro', 'shapiro built', 'shapiro built their', 'shapiro laid', 'shapiro laid the', 'share', 'share underlying', 'share underlying patterns', 'sharing', 'shifted', 'shifted focus', 'shifted focus away', 'shortly', 'shortly after', 'shortly after the', 'should', 'should match', 'should match the', 'show', 'show compression', 'show compression algorithms', 'show that', 'show that a', 'show that certain', 'shown', 'shown to', 'shown to contain', 'side', 'side the', 'side the history', 'signal', 'signal additional', 'signal additional artificial', 'signal at', 'signal at a', 'signal can', 'signal can process', 'signal crosses', 'signal crosses that', 'signal from', 'signal from one', 'signal from the', 'signal in', 'signal in the', 'signal is', 'signal is only', 'signal or', 'signal or feedback', 'signal processing', 'signal processing kmeans', 'signals', 'signals electrocardiograms', 'signals electrocardiograms and', 'signals or', 'signals or protein', 'signals travel', 'signals travel from', 'significant', 'significant challenge', 'significant challenge black', 'significant or', 'significant or theoretically', 'significantly', 'significantly but', 'significantly but while', 'significantly decreasing', 'significantly decreasing the', 'significantly from', 'significantly from the', 'similar', 'similar according', 'similar according to', 'similar data', 'similar data points', 'similar issues', 'similar issues with', 'similar models', 'similar models these', 'similar or', 'similar or related', 'similarity', 'similarity between', 'similarity between members', 'similarity function', 'similarity function that', 'similarity learning', 'similarity learning is', 'similarity measures', 'similarity measures compute', 'similarity metric', 'similarity metric and', 'similarity to', 'similarity to previous', 'similarity within', 'similarity within these', 'similarly', 'similarly investigators', 'similarly investigators sometimes', 'simplifies', 'simplifies handling', 'simplifies handling extensive', 'simulationbased', 'simulationbased optimisation', 'simulationbased optimisation multiagent', 'simulations', 'simulations on', 'simulations on conventional', 'simultaneously', 'simultaneously this', 'simultaneously this approach', 'since', 'since the', 'since the s', 'since their', 'since their introduction', 'since you', 'since you can', 'single', 'single adversarially', 'single adversarially chosen', 'single algorithm', 'single algorithm works', 'single line', 'single line is', 'single output', 'single output data', 'singular', 'singular model', 'singular model that', 'site', 'site characterization', 'site characterization recent', 'sitespecific', 'sitespecific data', 'sitespecific data and', 'situation', 'situation and', 'situation and only', 'situation the', 'situation the caa', 'situation where', 'situation where the', 'situations', 'situations the', 'situations the system', 'situations to', 'situations to be', 'size', 'size includes', 'size includes both', 'size of', 'size of data', 'skewed', 'skewed or', 'skewed or undesired', 'small', 'small amount', 'small amount of', 'small scale', 'small scale disasters', 'smaller', 'smaller combined', 'smaller combined form', 'smaller space', 'smaller space eg', 'smallest', 'smallest possible', 'smallest possible software', 'smartphones', 'smartphones performance', 'smartphones performance and', 'so', 'so as', 'so as to', 'so that', 'so that an', 'so that observations', 'so under', 'so under the', 'social', 'social network', 'social network filtering', 'social right', 'social right to', 'society', 'society or', 'society or objectives', 'software', 'software agents', 'software agents ought', 'software in', 'software in it', 'software include', 'software include nvidia', 'software since', 'software since you', 'software suites', 'software suites containing', 'software that', 'software that can', 'software that generates', 'softwarebased', 'softwarebased implementations', 'softwarebased implementations it', 'softwarebased simulations', 'softwarebased simulations on', 'solution', 'solution to', 'solution to the', 'solutions', 'solutions have', 'solutions have been', 'solutions to', 'solutions to a', 'solvable', 'solvable problems', 'solvable problems of', 'solve', 'solve approximately', 'solve approximately a', 'solve decision', 'solve decision problems', 'solve problems', 'solve problems in', 'solvent', 'solvent effects', 'solvent effects on', 'some', 'some analogous', 'some analogous properties', 'some class', 'some class of', 'some fields', 'some fields machinelearning', 'some generally', 'some generally unknown', 'some loss', 'some loss function', 'some measure', 'some measure of', 'some nonlinear', 'some nonlinear function', 'some notion', 'some notion of', 'some of', 'some of the', 'some researchers', 'some researchers blame', 'some researchers were', 'some similarity', 'some similarity metric', 'some statisticians', 'some statisticians have', 'some successful', 'some successful applications', 'some systems', 'some systems it', 'something', 'something to', 'something to watch', 'sometimes', 'sometimes called', 'sometimes called a', 'sometimes more', 'sometimes more than', 'sometimes report', 'sometimes report the', 'sonar', 'sonar signals', 'sonar signals electrocardiograms', 'sound', 'sound into', 'sound into vision', 'sounding', 'sounding names', 'sounding names using', 'space', 'space eg', 'space eg dthe', 'space instead', 'space instead feature', 'space of', 'space of deep', 'space of occurrences', 'space that', 'space that enables', 'space vectors', 'space vectors and', 'space â„µ', 'space â„µ such', 'spaces', 'spaces for', 'spaces for each', 'spaces underlying', 'spaces underlying all', 'spam', 'spam and', 'spam and wellvisible', 'spam of', 'spam of posts', 'sparse', 'sparse coding', 'sparse coding algorithms', 'sparse dictionary', 'sparse dictionary learning', 'sparse matrix', 'sparse matrix the', 'sparse meaning', 'sparse meaning that', 'sparsely', 'sparsely represented', 'sparsely represented by', 'spatial', 'spatial relationship', 'spatial relationship between', 'speaker', 'speaker verification', 'special', 'special symbols', 'special symbols from', 'special type', 'special type of', 'specialised', 'specialised hardware', 'specialised hardware accelerators', 'specialised hardware architectures', 'species', 'species vector', 'species vector from', 'specific', 'specific decision', 'specific decision by', 'specific features', 'specific features an', 'specific task', 'specific tasks', 'specific tasks leading', 'specific to', 'specific to classifying', 'specific type', 'specific type of', 'specifically', 'specifically for', 'specifically for machine', 'specifically on', 'specifically on current', 'specificity', 'specificity from', 'specificity from a', 'specificity meaning', 'specificity meaning true', 'specified', 'specified number', 'specified number of', 'speech', 'speech patterns', 'speech patterns using', 'speech recognition', 'speech recognition email', 'speech recognition machine', 'speech signals', 'speech signals or', 'speeding', 'speeding up', 'speeding up data', 'splits', 'splits the', 'splits the data', 'springer', 'springer nature', 'springer nature published', 'squares', 'squares the', 'squares the latter', 'st', 'st georges', 'st georges medical', 'staff', 'staff and', 'staff and that', 'stakes', 'stakes there', 'stakes there is', 'stakes this', 'stakes this includes', 'standard', 'standard machine', 'standard machine learning', 'started', 'started to', 'started to flourish', 'starting', 'starting from', 'starting from supervised', 'state', 'state evaluation', 'state evaluation of', 'states', 'states where', 'states where there', 'statistical', 'statistical algorithms', 'statistical algorithms that', 'statistical algorithms to', 'statistical analyses', 'statistical analyses require', 'statistical classification', 'statistical classification or', 'statistical classification problems', 'statistical definition', 'statistical definition of', 'statistical learning', 'statistical line', 'statistical line of', 'statistical methods', 'statistical methods to', 'statistical modelling', 'statistical modelling paradigms', 'statistical physics', 'statistical physics is', 'statisticians', 'statisticians have', 'statisticians have adopted', 'statistics', 'statistics and', 'statistics and genetic', 'statistics and mathematical', 'statistics are', 'statistics are closely', 'statistics data', 'statistics data mining', 'statistics draws', 'statistics draws population', 'statistics fuzzy', 'statistics fuzzy logic', 'statistics he', 'statistics he also', 'statistics probabilistic', 'statistics probabilistic reasoning', 'statistics was', 'statistics was out', 'status', 'status ai', 'status ai welfare', 'step', 'step before', 'step before performing', 'step of', 'step of knowledge', 'step to', 'step to improve', 'still', 'still cannot', 'still cannot recognise', 'still correlate', 'still correlate with', 'stochastic', 'stochastic process', 'stochastic process in', 'stock', 'stock returns', 'stock returns without', 'stock trading', 'stock trading may', 'storage', 'storage efficiency', 'storage efficiency and', 'storage space', 'store', 'store and', 'store and apply', 'store data', 'store data on', 'store manipulate', 'store manipulate or', 'strategies', 'strategies so', 'strategies so that', 'strategy', 'strategy to', 'strategy to update', 'street', 'street journal', 'street journal wrote', 'strength', 'strength of', 'strength of the', 'string', 'string x', 'string x corresponding', 'strings', 'strings into', 'strings into implicit', 'strong', 'strong rules', 'strong rules discovered', 'strong rules rakesh', 'strongly', 'strongly nphard', 'strongly nphard and', 'structural', 'structural defect', 'structural defect medical', 'structure', 'structure and', 'structure and functionality', 'structure formed', 'structure formed by', 'structure of', 'structure of the', 'structures', 'structures in', 'structures in data', 'structures leaves', 'structures leaves represent', 'studied', 'studied human', 'studied human cognitive', 'studied in', 'studied in many', 'studied in the', 'study', 'study and', 'study and notably', 'study data', 'study data set', 'study fine', 'study fine art', 'study focusing', 'study focusing on', 'study human', 'study human cognitive', 'study in', 'study in artificial', 'study of', 'study of statistical', 'study the', 'study the time', 'subdiscipline', 'subdiscipline in', 'subdiscipline in machine', 'subdomain', 'subdomain of', 'subdomain of machine', 'subfield', 'subfield of', 'subfield of machine', 'subject', 'subject to', 'subject to overfitting', 'subsequently', 'subsequently removed', 'subsequently removed and', 'subset', 'subset for', 'subset for evaluation', 'subsets', 'subsets and', 'subsets and then', 'subsets called', 'subsets called clusters', 'subsets for', 'subsets for training', 'subspace', 'subspace learning', 'subspace learning algorithms', 'substantial', 'substantial impact', 'substantial impact on', 'success', 'success came', 'success came in', 'successful', 'successful applicants', 'successful applicants another', 'successful applications', 'successful applications of', 'such', 'such an', 'such an intelligence', 'such as', 'such as bank', 'such as classification', 'such as functional', 'such as game', 'such as ground', 'such as hardware', 'such as image', 'such as images', 'such as machine', 'such as memristors', 'such as mutation', 'such as ordinary', 'such as platt', 'such as predicting', 'such as probability', 'such as promotional', 'such as training', 'such as wearable', 'such challenges', 'such challenges the', 'such commonalities', 'such commonalities in', 'such data', 'such data unless', 'such features', 'such features or', 'such information', 'such information can', 'such systems', 'such systems learn', 'such that', 'such that c', 'such that in', 'such that the', 'suffer', 'suffer from', 'suffer from different', 'sufficiently', 'sufficiently accurate', 'sufficiently accurate predictions', 'sufficiently to', 'sufficiently to reduce', 'suggested', 'suggested the', 'suggested the term', 'suggesting', 'suggesting a', 'suggesting a theory', 'suitable', 'suitable data', 'suitable data lack', 'suitable for', 'suitable for the', 'suites', 'suites containing', 'suites containing a', 'sum', 'sum of', 'sum of its', 'sun', 'sun microsystems', 'sun microsystems vinod', 'superintelligence', 'superintelligence and', 'superintelligence and existential', 'supermarket', 'supermarket would', 'supermarket would indicate', 'supermarkets', 'supermarkets for', 'supermarkets for example', 'supervised', 'supervised anomaly', 'supervised anomaly detection', 'supervised dictionary', 'supervised dictionary learning', 'supervised feature', 'supervised feature learning', 'supervised learning', 'supervised learning algorithms', 'supervised learning in', 'supervised learning methods', 'supervised learning reinforcement', 'supervised learning the', 'supervised learning with', 'supervised machine', 'supervised machine learning', 'supervised methods', 'supervised methods cannot', 'supervised methods while', 'supervised or', 'supervised or unsupervised', 'supervisedlearning', 'supervisedlearning algorithms', 'supervisedlearning algorithms include', 'supervisory', 'supervisory signal', 'supervisory signal from', 'supervisory signal in', 'support', 'support tasks', 'support tasks such', 'supportvector', 'supportvector machines', 'supportvector machines svms', 'supportvector networks', 'supportvector networks are', 'surpass', 'surpass many', 'surpass many previous', 'surpass those', 'surpass those obtained', 'surrogate', 'surrogate models', 'surrogate models in', 'suspicions', 'suspicions by', 'suspicions by differing', 'svm', 'svm in', 'svm in a', 'svm training', 'svm training algorithm', 'svms', 'svms also', 'svms also known', 'svms can', 'svms can efficiently', 'swami', 'swami introduced', 'swami introduced association', 'swarm', 'swarm intelligence', 'swarm intelligence statistics', 'symbol', 'symbol that', 'symbol that compresses', 'symbolic', 'symbolic approaches', 'symbolic approaches it', 'symbolic methods', 'symbolic methods as', 'symbolicknowledgebased', 'symbolicknowledgebased learning', 'symbolicknowledgebased learning did', 'symbols', 'symbols from', 'symbols from a', 'symptoms', 'symptoms given', 'symptoms given symptoms', 'symptoms the', 'symptoms the network', 'synapses', 'synapses in', 'synapses in a', 'synapses the', 'synapses the term', 'synonym', 'synonym selfteaching', 'synonym selfteaching computers', 'system', 'system duplicating', 'system duplicating the', 'system failed', 'system failed to', 'system for', 'system for example', 'system in', 'system in a', 'system is', 'system is considered', 'system is driven', 'system misclassifies', 'system that', 'system that could', 'system that predicts', 'system this', 'system this is', 'system trained', 'system trained specifically', 'system will', 'system will derive', 'system with', 'system with only', 'systematic', 'systematic review', 'systematic review and', 'systems', 'systems and', 'systems and dismantling', 'systems and other', 'systems are', 'systems are computing', 'systems arms', 'systems arms race', 'systems association', 'systems association rule', 'systems attempt', 'systems attempt to', 'systems can', 'systems can be', 'systems contributed', 'systems contributed to', 'systems designed', 'systems designed to', 'systems had', 'systems had come', 'systems if', 'systems if they', 'systems in', 'systems in supermarkets', 'systems it', 'systems it is', 'systems lcs', 'systems lcs are', 'systems learn', 'systems learn to', 'systems may', 'systems may be', 'systems might', 'systems might not', 'systems or', 'systems or from', 'systems picking', 'systems picking the', 'systems swarm', 'systems swarm intelligence', 'systems that', 'systems that are', 'systems vaguely', 'systems vaguely inspired', 'systems visual', 'systems visual identity', 'systems were', 'systems were plagued', 'systems with', 'systems with limited', 't', 't and', 't and performance', 't as', 't as measured', 'tackling', 'tackling solvable', 'tackling solvable problems', 'tagged', 'tagged a', 'tagged a couple', 'tailor', 'tailor experimental', 'tailor experimental conditions', 'take', 'take a', 'take a discrete', 'take actions', 'take actions in', 'take any', 'take any numerical', 'take continuous', 'take continuous values', 'take longer', 'take longer to', 'taking', 'taking advantage', 'taking advantage of', 'tape', 'tape memory', 'tape memory called', 'target', 'target and', 'target and collect', 'target value', 'target value represented', 'target variable', 'target variable can', 'task', 'task is', 'task is called', 'task is the', 'task supervised', 'task supervised methods', 'task this', 'task this makes', 'tasks', 'tasks and', 'tasks and algorithms', 'tasks by', 'tasks by considering', 'tasks in', 'tasks in t', 'tasks in which', 'tasks including', 'tasks including computer', 'tasks leading', 'tasks leading to', 'tasks such', 'tasks such as', 'tasks t', 'tasks t and', 'tasks without', 'tasks without explicit', 'taskspecific', 'taskspecific rules', 'tay', 'tay a', 'tay a chatbot', 'teaching', 'teaching strategies', 'teaching strategies so', 'team', 'team made', 'team made up', 'teams', 'teams big', 'teams big chaos', 'technique', 'technique allows', 'technique allows reconstruction', 'technique simplifies', 'technique simplifies handling', 'technique that', 'technique that mimics', 'techniques', 'techniques can', 'techniques can be', 'techniques construct', 'techniques construct a', 'techniques derived', 'techniques derived from', 'techniques detect', 'techniques detect anomalies', 'techniques exist', 'techniques exist unsupervised', 'techniques have', 'techniques have been', 'techniques include', 'techniques include pruning', 'techniques includes', 'techniques includes learning', 'techniques like', 'techniques like ols', 'techniques like the', 'techniques make', 'techniques make different', 'techniques make this', 'techniques reinforcement', 'techniques reinforcement learning', 'techniques require', 'techniques require a', 'techniques such', 'techniques such as', 'technological', 'technological unemployment', 'technological unemployment aienabled', 'technologies', 'technologies as', 'technologies as well', 'technology', 'technology was', 'technology was also', 'technology was used', 'temperatures', 'temperatures based', 'temperatures based on', 'tend', 'tend to', 'tend to have', 'tensor', 'tensor computations', 'tensor computations making', 'tensor processing', 'tensor processing units', 'tensor representations', 'tensor representations for', 'tensorflow', 'tensorflow matlabs', 'tensorflow matlabs image', 'term', 'term data', 'term data science', 'term for', 'term for any', 'term inductive', 'term inductive here', 'term machine', 'term machine learning', 'term model', 'term model can', 'term physical', 'term physical neural', 'termed', 'termed neural', 'termed neural networks', 'terminal', 'terms', 'terms of', 'terms of methods', 'terms of or', 'terms this', 'terms this follows', 'test', 'test data', 'test data set', 'test instance', 'test instance to', 'test set', 'test set conventionally', 'test set designation', 'test set in', 'test the', 'test the likelihood', 'tested', 'tested tay', 'tested tay a', 'tested to', 'tested to predict', 'tests', 'tests or', 'tests or medication', 'text', 'text a', 'text a collection', 'text anomalies', 'text anomalies are', 'than', 'than defining', 'than defining the', 'than mathematical', 'than mathematical induction', 'than one', 'than one is', 'than the', 'than the function', 'that', 'that a', 'that a certain', 'that a clean', 'that a human', 'that a machine', 'that adjusts', 'that adjusts as', 'that all', 'that all brown', 'that an', 'that an artificial', 'that an image', 'that an intelligent', 'that are', 'that are considered', 'that are implausible', 'that are implemented', 'that are not', 'that are often', 'that are trained', 'that automatically', 'that automatically discovers', 'that behave', 'that behave ethically', 'that builds', 'that builds multiple', 'that c', 'that c maps', 'that calculated', 'that calculated the', 'that can', 'that can be', 'that can learn', 'that can perform', 'that can represent', 'that certain', 'that certain classes', 'that collectively', 'that collectively represent', 'that collectively store', 'that combine', 'that combine a', 'that commonly', 'that commonly identify', 'that compresses', 'that compresses best', 'that considers', 'that considers any', 'that constitute', 'that constitute animal', 'that contain', 'that contain many', 'that contains', 'that contains both', 'that could', 'that could have', 'that decentralises', 'that decentralises the', 'that disentangles', 'that disentangles the', 'that distribution', 'that distribution this', 'that enables', 'that enables it', 'that entails', 'that entails all', 'that even', 'that even the', 'that explain', 'that explain the', 'that fail', 'that fail to', 'that far', 'that far surpass', 'that filters', 'that filters emails', 'that generates', 'that generates x', 'that has', 'that has been', 'that has not', 'that highdimensional', 'that highdimensional data', 'that humans', 'that humans are', 'that identifies', 'that identifies learns', 'that if', 'that if a', 'that improves', 'that improves the', 'that in', 'that in each', 'that inductively', 'that inductively inferred', 'that is', 'that is a', 'that is best', 'that is mathematically', 'that is reducing', 'that it', 'that it may', 'that lack', 'that lack predefined', 'that lead', 'that lead to', 'that learned', 'that learned from', 'that learns', 'that learns a', 'that machine', 'that machine learning', 'that makes', 'that makes it', 'that measures', 'that measures how', 'that mimics', 'that mimics the', 'that mirror', 'that mirror human', 'that model', 'that model a', 'that model sequences', 'that models', 'that models how', 'that observations', 'that observations within', 'that of', 'that of medical', 'that once', 'that once trained', 'that perform', 'that perform inference', 'that predicts', 'that predicts the', 'that predicts whether', 'that receives', 'that receives a', 'that relies', 'that relies on', 'that represents', 'that represents a', 'that resulted', 'that resulted in', 'that seem', 'that seem to', 'that st', 'that st georges', 'that standard', 'that standard machine', 'that still', 'that still correlate', 'that such', 'that such an', 'that task', 'that the', 'that the learned', 'that the machine', 'that the majority', 'that the mathematical', 'that the signal', 'that the system', 'that theres', 'that theres nothing', 'that these', 'that these systems', 'that they', 'that they call', 'that this', 'that this program', 'that threshold', 'that threshold typically', 'that unlabelled', 'that unlabelled data', 'that unlike', 'that unlike humans', 'that use', 'that use materials', 'that viewers', 'that viewers ratings', 'that were', 'that were later', 'that were not', 'the', 'the a', 'the a priori', 'the ability', 'the ability of', 'the ability to', 'the accompanying', 'the accompanying area', 'the accuracy', 'the accuracy of', 'the actual', 'the actual problem', 'the aggregate', 'the aggregate signal', 'the ai', 'the ai it', 'the aics', 'the aics field', 'the algorithm', 'the algorithm cannot', 'the algorithm or', 'the algorithm to', 'the algorithms', 'the algorithms could', 'the algorithms proprietary', 'the algorithms studied', 'the amount', 'the amount of', 'the analysis', 'the analysis step', 'the ann', 'the ann approach', 'the anomalous', 'the anomalous items', 'the application', 'the application of', 'the area', 'the area of', 'the assignment', 'the assignment of', 'the assumption', 'the assumption that', 'the backpropagated', 'the backpropagated value', 'the basic', 'the basic assumptions', 'the basis', 'the basis for', 'the behavioural', 'the behavioural environment', 'the best', 'the best indicators', 'the best model', 'the best performance', 'the best possible', 'the bias', 'the bias by', 'the biasvariance', 'the biasvariance decomposition', 'the biological', 'the biological neural', 'the black', 'the black box', 'the book', 'the book the', 'the branches', 'the branches to', 'the caa', 'the caa exists', 'the caa learns', 'the caa selflearning', 'the cancerous', 'the cancerous moles', 'the centroid', 'the centroid of', 'the class', 'the class that', 'the class to', 'the classification', 'the classification of', 'the coders', 'the coders of', 'the common', 'the common statistical', 'the complexity', 'the complexity of', 'the computational', 'the computational analysis', 'the computational complexity', 'the computing', 'the computing research', 'the concept', 'the concept of', 'the confusion', 'the confusion between', 'the connections', 'the connections between', 'the consequence', 'the consequence situation', 'the constitutional', 'the constitutional and', 'the constraint', 'the constraint that', 'the context', 'the context of', 'the core', 'the core information', 'the corresponding', 'the corresponding dictionary', 'the covariances', 'the covariances between', 'the data', 'the data and', 'the data but', 'the data data', 'the data if', 'the data in', 'the data into', 'the data itself', 'the data known', 'the data often', 'the data set', 'the data shape', 'the data the', 'the data this', 'the data typically', 'the dataset', 'the dataset can', 'the decisions', 'the decisions it', 'the decisions or', 'the defining', 'the defining characteristic', 'the desired', 'the desired output', 'the desired outputs', 'the development', 'the development and', 'the difference', 'the difference between', 'the dimension', 'the dimension of', 'the dimensionality', 'the dimensionality reduction', 'the discovery', 'the discovery of', 'the discrepancy', 'the discrepancy between', 'the distribution', 'the distribution of', 'the dominant', 'the dominant method', 'the earliest', 'the earliest machine', 'the early', 'the early days', 'the early mathematical', 'the early s', 'the effective', 'the effective use', 'the email', 'the email in', 'the emotion', 'the emotion toward', 'the environment', 'the environment is', 'the environment the', 'the ethics', 'the ethics of', 'the evidence', 'the evidence related', 'the fact', 'the fact that', 'the false', 'the false negative', 'the false positive', 'the feature', 'the feature set', 'the feature spaces', 'the features', 'the features and', 'the field', 'the field changed', 'the field in', 'the field is', 'the field of', 'the financial', 'the financial crisis', 'the findings', 'the findings research', 'the firm', 'the firm rebellion', 'the first', 'the first layer', 'the first netflix', 'the first research', 'the folder', 'the folder in', 'the following', 'the following machine', 'the foundations', 'the foundations of', 'the function', 'the function of', 'the function then', 'the function underlying', 'the future', 'the future is', 'the generalisation', 'the generalisation of', 'the generalised', 'the generalised linear', 'the genetic', 'the genetic environment', 'the genome', 'the genome species', 'the given', 'the given data', 'the goal', 'the goal is', 'the gorilla', 'the gorilla label', 'the grand', 'the grand prize', 'the group', 'the group of', 'the growth', 'the growth of', 'the hardware', 'the hardware compute', 'the history', 'the history of', 'the holdout', 'the holdout and', 'the holdout method', 'the hope', 'the hope of', 'the house', 'the house of', 'the human', 'the human brain', 'the hypothesis', 'the hypothesis is', 'the hypothesis should', 'the ibm', 'the ibm watson', 'the ideas', 'the ideas of', 'the identification', 'the identification and', 'the identification of', 'the information', 'the information in', 'the inherently', 'the inherently unbalanced', 'the initial', 'the initial theoretical', 'the input', 'the input is', 'the input layer', 'the inputs', 'the inputs and', 'the inputs coming', 'the inputs provided', 'the instances', 'the instances in', 'the interaction', 'the interaction between', 'the interesting', 'the interesting objects', 'the items', 'the items target', 'the kernel', 'the kernel trick', 'the key', 'the key difference', 'the key idea', 'the key task', 'the kfoldcrossvalidation', 'the kfoldcrossvalidation method', 'the knowledge', 'the knowledge captured', 'the known', 'the known background', 'the ksvd', 'the ksvd algorithm', 'the largest', 'the largest deep', 'the last', 'the last layer', 'the latter', 'the latter is', 'the layers', 'the layers multiple', 'the learned', 'the learned representation', 'the learner', 'the learner has', 'the learners', 'the learners decision', 'the learning', 'the learning system', 'the least', 'the least to', 'the leaves', 'the leaves it', 'the likelihood', 'the likelihood of', 'the logical', 'the logical knowledgebased', 'the machine', 'the machine extracted', 'the machine learning', 'the majority', 'the majority of', 'the mathematical', 'the mathematical model', 'the mdp', 'the mdp and', 'the mediaservices', 'the mediaservices provider', 'the mental', 'the mental models', 'the method', 'the method is', 'the microclusters', 'the microclusters formed', 'the mids', 'the mids with', 'the model', 'the model being', 'the model by', 'the model has', 'the model in', 'the model is', 'the model the', 'the models', 'the models internal', 'the modern', 'the modern machine', 'the more', 'the more accurate', 'the more statistical', 'the more variables', 'the nature', 'the nature of', 'the necessary', 'the necessary sensitivity', 'the need', 'the need to', 'the needs', 'the needs of', 'the negative', 'the negative impacts', 'the network', 'the network can', 'the neurons', 'the neurons in', 'the new', 'the new unobserved', 'the next', 'the next two', 'the noise', 'the noise cannot', 'the number', 'the number of', 'the observed', 'the observed data', 'the observed points', 'the order', 'the order of', 'the organization', 'the organization of', 'the original', 'the original data', 'the original goal', 'the other', 'the other hand', 'the other is', 'the other purpose', 'the output', 'the output associated', 'the output by', 'the output distribution', 'the output for', 'the output is', 'the output layer', 'the output of', 'the outputs', 'the outputs are', 'the outputs can', 'the overall', 'the overall field', 'the past', 'the past training', 'the pattern', 'the pattern that', 'the performance', 'the performance are', 'the performance of', 'the phone', 'the phone when', 'the picture', 'the picture and', 'the popular', 'the popular methods', 'the posterior', 'the posterior probabilities', 'the preassigned', 'the preassigned labels', 'the prediction', 'the prediction of', 'the predictions', 'the predictions of', 'the predictive', 'the predictive modelling', 'the presence', 'the presence of', 'the presence or', 'the previous', 'the previous history', 'the prize', 'the prize was', 'the probabilistic', 'the probabilistic relationships', 'the probabilities', 'the probabilities of', 'the probably', 'the probably approximately', 'the problem', 'the problem is', 'the problem learning', 'the problem with', 'the process', 'the process has', 'the process of', 'the proenvironmental', 'the proenvironmental behaviour', 'the publics', 'the publics interest', 'the quest', 'the quest for', 'the question', 'the question can', 'the random', 'the random variables', 'the recidivism', 'the recidivism rates', 'the reinvention', 'the reinvention of', 'the relationship', 'the relationship between', 'the relationships', 'the relationships between', 'the remainder', 'the remainder of', 'the remaining', 'the remaining k', 'the required', 'the required storage', 'the resulting', 'the resulting classification', 'the risk', 'the risk of', 'the roc', 'the roc curve', 'the rule', 'the rule onionspotatoesburgerdisplaystyle', 'the s', 'the s advances', 'the s and', 'the s as', 'the s the', 'the s was', 'the s when', 'the sales', 'the sales data', 'the same', 'the same cluster', 'the same machine', 'the same methods', 'the same time', 'the same way', 'the signal', 'the signal at', 'the signal is', 'the signal or', 'the similarity', 'the similarity between', 'the size', 'the size of', 'the smallest', 'the smallest possible', 'the social', 'the social right', 'the space', 'the space of', 'the spatial', 'the spatial relationship', 'the strength', 'the strength of', 'the structure', 'the structure and', 'the structure of', 'the study', 'the study data', 'the sum', 'the sum of', 'the supervisory', 'the supervisory signal', 'the symbol', 'the symbol that', 'the symbolic', 'the symbolic approaches', 'the synapses', 'the synapses in', 'the synonym', 'the synonym selfteaching', 'the system', 'the system is', 'the system misclassifies', 'the system this', 'the target', 'the target variable', 'the tasks', 'the tasks in', 'the teams', 'the teams big', 'the term', 'the term data', 'the term inductive', 'the term machine', 'the term model', 'the term physical', 'the test', 'the test set', 'the theory', 'the theory in', 'the theory is', 'the theory of', 'the time', 'the time complexity', 'the trader', 'the trader of', 'the training', 'the training data', 'the training error', 'the training examples', 'the training labels', 'the training model', 'the training process', 'the training set', 'the uks', 'the uks commission', 'the ultimate', 'the ultimate model', 'the unavailability', 'the unavailability of', 'the underlying', 'the underlying factors', 'the united', 'the united states', 'the unknown', 'the unknown datagenerating', 'the unobserved', 'the unobserved output', 'the unzipping', 'the unzipping software', 'the use', 'the use of', 'the users', 'the users interaction', 'the vector', 'the vector norm', 'the wall', 'the wall street', 'the way', 'the way the', 'the weight', 'the weight increases', 'the weight space', 'the winning', 'the winning chance', 'the workload', 'the workload burden', 'the world', 'the world furthermore', 'the wrong', 'the wrong lesson', 'the zip', 'the zip file', 'theft', 'theft of', 'theft of intellectual', 'their', 'their associated', 'their associated features', 'their associated learning', 'their centroids', 'their centroids thereby', 'their conditional', 'their conditional independence', 'their data', 'their data to', 'their first', 'their first implementation', 'their input', 'their input but', 'their inputs', 'their inputs into', 'their inputs signals', 'their introduction', 'their introduction in', 'their locations', 'their main', 'their main success', 'their misconceptions', 'their misconceptions xai', 'their numerators', 'their numerators and', 'their performance', 'their performance is', 'their predictions', 'their predictions to', 'their principal', 'their principal goal', 'their recommendation', 'their recommendation engine', 'their use', 'their use of', 'their viewing', 'their viewing patterns', 'them', 'them into', 'them into higherdimensional', 'them particularly', 'them particularly efficient', 'them to', 'them to perform', 'themselves', 'then', 'then k', 'then k experiments', 'then signal', 'then signal additional', 'then termed', 'then termed neural', 'then test', 'then test the', 'then the', 'then the model', 'then the training', 'theoretical', 'theoretical and', 'theoretical and practical', 'theoretical computer', 'theoretical computer science', 'theoretical foundation', 'theoretical foundation for', 'theoretical frameworks', 'theoretical frameworks can', 'theoretical neural', 'theoretical neural structure', 'theoretical tools', 'theoretical tools have', 'theoretical viewpoint', 'theoretical viewpoint probably', 'theoretically', 'theoretically relevant', 'theoretically relevant variables', 'theories', 'theories these', 'theories these theoretical', 'theorists', 'theorists study', 'theorists study the', 'theory', 'theory a', 'theory a computation', 'theory a connection', 'theory built', 'theory built an', 'theory control', 'theory control theory', 'theory gerrymandered', 'theory gerrymandered to', 'theory in', 'theory in accordance', 'theory is', 'theory is a', 'theory of', 'theory of belief', 'theory operations', 'theory operations research', 'theory or', 'theory or dempstershafer', 'theory poses', 'theory poses another', 'theory simulationbased', 'theory simulationbased optimisation', 'theory to', 'theory to explain', 'theory usually', 'theory usually does', 'theory via', 'theory via the', 'there', 'there are', 'there are concerns', 'there are many', 'there are two', 'there is', 'there is a', 'there is neither', 'there is potential', 'there may', 'there may be', 'thereby', 'thereby furthering', 'thereby furthering the', 'thereby offering', 'thereby offering new', 'thereby preserving', 'thereby preserving the', 'thereby reducing', 'thereby reducing the', 'theres', 'theres nothing', 'theres nothing artificial', 'thermal', 'thermal behaviour', 'thermal behaviour based', 'these', 'these algorithms', 'these algorithms are', 'these belief', 'these belief function', 'these beliefs', 'these beliefs functions', 'these biases', 'these biases in', 'these biases to', 'these biases upon', 'these devices', 'these devices eliminates', 'these feature', 'these feature spaces', 'these labels', 'these labels are', 'these methods', 'these methods extract', 'these models', 'these models a', 'these patterns', 'these patterns on', 'these rates', 'these rates are', 'these systems', 'these systems may', 'these systems might', 'these theoretical', 'these theoretical frameworks', 'these tree', 'these tree structures', 'these two', 'these two research', 'these were', 'these were mostly', 'they', 'they are', 'they are likely', 'they are widely', 'they attempted', 'they attempted to', 'they call', 'they call statistical', 'they changed', 'they changed their', 'they have', 'they have a', 'they learn', 'they learn relationships', 'they seek', 'they seek to', 'they work', 'they work with', 'think', 'think is', 'think is replaced', 'thinking', 'thinking entities', 'thinking entities can', 'third', 'third parties', 'third parties parties', 'this', 'this also', 'this also increases', 'this approach', 'this approach estimates', 'this approach tries', 'this are', 'this are numerous', 'this assumption', 'this assumption leading', 'this context', 'this context is', 'this definition', 'this definition of', 'this equivalence', 'this equivalence has', 'this field', 'this field where', 'this follows', 'this follows alan', 'this includes', 'this includes algorithmic', 'this is', 'this is especially', 'this is in', 'this is the', 'this line', 'this line too', 'this makes', 'this makes rfr', 'this pattern', 'this pattern does', 'this process', 'this process condenses', 'this program', 'this program had', 'this random', 'this random selection', 'this replaces', 'this replaces manual', 'this requires', 'this requires these', 'this space', 'this space that', 'this technique', 'this technique allows', 'this technique simplifies', 'this threefold', 'this threefold categorisation', 'this time', 'this time period', 'those', 'those class', 'those class labels', 'those obtained', 'those obtained from', 'those points', 'those points and', 'thought', 'thought of', 'thought of as', 'thought processes', 'three', 'three broad', 'three broad categories', 'three representative', 'three representative lossless', 'threefold', 'threefold categorisation', 'threefold categorisation and', 'threshold', 'threshold such', 'threshold such that', 'threshold typically', 'threshold typically artificial', 'through', 'through examination', 'through examination without', 'through iterative', 'through iterative optimisation', 'through softwarebased', 'through softwarebased simulations', 'through specialised', 'through specialised hardware', 'through various', 'through various techniques', 'thus', 'thus digitising', 'thus digitising cultural', 'thus finding', 'thus finding applications', 'thus perform', 'thus perform tasks', 'ties', 'ties to', 'ties to optimisation', 'time', 'time and', 'time and billions', 'time attention', 'time attention moved', 'time complexity', 'time complexity and', 'time complexity results', 'time is', 'time is said', 'time negative', 'time negative results', 'time period', 'time there', 'time there are', 'time this', 'time this line', 'time when', 'time when compared', 'times', 'tnr', 'tnr respectively', 'tnr respectively similarly', 'to', 'to a', 'to a centralised', 'to a class', 'to a combined', 'to a fully', 'to a given', 'to a limited', 'to a machine', 'to a mathematical', 'to a much', 'to a situation', 'to a smaller', 'to a systematic', 'to accelerate', 'to accelerate computations', 'to aixi', 'to aixi theory', 'to algorithmically', 'to algorithmically define', 'to alphazero', 'to alphazero and', 'to also', 'to also buy', 'to analyse', 'to analyse sonar', 'to analyse the', 'to another', 'to another an', 'to any', 'to any instance', 'to approach', 'to approach the', 'to artificial', 'to artificial neural', 'to as', 'to as evidence', 'to as outliers', 'to assess', 'to assess model', 'to assign', 'to assign a', 'to automated', 'to automated machine', 'to avoid', 'to avoid overfitting', 'to bayesian', 'to bayesian approaches', 'to be', 'to be a', 'to be adopted', 'to be encountered', 'to be generated', 'to be horses', 'to be maintained', 'to be mitigated', 'to be reinventions', 'to be used', 'to best', 'to best fit', 'to better', 'to better handle', 'to better predict', 'to biases', 'to biases in', 'to both', 'to both learn', 'to build', 'to build a', 'to build decision', 'to business', 'to business problems', 'to but', 'to but that', 'to call', 'to call the', 'to cause', 'to cause it', 'to change', 'to change the', 'to classify', 'to classify data', 'to classify the', 'to classifying', 'to classifying data', 'to come', 'to come up', 'to communicate', 'to communicate data', 'to compress', 'to compress data', 'to compute', 'to compute the', 'to conclusions', 'to conclusions about', 'to configurations', 'to configurations that', 'to contain', 'to contain humanlike', 'to correctly', 'to correctly determine', 'to correctly predict', 'to decades', 'to decades of', 'to deliver', 'to deliver even', 'to deliver expected', 'to detect', 'to detect a', 'to detect the', 'to determine', 'to determine the', 'to deviations', 'to deviations from', 'to diagnose', 'to diagnose medicate', 'to discover', 'to discover such', 'to do', 'to do hyperparameter', 'to do so', 'to dominate', 'to dominate ai', 'to each', 'to each other', 'to either', 'to either be', 'to emulate', 'to emulate the', 'to enhance', 'to enhance it', 'to estimate', 'to estimate the', 'to evacuate', 'to evacuate during', 'to examine', 'to examine three', 'to explain', 'to explain observed', 'to explanation', 'to feedback', 'to feedback unsupervised', 'to file', 'to file the', 'to find', 'to find a', 'to fit', 'to fit all', 'to fit the', 'to flourish', 'to flourish in', 'to generalise', 'to generalise from', 'to generate', 'to generate new', 'to go', 'to go from', 'to google', 'to handle', 'to handle multiple', 'to have', 'to have difficulty', 'to have learned', 'to have particular', 'to help', 'to help make', 'to help users', 'to higherdimensional', 'to higherdimensional space', 'to identify', 'to identify a', 'to identify strong', 'to implicitly', 'to implicitly map', 'to improve', 'to improve accuracy', 'to improve learner', 'to improve the', 'to incorporate', 'to incorporate ignorance', 'to inductive', 'to inductive logic', 'to instances', 'to instances and', 'to investigate', 'to investigate and', 'to it', 'to it in', 'to its', 'to its generality', 'to known', 'to known knowledge', 'to largescale', 'to largescale problems', 'to learn', 'to learn from', 'to learn lowdimensional', 'to learning', 'to learning paradigms', 'to make', 'to make a', 'to make machines', 'to make predictions', 'to manipulation', 'to manipulation or', 'to many', 'to many devices', 'to market', 'to market basket', 'to maximise', 'to maximise some', 'to michael', 'to michael i', 'to minimise', 'to minimise errors', 'to mitigate', 'to mitigate overfitting', 'to model', 'to model the', 'to more', 'to more efficient', 'to obtain', 'to obtain resulting', 'to one', 'to one of', 'to one or', 'to optimisation', 'to optimisation many', 'to optimise', 'to optimise smartphones', 'to other', 'to other frameworks', 'to other machine', 'to overall', 'to overall accuracy', 'to overfitting', 'to overfitting and', 'to partition', 'to partition a', 'to pattern', 'to pattern recognition', 'to perform', 'to perform a', 'to perform accurate', 'to perform accurately', 'to perform tasks', 'to perform that', 'to performance', 'to performance bounds', 'to performing', 'to performing linear', 'to performing specific', 'to philosophical', 'to philosophical induction', 'to pick', 'to pick up', 'to play', 'to play a', 'to predict', 'to predict if', 'to predict stock', 'to predict the', 'to preserve', 'to preserve the', 'to previous', 'to previous successful', 'to process', 'to process however', 'to produce', 'to produce hostile', 'to produce sufficiently', 'to provide', 'to provide patients', 'to provide professionals', 'to quantify', 'to quantify generalisation', 'to recognise', 'to recognise characters', 'to recognise patterns', 'to reduce', 'to reduce bias', 'to reduce overfitting', 'to reduce the', 'to reevaluate', 'to reevaluate incorrect', 'to regression', 'to regression and', 'to replicate', 'to replicate neural', 'to reproduce', 'to reproduce known', 'to research', 'to research carried', 'to reveal', 'to reveal their', 'to rule', 'to rule learning', 'to send', 'to send individual', 'to send their', 'to several', 'to several levels', 'to softwarebased', 'to softwarebased implementations', 'to solve', 'to solve approximately', 'to solve problems', 'to some', 'to some class', 'to store', 'to store manipulate', 'to study', 'to study fine', 'to study human', 'to support', 'to support tasks', 'to surpass', 'to surpass many', 'to tackling', 'to tackling solvable', 'to tailor', 'to tailor experimental', 'to take', 'to take actions', 'to target', 'to target and', 'to the', 'to the ability', 'to the area', 'to the common', 'to the data', 'to the growth', 'to the holdout', 'to the last', 'to the learning', 'to the modern', 'to the problem', 'to the remainder', 'to the unavailability', 'to the vector', 'to theoretical', 'to theoretical tools', 'to these', 'to these beliefs', 'to those', 'to those class', 'to train', 'to train it', 'to train search', 'to train the', 'to training', 'to training machine', 'to transfer', 'to transfer and', 'to treat', 'to treat certain', 'to understand', 'to understand and', 'to unseen', 'to unseen data', 'to update', 'to update the', 'to use', 'to use machine', 'to use svm', 'to visually', 'to visually and', 'to watch', 'to watch out', 'to which', 'to which a', 'to win', 'to win the', 'today', 'today in', 'today in application', 'together', 'together they', 'together they are', 'tom', 'tom m', 'tom m mitchell', 'tomasz', 'tomasz imieliÅ„ski', 'tomasz imieliÅ„ski and', 'too', 'too complex', 'too complex then', 'too was', 'too was continued', 'tool', 'tool in', 'tool in geotechnical', 'tool to', 'tool to diagnose', 'tool to investigate', 'tool we', 'tool we are', 'toolbox', 'toolbox ipt', 'toolbox ipt and', 'tools', 'tools and', 'tools and people', 'tools for', 'tools for chemists', 'tools for classification', 'tools have', 'tools have had', 'topic', 'topic modelling', 'topic modelling metalearning', 'topic of', 'topic of current', 'topics', 'topics within', 'topics within ai', 'toward', 'toward datacentric', 'toward datacentric methods', 'toward methods', 'toward methods and', 'toward the', 'toward the consequence', 'toy', 'toy example', 'toy example is', 'tpr', 'tpr and', 'tpr and true', 'tpus', 'tpus are', 'tpus are optimised', 'tpus are specialised', 'tpus have', 'tpus have become', 'tpus leverage', 'tpus leverage matrix', 'tracking', 'tracking face', 'tracking face verification', 'trader', 'trader of', 'trader of future', 'trading', 'trading may', 'trading may inform', 'traditionally', 'traditionally divided', 'traditionally divided into', 'train', 'train it', 'train it to', 'train search', 'train search query', 'train the', 'train the model', 'trained', 'trained and', 'trained and the', 'trained by', 'trained by a', 'trained by third', 'trained from', 'trained from data', 'trained model', 'trained model with', 'trained models', 'trained models derived', 'trained on', 'trained on a', 'trained on datasets', 'trained on humanmade', 'trained on language', 'trained on random', 'trained only', 'trained only on', 'trained specifically', 'trained specifically on', 'trained to', 'trained to correctly', 'trained with', 'trained with historical', 'training', 'training a', 'training a classifier', 'training a learning', 'training a machine', 'training a model', 'training algorithm', 'training algorithm builds', 'training algorithm is', 'training and', 'training and inference', 'training and test', 'training classic', 'training classic examples', 'training data', 'training data an', 'training data and', 'training data consists', 'training data data', 'training data is', 'training data set', 'training data some', 'training data when', 'training deep', 'training deep neural', 'training enables', 'training enables model', 'training error', 'training error decreases', 'training example', 'training example belongs', 'training example has', 'training example is', 'training examples', 'training examples are', 'training examples come', 'training examples each', 'training labels', 'training labels are', 'training labels yet', 'training largescale', 'training largescale commercial', 'training machine', 'training machine learning', 'training model', 'training model on', 'training process', 'training process allowing', 'training process to', 'training set', 'training set and', 'training set can', 'training set of', 'training set this', 'training sets', 'training sets are', 'training sets it', 'training the', 'training the model', 'transaction', 'transaction data', 'transaction data recorded', 'transaction or', 'transaction or across', 'transactions', 'transfer', 'transfer and', 'transfer and store', 'transform', 'transform it', 'transform it in', 'transformations', 'transformations on', 'transformations on their', 'transformative', 'transformative in', 'transformative in some', 'translation', 'translation social', 'translation social network', 'transmission', 'transmission kmeans', 'transmission kmeans clustering', 'transmit', 'transmit information', 'transmit information a', 'transparency', 'transparency is', 'transparency is provided', 'travel', 'travel from', 'travel from the', 'travellers', 'travellers recently', 'travellers recently machine', 'traversing', 'traversing the', 'traversing the layers', 'treat', 'treat certain', 'treat certain ai', 'tree', 'tree as', 'tree as a', 'tree can', 'tree can be', 'tree describes', 'tree describes data', 'tree is', 'tree is trained', 'tree learning', 'tree learning uses', 'tree models', 'tree models where', 'tree structures', 'tree structures leaves', 'treebased', 'treebased models', 'treebased models rfr', 'trees', 'trees and', 'trees and averages', 'trees and it', 'trees in', 'trees in decision', 'trees in these', 'trees rfr', 'trees rfr uses', 'trees where', 'trees where the', 'trendline', 'trendline fitting', 'trendline fitting in', 'trendline of', 'trendline of months', 'trick', 'trick implicitly', 'trick implicitly mapping', 'trick to', 'trick to implicitly', 'tries', 'tries to', 'tries to model', 'true', 'true in', 'true in the', 'true negative', 'true negative rate', 'true positive', 'true positive rate', 'tuned', 'turings', 'turings proposal', 'turings proposal in', 'twice', 'twice as', 'twice as often', 'twitter', 'twitter and', 'twitter and it', 'two', 'two categories', 'two categories an', 'two decades', 'two decades to', 'two environments', 'two environments one', 'two kinds', 'two kinds of', 'two objectives', 'two objectives one', 'two objects', 'two objects are', 'two research', 'two research communities', 'two statistical', 'two statistical modelling', 'type', 'type of', 'type of datasoftware', 'type of mathematical', 'type of neuromorphic', 'type of unsupervised', 'types', 'types of', 'types of models', 'types of real', 'types of supervisedlearning', 'typical', 'typical kdd', 'typical kdd task', 'typically', 'typically a', 'typically a genetic', 'typically artificial', 'typically artificial neurons', 'typically does', 'typically does not', 'typically have', 'typically have a', 'typically leverage', 'typically leverage a', 'typically machine', 'typically machine learning', 'typically real', 'typically real numbers', 'typically represented', 'typically represented as', 'typically the', 'typically the anomalous', 'uber', 'uber failed', 'uber failed to', 'uks', 'uks commission', 'uks commission for', 'ultimate', 'ultimate model', 'ultimate model will', 'umbrella', 'umbrella of', 'umbrella of decision', 'unavailability', 'unavailability of', 'unavailability of training', 'unbalanced', 'unbalanced nature', 'unbalanced nature of', 'uncertain', 'uncertain learning', 'uncertain learning theory', 'uncertainty', 'uncertainty are', 'uncertainty are called', 'uncertainty quantification', 'uncertainty quantification these', 'uncertainty with', 'uncertainty with understood', 'unconscious', 'unconscious biases', 'unconscious biases already', 'under', 'under consideration', 'under consideration by', 'under fitted', 'under fitted the', 'under nodes', 'under nodes or', 'under that', 'under that distribution', 'under the', 'under the assumption', 'under the constraint', 'under the roc', 'under umbrella', 'under umbrella of', 'under uncertainty', 'under uncertainty are', 'underlying', 'underlying all', 'underlying all compression', 'underlying factors', 'underlying factors of', 'underlying patterns', 'underlying patterns such', 'underlying patterns the', 'underlying the', 'underlying the data', 'understand', 'understand and', 'understand and that', 'understand the', 'understand the decisions', 'understood', 'understood connections', 'understood connections to', 'undesirable', 'undesirable situations', 'undesired', 'undesired predictions', 'undesired predictions biased', 'undetectably', 'undetectably into', 'undetectably into classifying', 'unemployment', 'unemployment aienabled', 'unemployment aienabled misinformation', 'unexpected', 'unexpected bursts', 'unexpected bursts of', 'uniform', 'uniform representation', 'uniform representation for', 'uninformed', 'uninformed unsupervised', 'uninformed unsupervised method', 'united', 'united states', 'united states where', 'units', 'units and', 'units and highbandwidth', 'units by', 'units by graphics', 'units gpus', 'units gpus often', 'units or', 'units or nodes', 'units tpus', 'units tpus are', 'universally', 'universally applied', 'universally applied to', 'universities', 'universities around', 'universities around the', 'unknown', 'unknown datagenerating', 'unknown datagenerating distribution', 'unknown knowledge', 'unknown knowledge evaluated', 'unknown probability', 'unknown probability distribution', 'unknown properties', 'unknown properties in', 'unlabelled', 'unlabelled data', 'unlabelled data when', 'unlabelled input', 'unlabelled input data', 'unlabelled test', 'unlabelled test data', 'unless', 'unless aggregated', 'unless aggregated appropriately', 'unless it', 'unless it provided', 'unlike', 'unlike generalpurpose', 'unlike generalpurpose gpus', 'unlike humans', 'unlike humans current', 'unnecessary', 'unnecessary tests', 'unnecessary tests or', 'unobserved', 'unobserved output', 'unobserved output of', 'unobserved point', 'unrecognised', 'unrecognised influences', 'unrecognised influences among', 'unseen', 'unseen data', 'unseen data and', 'unseen examplestasks', 'unseen examplestasks after', 'unseen training', 'unseen training example', 'unsupervised', 'unsupervised algorithms', 'unsupervised algorithms will', 'unsupervised anomaly', 'unsupervised anomaly detection', 'unsupervised feature', 'unsupervised feature learning', 'unsupervised in', 'unsupervised in supervised', 'unsupervised learning', 'unsupervised learning algorithms', 'unsupervised learning called', 'unsupervised learning or', 'unsupervised learning they', 'unsupervised learning without', 'unsupervised machine', 'unsupervised machine learning', 'unsupervised method', 'unsupervised method will', 'unzip', 'unzip it', 'unzip it without', 'unzipping', 'unzipping software', 'unzipping software since', 'up', 'up data', 'up data transmission', 'up of', 'up of all', 'up of researchers', 'up racist', 'up racist and', 'up the', 'up the constitutional', 'up with', 'up with algorithms', 'update', 'update the', 'update the evidence', 'updates', 'updates a', 'updates a memory', 'upon', 'upon use', 'upon use algorithmic', 'us', 'us resident', 'us resident ai', 'usage', 'usage mining', 'usage mining intrusion', 'use', 'use algorithmic', 'use algorithmic bias', 'use computer', 'use computer vision', 'use dynamic', 'use dynamic programming', 'use for', 'use for human', 'use in', 'use in fields', 'use machine', 'use machine learning', 'use materials', 'use materials with', 'use of', 'use of machine', 'use of physical', 'use svm', 'use svm in', 'use them', 'use them to', 'used', 'used and', 'used and researched', 'used as', 'used as a', 'used as state', 'used as the', 'used by', 'used by a', 'used by computers', 'used by the', 'used due', 'used due to', 'used for', 'used for classification', 'used for optimal', 'used for prediction', 'used for tasks', 'used for trendline', 'used in', 'used in autonomous', 'used in conjunction', 'used in google', 'used in statistical', 'used in statistics', 'used in the', 'used in this', 'used in various', 'used on', 'used on a', 'used to', 'used to assess', 'used to compute', 'used to do', 'used to help', 'used to improve', 'used to make', 'used to predict', 'used to support', 'used to train', 'used to visually', 'used when', 'used when exact', 'used when the', 'useful', 'useful for', 'useful for decisionmaking', 'useful in', 'useful in bioinformatics', 'useful in scenarios', 'useful often', 'useful often as', 'useful tool', 'useful tool to', 'user', 'user preferences', 'user preferences and', 'users', 'users interaction', 'users interaction with', 'users mobile', 'users mobile phones', 'users of', 'users of a', 'users of aipowered', 'users perform', 'users perform more', 'users privacy', 'users privacy to', 'uses', 'uses a', 'uses a decision', 'uses bootstrapped', 'uses bootstrapped sampling', 'uses federated', 'uses federated machine', 'uses many', 'uses many machine', 'using', 'using a', 'using a computer', 'using a similarity', 'using arithmetic', 'using arithmetic coding', 'using data', 'using data compression', 'using job', 'using job hiring', 'using labelled', 'using labelled input', 'using logic', 'using logic programming', 'using machine', 'using machine learning', 'using methods', 'using methods such', 'using rudimentary', 'using rudimentary reinforcement', 'using sitespecific', 'using sitespecific data', 'using some', 'using some measure', 'using teaching', 'using teaching strategies', 'using what', 'using what is', 'usually', 'usually does', 'usually does not', 'usually evaluated', 'usually evaluated with', 'utilisation', 'utilisation of', 'utilisation of a', 'utilise', 'utilise a', 'utilise a wide', 'utilized', 'utilized to', 'utilized to compress', 'vaguely', 'vaguely inspired', 'vaguely inspired by', 'validated', 'validated by', 'validated by accuracy', 'value', 'value represented', 'value represented in', 'value secondary', 'value secondary reinforcement', 'value within', 'value within a', 'values', 'values are', 'values are called', 'values typically', 'values typically real', 'values while', 'values while regression', 'variable', 'variable can', 'variable can take', 'variables', 'variables and', 'variables and several', 'variables and their', 'variables based', 'variables based on', 'variables by', 'variables by fitting', 'variables in', 'variables in large', 'variables in other', 'variables in the', 'variables input', 'variables input used', 'variables like', 'variables like speech', 'variables simultaneously', 'variables simultaneously this', 'variables to', 'variables to higherdimensional', 'variables under', 'variables under consideration', 'variation', 'variation that', 'variation that explain', 'varied', 'varied as', 'varied as a', 'variety', 'variety of', 'variety of machine', 'variety of statistical', 'variety of tasks', 'various', 'various application', 'various diseases', 'various diseases efficient', 'various emerging', 'various emerging or', 'various ensemble', 'various ensemble methods', 'various forms', 'various forms of', 'various learning', 'various learning algorithms', 'various symbolic', 'various symbolic methods', 'various techniques', 'various techniques such', 'various types', 'various types of', 'vector', 'vector and', 'vector and the', 'vector from', 'vector from the', 'vector norm', 'vector norm x', 'vector sometimes', 'vector sometimes called', 'vector space', 'vector space â„µ', 'vectors', 'vectors and', 'vectors and compressionbased', 'vectors chooses', 'vectors chooses to', 'vectors deep', 'vectors deep learning', 'vehicles', 'vehicles or', 'vehicles or in', 'verification', 'verification and', 'verification and speaker', 'via', 'via adversarial', 'via adversarial machine', 'via the', 'via the probably', 'via unsupervised', 'via unsupervised learning', 'video', 'video and', 'video and sensory', 'video games', 'video games and', 'view', 'view can', 'view can show', 'viewers', 'viewers ratings', 'viewers ratings were', 'viewing', 'viewing patterns', 'viewing patterns everything', 'viewpoint', 'viewpoint probably', 'viewpoint probably approximately', 'vinod', 'vinod khosla', 'vinod khosla predicted', 'vision', 'vision and', 'vision and hearing', 'vision and speech', 'vision of', 'vision of moles', 'vision speech', 'vision speech recognition', 'visual', 'visual identity', 'visual identity tracking', 'visually', 'visually and', 'visually and explicitly', 'vulnerabilities', 'vulnerabilities can', 'vulnerabilities can also', 'vulnerability', 'vulnerability to', 'vulnerability to biases', 'vulnerable', 'vulnerable to', 'vulnerable to manipulation', 'w', 'w was', 'w was such', 'wall', 'wall street', 'wall street journal', 'walter', 'walter pitts', 'walter pitts and', 'wants', 'wants to', 'wants to assign', 'warren', 'warren mcculloch', 'warren mcculloch who', 'was', 'was also', 'was also applied', 'was also employed', 'was also used', 'was awarded', 'was awarded netflix', 'was coined', 'was coined in', 'was continued', 'was continued outside', 'was given', 'was given on', 'was introduced', 'was introduced in', 'was killed', 'was killed after', 'was nilssons', 'was nilssons book', 'was now', 'was now outside', 'was out', 'was out of', 'was recently', 'was recently applied', 'was repetitively', 'was repetitively trained', 'was reported', 'was reported that', 'was subsequently', 'was subsequently removed', 'was such', 'was such that', 'was to', 'was to solve', 'was used', 'was used to', 'watch', 'watch out', 'watch out for', 'watson', 'watson system', 'watson system failed', 'way', 'way that', 'way that a', 'way that makes', 'way the', 'way the human', 'way to', 'way to enhance', 'way to quantify', 'we', 'we are', 'we are only', 'we as', 'we as thinking', 'we define', 'we define an', 'weakly', 'weakly supervised', 'weakly supervised learning', 'weapon', 'weapon systems', 'weapon systems arms', 'wearable', 'wearable computers', 'wearable computers edge', 'web', 'web usage', 'web usage mining', 'weight', 'weight increases', 'weight increases or', 'weight space', 'weight space of', 'weight that', 'weight that adjusts', 'welfare', 'welfare and', 'welfare and rights', 'well', 'well as', 'well as the', 'well as what', 'well including', 'well including logician', 'well it', 'well it fits', 'well multiple', 'well multiple regressor', 'wellordered', 'wellordered set', 'wellvisible', 'wellvisible not', 'wellvisible not spam', 'were', 'were found', 'were found to', 'were interested', 'were interested in', 'were later', 'were later found', 'were mostly', 'were mostly perceptrons', 'were not', 'were not a', 'were not the', 'were plagued', 'were plagued by', 'were then', 'were then termed', 'were used', 'were used in', 'what', 'what is', 'what is called', 'what we', 'what we as', 'what were', 'what were then', 'when', 'when applied', 'when applied correctly', 'when arthur', 'when arthur samuel', 'when compared', 'when compared to', 'when dealing', 'when dealing with', 'when exact', 'when exact models', 'when householders', 'when householders decide', 'when the', 'when the outputs', 'when trained', 'when trained on', 'when training', 'when training a', 'when used', 'when used in', 'where', 'where a', 'where a single', 'where a training', 'where each', 'where each class', 'where even', 'where even its', 'where it', 'where it behaves', 'where it is', 'where machine', 'where machine learning', 'where models', 'where models are', 'where novel', 'where novel algorithms', 'where outputs', 'where outputs are', 'where the', 'where the algorithm', 'where the target', 'where there', 'where there is', 'wherefrom', 'wherefrom it', 'wherefrom it initially', 'wherein', 'wherein algorithmic', 'wherein algorithmic model', 'whether', 'whether a', 'whether a new', 'which', 'which a', 'which a previously', 'which a type', 'which are', 'which are inherently', 'which caused', 'which caused controversy', 'which claimed', 'which claimed that', 'which correspond', 'which correspond to', 'which do', 'which do not', 'which do often', 'which every', 'which every finite', 'which further', 'which further demonstrates', 'which have', 'which have been', 'which he', 'which he introduced', 'which humans', 'which humans can', 'which introduces', 'which introduces nonlinearity', 'which loosely', 'which loosely model', 'which machine', 'which machine learning', 'which raise', 'which raise suspicions', 'which samples', 'which samples n', 'which splits', 'which splits the', 'which the', 'which the algorithms', 'which the question', 'which to', 'which to file', 'while', 'while in', 'while in a', 'while in knowledge', 'while it', 'while it has', 'while machine', 'while machine learning', 'while maintaining', 'while maintaining energy', 'while not', 'while not being', 'while observations', 'while observations drawn', 'while regression', 'while regression algorithms', 'while responsible', 'while responsible collection', 'while significantly', 'while significantly decreasing', 'white', 'white as', 'white as asian', 'white defendants', 'white defendants in', 'whitebox', 'whitebox access', 'who', 'who focus', 'who focus on', 'who have', 'who have studied', 'who proposed', 'who proposed the', 'who said', 'who said that', 'who was', 'who was killed', 'who were', 'who were found', 'why', 'why an', 'why an ai', 'wide', 'wide range', 'wide range of', 'widely', 'widely quoted', 'widely quoted more', 'widely used', 'widely used in', 'widespread', 'widespread use', 'widespread use in', 'wildfires', 'wildfires and', 'wildfires and hurricanes', 'will', 'will be', 'will be poorer', 'will derive', 'will derive a', 'will easily', 'will easily be', 'will fail', 'will fail on', 'will necessarily', 'will necessarily also', 'win', 'win the', 'win the grand', 'winning', 'winning chance', 'winning chance in', 'with', 'with a', 'with a better', 'with a directed', 'with a doublingtime', 'with a goof', 'with a learning', 'with a neural', 'with a small', 'with adjustable', 'with adjustable resistance', 'with aispecific', 'with aispecific enhancements', 'with algorithms', 'with algorithms that', 'with all', 'with all its', 'with any', 'with any taskspecific', 'with biases', 'with biases may', 'with completely', 'with completely labelled', 'with different', 'with different goals', 'with experience', 'with experience e', 'with higherlevel', 'with higherlevel more', 'with historical', 'with historical crime', 'with how', 'with how complex', 'with how software', 'with how well', 'with images', 'with images of', 'with in', 'with in machine', 'with limited', 'with limited computing', 'with machine', 'with machine learning', 'with new', 'with new inputs', 'with nonlinear', 'with nonlinear problems', 'with one', 'with one another', 'with only', 'with only one', 'with punched', 'with punched tape', 'with racist', 'with racist hiring', 'with recognising', 'with recognising nonwhite', 'with replacement', 'with replacement from', 'with respect', 'with respect to', 'with sequence', 'with sequence mining', 'with supervised', 'with supervised learning', 'with the', 'with the accompanying', 'with the black', 'with the class', 'with the development', 'with the ibm', 'with the phone', 'with the question', 'with the reinvention', 'with the teams', 'with their', 'with their centroids', 'with training', 'with training sets', 'with uncertainty', 'with uncertainty with', 'with understood', 'with understood connections', 'with unlabelled', 'with unlabelled input', 'with unnecessary', 'with unnecessary tests', 'with various', 'with various symbolic', 'within', 'within a', 'within a range', 'within a subdiscipline', 'within a transaction', 'within ai', 'within ai leading', 'within ai that', 'within machine', 'within machine learning', 'within the', 'within the machine', 'within the same', 'within these', 'within these feature', 'without', 'without any', 'without any external', 'without any labelled', 'without being', 'without being programmed', 'without both', 'without both but', 'without explicit', 'without explicit instructions', 'without having', 'without having to', 'without limiting', 'without limiting the', 'without overfitting', 'without overfitting by', 'without relying', 'without relying on', 'without reshaping', 'without reshaping them', 'women', 'women or', 'women or have', 'words', 'words it', 'words it is', 'work', 'work on', 'work on single', 'work on symbolicknowledgebased', 'work under', 'work under nodes', 'work with', 'work with in', 'workload', 'workload burden', 'workload burden without', 'workloads', 'workloads unlike', 'workloads unlike generalpurpose', 'works', 'works for', 'works for all', 'world', 'world furthermore', 'world furthermore among', 'would', 'would be', 'would be lost', 'would combine', 'would combine probabilities', 'would however', 'would however over', 'would indicate', 'would indicate that', 'would not', 'would not be', 'wrong', 'wrong lesson', 'wrong lesson a', 'wrong tools', 'wrong tools and', 'wrote', 'wrote about', 'wrote about the', 'x', 'x an', 'x an exhaustive', 'x corresponding', 'x corresponding to', 'x for', 'x for example', 'x is', 'x is the', 'xai', 'xai may', 'xai may be', 'xai or', 'xai or interpretable', 'xai promises', 'xai promises to', 'xml', 'xml is', 'xml is artificial', 'years', 'years of', 'years of time', 'yet', 'yet developed', 'yet developed sufficiently', 'yet many', 'yet many machinelearning', 'yet significant', 'yet significant challenge', 'yield', 'yield guarantees', 'yield guarantees of', 'yielded', 'yielded attempts', 'yielded attempts to', 'you', 'you can', 'you can not', 'zeros', 'zeros multilinear', 'zeros multilinear subspace', 'zip', 'zip file', 'zip file and', 'zip files', 'zip files compressed', 'â„µ', 'â„µ such', 'â„µ such that']\n"
     ]
    }
   ],
   "source": [
    "vocab = set()\n",
    "for ngrams in docs_ngrams:\n",
    "    vocab.update(ngrams)\n",
    "vocab = sorted(list(vocab))\n",
    "print(\"Vocabulary (n-grams):\")\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "3c8Nyw0Xgsan"
   },
   "outputs": [],
   "source": [
    "doc_tf = []\n",
    "for ngrams in docs_ngrams:\n",
    "    tf = {}\n",
    "    for term in ngrams:\n",
    "        tf[term] = tf.get(term, 0) + 1\n",
    "    doc_tf.append(tf)\n",
    "\n",
    "df = {}\n",
    "for tf in doc_tf:\n",
    "    for term in tf.keys():\n",
    "        df[term] = df.get(term, 0) + 1\n",
    "\n",
    "N = len(docs)\n",
    "idf = {term: math.log((N + 1) / (df_count + 1)) + 1 for term, df_count in df.items()}\n",
    "\n",
    "doc_tfidf = []\n",
    "for tf in doc_tf:\n",
    "    tfidf = {}\n",
    "    for term, freq in tf.items():\n",
    "        tfidf[term] = freq * idf[term]\n",
    "    doc_tfidf.append(tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X82iPPxVgunU",
    "outputId": "ffd4c8fb-64cc-4e5f-f8a4-b971f16e16f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF: \n",
      "\n",
      "Document 1:\n",
      "\n",
      "Document 2:\n",
      "  a: 3.7766\n",
      "  a class: 4.6376\n",
      "  a class of: 4.6376\n",
      "  a field: 4.6376\n",
      "  a field of: 4.6376\n",
      "  a subdiscipline: 5.0431\n",
      "  a subdiscipline in: 5.0431\n",
      "  advances: 4.6376\n",
      "  advances in: 4.6376\n",
      "  advances in the: 5.0431\n",
      "  algorithms: 4.7378\n",
      "  algorithms that: 4.1268\n",
      "  algorithms that can: 5.0431\n",
      "  algorithms to: 4.6376\n",
      "  algorithms to surpass: 5.0431\n",
      "  allowed: 5.0431\n",
      "  allowed neural: 5.0431\n",
      "  allowed neural networks: 5.0431\n",
      "  and: 3.6432\n",
      "  and generalise: 5.0431\n",
      "  and generalise to: 5.0431\n",
      "  and study: 5.0431\n",
      "  and study of: 5.0431\n",
      "  and thus: 5.0431\n",
      "  and thus perform: 5.0431\n",
      "  approaches: 3.5390\n",
      "  approaches in: 4.6376\n",
      "  approaches in performance: 5.0431\n",
      "  artificial: 2.7918\n",
      "  artificial intelligence: 3.5390\n",
      "  artificial intelligence concerned: 5.0431\n",
      "  can: 2.1809\n",
      "  can learn: 5.0431\n",
      "  can learn from: 5.0431\n",
      "  class: 3.5390\n",
      "  class of: 3.9444\n",
      "  class of statistical: 5.0431\n",
      "  concerned: 4.3499\n",
      "  concerned with: 4.6376\n",
      "  concerned with the: 5.0431\n",
      "  data: 3.7300\n",
      "  data and: 7.0779\n",
      "  data and generalise: 5.0431\n",
      "  data and thus: 5.0431\n",
      "  deep: 3.6568\n",
      "  deep learning: 3.7903\n",
      "  deep learning have: 5.0431\n",
      "  development: 5.0431\n",
      "  development and: 5.0431\n",
      "  development and study: 5.0431\n",
      "  explicit: 4.6376\n",
      "  explicit instructions: 5.0431\n",
      "  explicit instructions within: 5.0431\n",
      "  field: 5.9272\n",
      "  field of: 7.0779\n",
      "  field of deep: 5.0431\n",
      "  field of study: 4.3499\n",
      "  from: 2.0726\n",
      "  from data: 3.9444\n",
      "  from data and: 4.6376\n",
      "  generalise: 4.6376\n",
      "  generalise to: 5.0431\n",
      "  generalise to unseen: 5.0431\n",
      "  have: 2.4781\n",
      "  have allowed: 5.0431\n",
      "  have allowed neural: 5.0431\n",
      "  in: 5.3670\n",
      "  in artificial: 5.0431\n",
      "  in artificial intelligence: 5.0431\n",
      "  in machine: 3.6568\n",
      "  in machine learning: 3.6568\n",
      "  in performance: 5.0431\n",
      "  in the: 2.4404\n",
      "  in the field: 4.1268\n",
      "  instructions: 5.0431\n",
      "  instructions within: 5.0431\n",
      "  instructions within a: 5.0431\n",
      "  intelligence: 3.1712\n",
      "  intelligence concerned: 5.0431\n",
      "  intelligence concerned with: 5.0431\n",
      "  is: 1.5167\n",
      "  is a: 2.5173\n",
      "  is a field: 5.0431\n",
      "  learn: 3.3383\n",
      "  learn from: 4.1268\n",
      "  learn from data: 4.6376\n",
      "  learning: 5.1274\n",
      "  learning advances: 5.0431\n",
      "  learning advances in: 5.0431\n",
      "  learning approaches: 3.9444\n",
      "  learning approaches in: 5.0431\n",
      "  learning have: 4.6376\n",
      "  learning have allowed: 5.0431\n",
      "  learning ml: 4.6376\n",
      "  learning ml is: 5.0431\n",
      "  machine: 4.4206\n",
      "  machine learning: 4.6854\n",
      "  machine learning advances: 5.0431\n",
      "  machine learning approaches: 3.9444\n",
      "  machine learning ml: 4.6376\n",
      "  many: 2.9030\n",
      "  many previous: 5.0431\n",
      "  many previous machine: 5.0431\n",
      "  ml: 4.3499\n",
      "  ml is: 5.0431\n",
      "  ml is a: 5.0431\n",
      "  networks: 3.0971\n",
      "  networks a: 4.6376\n",
      "  networks a class: 5.0431\n",
      "  neural: 3.0281\n",
      "  neural networks: 3.2513\n",
      "  neural networks a: 4.6376\n",
      "  of: 4.8576\n",
      "  of deep: 4.3499\n",
      "  of deep learning: 4.6376\n",
      "  of statistical: 9.2752\n",
      "  of statistical algorithms: 10.0861\n",
      "  of study: 4.3499\n",
      "  of study in: 5.0431\n",
      "  perform: 3.2513\n",
      "  perform tasks: 4.6376\n",
      "  perform tasks without: 5.0431\n",
      "  performance: 3.4336\n",
      "  previous: 4.1268\n",
      "  previous machine: 5.0431\n",
      "  previous machine learning: 5.0431\n",
      "  statistical: 6.8672\n",
      "  statistical algorithms: 10.0861\n",
      "  statistical algorithms that: 5.0431\n",
      "  statistical algorithms to: 5.0431\n",
      "  study: 7.3135\n",
      "  study in: 5.0431\n",
      "  study in artificial: 5.0431\n",
      "  study of: 5.0431\n",
      "  study of statistical: 5.0431\n",
      "  subdiscipline: 5.0431\n",
      "  subdiscipline in: 5.0431\n",
      "  subdiscipline in machine: 5.0431\n",
      "  surpass: 4.6376\n",
      "  surpass many: 5.0431\n",
      "  surpass many previous: 5.0431\n",
      "  tasks: 3.4336\n",
      "  tasks without: 5.0431\n",
      "  tasks without explicit: 5.0431\n",
      "  that: 1.6758\n",
      "  that can: 3.9444\n",
      "  that can learn: 5.0431\n",
      "  the: 2.3858\n",
      "  the development: 5.0431\n",
      "  the development and: 5.0431\n",
      "  the field: 3.4336\n",
      "  the field of: 3.7903\n",
      "  thus: 4.3499\n",
      "  thus perform: 5.0431\n",
      "  thus perform tasks: 5.0431\n",
      "  to: 2.4507\n",
      "  to surpass: 5.0431\n",
      "  to surpass many: 5.0431\n",
      "  to unseen: 5.0431\n",
      "  to unseen data: 5.0431\n",
      "  unseen: 4.3499\n",
      "  unseen data: 5.0431\n",
      "  unseen data and: 5.0431\n",
      "  with: 2.0726\n",
      "  with the: 3.5390\n",
      "  with the development: 5.0431\n",
      "  within: 3.4336\n",
      "  within a: 4.3499\n",
      "  within a subdiscipline: 5.0431\n",
      "  without: 3.3383\n",
      "  without explicit: 5.0431\n",
      "  without explicit instructions: 5.0431\n",
      "\n",
      "Document 3:\n",
      "  agriculture: 5.0431\n",
      "  agriculture and: 5.0431\n",
      "  agriculture and medicine: 5.0431\n",
      "  analytics: 5.0431\n",
      "  and: 1.2144\n",
      "  and medicine: 5.0431\n",
      "  and medicine the: 5.0431\n",
      "  application: 8.6998\n",
      "  application in: 5.0431\n",
      "  application in many: 5.0431\n",
      "  application of: 5.0431\n",
      "  application of ml: 5.0431\n",
      "  as: 1.8444\n",
      "  as predictive: 5.0431\n",
      "  as predictive analytics: 5.0431\n",
      "  business: 4.6376\n",
      "  business problems: 5.0431\n",
      "  business problems is: 5.0431\n",
      "  computer: 3.2513\n",
      "  computer vision: 4.1268\n",
      "  computer vision speech: 4.6376\n",
      "  email: 4.6376\n",
      "  email filtering: 5.0431\n",
      "  email filtering agriculture: 5.0431\n",
      "  fields: 3.9444\n",
      "  fields including: 5.0431\n",
      "  fields including natural: 5.0431\n",
      "  filtering: 4.6376\n",
      "  filtering agriculture: 5.0431\n",
      "  filtering agriculture and: 5.0431\n",
      "  finds: 4.3499\n",
      "  finds application: 5.0431\n",
      "  finds application in: 5.0431\n",
      "  in: 1.3417\n",
      "  in many: 4.3499\n",
      "  in many fields: 5.0431\n",
      "  including: 3.4336\n",
      "  including natural: 5.0431\n",
      "  including natural language: 5.0431\n",
      "  is: 1.5167\n",
      "  is known: 4.6376\n",
      "  is known as: 4.6376\n",
      "  known: 3.5390\n",
      "  known as: 3.7903\n",
      "  known as predictive: 5.0431\n",
      "  language: 3.9444\n",
      "  language processing: 4.6376\n",
      "  language processing computer: 5.0431\n",
      "  many: 2.9030\n",
      "  many fields: 5.0431\n",
      "  many fields including: 5.0431\n",
      "  medicine: 5.0431\n",
      "  medicine the: 5.0431\n",
      "  medicine the application: 5.0431\n",
      "  ml: 8.6998\n",
      "  ml finds: 5.0431\n",
      "  ml finds application: 5.0431\n",
      "  ml to: 5.0431\n",
      "  ml to business: 5.0431\n",
      "  natural: 4.3499\n",
      "  natural language: 4.6376\n",
      "  natural language processing: 4.6376\n",
      "  of: 1.2144\n",
      "  of ml: 5.0431\n",
      "  of ml to: 5.0431\n",
      "  predictive: 4.1268\n",
      "  predictive analytics: 5.0431\n",
      "  problems: 3.1712\n",
      "  problems is: 4.6376\n",
      "  problems is known: 5.0431\n",
      "  processing: 3.6568\n",
      "  processing computer: 5.0431\n",
      "  processing computer vision: 5.0431\n",
      "  recognition: 3.9444\n",
      "  recognition email: 5.0431\n",
      "  recognition email filtering: 5.0431\n",
      "  speech: 3.9444\n",
      "  speech recognition: 4.3499\n",
      "  speech recognition email: 5.0431\n",
      "  the: 1.1929\n",
      "  the application: 5.0431\n",
      "  the application of: 5.0431\n",
      "  to: 1.2253\n",
      "  to business: 5.0431\n",
      "  to business problems: 5.0431\n",
      "  vision: 4.1268\n",
      "  vision speech: 4.6376\n",
      "  vision speech recognition: 4.6376\n",
      "\n",
      "Document 4:\n",
      "  a: 1.2589\n",
      "  a related: 4.6376\n",
      "  a related field: 4.6376\n",
      "  analysis: 3.1712\n",
      "  analysis eda: 5.0431\n",
      "  analysis eda via: 5.0431\n",
      "  and: 1.2144\n",
      "  and mathematical: 5.0431\n",
      "  and mathematical optimisation: 5.0431\n",
      "  comprise: 5.0431\n",
      "  comprise the: 5.0431\n",
      "  comprise the foundations: 5.0431\n",
      "  data: 3.7300\n",
      "  data analysis: 5.0431\n",
      "  data analysis eda: 5.0431\n",
      "  data mining: 4.1268\n",
      "  data mining is: 5.0431\n",
      "  eda: 5.0431\n",
      "  eda via: 5.0431\n",
      "  eda via unsupervised: 5.0431\n",
      "  exploratory: 5.0431\n",
      "  exploratory data: 5.0431\n",
      "  exploratory data analysis: 5.0431\n",
      "  field: 2.9636\n",
      "  field of: 3.5390\n",
      "  field of study: 4.3499\n",
      "  focusing: 4.6376\n",
      "  focusing on: 4.6376\n",
      "  focusing on exploratory: 5.0431\n",
      "  foundations: 5.0431\n",
      "  foundations of: 5.0431\n",
      "  foundations of machine: 5.0431\n",
      "  is: 1.5167\n",
      "  is a: 2.5173\n",
      "  is a related: 4.6376\n",
      "  learning: 2.5637\n",
      "  learning data: 4.6376\n",
      "  learning data mining: 5.0431\n",
      "  machine: 1.4735\n",
      "  machine learning: 1.5618\n",
      "  machine learning data: 5.0431\n",
      "  mathematical: 7.0779\n",
      "  mathematical optimisation: 5.0431\n",
      "  mathematical optimisation mathematical: 5.0431\n",
      "  mathematical programming: 5.0431\n",
      "  mathematical programming methods: 5.0431\n",
      "  methods: 2.7405\n",
      "  methods comprise: 5.0431\n",
      "  methods comprise the: 5.0431\n",
      "  mining: 3.9444\n",
      "  mining is: 5.0431\n",
      "  mining is a: 5.0431\n",
      "  of: 2.4288\n",
      "  of machine: 3.0281\n",
      "  of machine learning: 3.0281\n",
      "  of study: 4.3499\n",
      "  of study focusing: 5.0431\n",
      "  on: 2.0473\n",
      "  on exploratory: 5.0431\n",
      "  on exploratory data: 5.0431\n",
      "  optimisation: 3.7903\n",
      "  optimisation mathematical: 5.0431\n",
      "  optimisation mathematical programming: 5.0431\n",
      "  programming: 4.1268\n",
      "  programming methods: 5.0431\n",
      "  programming methods comprise: 5.0431\n",
      "  related: 3.6568\n",
      "  related field: 4.6376\n",
      "  related field of: 5.0431\n",
      "  statistics: 3.6568\n",
      "  statistics and: 4.6376\n",
      "  statistics and mathematical: 5.0431\n",
      "  study: 3.6568\n",
      "  study focusing: 5.0431\n",
      "  study focusing on: 5.0431\n",
      "  the: 1.1929\n",
      "  the foundations: 5.0431\n",
      "  the foundations of: 5.0431\n",
      "  unsupervised: 3.2513\n",
      "  unsupervised learning: 3.7903\n",
      "  via: 4.3499\n",
      "  via unsupervised: 5.0431\n",
      "  via unsupervised learning: 5.0431\n",
      "\n",
      "Document 5:\n",
      "  a: 2.5177\n",
      "  a framework: 5.0431\n",
      "  a framework for: 5.0431\n",
      "  a theoretical: 4.6376\n",
      "  a theoretical viewpoint: 5.0431\n",
      "  approximately: 4.3499\n",
      "  approximately correct: 4.6376\n",
      "  approximately correct learning: 4.6376\n",
      "  correct: 4.6376\n",
      "  correct learning: 4.6376\n",
      "  correct learning provides: 5.0431\n",
      "  describing: 5.0431\n",
      "  describing machine: 5.0431\n",
      "  describing machine learning: 5.0431\n",
      "  for: 1.7289\n",
      "  for describing: 5.0431\n",
      "  for describing machine: 5.0431\n",
      "  framework: 4.6376\n",
      "  framework for: 4.6376\n",
      "  framework for describing: 5.0431\n",
      "  from: 2.0726\n",
      "  from a: 3.7903\n",
      "  from a theoretical: 5.0431\n",
      "  learning: 2.5637\n",
      "  learning provides: 5.0431\n",
      "  learning provides a: 5.0431\n",
      "  machine: 1.4735\n",
      "  machine learning: 1.5618\n",
      "  probably: 4.6376\n",
      "  probably approximately: 4.6376\n",
      "  probably approximately correct: 4.6376\n",
      "  provides: 4.6376\n",
      "  provides a: 5.0431\n",
      "  provides a framework: 5.0431\n",
      "  theoretical: 3.6568\n",
      "  theoretical viewpoint: 5.0431\n",
      "  theoretical viewpoint probably: 5.0431\n",
      "  viewpoint: 5.0431\n",
      "  viewpoint probably: 5.0431\n",
      "  viewpoint probably approximately: 5.0431\n",
      "\n",
      "Document 6:\n",
      "  also: 2.6452\n",
      "  also used: 5.0431\n",
      "  also used in: 5.0431\n",
      "  an: 2.1527\n",
      "  an ibm: 5.0431\n",
      "  an ibm employee: 5.0431\n",
      "  and: 2.4288\n",
      "  and artificial: 4.6376\n",
      "  and artificial intelligence: 5.0431\n",
      "  and pioneer: 5.0431\n",
      "  and pioneer in: 5.0431\n",
      "  arthur: 4.6376\n",
      "  arthur samuel: 4.6376\n",
      "  arthur samuel an: 5.0431\n",
      "  artificial: 2.7918\n",
      "  artificial intelligence: 3.5390\n",
      "  artificial intelligence the: 5.0431\n",
      "  by: 1.9076\n",
      "  by arthur: 5.0431\n",
      "  by arthur samuel: 5.0431\n",
      "  coined: 5.0431\n",
      "  coined in: 5.0431\n",
      "  coined in by: 5.0431\n",
      "  computer: 3.2513\n",
      "  computer gaming: 5.0431\n",
      "  computer gaming and: 5.0431\n",
      "  computers: 4.3499\n",
      "  computers was: 5.0431\n",
      "  computers was also: 5.0431\n",
      "  employee: 5.0431\n",
      "  employee and: 5.0431\n",
      "  employee and pioneer: 5.0431\n",
      "  field: 2.9636\n",
      "  field of: 3.5390\n",
      "  field of computer: 5.0431\n",
      "  gaming: 5.0431\n",
      "  gaming and: 5.0431\n",
      "  gaming and artificial: 5.0431\n",
      "  ibm: 4.6376\n",
      "  ibm employee: 5.0431\n",
      "  ibm employee and: 5.0431\n",
      "  in: 4.0252\n",
      "  in by: 5.0431\n",
      "  in by arthur: 5.0431\n",
      "  in the: 2.4404\n",
      "  in the field: 4.1268\n",
      "  in this: 4.3499\n",
      "  in this time: 5.0431\n",
      "  intelligence: 3.1712\n",
      "  intelligence the: 5.0431\n",
      "  intelligence the synonym: 5.0431\n",
      "  learning: 1.2819\n",
      "  learning was: 4.6376\n",
      "  learning was coined: 5.0431\n",
      "  machine: 1.4735\n",
      "  machine learning: 1.5618\n",
      "  machine learning was: 4.6376\n",
      "  of: 1.2144\n",
      "  of computer: 5.0431\n",
      "  of computer gaming: 5.0431\n",
      "  period: 5.0431\n",
      "  pioneer: 5.0431\n",
      "  pioneer in: 5.0431\n",
      "  pioneer in the: 5.0431\n",
      "  samuel: 4.6376\n",
      "  samuel an: 5.0431\n",
      "  samuel an ibm: 5.0431\n",
      "  selfteaching: 5.0431\n",
      "  selfteaching computers: 5.0431\n",
      "  selfteaching computers was: 5.0431\n",
      "  synonym: 5.0431\n",
      "  synonym selfteaching: 5.0431\n",
      "  synonym selfteaching computers: 5.0431\n",
      "  term: 3.7903\n",
      "  term machine: 5.0431\n",
      "  term machine learning: 5.0431\n",
      "  the: 3.5787\n",
      "  the field: 3.4336\n",
      "  the field of: 3.7903\n",
      "  the synonym: 5.0431\n",
      "  the synonym selfteaching: 5.0431\n",
      "  the term: 3.9444\n",
      "  the term machine: 5.0431\n",
      "  this: 2.6007\n",
      "  this time: 5.0431\n",
      "  this time period: 5.0431\n",
      "  time: 3.5390\n",
      "  time period: 5.0431\n",
      "  used: 2.3350\n",
      "  used in: 3.4336\n",
      "  used in this: 5.0431\n",
      "  was: 6.6766\n",
      "  was also: 4.3499\n",
      "  was also used: 5.0431\n",
      "  was coined: 5.0431\n",
      "  was coined in: 5.0431\n",
      "\n",
      "Document 7:\n",
      "  a: 3.7766\n",
      "  a groundwork: 5.0431\n",
      "  a groundwork for: 5.0431\n",
      "  a program: 4.6376\n",
      "  a program that: 5.0431\n",
      "  a theoretical: 4.6376\n",
      "  a theoretical neural: 5.0431\n",
      "  ais: 5.0431\n",
      "  ais and: 5.0431\n",
      "  ais and machine: 5.0431\n",
      "  algorithms: 4.7378\n",
      "  algorithms that: 4.1268\n",
      "  algorithms that mirror: 5.0431\n",
      "  algorithms work: 5.0431\n",
      "  algorithms work under: 5.0431\n",
      "  although: 4.1268\n",
      "  although the: 5.0431\n",
      "  although the earliest: 5.0431\n",
      "  among: 3.9444\n",
      "  among nerve: 5.0431\n",
      "  among nerve cells: 5.0431\n",
      "  and: 3.6432\n",
      "  and effort: 5.0431\n",
      "  and effort to: 5.0431\n",
      "  and machine: 4.3499\n",
      "  and machine learning: 4.3499\n",
      "  and warren: 5.0431\n",
      "  and warren mcculloch: 5.0431\n",
      "  another: 4.1268\n",
      "  another set: 5.0431\n",
      "  another set a: 5.0431\n",
      "  arthur: 4.6376\n",
      "  arthur samuel: 4.6376\n",
      "  arthur samuel invented: 5.0431\n",
      "  artificial: 2.7918\n",
      "  artificial neurons: 4.6376\n",
      "  artificial neurons used: 5.0431\n",
      "  as: 1.8444\n",
      "  as well: 4.1268\n",
      "  as well including: 5.0431\n",
      "  back: 4.6376\n",
      "  back to: 4.6376\n",
      "  back to decades: 5.0431\n",
      "  behavior: 5.0431\n",
      "  behavior in: 5.0431\n",
      "  behavior in which: 5.0431\n",
      "  book: 4.3499\n",
      "  book the: 5.0431\n",
      "  book the organization: 5.0431\n",
      "  by: 3.8151\n",
      "  by certain: 5.0431\n",
      "  by certain interactions: 5.0431\n",
      "  by computers: 5.0431\n",
      "  by computers to: 5.0431\n",
      "  calculated: 5.0431\n",
      "  calculated the: 5.0431\n",
      "  calculated the winning: 5.0431\n",
      "  canadian: 5.0431\n",
      "  canadian psychologist: 5.0431\n",
      "  canadian psychologist donald: 5.0431\n",
      "  cells: 5.0431\n",
      "  cells hebbs: 5.0431\n",
      "  cells hebbs model: 5.0431\n",
      "  certain: 4.1268\n",
      "  certain interactions: 5.0431\n",
      "  certain interactions among: 5.0431\n",
      "  chance: 5.0431\n",
      "  chance in: 5.0431\n",
      "  chance in checkers: 5.0431\n",
      "  checkers: 5.0431\n",
      "  checkers for: 5.0431\n",
      "  checkers for each: 5.0431\n",
      "  cognitive: 9.2752\n",
      "  cognitive processes: 5.0431\n",
      "  cognitive processes in: 5.0431\n",
      "  cognitive systems: 5.0431\n",
      "  cognitive systems contributed: 5.0431\n",
      "  come: 4.3499\n",
      "  come up: 5.0431\n",
      "  come up with: 5.0431\n",
      "  communicate: 5.0431\n",
      "  communicate data: 5.0431\n",
      "  communicate data other: 5.0431\n",
      "  computers: 4.3499\n",
      "  computers to: 5.0431\n",
      "  computers to communicate: 5.0431\n",
      "  contributed: 5.0431\n",
      "  contributed to: 5.0431\n",
      "  contributed to the: 5.0431\n",
      "  data: 1.8650\n",
      "  data other: 5.0431\n",
      "  data other researchers: 5.0431\n",
      "  decades: 4.6376\n",
      "  decades of: 5.0431\n",
      "  decades of human: 5.0431\n",
      "  desire: 5.0431\n",
      "  desire and: 5.0431\n",
      "  desire and effort: 5.0431\n",
      "  donald: 5.0431\n",
      "  donald hebb: 5.0431\n",
      "  donald hebb published: 5.0431\n",
      "  each: 3.0971\n",
      "  each side: 5.0431\n",
      "  each side the: 5.0431\n",
      "  earliest: 5.0431\n",
      "  earliest machine: 5.0431\n",
      "  earliest machine learning: 5.0431\n",
      "  early: 4.3499\n",
      "  early mathematical: 5.0431\n",
      "  early mathematical models: 5.0431\n",
      "  effort: 5.0431\n",
      "  effort to: 5.0431\n",
      "  effort to study: 5.0431\n",
      "  for: 3.4577\n",
      "  for each: 4.6376\n",
      "  for each side: 5.0431\n",
      "  for how: 5.0431\n",
      "  for how ais: 5.0431\n",
      "  formed: 4.6376\n",
      "  formed by: 4.6376\n",
      "  formed by certain: 5.0431\n",
      "  groundwork: 5.0431\n",
      "  groundwork for: 5.0431\n",
      "  groundwork for how: 5.0431\n",
      "  have: 2.4781\n",
      "  have studied: 5.0431\n",
      "  have studied human: 5.0431\n",
      "  he: 4.6376\n",
      "  he introduced: 5.0431\n",
      "  he introduced a: 5.0431\n",
      "  hebb: 5.0431\n",
      "  hebb published: 5.0431\n",
      "  hebb published the: 5.0431\n",
      "  hebbs: 5.0431\n",
      "  hebbs model: 5.0431\n",
      "  hebbs model of: 5.0431\n",
      "  history: 4.3499\n",
      "  history of: 5.0431\n",
      "  history of machine: 5.0431\n",
      "  how: 3.5390\n",
      "  how ais: 5.0431\n",
      "  how ais and: 5.0431\n",
      "  human: 14.6270\n",
      "  human cognitive: 10.0861\n",
      "  human cognitive processes: 5.0431\n",
      "  human cognitive systems: 5.0431\n",
      "  human desire: 5.0431\n",
      "  human desire and: 5.0431\n",
      "  human thought: 5.0431\n",
      "  human thought processes: 5.0431\n",
      "  in: 5.3670\n",
      "  in canadian: 5.0431\n",
      "  in canadian psychologist: 5.0431\n",
      "  in checkers: 5.0431\n",
      "  in checkers for: 5.0431\n",
      "  in the: 2.4404\n",
      "  in the s: 4.3499\n",
      "  in which: 3.7903\n",
      "  in which he: 5.0431\n",
      "  including: 3.4336\n",
      "  including logician: 5.0431\n",
      "  including logician walter: 5.0431\n",
      "  interacting: 5.0431\n",
      "  interacting with: 5.0431\n",
      "  interacting with one: 5.0431\n",
      "  interactions: 5.0431\n",
      "  interactions among: 5.0431\n",
      "  interactions among nerve: 5.0431\n",
      "  introduced: 8.6998\n",
      "  introduced a: 5.0431\n",
      "  introduced a theoretical: 5.0431\n",
      "  introduced in: 4.6376\n",
      "  introduced in the: 5.0431\n",
      "  invented: 5.0431\n",
      "  invented a: 5.0431\n",
      "  invented a program: 5.0431\n",
      "  learning: 5.1274\n",
      "  learning algorithms: 2.9030\n",
      "  learning algorithms work: 5.0431\n",
      "  learning model: 4.1268\n",
      "  learning model was: 5.0431\n",
      "  learning roots: 5.0431\n",
      "  learning roots back: 5.0431\n",
      "  learning technologies: 5.0431\n",
      "  learning technologies as: 5.0431\n",
      "  logician: 5.0431\n",
      "  logician walter: 5.0431\n",
      "  logician walter pitts: 5.0431\n",
      "  machine: 5.8941\n",
      "  machine learning: 6.2472\n",
      "  machine learning algorithms: 3.4336\n",
      "  machine learning model: 4.3499\n",
      "  machine learning roots: 5.0431\n",
      "  machine learning technologies: 5.0431\n",
      "  mathematical: 3.5390\n",
      "  mathematical models: 5.0431\n",
      "  mathematical models of: 5.0431\n",
      "  mcculloch: 5.0431\n",
      "  mcculloch who: 5.0431\n",
      "  mcculloch who proposed: 5.0431\n",
      "  mirror: 5.0431\n",
      "  mirror human: 5.0431\n",
      "  mirror human thought: 5.0431\n",
      "  model: 4.6700\n",
      "  model of: 4.3499\n",
      "  model of neurons: 5.0431\n",
      "  model was: 5.0431\n",
      "  model was introduced: 5.0431\n",
      "  models: 2.5581\n",
      "  models of: 4.3499\n",
      "  models of neural: 5.0431\n",
      "  modern: 5.0431\n",
      "  modern machine: 5.0431\n",
      "  modern machine learning: 5.0431\n",
      "  nerve: 5.0431\n",
      "  nerve cells: 5.0431\n",
      "  nerve cells hebbs: 5.0431\n",
      "  networks: 3.0971\n",
      "  networks to: 5.0431\n",
      "  networks to come: 5.0431\n",
      "  neural: 6.0563\n",
      "  neural networks: 3.2513\n",
      "  neural networks to: 5.0431\n",
      "  neural structure: 5.0431\n",
      "  neural structure formed: 5.0431\n",
      "  neurons: 9.2752\n",
      "  neurons interacting: 5.0431\n",
      "  neurons interacting with: 5.0431\n",
      "  neurons used: 5.0431\n",
      "  neurons used by: 5.0431\n",
      "  nodes: 4.6376\n",
      "  nodes or: 5.0431\n",
      "  nodes or artificial: 5.0431\n",
      "  of: 6.0720\n",
      "  of behavior: 5.0431\n",
      "  of behavior in: 5.0431\n",
      "  of human: 5.0431\n",
      "  of human desire: 5.0431\n",
      "  of machine: 3.0281\n",
      "  of machine learning: 3.0281\n",
      "  of neural: 4.6376\n",
      "  of neural networks: 5.0431\n",
      "  of neurons: 5.0431\n",
      "  of neurons interacting: 5.0431\n",
      "  one: 3.0971\n",
      "  one another: 5.0431\n",
      "  one another set: 5.0431\n",
      "  or: 2.0226\n",
      "  or artificial: 5.0431\n",
      "  or artificial neurons: 5.0431\n",
      "  organization: 5.0431\n",
      "  organization of: 5.0431\n",
      "  organization of behavior: 5.0431\n",
      "  other: 2.7918\n",
      "  other researchers: 5.0431\n",
      "  other researchers who: 5.0431\n",
      "  pitts: 5.0431\n",
      "  pitts and: 5.0431\n",
      "  pitts and warren: 5.0431\n",
      "  processes: 8.6998\n",
      "  processes in: 5.0431\n",
      "  processes in canadian: 5.0431\n",
      "  program: 3.7903\n",
      "  program that: 4.3499\n",
      "  program that calculated: 5.0431\n",
      "  proposed: 5.0431\n",
      "  proposed the: 5.0431\n",
      "  proposed the early: 5.0431\n",
      "  psychologist: 5.0431\n",
      "  psychologist donald: 5.0431\n",
      "  psychologist donald hebb: 5.0431\n",
      "  published: 4.6376\n",
      "  published the: 4.6376\n",
      "  published the book: 5.0431\n",
      "  researchers: 3.6568\n",
      "  researchers who: 5.0431\n",
      "  researchers who have: 5.0431\n",
      "  roots: 5.0431\n",
      "  roots back: 5.0431\n",
      "  roots back to: 5.0431\n",
      "  s: 3.9444\n",
      "  s when: 5.0431\n",
      "  s when arthur: 5.0431\n",
      "  samuel: 4.6376\n",
      "  samuel invented: 5.0431\n",
      "  samuel invented a: 5.0431\n",
      "  set: 2.6007\n",
      "  set a: 5.0431\n",
      "  set a groundwork: 5.0431\n",
      "  side: 5.0431\n",
      "  side the: 5.0431\n",
      "  side the history: 5.0431\n",
      "  structure: 4.3499\n",
      "  structure formed: 5.0431\n",
      "  structure formed by: 5.0431\n",
      "  studied: 4.3499\n",
      "  studied human: 5.0431\n",
      "  studied human cognitive: 5.0431\n",
      "  study: 3.6568\n",
      "  study human: 5.0431\n",
      "  study human cognitive: 5.0431\n",
      "  systems: 2.6917\n",
      "  systems contributed: 5.0431\n",
      "  systems contributed to: 5.0431\n",
      "  technologies: 5.0431\n",
      "  technologies as: 5.0431\n",
      "  technologies as well: 5.0431\n",
      "  that: 3.3515\n",
      "  that calculated: 5.0431\n",
      "  that calculated the: 5.0431\n",
      "  that mirror: 5.0431\n",
      "  that mirror human: 5.0431\n",
      "  the: 9.5432\n",
      "  the book: 5.0431\n",
      "  the book the: 5.0431\n",
      "  the earliest: 5.0431\n",
      "  the earliest machine: 5.0431\n",
      "  the early: 4.3499\n",
      "  the early mathematical: 5.0431\n",
      "  the history: 5.0431\n",
      "  the history of: 5.0431\n",
      "  the modern: 5.0431\n",
      "  the modern machine: 5.0431\n",
      "  the organization: 5.0431\n",
      "  the organization of: 5.0431\n",
      "  the s: 3.9444\n",
      "  the s when: 5.0431\n",
      "  the winning: 5.0431\n",
      "  the winning chance: 5.0431\n",
      "  theoretical: 3.6568\n",
      "  theoretical neural: 5.0431\n",
      "  theoretical neural structure: 5.0431\n",
      "  thought: 4.6376\n",
      "  thought processes: 5.0431\n",
      "  to: 6.1267\n",
      "  to come: 5.0431\n",
      "  to come up: 5.0431\n",
      "  to communicate: 5.0431\n",
      "  to communicate data: 5.0431\n",
      "  to decades: 5.0431\n",
      "  to decades of: 5.0431\n",
      "  to study: 4.6376\n",
      "  to study human: 5.0431\n",
      "  to the: 3.1712\n",
      "  to the modern: 5.0431\n",
      "  under: 3.4336\n",
      "  under nodes: 5.0431\n",
      "  under nodes or: 5.0431\n",
      "  up: 3.7903\n",
      "  up with: 5.0431\n",
      "  up with algorithms: 5.0431\n",
      "  used: 2.3350\n",
      "  used by: 4.3499\n",
      "  used by computers: 5.0431\n",
      "  walter: 5.0431\n",
      "  walter pitts: 5.0431\n",
      "  walter pitts and: 5.0431\n",
      "  warren: 5.0431\n",
      "  warren mcculloch: 5.0431\n",
      "  warren mcculloch who: 5.0431\n",
      "  was: 3.3383\n",
      "  was introduced: 4.6376\n",
      "  was introduced in: 4.6376\n",
      "  well: 3.9444\n",
      "  well including: 5.0431\n",
      "  well including logician: 5.0431\n",
      "  when: 3.3383\n",
      "  when arthur: 5.0431\n",
      "  when arthur samuel: 5.0431\n",
      "  which: 2.6917\n",
      "  which he: 5.0431\n",
      "  which he introduced: 5.0431\n",
      "  who: 7.8889\n",
      "  who have: 5.0431\n",
      "  who have studied: 5.0431\n",
      "  who proposed: 5.0431\n",
      "  who proposed the: 5.0431\n",
      "  winning: 5.0431\n",
      "  winning chance: 5.0431\n",
      "  winning chance in: 5.0431\n",
      "  with: 4.1453\n",
      "  with algorithms: 5.0431\n",
      "  with algorithms that: 5.0431\n",
      "  with one: 5.0431\n",
      "  with one another: 5.0431\n",
      "  work: 4.1268\n",
      "  work under: 5.0431\n",
      "  work under nodes: 5.0431\n",
      "\n",
      "Document 8:\n",
      "  a: 6.2943\n",
      "  a computer: 4.3499\n",
      "  a computer terminal: 5.0431\n",
      "  a goof: 5.0431\n",
      "  a goof button: 5.0431\n",
      "  a human: 4.3499\n",
      "  a human operatorteacher: 5.0431\n",
      "  a report: 5.0431\n",
      "  a report was: 5.0431\n",
      "  a representative: 5.0431\n",
      "  a representative book: 5.0431\n",
      "  an: 4.3054\n",
      "  an artificial: 4.3499\n",
      "  an artificial neural: 4.6376\n",
      "  an experimental: 5.0431\n",
      "  an experimental learning: 5.0431\n",
      "  analyse: 4.6376\n",
      "  analyse sonar: 5.0431\n",
      "  analyse sonar signals: 5.0431\n",
      "  and: 4.8576\n",
      "  and equipped: 5.0431\n",
      "  and equipped with: 5.0431\n",
      "  and hart: 5.0431\n",
      "  and hart in: 5.0431\n",
      "  and special: 5.0431\n",
      "  and special symbols: 5.0431\n",
      "  and speech: 4.6376\n",
      "  and speech patterns: 5.0431\n",
      "  artificial: 2.7918\n",
      "  artificial neural: 3.7903\n",
      "  artificial neural network: 4.6376\n",
      "  as: 1.8444\n",
      "  as described: 5.0431\n",
      "  as described by: 5.0431\n",
      "  been: 2.6917\n",
      "  been developed: 4.3499\n",
      "  been developed by: 5.0431\n",
      "  book: 8.6998\n",
      "  book on: 10.0861\n",
      "  book on learning: 5.0431\n",
      "  book on research: 5.0431\n",
      "  button: 5.0431\n",
      "  button to: 5.0431\n",
      "  button to cause: 5.0431\n",
      "  by: 7.6302\n",
      "  by a: 4.1268\n",
      "  by a human: 5.0431\n",
      "  by duda: 5.0431\n",
      "  by duda and: 5.0431\n",
      "  by raytheon: 5.0431\n",
      "  by raytheon company: 5.0431\n",
      "  by the: 3.2513\n",
      "  by the early: 5.0431\n",
      "  called: 3.2513\n",
      "  called cybertron: 5.0431\n",
      "  called cybertron had: 5.0431\n",
      "  cause: 5.0431\n",
      "  cause it: 5.0431\n",
      "  cause it to: 5.0431\n",
      "  characters: 5.0431\n",
      "  characters letters: 5.0431\n",
      "  characters letters digits: 5.0431\n",
      "  classification: 2.9636\n",
      "  classification interest: 5.0431\n",
      "  classification interest related: 5.0431\n",
      "  company: 4.3499\n",
      "  company to: 5.0431\n",
      "  company to analyse: 5.0431\n",
      "  computer: 3.2513\n",
      "  computer terminal: 5.0431\n",
      "  continued: 4.6376\n",
      "  continued into: 5.0431\n",
      "  continued into the: 5.0431\n",
      "  cybertron: 5.0431\n",
      "  cybertron had: 5.0431\n",
      "  cybertron had been: 5.0431\n",
      "  dealing: 4.6376\n",
      "  dealing mostly: 5.0431\n",
      "  dealing mostly with: 5.0431\n",
      "  decisions: 3.6568\n",
      "  decisions a: 5.0431\n",
      "  decisions a representative: 5.0431\n",
      "  described: 5.0431\n",
      "  described by: 5.0431\n",
      "  described by duda: 5.0431\n",
      "  developed: 3.7903\n",
      "  developed by: 4.6376\n",
      "  developed by raytheon: 5.0431\n",
      "  digits: 5.0431\n",
      "  digits and: 5.0431\n",
      "  digits and special: 5.0431\n",
      "  duda: 5.0431\n",
      "  duda and: 5.0431\n",
      "  duda and hart: 5.0431\n",
      "  during: 4.1268\n",
      "  during the: 5.0431\n",
      "  during the s: 5.0431\n",
      "  early: 4.3499\n",
      "  early s: 5.0431\n",
      "  early s an: 5.0431\n",
      "  electrocardiograms: 5.0431\n",
      "  electrocardiograms and: 5.0431\n",
      "  electrocardiograms and speech: 5.0431\n",
      "  equipped: 5.0431\n",
      "  equipped with: 5.0431\n",
      "  equipped with a: 5.0431\n",
      "  experimental: 4.6376\n",
      "  experimental learning: 5.0431\n",
      "  experimental learning machine: 5.0431\n",
      "  for: 1.7289\n",
      "  for pattern: 5.0431\n",
      "  for pattern classification: 5.0431\n",
      "  from: 2.0726\n",
      "  from a: 3.7903\n",
      "  from a computer: 5.0431\n",
      "  given: 3.3383\n",
      "  given on: 5.0431\n",
      "  given on using: 5.0431\n",
      "  goof: 5.0431\n",
      "  goof button: 5.0431\n",
      "  goof button to: 5.0431\n",
      "  had: 3.6568\n",
      "  had been: 4.1268\n",
      "  had been developed: 5.0431\n",
      "  hart: 5.0431\n",
      "  hart in: 5.0431\n",
      "  hart in in: 5.0431\n",
      "  human: 3.6568\n",
      "  human operatorteacher: 5.0431\n",
      "  human operatorteacher to: 5.0431\n",
      "  in: 2.6835\n",
      "  in a: 3.0971\n",
      "  in a report: 5.0431\n",
      "  in in: 5.0431\n",
      "  in in a: 5.0431\n",
      "  incorrect: 5.0431\n",
      "  incorrect decisions: 5.0431\n",
      "  incorrect decisions a: 5.0431\n",
      "  interest: 4.6376\n",
      "  interest related: 5.0431\n",
      "  interest related to: 5.0431\n",
      "  into: 5.9272\n",
      "  into machine: 5.0431\n",
      "  into machine learning: 5.0431\n",
      "  into the: 4.3499\n",
      "  into the s: 5.0431\n",
      "  it: 4.5409\n",
      "  it to: 4.3499\n",
      "  it to reevaluate: 5.0431\n",
      "  it was: 4.6376\n",
      "  it was repetitively: 5.0431\n",
      "  learning: 6.4093\n",
      "  learning during: 5.0431\n",
      "  learning during the: 5.0431\n",
      "  learning for: 5.0431\n",
      "  learning for pattern: 5.0431\n",
      "  learning it: 5.0431\n",
      "  learning it was: 5.0431\n",
      "  learning machine: 4.6376\n",
      "  learning machine with: 5.0431\n",
      "  learning machines: 5.0431\n",
      "  learning machines dealing: 5.0431\n",
      "  learns: 3.9444\n",
      "  learns to: 5.0431\n",
      "  learns to recognise: 5.0431\n",
      "  letters: 5.0431\n",
      "  letters digits: 5.0431\n",
      "  letters digits and: 5.0431\n",
      "  machine: 4.4206\n",
      "  machine learning: 3.1236\n",
      "  machine learning during: 5.0431\n",
      "  machine learning for: 5.0431\n",
      "  machine with: 5.0431\n",
      "  machine with punched: 5.0431\n",
      "  machines: 3.6568\n",
      "  machines dealing: 5.0431\n",
      "  machines dealing mostly: 5.0431\n",
      "  memory: 4.3499\n",
      "  memory called: 5.0431\n",
      "  memory called cybertron: 5.0431\n",
      "  mostly: 4.6376\n",
      "  mostly with: 5.0431\n",
      "  mostly with machine: 5.0431\n",
      "  network: 3.5390\n",
      "  network learns: 5.0431\n",
      "  network learns to: 5.0431\n",
      "  neural: 3.0281\n",
      "  neural network: 4.1268\n",
      "  neural network learns: 5.0431\n",
      "  nilssons: 5.0431\n",
      "  nilssons book: 5.0431\n",
      "  nilssons book on: 5.0431\n",
      "  on: 6.1420\n",
      "  on learning: 5.0431\n",
      "  on learning machines: 5.0431\n",
      "  on research: 5.0431\n",
      "  on research into: 5.0431\n",
      "  on using: 5.0431\n",
      "  on using teaching: 5.0431\n",
      "  operatorteacher: 5.0431\n",
      "  operatorteacher to: 5.0431\n",
      "  operatorteacher to recognise: 5.0431\n",
      "  pattern: 8.2535\n",
      "  pattern classification: 5.0431\n",
      "  pattern classification interest: 5.0431\n",
      "  pattern recognition: 4.6376\n",
      "  pattern recognition continued: 5.0431\n",
      "  patterns: 6.8672\n",
      "  patterns and: 5.0431\n",
      "  patterns and equipped: 5.0431\n",
      "  patterns using: 5.0431\n",
      "  patterns using rudimentary: 5.0431\n",
      "  punched: 5.0431\n",
      "  punched tape: 5.0431\n",
      "  punched tape memory: 5.0431\n",
      "  raytheon: 5.0431\n",
      "  raytheon company: 5.0431\n",
      "  raytheon company to: 5.0431\n",
      "  recognise: 9.2752\n",
      "  recognise characters: 5.0431\n",
      "  recognise characters letters: 5.0431\n",
      "  recognise patterns: 5.0431\n",
      "  recognise patterns and: 5.0431\n",
      "  recognition: 3.9444\n",
      "  recognition continued: 5.0431\n",
      "  recognition continued into: 5.0431\n",
      "  reevaluate: 5.0431\n",
      "  reevaluate incorrect: 5.0431\n",
      "  reevaluate incorrect decisions: 5.0431\n",
      "  reinforcement: 3.9444\n",
      "  reinforcement learning: 4.1268\n",
      "  reinforcement learning it: 5.0431\n",
      "  related: 3.6568\n",
      "  related to: 4.3499\n",
      "  related to pattern: 5.0431\n",
      "  repetitively: 5.0431\n",
      "  repetitively trained: 5.0431\n",
      "  repetitively trained by: 5.0431\n",
      "  report: 4.6376\n",
      "  report was: 5.0431\n",
      "  report was given: 5.0431\n",
      "  representative: 3.9444\n",
      "  representative book: 5.0431\n",
      "  representative book on: 5.0431\n",
      "  research: 3.4336\n",
      "  research into: 5.0431\n",
      "  research into machine: 5.0431\n",
      "  rudimentary: 5.0431\n",
      "  rudimentary reinforcement: 5.0431\n",
      "  rudimentary reinforcement learning: 5.0431\n",
      "  s: 11.8333\n",
      "  s an: 5.0431\n",
      "  s an experimental: 5.0431\n",
      "  s as: 5.0431\n",
      "  s as described: 5.0431\n",
      "  s was: 5.0431\n",
      "  s was nilssons: 5.0431\n",
      "  signals: 4.3499\n",
      "  signals electrocardiograms: 5.0431\n",
      "  signals electrocardiograms and: 5.0431\n",
      "  so: 4.1268\n",
      "  so that: 4.6376\n",
      "  so that an: 5.0431\n",
      "  sonar: 5.0431\n",
      "  sonar signals: 5.0431\n",
      "  sonar signals electrocardiograms: 5.0431\n",
      "  special: 4.6376\n",
      "  special symbols: 5.0431\n",
      "  special symbols from: 5.0431\n",
      "  speech: 3.9444\n",
      "  speech patterns: 5.0431\n",
      "  speech patterns using: 5.0431\n",
      "  strategies: 5.0431\n",
      "  strategies so: 5.0431\n",
      "  strategies so that: 5.0431\n",
      "  symbols: 5.0431\n",
      "  symbols from: 5.0431\n",
      "  symbols from a: 5.0431\n",
      "  tape: 5.0431\n",
      "  tape memory: 5.0431\n",
      "  tape memory called: 5.0431\n",
      "  teaching: 5.0431\n",
      "  teaching strategies: 5.0431\n",
      "  teaching strategies so: 5.0431\n",
      "  terminal: 5.0431\n",
      "  that: 1.6758\n",
      "  that an: 4.3499\n",
      "  that an artificial: 5.0431\n",
      "  the: 3.5787\n",
      "  the early: 4.3499\n",
      "  the early s: 5.0431\n",
      "  the s: 7.8889\n",
      "  the s as: 5.0431\n",
      "  the s was: 5.0431\n",
      "  to: 7.3520\n",
      "  to analyse: 4.6376\n",
      "  to analyse sonar: 5.0431\n",
      "  to cause: 5.0431\n",
      "  to cause it: 5.0431\n",
      "  to pattern: 5.0431\n",
      "  to pattern recognition: 5.0431\n",
      "  to recognise: 10.0861\n",
      "  to recognise characters: 5.0431\n",
      "  to recognise patterns: 5.0431\n",
      "  to reevaluate: 5.0431\n",
      "  to reevaluate incorrect: 5.0431\n",
      "  trained: 3.3383\n",
      "  trained by: 4.6376\n",
      "  trained by a: 5.0431\n",
      "  using: 6.5026\n",
      "  using rudimentary: 5.0431\n",
      "  using rudimentary reinforcement: 5.0431\n",
      "  using teaching: 5.0431\n",
      "  using teaching strategies: 5.0431\n",
      "  was: 10.0149\n",
      "  was given: 5.0431\n",
      "  was given on: 5.0431\n",
      "  was nilssons: 5.0431\n",
      "  was nilssons book: 5.0431\n",
      "  was repetitively: 5.0431\n",
      "  was repetitively trained: 5.0431\n",
      "  with: 6.2179\n",
      "  with a: 3.6568\n",
      "  with a goof: 5.0431\n",
      "  with machine: 5.0431\n",
      "  with machine learning: 5.0431\n",
      "  with punched: 5.0431\n",
      "  with punched tape: 5.0431\n",
      "\n",
      "Document 9:\n",
      "  a: 3.7766\n",
      "  a computer: 4.3499\n",
      "  a computer program: 4.6376\n",
      "  a fundamentally: 5.0431\n",
      "  a fundamentally operational: 5.0431\n",
      "  a widely: 5.0431\n",
      "  a widely quoted: 5.0431\n",
      "  alan: 5.0431\n",
      "  alan turings: 5.0431\n",
      "  alan turings proposal: 5.0431\n",
      "  algorithms: 2.3689\n",
      "  algorithms studied: 5.0431\n",
      "  algorithms studied in: 5.0431\n",
      "  and: 2.4288\n",
      "  and intelligence: 5.0431\n",
      "  and intelligence in: 5.0431\n",
      "  and performance: 5.0431\n",
      "  and performance measure: 5.0431\n",
      "  as: 3.6888\n",
      "  as measured: 5.0431\n",
      "  as measured by: 5.0431\n",
      "  as thinking: 5.0431\n",
      "  as thinking entities: 5.0431\n",
      "  at: 3.9444\n",
      "  at tasks: 5.0431\n",
      "  at tasks in: 5.0431\n",
      "  by: 1.9076\n",
      "  by p: 5.0431\n",
      "  by p improves: 5.0431\n",
      "  can: 6.5426\n",
      "  can do: 5.0431\n",
      "  can machines: 10.0861\n",
      "  can machines do: 5.0431\n",
      "  can machines think: 5.0431\n",
      "  class: 3.5390\n",
      "  class of: 3.9444\n",
      "  class of tasks: 5.0431\n",
      "  cognitive: 4.6376\n",
      "  cognitive terms: 5.0431\n",
      "  cognitive terms this: 5.0431\n",
      "  computer: 3.2513\n",
      "  computer program: 4.6376\n",
      "  computer program is: 5.0431\n",
      "  computing: 3.9444\n",
      "  computing machinery: 5.0431\n",
      "  computing machinery and: 5.0431\n",
      "  concerned: 4.3499\n",
      "  concerned offers: 5.0431\n",
      "  concerned offers a: 5.0431\n",
      "  defining: 4.6376\n",
      "  defining the: 5.0431\n",
      "  defining the field: 5.0431\n",
      "  definition: 13.9128\n",
      "  definition of: 9.2752\n",
      "  definition of the: 10.0861\n",
      "  definition rather: 5.0431\n",
      "  definition rather than: 5.0431\n",
      "  do: 7.3135\n",
      "  do what: 5.0431\n",
      "  do what we: 5.0431\n",
      "  e: 10.0861\n",
      "  e this: 5.0431\n",
      "  e this definition: 5.0431\n",
      "  e with: 5.0431\n",
      "  e with respect: 5.0431\n",
      "  entities: 5.0431\n",
      "  entities can: 5.0431\n",
      "  entities can do: 5.0431\n",
      "  experience: 8.6998\n",
      "  experience e: 10.0861\n",
      "  experience e this: 5.0431\n",
      "  experience e with: 5.0431\n",
      "  field: 5.9272\n",
      "  field a: 5.0431\n",
      "  field a computer: 5.0431\n",
      "  field in: 5.0431\n",
      "  field in cognitive: 5.0431\n",
      "  follows: 5.0431\n",
      "  follows alan: 5.0431\n",
      "  follows alan turings: 5.0431\n",
      "  formal: 5.0431\n",
      "  formal definition: 5.0431\n",
      "  formal definition of: 5.0431\n",
      "  from: 2.0726\n",
      "  from experience: 5.0431\n",
      "  from experience e: 5.0431\n",
      "  fundamentally: 5.0431\n",
      "  fundamentally operational: 5.0431\n",
      "  fundamentally operational definition: 5.0431\n",
      "  his: 5.0431\n",
      "  his paper: 5.0431\n",
      "  his paper computing: 5.0431\n",
      "  if: 3.6568\n",
      "  if its: 5.0431\n",
      "  if its performance: 5.0431\n",
      "  improves: 4.6376\n",
      "  improves with: 5.0431\n",
      "  improves with experience: 5.0431\n",
      "  in: 8.0505\n",
      "  in cognitive: 5.0431\n",
      "  in cognitive terms: 5.0431\n",
      "  in his: 5.0431\n",
      "  in his paper: 5.0431\n",
      "  in t: 5.0431\n",
      "  in t as: 5.0431\n",
      "  in the: 2.4404\n",
      "  in the machine: 5.0431\n",
      "  in which: 7.5806\n",
      "  in which machine: 5.0431\n",
      "  in which the: 4.6376\n",
      "  intelligence: 3.1712\n",
      "  intelligence in: 5.0431\n",
      "  intelligence in which: 5.0431\n",
      "  is: 4.5501\n",
      "  is concerned: 5.0431\n",
      "  is concerned offers: 5.0431\n",
      "  is replaced: 5.0431\n",
      "  is replaced with: 5.0431\n",
      "  is said: 4.6376\n",
      "  is said to: 4.6376\n",
      "  its: 2.9636\n",
      "  its performance: 5.0431\n",
      "  its performance at: 5.0431\n",
      "  learn: 3.3383\n",
      "  learn from: 4.1268\n",
      "  learn from experience: 5.0431\n",
      "  learning: 2.5637\n",
      "  learning field: 5.0431\n",
      "  learning field a: 5.0431\n",
      "  learning is: 3.0281\n",
      "  learning is concerned: 5.0431\n",
      "  m: 5.0431\n",
      "  m mitchell: 5.0431\n",
      "  m mitchell provided: 5.0431\n",
      "  machine: 2.9470\n",
      "  machine learning: 3.1236\n",
      "  machine learning field: 5.0431\n",
      "  machine learning is: 3.6568\n",
      "  machinery: 5.0431\n",
      "  machinery and: 5.0431\n",
      "  machinery and intelligence: 5.0431\n",
      "  machines: 7.3135\n",
      "  machines do: 5.0431\n",
      "  machines do what: 5.0431\n",
      "  machines think: 5.0431\n",
      "  machines think is: 5.0431\n",
      "  measure: 4.6376\n",
      "  measure p: 5.0431\n",
      "  measure p if: 5.0431\n",
      "  measured: 5.0431\n",
      "  measured by: 5.0431\n",
      "  measured by p: 5.0431\n",
      "  mitchell: 5.0431\n",
      "  mitchell provided: 5.0431\n",
      "  mitchell provided a: 5.0431\n",
      "  more: 3.1712\n",
      "  more formal: 5.0431\n",
      "  more formal definition: 5.0431\n",
      "  of: 3.6432\n",
      "  of tasks: 4.6376\n",
      "  of tasks t: 5.0431\n",
      "  of the: 4.6044\n",
      "  of the algorithms: 5.0431\n",
      "  of the tasks: 5.0431\n",
      "  offers: 5.0431\n",
      "  offers a: 5.0431\n",
      "  offers a fundamentally: 5.0431\n",
      "  operational: 5.0431\n",
      "  operational definition: 5.0431\n",
      "  operational definition rather: 5.0431\n",
      "  p: 10.0861\n",
      "  p if: 5.0431\n",
      "  p if its: 5.0431\n",
      "  p improves: 5.0431\n",
      "  p improves with: 5.0431\n",
      "  paper: 5.0431\n",
      "  paper computing: 5.0431\n",
      "  paper computing machinery: 5.0431\n",
      "  performance: 6.8672\n",
      "  performance at: 5.0431\n",
      "  performance at tasks: 5.0431\n",
      "  performance measure: 5.0431\n",
      "  performance measure p: 5.0431\n",
      "  program: 3.7903\n",
      "  program is: 5.0431\n",
      "  program is said: 5.0431\n",
      "  proposal: 5.0431\n",
      "  proposal in: 5.0431\n",
      "  proposal in his: 5.0431\n",
      "  provided: 4.1268\n",
      "  provided a: 4.6376\n",
      "  provided a widely: 5.0431\n",
      "  question: 10.0861\n",
      "  question can: 10.0861\n",
      "  question can machines: 10.0861\n",
      "  quoted: 5.0431\n",
      "  quoted more: 5.0431\n",
      "  quoted more formal: 5.0431\n",
      "  rather: 4.3499\n",
      "  rather than: 4.6376\n",
      "  rather than defining: 5.0431\n",
      "  replaced: 5.0431\n",
      "  replaced with: 5.0431\n",
      "  replaced with the: 5.0431\n",
      "  respect: 4.6376\n",
      "  respect to: 4.6376\n",
      "  respect to some: 5.0431\n",
      "  said: 4.3499\n",
      "  said to: 4.6376\n",
      "  said to learn: 5.0431\n",
      "  some: 2.9636\n",
      "  some class: 5.0431\n",
      "  some class of: 5.0431\n",
      "  studied: 4.3499\n",
      "  studied in: 4.6376\n",
      "  studied in the: 5.0431\n",
      "  t: 10.0861\n",
      "  t and: 5.0431\n",
      "  t and performance: 5.0431\n",
      "  t as: 5.0431\n",
      "  t as measured: 5.0431\n",
      "  tasks: 10.3008\n",
      "  tasks in: 10.0861\n",
      "  tasks in t: 5.0431\n",
      "  tasks in which: 5.0431\n",
      "  tasks t: 5.0431\n",
      "  tasks t and: 5.0431\n",
      "  terms: 4.3499\n",
      "  terms this: 5.0431\n",
      "  terms this follows: 5.0431\n",
      "  than: 4.1268\n",
      "  than defining: 5.0431\n",
      "  than defining the: 5.0431\n",
      "  the: 7.1574\n",
      "  the algorithms: 4.6376\n",
      "  the algorithms studied: 5.0431\n",
      "  the field: 3.4336\n",
      "  the field in: 5.0431\n",
      "  the machine: 4.1268\n",
      "  the machine learning: 4.3499\n",
      "  the question: 10.0861\n",
      "  the question can: 10.0861\n",
      "  the tasks: 5.0431\n",
      "  the tasks in: 5.0431\n",
      "  think: 5.0431\n",
      "  think is: 5.0431\n",
      "  think is replaced: 5.0431\n",
      "  thinking: 5.0431\n",
      "  thinking entities: 5.0431\n",
      "  thinking entities can: 5.0431\n",
      "  this: 5.2014\n",
      "  this definition: 5.0431\n",
      "  this definition of: 5.0431\n",
      "  this follows: 5.0431\n",
      "  this follows alan: 5.0431\n",
      "  to: 2.4507\n",
      "  to learn: 4.3499\n",
      "  to learn from: 4.6376\n",
      "  to some: 5.0431\n",
      "  to some class: 5.0431\n",
      "  tom: 5.0431\n",
      "  tom m: 5.0431\n",
      "  tom m mitchell: 5.0431\n",
      "  turings: 5.0431\n",
      "  turings proposal: 5.0431\n",
      "  turings proposal in: 5.0431\n",
      "  we: 4.3499\n",
      "  we as: 5.0431\n",
      "  we as thinking: 5.0431\n",
      "  what: 4.3499\n",
      "  what we: 5.0431\n",
      "  what we as: 5.0431\n",
      "  which: 5.3834\n",
      "  which machine: 5.0431\n",
      "  which machine learning: 5.0431\n",
      "  which the: 4.6376\n",
      "  which the question: 5.0431\n",
      "  widely: 4.6376\n",
      "  widely quoted: 5.0431\n",
      "  widely quoted more: 5.0431\n",
      "  with: 6.2179\n",
      "  with experience: 5.0431\n",
      "  with experience e: 5.0431\n",
      "  with respect: 4.6376\n",
      "  with respect to: 4.6376\n",
      "  with the: 3.5390\n",
      "  with the question: 5.0431\n",
      "\n",
      "Document 10:\n",
      "  a: 2.5177\n",
      "  a hypothetical: 5.0431\n",
      "  a hypothetical algorithm: 5.0431\n",
      "  a machine: 3.4336\n",
      "  a machine learning: 3.5390\n",
      "  algorithm: 5.8060\n",
      "  algorithm for: 5.0431\n",
      "  algorithm for stock: 5.0431\n",
      "  algorithm specific: 5.0431\n",
      "  algorithm specific to: 5.0431\n",
      "  based: 6.8672\n",
      "  based on: 6.8672\n",
      "  based on models: 5.0431\n",
      "  based on these: 5.0431\n",
      "  been: 2.6917\n",
      "  been developed: 4.3499\n",
      "  been developed the: 5.0431\n",
      "  cancerous: 5.0431\n",
      "  cancerous moles: 5.0431\n",
      "  cancerous moles a: 5.0431\n",
      "  classify: 10.0861\n",
      "  classify data: 5.0431\n",
      "  classify data based: 5.0431\n",
      "  classify the: 5.0431\n",
      "  classify the cancerous: 5.0431\n",
      "  classifying: 4.6376\n",
      "  classifying data: 5.0431\n",
      "  classifying data may: 5.0431\n",
      "  computer: 3.2513\n",
      "  computer vision: 4.1268\n",
      "  computer vision of: 5.0431\n",
      "  coupled: 5.0431\n",
      "  coupled with: 5.0431\n",
      "  coupled with supervised: 5.0431\n",
      "  data: 3.7300\n",
      "  data based: 5.0431\n",
      "  data based on: 5.0431\n",
      "  data may: 5.0431\n",
      "  data may use: 5.0431\n",
      "  developed: 3.7903\n",
      "  developed the: 5.0431\n",
      "  developed the other: 5.0431\n",
      "  for: 3.4577\n",
      "  for future: 5.0431\n",
      "  for future outcomes: 5.0431\n",
      "  for stock: 5.0431\n",
      "  for stock trading: 5.0431\n",
      "  future: 8.2535\n",
      "  future outcomes: 5.0431\n",
      "  future outcomes based: 5.0431\n",
      "  future potential: 5.0431\n",
      "  future potential predictions: 5.0431\n",
      "  has: 2.8458\n",
      "  has two: 5.0431\n",
      "  has two objectives: 5.0431\n",
      "  have: 2.4781\n",
      "  have been: 3.5390\n",
      "  have been developed: 4.6376\n",
      "  hypothetical: 5.0431\n",
      "  hypothetical algorithm: 5.0431\n",
      "  hypothetical algorithm specific: 5.0431\n",
      "  in: 1.3417\n",
      "  in order: 4.1268\n",
      "  in order to: 4.1268\n",
      "  inform: 5.0431\n",
      "  inform the: 5.0431\n",
      "  inform the trader: 5.0431\n",
      "  is: 3.0334\n",
      "  is to: 7.8889\n",
      "  is to classify: 5.0431\n",
      "  is to make: 5.0431\n",
      "  it: 2.2705\n",
      "  it to: 4.3499\n",
      "  it to classify: 5.0431\n",
      "  learning: 3.8456\n",
      "  learning algorithm: 3.9444\n",
      "  learning algorithm for: 5.0431\n",
      "  learning has: 4.1268\n",
      "  learning has two: 5.0431\n",
      "  learning in: 3.6568\n",
      "  learning in order: 5.0431\n",
      "  machine: 2.9470\n",
      "  machine learning: 3.1236\n",
      "  machine learning algorithm: 4.1268\n",
      "  machine learning has: 4.3499\n",
      "  make: 3.3383\n",
      "  make predictions: 4.3499\n",
      "  make predictions for: 5.0431\n",
      "  may: 6.5026\n",
      "  may inform: 5.0431\n",
      "  may inform the: 5.0431\n",
      "  may use: 5.0431\n",
      "  may use computer: 5.0431\n",
      "  models: 5.1163\n",
      "  models a: 5.0431\n",
      "  models a hypothetical: 5.0431\n",
      "  models which: 5.0431\n",
      "  models which have: 5.0431\n",
      "  modernday: 5.0431\n",
      "  modernday machine: 5.0431\n",
      "  modernday machine learning: 5.0431\n",
      "  moles: 10.0861\n",
      "  moles a: 5.0431\n",
      "  moles a machine: 5.0431\n",
      "  moles coupled: 5.0431\n",
      "  moles coupled with: 5.0431\n",
      "  objectives: 4.6376\n",
      "  objectives one: 5.0431\n",
      "  objectives one is: 5.0431\n",
      "  of: 2.4288\n",
      "  of future: 5.0431\n",
      "  of future potential: 5.0431\n",
      "  of moles: 5.0431\n",
      "  of moles coupled: 5.0431\n",
      "  on: 4.0946\n",
      "  on models: 5.0431\n",
      "  on models which: 5.0431\n",
      "  on these: 4.6376\n",
      "  on these models: 5.0431\n",
      "  one: 3.0971\n",
      "  one is: 4.3499\n",
      "  one is to: 5.0431\n",
      "  order: 3.9444\n",
      "  order to: 4.1268\n",
      "  order to train: 5.0431\n",
      "  other: 2.7918\n",
      "  other purpose: 5.0431\n",
      "  other purpose is: 5.0431\n",
      "  outcomes: 4.3499\n",
      "  outcomes based: 5.0431\n",
      "  outcomes based on: 5.0431\n",
      "  potential: 4.1268\n",
      "  potential predictions: 5.0431\n",
      "  predictions: 6.6766\n",
      "  predictions for: 5.0431\n",
      "  predictions for future: 5.0431\n",
      "  purpose: 5.0431\n",
      "  purpose is: 5.0431\n",
      "  purpose is to: 5.0431\n",
      "  specific: 3.7903\n",
      "  specific to: 5.0431\n",
      "  specific to classifying: 5.0431\n",
      "  stock: 4.6376\n",
      "  stock trading: 5.0431\n",
      "  stock trading may: 5.0431\n",
      "  supervised: 3.2513\n",
      "  supervised learning: 3.6568\n",
      "  supervised learning in: 5.0431\n",
      "  the: 3.5787\n",
      "  the cancerous: 5.0431\n",
      "  the cancerous moles: 5.0431\n",
      "  the other: 4.3499\n",
      "  the other purpose: 5.0431\n",
      "  the trader: 5.0431\n",
      "  the trader of: 5.0431\n",
      "  these: 2.9030\n",
      "  these models: 5.0431\n",
      "  these models a: 5.0431\n",
      "  to: 6.1267\n",
      "  to classify: 10.0861\n",
      "  to classify data: 5.0431\n",
      "  to classify the: 5.0431\n",
      "  to classifying: 5.0431\n",
      "  to classifying data: 5.0431\n",
      "  to make: 3.9444\n",
      "  to make predictions: 4.3499\n",
      "  to train: 4.3499\n",
      "  to train it: 5.0431\n",
      "  trader: 5.0431\n",
      "  trader of: 5.0431\n",
      "  trader of future: 5.0431\n",
      "  trading: 5.0431\n",
      "  trading may: 5.0431\n",
      "  trading may inform: 5.0431\n",
      "  train: 4.3499\n",
      "  train it: 5.0431\n",
      "  train it to: 5.0431\n",
      "  two: 3.5390\n",
      "  two objectives: 5.0431\n",
      "  two objectives one: 5.0431\n",
      "  use: 3.3383\n",
      "  use computer: 5.0431\n",
      "  use computer vision: 5.0431\n",
      "  vision: 4.1268\n",
      "  vision of: 5.0431\n",
      "  vision of moles: 5.0431\n",
      "  which: 2.6917\n",
      "  which have: 5.0431\n",
      "  which have been: 5.0431\n",
      "  with: 2.0726\n",
      "  with supervised: 5.0431\n",
      "  with supervised learning: 5.0431\n",
      "\n",
      "Document 11:\n",
      "  a: 1.2589\n",
      "  a scientific: 5.0431\n",
      "  a scientific endeavour: 5.0431\n",
      "  academic: 5.0431\n",
      "  academic discipline: 5.0431\n",
      "  academic discipline some: 5.0431\n",
      "  ai: 6.8672\n",
      "  ai as: 5.0431\n",
      "  ai as an: 5.0431\n",
      "  ai in: 4.6376\n",
      "  ai in the: 5.0431\n",
      "  also: 2.6452\n",
      "  also employed: 5.0431\n",
      "  also employed especially: 5.0431\n",
      "  an: 2.1527\n",
      "  an academic: 5.0431\n",
      "  an academic discipline: 5.0431\n",
      "  and: 1.2144\n",
      "  and other: 4.6376\n",
      "  and other models: 5.0431\n",
      "  approach: 3.6568\n",
      "  approach the: 5.0431\n",
      "  approach the problem: 5.0431\n",
      "  artificial: 2.7918\n",
      "  artificial intelligence: 3.5390\n",
      "  artificial intelligence ai: 4.6376\n",
      "  as: 7.3775\n",
      "  as a: 2.9030\n",
      "  as a scientific: 5.0431\n",
      "  as an: 4.6376\n",
      "  as an academic: 5.0431\n",
      "  as well: 4.1268\n",
      "  as well as: 4.6376\n",
      "  as what: 5.0431\n",
      "  as what were: 5.0431\n",
      "  attempted: 5.0431\n",
      "  attempted to: 5.0431\n",
      "  attempted to approach: 5.0431\n",
      "  automated: 4.3499\n",
      "  automated medical: 5.0431\n",
      "  automated medical diagnosis: 5.0431\n",
      "  be: 2.0726\n",
      "  be reinventions: 5.0431\n",
      "  be reinventions of: 5.0431\n",
      "  data: 1.8650\n",
      "  data they: 5.0431\n",
      "  data they attempted: 5.0431\n",
      "  days: 5.0431\n",
      "  days of: 5.0431\n",
      "  days of ai: 5.0431\n",
      "  diagnosis: 4.6376\n",
      "  discipline: 5.0431\n",
      "  discipline some: 5.0431\n",
      "  discipline some researchers: 5.0431\n",
      "  early: 4.3499\n",
      "  early days: 5.0431\n",
      "  early days of: 5.0431\n",
      "  employed: 4.3499\n",
      "  employed especially: 5.0431\n",
      "  employed especially in: 5.0431\n",
      "  endeavour: 5.0431\n",
      "  endeavour machine: 5.0431\n",
      "  endeavour machine learning: 5.0431\n",
      "  especially: 4.1268\n",
      "  especially in: 4.6376\n",
      "  especially in automated: 5.0431\n",
      "  for: 1.7289\n",
      "  for artificial: 5.0431\n",
      "  for artificial intelligence: 5.0431\n",
      "  found: 3.7903\n",
      "  found to: 4.6376\n",
      "  found to be: 5.0431\n",
      "  from: 2.0726\n",
      "  from data: 3.9444\n",
      "  from data they: 5.0431\n",
      "  generalised: 5.0431\n",
      "  generalised linear: 5.0431\n",
      "  generalised linear models: 5.0431\n",
      "  grew: 5.0431\n",
      "  grew out: 5.0431\n",
      "  grew out of: 5.0431\n",
      "  having: 4.3499\n",
      "  having machines: 5.0431\n",
      "  having machines learn: 5.0431\n",
      "  in: 4.0252\n",
      "  in automated: 5.0431\n",
      "  in automated medical: 5.0431\n",
      "  in having: 5.0431\n",
      "  in having machines: 5.0431\n",
      "  in the: 2.4404\n",
      "  in the early: 5.0431\n",
      "  intelligence: 3.1712\n",
      "  intelligence ai: 4.6376\n",
      "  intelligence ai in: 4.6376\n",
      "  interested: 5.0431\n",
      "  interested in: 5.0431\n",
      "  interested in having: 5.0431\n",
      "  later: 5.0431\n",
      "  later found: 5.0431\n",
      "  later found to: 5.0431\n",
      "  learn: 3.3383\n",
      "  learn from: 4.1268\n",
      "  learn from data: 4.6376\n",
      "  learning: 1.2819\n",
      "  learning grew: 5.0431\n",
      "  learning grew out: 5.0431\n",
      "  linear: 3.7903\n",
      "  linear models: 5.0431\n",
      "  linear models of: 5.0431\n",
      "  machine: 1.4735\n",
      "  machine learning: 1.5618\n",
      "  machine learning grew: 5.0431\n",
      "  machines: 3.6568\n",
      "  machines learn: 5.0431\n",
      "  machines learn from: 5.0431\n",
      "  medical: 3.7903\n",
      "  medical diagnosis: 4.6376\n",
      "  methods: 2.7405\n",
      "  methods as: 4.6376\n",
      "  methods as well: 5.0431\n",
      "  models: 5.1163\n",
      "  models of: 4.3499\n",
      "  models of statistics: 5.0431\n",
      "  models that: 4.3499\n",
      "  models that were: 5.0431\n",
      "  mostly: 4.6376\n",
      "  mostly perceptrons: 5.0431\n",
      "  mostly perceptrons and: 5.0431\n",
      "  networks: 3.0971\n",
      "  networks these: 4.6376\n",
      "  networks these were: 5.0431\n",
      "  neural: 3.0281\n",
      "  neural networks: 3.2513\n",
      "  neural networks these: 4.6376\n",
      "  of: 4.8576\n",
      "  of ai: 4.1268\n",
      "  of ai as: 5.0431\n",
      "  of statistics: 5.0431\n",
      "  of statistics probabilistic: 5.0431\n",
      "  of the: 4.6044\n",
      "  of the generalised: 5.0431\n",
      "  of the quest: 5.0431\n",
      "  other: 2.7918\n",
      "  other models: 5.0431\n",
      "  other models that: 5.0431\n",
      "  out: 3.7903\n",
      "  out of: 4.3499\n",
      "  out of the: 4.6376\n",
      "  perceptrons: 4.6376\n",
      "  perceptrons and: 4.6376\n",
      "  perceptrons and other: 5.0431\n",
      "  probabilistic: 3.9444\n",
      "  probabilistic reasoning: 5.0431\n",
      "  probabilistic reasoning was: 5.0431\n",
      "  problem: 3.9444\n",
      "  problem with: 5.0431\n",
      "  problem with various: 5.0431\n",
      "  quest: 5.0431\n",
      "  quest for: 5.0431\n",
      "  quest for artificial: 5.0431\n",
      "  reasoning: 4.6376\n",
      "  reasoning was: 5.0431\n",
      "  reasoning was also: 5.0431\n",
      "  reinventions: 5.0431\n",
      "  reinventions of: 5.0431\n",
      "  reinventions of the: 5.0431\n",
      "  researchers: 3.6568\n",
      "  researchers were: 5.0431\n",
      "  researchers were interested: 5.0431\n",
      "  scientific: 5.0431\n",
      "  scientific endeavour: 5.0431\n",
      "  scientific endeavour machine: 5.0431\n",
      "  some: 2.9636\n",
      "  some researchers: 4.6376\n",
      "  some researchers were: 5.0431\n",
      "  statistics: 3.6568\n",
      "  statistics probabilistic: 5.0431\n",
      "  statistics probabilistic reasoning: 5.0431\n",
      "  symbolic: 4.6376\n",
      "  symbolic methods: 5.0431\n",
      "  symbolic methods as: 5.0431\n",
      "  termed: 5.0431\n",
      "  termed neural: 5.0431\n",
      "  termed neural networks: 5.0431\n",
      "  that: 1.6758\n",
      "  that were: 4.6376\n",
      "  that were later: 5.0431\n",
      "  the: 4.7716\n",
      "  the early: 4.3499\n",
      "  the early days: 5.0431\n",
      "  the generalised: 5.0431\n",
      "  the generalised linear: 5.0431\n",
      "  the problem: 4.3499\n",
      "  the problem with: 5.0431\n",
      "  the quest: 5.0431\n",
      "  the quest for: 5.0431\n",
      "  then: 3.9444\n",
      "  then termed: 5.0431\n",
      "  then termed neural: 5.0431\n",
      "  these: 2.9030\n",
      "  these were: 5.0431\n",
      "  these were mostly: 5.0431\n",
      "  they: 3.4336\n",
      "  they attempted: 5.0431\n",
      "  they attempted to: 5.0431\n",
      "  to: 2.4507\n",
      "  to approach: 5.0431\n",
      "  to approach the: 5.0431\n",
      "  to be: 3.4336\n",
      "  to be reinventions: 5.0431\n",
      "  various: 3.4336\n",
      "  various symbolic: 5.0431\n",
      "  various symbolic methods: 5.0431\n",
      "  was: 3.3383\n",
      "  was also: 4.3499\n",
      "  was also employed: 5.0431\n",
      "  well: 3.9444\n",
      "  well as: 4.6376\n",
      "  well as what: 5.0431\n",
      "  were: 15.1612\n",
      "  were interested: 5.0431\n",
      "  were interested in: 5.0431\n",
      "  were later: 5.0431\n",
      "  were later found: 5.0431\n",
      "  were mostly: 5.0431\n",
      "  were mostly perceptrons: 5.0431\n",
      "  were then: 5.0431\n",
      "  were then termed: 5.0431\n",
      "  what: 4.3499\n",
      "  what were: 5.0431\n",
      "  what were then: 5.0431\n",
      "  with: 2.0726\n",
      "  with various: 5.0431\n",
      "  with various symbolic: 5.0431\n",
      "\n",
      "Document 12:\n",
      "  a: 1.2589\n",
      "  a rift: 5.0431\n",
      "  a rift between: 5.0431\n",
      "  abandoned: 5.0431\n",
      "  abandoned by: 5.0431\n",
      "  abandoned by ai: 5.0431\n",
      "  acquisition: 5.0431\n",
      "  acquisition and: 5.0431\n",
      "  acquisition and representation: 5.0431\n",
      "  ai: 17.1681\n",
      "  ai and: 13.9128\n",
      "  ai and computer: 5.0431\n",
      "  ai and machine: 5.0431\n",
      "  ai and statistics: 5.0431\n",
      "  ai leading: 5.0431\n",
      "  ai leading to: 5.0431\n",
      "  ai proper: 5.0431\n",
      "  ai proper in: 5.0431\n",
      "  aics: 5.0431\n",
      "  aics field: 5.0431\n",
      "  aics field as: 5.0431\n",
      "  an: 2.1527\n",
      "  an increasing: 5.0431\n",
      "  an increasing emphasis: 5.0431\n",
      "  and: 8.5009\n",
      "  and computer: 4.6376\n",
      "  and computer science: 5.0431\n",
      "  and geoffrey: 5.0431\n",
      "  and geoffrey hinton: 5.0431\n",
      "  and information: 5.0431\n",
      "  and information retrieval: 5.0431\n",
      "  and machine: 4.3499\n",
      "  and machine learning: 4.3499\n",
      "  and practical: 5.0431\n",
      "  and practical problems: 5.0431\n",
      "  and representation: 4.6376\n",
      "  and representation by: 5.0431\n",
      "  and statistics: 4.6376\n",
      "  and statistics was: 5.0431\n",
      "  approach: 3.6568\n",
      "  approach caused: 5.0431\n",
      "  approach caused a: 5.0431\n",
      "  around: 4.6376\n",
      "  around the: 4.6376\n",
      "  around the same: 5.0431\n",
      "  as: 1.8444\n",
      "  as connectionism: 5.0431\n",
      "  as connectionism by: 5.0431\n",
      "  backpropagation: 5.0431\n",
      "  been: 2.6917\n",
      "  been abandoned: 5.0431\n",
      "  been abandoned by: 5.0431\n",
      "  between: 2.9636\n",
      "  between ai: 5.0431\n",
      "  between ai and: 5.0431\n",
      "  but: 3.0281\n",
      "  but the: 4.1268\n",
      "  but the more: 5.0431\n",
      "  by: 7.6302\n",
      "  by ai: 5.0431\n",
      "  by ai and: 5.0431\n",
      "  by expert: 5.0431\n",
      "  by expert systems: 5.0431\n",
      "  by researchers: 5.0431\n",
      "  by researchers from: 5.0431\n",
      "  by theoretical: 5.0431\n",
      "  by theoretical and: 5.0431\n",
      "  came: 5.0431\n",
      "  came in: 5.0431\n",
      "  came in the: 5.0431\n",
      "  caused: 4.6376\n",
      "  caused a: 5.0431\n",
      "  caused a rift: 5.0431\n",
      "  come: 4.3499\n",
      "  come to: 5.0431\n",
      "  come to dominate: 5.0431\n",
      "  computer: 3.2513\n",
      "  computer science: 4.6376\n",
      "  computer science around: 5.0431\n",
      "  connectionism: 5.0431\n",
      "  connectionism by: 5.0431\n",
      "  connectionism by researchers: 5.0431\n",
      "  continue: 5.0431\n",
      "  continue within: 5.0431\n",
      "  continue within ai: 5.0431\n",
      "  continued: 4.6376\n",
      "  continued outside: 5.0431\n",
      "  continued outside the: 5.0431\n",
      "  data: 1.8650\n",
      "  data acquisition: 5.0431\n",
      "  data acquisition and: 5.0431\n",
      "  david: 5.0431\n",
      "  david rumelhart: 5.0431\n",
      "  david rumelhart and: 5.0431\n",
      "  did: 5.0431\n",
      "  did continue: 5.0431\n",
      "  did continue within: 5.0431\n",
      "  disciplines: 4.6376\n",
      "  disciplines including: 5.0431\n",
      "  disciplines including john: 5.0431\n",
      "  dominate: 5.0431\n",
      "  dominate ai: 5.0431\n",
      "  dominate ai and: 5.0431\n",
      "  emphasis: 5.0431\n",
      "  emphasis on: 5.0431\n",
      "  emphasis on the: 5.0431\n",
      "  expert: 5.0431\n",
      "  expert systems: 5.0431\n",
      "  expert systems had: 5.0431\n",
      "  favour: 5.0431\n",
      "  favour work: 5.0431\n",
      "  favour work on: 5.0431\n",
      "  field: 5.9272\n",
      "  field as: 5.0431\n",
      "  field as connectionism: 5.0431\n",
      "  field of: 3.5390\n",
      "  field of ai: 4.6376\n",
      "  from: 2.0726\n",
      "  from other: 5.0431\n",
      "  from other disciplines: 5.0431\n",
      "  geoffrey: 5.0431\n",
      "  geoffrey hinton: 5.0431\n",
      "  geoffrey hinton their: 5.0431\n",
      "  had: 7.3135\n",
      "  had been: 4.1268\n",
      "  had been abandoned: 5.0431\n",
      "  had come: 5.0431\n",
      "  had come to: 5.0431\n",
      "  hinton: 5.0431\n",
      "  hinton their: 5.0431\n",
      "  hinton their main: 5.0431\n",
      "  hopfield: 5.0431\n",
      "  hopfield david: 5.0431\n",
      "  hopfield david rumelhart: 5.0431\n",
      "  however: 3.7903\n",
      "  however an: 5.0431\n",
      "  however an increasing: 5.0431\n",
      "  in: 2.6835\n",
      "  in pattern: 5.0431\n",
      "  in pattern recognition: 5.0431\n",
      "  in the: 2.4404\n",
      "  in the mids: 5.0431\n",
      "  including: 3.4336\n",
      "  including john: 5.0431\n",
      "  including john hopfield: 5.0431\n",
      "  increasing: 4.6376\n",
      "  increasing emphasis: 5.0431\n",
      "  increasing emphasis on: 5.0431\n",
      "  inductive: 4.3499\n",
      "  inductive logic: 4.3499\n",
      "  inductive logic programmingilp: 5.0431\n",
      "  information: 3.7903\n",
      "  information retrieval: 5.0431\n",
      "  information retrieval neural: 5.0431\n",
      "  john: 5.0431\n",
      "  john hopfield: 5.0431\n",
      "  john hopfield david: 5.0431\n",
      "  knowledgebased: 5.0431\n",
      "  knowledgebased approach: 5.0431\n",
      "  knowledgebased approach caused: 5.0431\n",
      "  leading: 4.1268\n",
      "  leading to: 4.1268\n",
      "  leading to inductive: 5.0431\n",
      "  learning: 2.5637\n",
      "  learning did: 5.0431\n",
      "  learning did continue: 5.0431\n",
      "  learning probabilistic: 5.0431\n",
      "  learning probabilistic systems: 5.0431\n",
      "  line: 9.2752\n",
      "  line of: 5.0431\n",
      "  line of research: 5.0431\n",
      "  line too: 5.0431\n",
      "  line too was: 5.0431\n",
      "  logic: 4.1268\n",
      "  logic programmingilp: 5.0431\n",
      "  logic programmingilp but: 5.0431\n",
      "  logical: 4.3499\n",
      "  logical knowledgebased: 5.0431\n",
      "  logical knowledgebased approach: 5.0431\n",
      "  machine: 1.4735\n",
      "  machine learning: 1.5618\n",
      "  machine learning probabilistic: 5.0431\n",
      "  main: 5.0431\n",
      "  main success: 5.0431\n",
      "  main success came: 5.0431\n",
      "  mids: 5.0431\n",
      "  mids with: 5.0431\n",
      "  mids with the: 5.0431\n",
      "  more: 3.1712\n",
      "  more statistical: 5.0431\n",
      "  more statistical line: 5.0431\n",
      "  networks: 3.0971\n",
      "  networks research: 5.0431\n",
      "  networks research had: 5.0431\n",
      "  neural: 3.0281\n",
      "  neural networks: 3.2513\n",
      "  neural networks research: 5.0431\n",
      "  now: 4.6376\n",
      "  now outside: 5.0431\n",
      "  now outside the: 5.0431\n",
      "  of: 6.0720\n",
      "  of ai: 4.1268\n",
      "  of ai proper: 5.0431\n",
      "  of backpropagation: 5.0431\n",
      "  of data: 3.6568\n",
      "  of data acquisition: 5.0431\n",
      "  of favour: 5.0431\n",
      "  of favour work: 5.0431\n",
      "  of research: 5.0431\n",
      "  of research was: 5.0431\n",
      "  on: 4.0946\n",
      "  on symbolicknowledgebased: 5.0431\n",
      "  on symbolicknowledgebased learning: 5.0431\n",
      "  on the: 3.2513\n",
      "  on the logical: 5.0431\n",
      "  other: 2.7918\n",
      "  other disciplines: 4.6376\n",
      "  other disciplines including: 5.0431\n",
      "  out: 3.7903\n",
      "  out of: 4.3499\n",
      "  out of favour: 5.0431\n",
      "  outside: 10.0861\n",
      "  outside the: 10.0861\n",
      "  outside the aics: 5.0431\n",
      "  outside the field: 5.0431\n",
      "  pattern: 4.1268\n",
      "  pattern recognition: 4.6376\n",
      "  pattern recognition and: 5.0431\n",
      "  plagued: 5.0431\n",
      "  plagued by: 5.0431\n",
      "  plagued by theoretical: 5.0431\n",
      "  practical: 4.6376\n",
      "  practical problems: 5.0431\n",
      "  practical problems of: 5.0431\n",
      "  probabilistic: 3.9444\n",
      "  probabilistic systems: 5.0431\n",
      "  probabilistic systems were: 5.0431\n",
      "  problems: 3.1712\n",
      "  problems of: 4.6376\n",
      "  problems of data: 5.0431\n",
      "  programmingilp: 5.0431\n",
      "  programmingilp but: 5.0431\n",
      "  programmingilp but the: 5.0431\n",
      "  proper: 5.0431\n",
      "  proper in: 5.0431\n",
      "  proper in pattern: 5.0431\n",
      "  recognition: 3.9444\n",
      "  recognition and: 5.0431\n",
      "  recognition and information: 5.0431\n",
      "  reinvention: 5.0431\n",
      "  reinvention of: 5.0431\n",
      "  reinvention of backpropagation: 5.0431\n",
      "  representation: 3.9444\n",
      "  representation by: 5.0431\n",
      "  representation by expert: 5.0431\n",
      "  research: 6.8672\n",
      "  research had: 5.0431\n",
      "  research had been: 5.0431\n",
      "  research was: 5.0431\n",
      "  research was now: 5.0431\n",
      "  researchers: 3.6568\n",
      "  researchers from: 4.6376\n",
      "  researchers from other: 5.0431\n",
      "  retrieval: 5.0431\n",
      "  retrieval neural: 5.0431\n",
      "  retrieval neural networks: 5.0431\n",
      "  rift: 5.0431\n",
      "  rift between: 5.0431\n",
      "  rift between ai: 5.0431\n",
      "  rumelhart: 5.0431\n",
      "  rumelhart and: 5.0431\n",
      "  rumelhart and geoffrey: 5.0431\n",
      "  same: 3.9444\n",
      "  same time: 5.0431\n",
      "  same time this: 5.0431\n",
      "  science: 4.3499\n",
      "  science around: 5.0431\n",
      "  science around the: 5.0431\n",
      "  statistical: 3.4336\n",
      "  statistical line: 5.0431\n",
      "  statistical line of: 5.0431\n",
      "  statistics: 3.6568\n",
      "  statistics was: 5.0431\n",
      "  statistics was out: 5.0431\n",
      "  success: 5.0431\n",
      "  success came: 5.0431\n",
      "  success came in: 5.0431\n",
      "  symbolicknowledgebased: 5.0431\n",
      "  symbolicknowledgebased learning: 5.0431\n",
      "  symbolicknowledgebased learning did: 5.0431\n",
      "  systems: 5.3834\n",
      "  systems had: 5.0431\n",
      "  systems had come: 5.0431\n",
      "  systems were: 5.0431\n",
      "  systems were plagued: 5.0431\n",
      "  the: 8.3503\n",
      "  the aics: 5.0431\n",
      "  the aics field: 5.0431\n",
      "  the field: 3.4336\n",
      "  the field of: 3.7903\n",
      "  the logical: 5.0431\n",
      "  the logical knowledgebased: 5.0431\n",
      "  the mids: 5.0431\n",
      "  the mids with: 5.0431\n",
      "  the more: 4.6376\n",
      "  the more statistical: 5.0431\n",
      "  the reinvention: 5.0431\n",
      "  the reinvention of: 5.0431\n",
      "  the same: 3.9444\n",
      "  the same time: 5.0431\n",
      "  their: 2.7918\n",
      "  their main: 5.0431\n",
      "  their main success: 5.0431\n",
      "  theoretical: 3.6568\n",
      "  theoretical and: 5.0431\n",
      "  theoretical and practical: 5.0431\n",
      "  this: 2.6007\n",
      "  this line: 5.0431\n",
      "  this line too: 5.0431\n",
      "  time: 3.5390\n",
      "  time this: 5.0431\n",
      "  time this line: 5.0431\n",
      "  to: 2.4507\n",
      "  to dominate: 5.0431\n",
      "  to dominate ai: 5.0431\n",
      "  to inductive: 5.0431\n",
      "  to inductive logic: 5.0431\n",
      "  too: 4.6376\n",
      "  too was: 5.0431\n",
      "  too was continued: 5.0431\n",
      "  was: 10.0149\n",
      "  was continued: 5.0431\n",
      "  was continued outside: 5.0431\n",
      "  was now: 5.0431\n",
      "  was now outside: 5.0431\n",
      "  was out: 5.0431\n",
      "  was out of: 5.0431\n",
      "  were: 3.7903\n",
      "  were plagued: 5.0431\n",
      "  were plagued by: 5.0431\n",
      "  with: 2.0726\n",
      "  with the: 3.5390\n",
      "  with the reinvention: 5.0431\n",
      "  within: 3.4336\n",
      "  within ai: 4.6376\n",
      "  within ai leading: 5.0431\n",
      "  work: 4.1268\n",
      "  work on: 4.6376\n",
      "  work on symbolicknowledgebased: 5.0431\n",
      "\n",
      "Document 13:\n",
      "  a: 1.2589\n",
      "  a practical: 5.0431\n",
      "  a practical nature: 5.0431\n",
      "  achieving: 5.0431\n",
      "  achieving artificial: 5.0431\n",
      "  achieving artificial intelligence: 5.0431\n",
      "  ai: 3.4336\n",
      "  ai and: 4.6376\n",
      "  ai and toward: 5.0431\n",
      "  and: 4.8576\n",
      "  and models: 4.6376\n",
      "  and models borrowed: 5.0431\n",
      "  and probability: 5.0431\n",
      "  and probability theory: 5.0431\n",
      "  and recognised: 5.0431\n",
      "  and recognised as: 5.0431\n",
      "  and toward: 5.0431\n",
      "  and toward methods: 5.0431\n",
      "  approaches: 3.5390\n",
      "  approaches it: 5.0431\n",
      "  approaches it had: 5.0431\n",
      "  artificial: 2.7918\n",
      "  artificial intelligence: 3.5390\n",
      "  artificial intelligence to: 4.6376\n",
      "  as: 1.8444\n",
      "  as its: 5.0431\n",
      "  as its own: 5.0431\n",
      "  away: 5.0431\n",
      "  away from: 5.0431\n",
      "  away from the: 5.0431\n",
      "  borrowed: 5.0431\n",
      "  borrowed from: 5.0431\n",
      "  borrowed from statistics: 5.0431\n",
      "  changed: 4.6376\n",
      "  changed its: 5.0431\n",
      "  changed its goal: 5.0431\n",
      "  field: 5.9272\n",
      "  field changed: 5.0431\n",
      "  field changed its: 5.0431\n",
      "  field started: 5.0431\n",
      "  field started to: 5.0431\n",
      "  flourish: 5.0431\n",
      "  flourish in: 5.0431\n",
      "  flourish in the: 5.0431\n",
      "  focus: 4.6376\n",
      "  focus away: 5.0431\n",
      "  focus away from: 5.0431\n",
      "  from: 8.2905\n",
      "  from achieving: 5.0431\n",
      "  from achieving artificial: 5.0431\n",
      "  from ai: 5.0431\n",
      "  from ai and: 5.0431\n",
      "  from statistics: 5.0431\n",
      "  from statistics fuzzy: 5.0431\n",
      "  from the: 3.3383\n",
      "  from the symbolic: 5.0431\n",
      "  fuzzy: 5.0431\n",
      "  fuzzy logic: 5.0431\n",
      "  fuzzy logic and: 5.0431\n",
      "  goal: 4.1268\n",
      "  goal from: 5.0431\n",
      "  goal from achieving: 5.0431\n",
      "  had: 3.6568\n",
      "  had inherited: 5.0431\n",
      "  had inherited from: 5.0431\n",
      "  in: 1.3417\n",
      "  in the: 2.4404\n",
      "  in the s: 4.3499\n",
      "  inherited: 5.0431\n",
      "  inherited from: 5.0431\n",
      "  inherited from ai: 5.0431\n",
      "  intelligence: 3.1712\n",
      "  intelligence to: 4.6376\n",
      "  intelligence to tackling: 5.0431\n",
      "  it: 4.5409\n",
      "  it had: 5.0431\n",
      "  it had inherited: 5.0431\n",
      "  it shifted: 5.0431\n",
      "  it shifted focus: 5.0431\n",
      "  its: 5.9272\n",
      "  its goal: 5.0431\n",
      "  its goal from: 5.0431\n",
      "  its own: 5.0431\n",
      "  its own field: 5.0431\n",
      "  learning: 1.2819\n",
      "  learning ml: 4.6376\n",
      "  learning ml reorganised: 5.0431\n",
      "  logic: 4.1268\n",
      "  logic and: 5.0431\n",
      "  logic and probability: 5.0431\n",
      "  machine: 1.4735\n",
      "  machine learning: 1.5618\n",
      "  machine learning ml: 4.6376\n",
      "  methods: 2.7405\n",
      "  methods and: 4.6376\n",
      "  methods and models: 5.0431\n",
      "  ml: 4.3499\n",
      "  ml reorganised: 5.0431\n",
      "  ml reorganised and: 5.0431\n",
      "  models: 2.5581\n",
      "  models borrowed: 5.0431\n",
      "  models borrowed from: 5.0431\n",
      "  nature: 4.1268\n",
      "  nature it: 5.0431\n",
      "  nature it shifted: 5.0431\n",
      "  of: 1.2144\n",
      "  of a: 3.0281\n",
      "  of a practical: 5.0431\n",
      "  own: 5.0431\n",
      "  own field: 5.0431\n",
      "  own field started: 5.0431\n",
      "  practical: 4.6376\n",
      "  practical nature: 5.0431\n",
      "  practical nature it: 5.0431\n",
      "  probability: 4.3499\n",
      "  probability theory: 5.0431\n",
      "  problems: 3.1712\n",
      "  problems of: 4.6376\n",
      "  problems of a: 5.0431\n",
      "  recognised: 5.0431\n",
      "  recognised as: 5.0431\n",
      "  recognised as its: 5.0431\n",
      "  reorganised: 5.0431\n",
      "  reorganised and: 5.0431\n",
      "  reorganised and recognised: 5.0431\n",
      "  s: 3.9444\n",
      "  s the: 5.0431\n",
      "  s the field: 5.0431\n",
      "  shifted: 5.0431\n",
      "  shifted focus: 5.0431\n",
      "  shifted focus away: 5.0431\n",
      "  solvable: 5.0431\n",
      "  solvable problems: 5.0431\n",
      "  solvable problems of: 5.0431\n",
      "  started: 5.0431\n",
      "  started to: 5.0431\n",
      "  started to flourish: 5.0431\n",
      "  statistics: 3.6568\n",
      "  statistics fuzzy: 5.0431\n",
      "  statistics fuzzy logic: 5.0431\n",
      "  symbolic: 4.6376\n",
      "  symbolic approaches: 5.0431\n",
      "  symbolic approaches it: 5.0431\n",
      "  tackling: 5.0431\n",
      "  tackling solvable: 5.0431\n",
      "  tackling solvable problems: 5.0431\n",
      "  the: 3.5787\n",
      "  the field: 3.4336\n",
      "  the field changed: 5.0431\n",
      "  the s: 3.9444\n",
      "  the s the: 5.0431\n",
      "  the symbolic: 5.0431\n",
      "  the symbolic approaches: 5.0431\n",
      "  theory: 3.3383\n",
      "  to: 2.4507\n",
      "  to flourish: 5.0431\n",
      "  to flourish in: 5.0431\n",
      "  to tackling: 5.0431\n",
      "  to tackling solvable: 5.0431\n",
      "  toward: 4.3499\n",
      "  toward methods: 5.0431\n",
      "  toward methods and: 5.0431\n",
      "\n",
      "Document 14:\n",
      "  a: 6.2943\n",
      "  a benchmark: 5.0431\n",
      "  a benchmark for: 5.0431\n",
      "  a close: 5.0431\n",
      "  a close connection: 5.0431\n",
      "  a justification: 5.0431\n",
      "  a justification for: 5.0431\n",
      "  a sequence: 5.0431\n",
      "  a sequence given: 5.0431\n",
      "  a system: 4.3499\n",
      "  a system that: 5.0431\n",
      "  an: 2.1527\n",
      "  an optimal: 4.6376\n",
      "  an optimal compressor: 5.0431\n",
      "  and: 1.2144\n",
      "  and compression: 5.0431\n",
      "  and compression a: 5.0431\n",
      "  arithmetic: 5.0431\n",
      "  arithmetic coding: 5.0431\n",
      "  arithmetic coding on: 5.0431\n",
      "  as: 3.6888\n",
      "  as a: 5.8060\n",
      "  as a benchmark: 5.0431\n",
      "  as a justification: 5.0431\n",
      "  be: 4.1453\n",
      "  be used: 6.8672\n",
      "  be used for: 10.0861\n",
      "  been: 2.6917\n",
      "  been used: 3.9444\n",
      "  been used as: 4.6376\n",
      "  benchmark: 5.0431\n",
      "  benchmark for: 5.0431\n",
      "  benchmark for general: 5.0431\n",
      "  best: 3.6568\n",
      "  best given: 5.0431\n",
      "  best given the: 5.0431\n",
      "  between: 2.9636\n",
      "  between machine: 5.0431\n",
      "  between machine learning: 5.0431\n",
      "  by: 3.8151\n",
      "  by finding: 5.0431\n",
      "  by finding the: 5.0431\n",
      "  by using: 5.0431\n",
      "  by using arithmetic: 5.0431\n",
      "  can: 4.3617\n",
      "  can be: 5.4809\n",
      "  can be used: 7.3135\n",
      "  close: 5.0431\n",
      "  close connection: 5.0431\n",
      "  close connection between: 5.0431\n",
      "  coding: 4.6376\n",
      "  coding on: 5.0431\n",
      "  coding on the: 5.0431\n",
      "  compresses: 5.0431\n",
      "  compresses best: 5.0431\n",
      "  compresses best given: 5.0431\n",
      "  compression: 11.3709\n",
      "  compression a: 5.0431\n",
      "  compression a system: 5.0431\n",
      "  compression as: 5.0431\n",
      "  compression as a: 5.0431\n",
      "  compression by: 5.0431\n",
      "  compression by using: 5.0431\n",
      "  compressor: 4.6376\n",
      "  compressor can: 5.0431\n",
      "  compressor can be: 5.0431\n",
      "  connection: 4.3499\n",
      "  connection between: 4.6376\n",
      "  connection between machine: 5.0431\n",
      "  conversely: 4.6376\n",
      "  conversely an: 5.0431\n",
      "  conversely an optimal: 5.0431\n",
      "  data: 3.7300\n",
      "  data compression: 9.2752\n",
      "  data compression as: 5.0431\n",
      "  data compression by: 5.0431\n",
      "  distribution: 3.9444\n",
      "  distribution conversely: 5.0431\n",
      "  distribution conversely an: 5.0431\n",
      "  entire: 5.0431\n",
      "  entire history: 5.0431\n",
      "  entire history can: 5.0431\n",
      "  equivalence: 5.0431\n",
      "  equivalence has: 5.0431\n",
      "  equivalence has been: 5.0431\n",
      "  finding: 4.3499\n",
      "  finding the: 5.0431\n",
      "  finding the symbol: 5.0431\n",
      "  for: 6.9155\n",
      "  for general: 5.0431\n",
      "  for general intelligence: 5.0431\n",
      "  for optimal: 4.6376\n",
      "  for optimal data: 5.0431\n",
      "  for prediction: 5.0431\n",
      "  for prediction by: 5.0431\n",
      "  for using: 5.0431\n",
      "  for using data: 5.0431\n",
      "  general: 3.9444\n",
      "  general intelligence: 5.0431\n",
      "  given: 6.6766\n",
      "  given its: 5.0431\n",
      "  given its entire: 5.0431\n",
      "  given the: 5.0431\n",
      "  given the previous: 5.0431\n",
      "  has: 2.8458\n",
      "  has been: 3.6568\n",
      "  has been used: 4.6376\n",
      "  history: 8.6998\n",
      "  history can: 5.0431\n",
      "  history can be: 5.0431\n",
      "  history this: 5.0431\n",
      "  history this equivalence: 5.0431\n",
      "  intelligence: 3.1712\n",
      "  is: 1.5167\n",
      "  is a: 2.5173\n",
      "  is a close: 5.0431\n",
      "  its: 2.9636\n",
      "  its entire: 5.0431\n",
      "  its entire history: 5.0431\n",
      "  justification: 5.0431\n",
      "  justification for: 5.0431\n",
      "  justification for using: 5.0431\n",
      "  learning: 1.2819\n",
      "  learning and: 3.6568\n",
      "  learning and compression: 5.0431\n",
      "  machine: 1.4735\n",
      "  machine learning: 1.5618\n",
      "  machine learning and: 4.1268\n",
      "  of: 1.2144\n",
      "  of a: 3.0281\n",
      "  of a sequence: 5.0431\n",
      "  on: 2.0473\n",
      "  on the: 3.2513\n",
      "  on the output: 5.0431\n",
      "  optimal: 8.6998\n",
      "  optimal compressor: 5.0431\n",
      "  optimal compressor can: 5.0431\n",
      "  optimal data: 5.0431\n",
      "  optimal data compression: 5.0431\n",
      "  output: 3.3383\n",
      "  output distribution: 5.0431\n",
      "  output distribution conversely: 5.0431\n",
      "  posterior: 5.0431\n",
      "  posterior probabilities: 5.0431\n",
      "  posterior probabilities of: 5.0431\n",
      "  prediction: 3.7903\n",
      "  prediction by: 5.0431\n",
      "  prediction by finding: 5.0431\n",
      "  predicts: 4.6376\n",
      "  predicts the: 5.0431\n",
      "  predicts the posterior: 5.0431\n",
      "  previous: 4.1268\n",
      "  previous history: 5.0431\n",
      "  previous history this: 5.0431\n",
      "  probabilities: 4.3499\n",
      "  probabilities of: 4.6376\n",
      "  probabilities of a: 5.0431\n",
      "  sequence: 4.6376\n",
      "  sequence given: 5.0431\n",
      "  sequence given its: 5.0431\n",
      "  symbol: 5.0431\n",
      "  symbol that: 5.0431\n",
      "  symbol that compresses: 5.0431\n",
      "  system: 3.0281\n",
      "  system that: 4.6376\n",
      "  system that predicts: 5.0431\n",
      "  that: 3.3515\n",
      "  that compresses: 5.0431\n",
      "  that compresses best: 5.0431\n",
      "  that predicts: 4.6376\n",
      "  that predicts the: 5.0431\n",
      "  the: 4.7716\n",
      "  the output: 3.9444\n",
      "  the output distribution: 5.0431\n",
      "  the posterior: 5.0431\n",
      "  the posterior probabilities: 5.0431\n",
      "  the previous: 5.0431\n",
      "  the previous history: 5.0431\n",
      "  the symbol: 5.0431\n",
      "  the symbol that: 5.0431\n",
      "  there: 3.6568\n",
      "  there is: 4.3499\n",
      "  there is a: 4.6376\n",
      "  this: 2.6007\n",
      "  this equivalence: 5.0431\n",
      "  this equivalence has: 5.0431\n",
      "  used: 7.0050\n",
      "  used as: 4.1268\n",
      "  used as a: 4.6376\n",
      "  used for: 8.2535\n",
      "  used for optimal: 5.0431\n",
      "  used for prediction: 5.0431\n",
      "  using: 6.5026\n",
      "  using arithmetic: 5.0431\n",
      "  using arithmetic coding: 5.0431\n",
      "  using data: 5.0431\n",
      "  using data compression: 5.0431\n",
      "\n",
      "Document 15:\n",
      "  algorithms: 4.7378\n",
      "  algorithms implicitly: 5.0431\n",
      "  algorithms implicitly map: 5.0431\n",
      "  algorithms is: 4.6376\n",
      "  algorithms is precluded: 5.0431\n",
      "  all: 3.5390\n",
      "  all compression: 5.0431\n",
      "  all compression algorithms: 5.0431\n",
      "  alternative: 4.6376\n",
      "  alternative view: 5.0431\n",
      "  alternative view can: 5.0431\n",
      "  an: 8.6107\n",
      "  an alternative: 4.6376\n",
      "  an alternative view: 5.0431\n",
      "  an associated: 5.0431\n",
      "  an associated vector: 5.0431\n",
      "  an exhaustive: 5.0431\n",
      "  an exhaustive examination: 5.0431\n",
      "  an input: 4.6376\n",
      "  an input string: 5.0431\n",
      "  and: 2.4288\n",
      "  and compressionbased: 5.0431\n",
      "  and compressionbased similarity: 5.0431\n",
      "  and ppm: 5.0431\n",
      "  associated: 3.7903\n",
      "  associated vector: 5.0431\n",
      "  associated vector space: 5.0431\n",
      "  by: 1.9076\n",
      "  by space: 5.0431\n",
      "  by space instead: 5.0431\n",
      "  c: 10.0861\n",
      "  c maps: 5.0431\n",
      "  c maps an: 5.0431\n",
      "  c we: 5.0431\n",
      "  c we define: 5.0431\n",
      "  can: 2.1809\n",
      "  can show: 5.0431\n",
      "  can show compression: 5.0431\n",
      "  chooses: 5.0431\n",
      "  chooses to: 5.0431\n",
      "  chooses to examine: 5.0431\n",
      "  compression: 11.3709\n",
      "  compression algorithms: 10.0861\n",
      "  compression algorithms implicitly: 5.0431\n",
      "  compression algorithms is: 5.0431\n",
      "  compression methods: 5.0431\n",
      "  compression methods lzw: 5.0431\n",
      "  compressionbased: 5.0431\n",
      "  compressionbased similarity: 5.0431\n",
      "  compressionbased similarity measures: 5.0431\n",
      "  compressor: 4.6376\n",
      "  compressor c: 5.0431\n",
      "  compressor c we: 5.0431\n",
      "  compute: 4.3499\n",
      "  compute similarity: 5.0431\n",
      "  compute similarity within: 5.0431\n",
      "  corresponding: 4.6376\n",
      "  corresponding to: 5.0431\n",
      "  corresponding to the: 5.0431\n",
      "  define: 4.6376\n",
      "  define an: 5.0431\n",
      "  define an associated: 5.0431\n",
      "  each: 3.0971\n",
      "  each compressor: 5.0431\n",
      "  each compressor c: 5.0431\n",
      "  examination: 4.6376\n",
      "  examination of: 5.0431\n",
      "  examination of the: 5.0431\n",
      "  examine: 5.0431\n",
      "  examine three: 5.0431\n",
      "  examine three representative: 5.0431\n",
      "  exhaustive: 5.0431\n",
      "  exhaustive examination: 5.0431\n",
      "  exhaustive examination of: 5.0431\n",
      "  feature: 13.7345\n",
      "  feature space: 5.0431\n",
      "  feature space vectors: 5.0431\n",
      "  feature spaces: 9.2752\n",
      "  feature spaces for: 5.0431\n",
      "  feature spaces underlying: 5.0431\n",
      "  feature vectors: 5.0431\n",
      "  feature vectors chooses: 5.0431\n",
      "  for: 1.7289\n",
      "  for each: 4.6376\n",
      "  for each compressor: 5.0431\n",
      "  implicit: 5.0431\n",
      "  implicit feature: 5.0431\n",
      "  implicit feature space: 5.0431\n",
      "  implicitly: 4.3499\n",
      "  implicitly map: 4.6376\n",
      "  implicitly map strings: 5.0431\n",
      "  input: 3.0281\n",
      "  input string: 5.0431\n",
      "  input string x: 5.0431\n",
      "  instead: 4.1268\n",
      "  instead feature: 5.0431\n",
      "  instead feature vectors: 5.0431\n",
      "  into: 2.9636\n",
      "  into implicit: 5.0431\n",
      "  into implicit feature: 5.0431\n",
      "  is: 1.5167\n",
      "  is precluded: 5.0431\n",
      "  is precluded by: 5.0431\n",
      "  lossless: 5.0431\n",
      "  lossless compression: 5.0431\n",
      "  lossless compression methods: 5.0431\n",
      "  lz: 5.0431\n",
      "  lz and: 5.0431\n",
      "  lz and ppm: 5.0431\n",
      "  lzw: 5.0431\n",
      "  lzw lz: 5.0431\n",
      "  lzw lz and: 5.0431\n",
      "  map: 4.6376\n",
      "  map strings: 5.0431\n",
      "  map strings into: 5.0431\n",
      "  maps: 5.0431\n",
      "  maps an: 5.0431\n",
      "  maps an input: 5.0431\n",
      "  measures: 4.6376\n",
      "  measures compute: 5.0431\n",
      "  measures compute similarity: 5.0431\n",
      "  methods: 2.7405\n",
      "  methods lzw: 5.0431\n",
      "  methods lzw lz: 5.0431\n",
      "  norm: 5.0431\n",
      "  norm x: 5.0431\n",
      "  norm x an: 5.0431\n",
      "  of: 1.2144\n",
      "  of the: 2.3022\n",
      "  of the feature: 4.6376\n",
      "  ppm: 5.0431\n",
      "  precluded: 5.0431\n",
      "  precluded by: 5.0431\n",
      "  precluded by space: 5.0431\n",
      "  representative: 3.9444\n",
      "  representative lossless: 5.0431\n",
      "  representative lossless compression: 5.0431\n",
      "  show: 4.6376\n",
      "  show compression: 5.0431\n",
      "  show compression algorithms: 5.0431\n",
      "  similarity: 8.2535\n",
      "  similarity measures: 5.0431\n",
      "  similarity measures compute: 5.0431\n",
      "  similarity within: 5.0431\n",
      "  similarity within these: 5.0431\n",
      "  space: 11.3709\n",
      "  space instead: 5.0431\n",
      "  space instead feature: 5.0431\n",
      "  space vectors: 5.0431\n",
      "  space vectors and: 5.0431\n",
      "  space â„µ: 5.0431\n",
      "  space â„µ such: 5.0431\n",
      "  spaces: 9.2752\n",
      "  spaces for: 5.0431\n",
      "  spaces for each: 5.0431\n",
      "  spaces underlying: 5.0431\n",
      "  spaces underlying all: 5.0431\n",
      "  string: 5.0431\n",
      "  string x: 5.0431\n",
      "  string x corresponding: 5.0431\n",
      "  strings: 5.0431\n",
      "  strings into: 5.0431\n",
      "  strings into implicit: 5.0431\n",
      "  such: 2.4781\n",
      "  such that: 4.3499\n",
      "  such that c: 5.0431\n",
      "  that: 1.6758\n",
      "  that c: 5.0431\n",
      "  that c maps: 5.0431\n",
      "  the: 2.3858\n",
      "  the feature: 4.6376\n",
      "  the feature spaces: 5.0431\n",
      "  the vector: 5.0431\n",
      "  the vector norm: 5.0431\n",
      "  these: 2.9030\n",
      "  these feature: 5.0431\n",
      "  these feature spaces: 5.0431\n",
      "  three: 4.3499\n",
      "  three representative: 5.0431\n",
      "  three representative lossless: 5.0431\n",
      "  to: 2.4507\n",
      "  to examine: 5.0431\n",
      "  to examine three: 5.0431\n",
      "  to the: 3.1712\n",
      "  to the vector: 5.0431\n",
      "  underlying: 3.9444\n",
      "  underlying all: 5.0431\n",
      "  underlying all compression: 5.0431\n",
      "  vector: 8.6998\n",
      "  vector norm: 5.0431\n",
      "  vector norm x: 5.0431\n",
      "  vector space: 5.0431\n",
      "  vector space â„µ: 5.0431\n",
      "  vectors: 9.2752\n",
      "  vectors and: 5.0431\n",
      "  vectors and compressionbased: 5.0431\n",
      "  vectors chooses: 5.0431\n",
      "  vectors chooses to: 5.0431\n",
      "  view: 5.0431\n",
      "  view can: 5.0431\n",
      "  view can show: 5.0431\n",
      "  we: 4.3499\n",
      "  we define: 5.0431\n",
      "  we define an: 5.0431\n",
      "  within: 3.4336\n",
      "  within these: 5.0431\n",
      "  within these feature: 5.0431\n",
      "  x: 9.2752\n",
      "  x an: 5.0431\n",
      "  x an exhaustive: 5.0431\n",
      "  x corresponding: 5.0431\n",
      "  x corresponding to: 5.0431\n",
      "  â„µ: 5.0431\n",
      "  â„µ such: 5.0431\n",
      "  â„µ such that: 5.0431\n",
      "\n",
      "Document 16:\n",
      "  a: 2.5177\n",
      "  a connection: 4.6376\n",
      "  a connection more: 5.0431\n",
      "  a zip: 5.0431\n",
      "  a zip files: 5.0431\n",
      "  according: 3.9444\n",
      "  according to: 3.9444\n",
      "  according to aixi: 5.0431\n",
      "  aixi: 5.0431\n",
      "  aixi theory: 5.0431\n",
      "  aixi theory a: 5.0431\n",
      "  an: 2.1527\n",
      "  an even: 5.0431\n",
      "  an even smaller: 5.0431\n",
      "  and: 1.2144\n",
      "  and the: 3.3383\n",
      "  and the unzipping: 5.0431\n",
      "  be: 2.0726\n",
      "  be an: 4.3499\n",
      "  be an even: 5.0431\n",
      "  best: 3.6568\n",
      "  best possible: 5.0431\n",
      "  best possible compression: 5.0431\n",
      "  both: 7.5806\n",
      "  both but: 5.0431\n",
      "  both but there: 5.0431\n",
      "  both the: 4.6376\n",
      "  both the zip: 5.0431\n",
      "  but: 3.0281\n",
      "  but there: 5.0431\n",
      "  but there may: 5.0431\n",
      "  can: 2.1809\n",
      "  can not: 5.0431\n",
      "  can not unzip: 5.0431\n",
      "  combined: 4.3499\n",
      "  combined form: 5.0431\n",
      "  compressed: 5.0431\n",
      "  compressed size: 5.0431\n",
      "  compressed size includes: 5.0431\n",
      "  compression: 3.7903\n",
      "  compression of: 5.0431\n",
      "  compression of x: 5.0431\n",
      "  connection: 4.3499\n",
      "  connection more: 5.0431\n",
      "  connection more directly: 5.0431\n",
      "  directly: 4.1268\n",
      "  directly explained: 5.0431\n",
      "  directly explained in: 5.0431\n",
      "  even: 3.9444\n",
      "  even smaller: 5.0431\n",
      "  even smaller combined: 5.0431\n",
      "  example: 2.9636\n",
      "  example in: 4.1268\n",
      "  example in that: 5.0431\n",
      "  explained: 5.0431\n",
      "  explained in: 5.0431\n",
      "  explained in hutter: 5.0431\n",
      "  file: 4.6376\n",
      "  file and: 5.0431\n",
      "  file and the: 5.0431\n",
      "  files: 4.6376\n",
      "  files compressed: 5.0431\n",
      "  files compressed size: 5.0431\n",
      "  for: 1.7289\n",
      "  for example: 3.2513\n",
      "  for example in: 4.1268\n",
      "  form: 4.3499\n",
      "  generates: 4.6376\n",
      "  generates x: 5.0431\n",
      "  generates x for: 5.0431\n",
      "  hutter: 5.0431\n",
      "  hutter prize: 5.0431\n",
      "  hutter prize the: 5.0431\n",
      "  in: 2.6835\n",
      "  in hutter: 5.0431\n",
      "  in hutter prize: 5.0431\n",
      "  in that: 5.0431\n",
      "  in that model: 5.0431\n",
      "  includes: 4.1268\n",
      "  includes both: 5.0431\n",
      "  includes both the: 5.0431\n",
      "  is: 1.5167\n",
      "  is the: 3.3383\n",
      "  is the smallest: 5.0431\n",
      "  it: 2.2705\n",
      "  it without: 5.0431\n",
      "  it without both: 5.0431\n",
      "  may: 3.2513\n",
      "  may be: 4.1268\n",
      "  may be an: 4.6376\n",
      "  model: 2.3350\n",
      "  model a: 5.0431\n",
      "  model a zip: 5.0431\n",
      "  more: 3.1712\n",
      "  more directly: 5.0431\n",
      "  more directly explained: 5.0431\n",
      "  not: 2.6007\n",
      "  not unzip: 5.0431\n",
      "  not unzip it: 5.0431\n",
      "  of: 1.2144\n",
      "  of x: 5.0431\n",
      "  of x is: 5.0431\n",
      "  possible: 9.2752\n",
      "  possible compression: 5.0431\n",
      "  possible compression of: 5.0431\n",
      "  possible software: 5.0431\n",
      "  possible software that: 5.0431\n",
      "  prize: 4.6376\n",
      "  prize the: 5.0431\n",
      "  prize the best: 5.0431\n",
      "  since: 4.3499\n",
      "  since you: 5.0431\n",
      "  since you can: 5.0431\n",
      "  size: 4.6376\n",
      "  size includes: 5.0431\n",
      "  size includes both: 5.0431\n",
      "  smaller: 4.6376\n",
      "  smaller combined: 5.0431\n",
      "  smaller combined form: 5.0431\n",
      "  smallest: 5.0431\n",
      "  smallest possible: 5.0431\n",
      "  smallest possible software: 5.0431\n",
      "  software: 7.8889\n",
      "  software since: 5.0431\n",
      "  software since you: 5.0431\n",
      "  software that: 4.6376\n",
      "  software that generates: 5.0431\n",
      "  that: 3.3515\n",
      "  that generates: 5.0431\n",
      "  that generates x: 5.0431\n",
      "  that model: 4.6376\n",
      "  that model a: 5.0431\n",
      "  the: 4.7716\n",
      "  the best: 4.1268\n",
      "  the best possible: 5.0431\n",
      "  the smallest: 5.0431\n",
      "  the smallest possible: 5.0431\n",
      "  the unzipping: 5.0431\n",
      "  the unzipping software: 5.0431\n",
      "  the zip: 5.0431\n",
      "  the zip file: 5.0431\n",
      "  theory: 3.3383\n",
      "  theory a: 4.6376\n",
      "  theory a connection: 5.0431\n",
      "  there: 3.6568\n",
      "  there may: 5.0431\n",
      "  there may be: 5.0431\n",
      "  to: 1.2253\n",
      "  to aixi: 5.0431\n",
      "  to aixi theory: 5.0431\n",
      "  unzip: 5.0431\n",
      "  unzip it: 5.0431\n",
      "  unzip it without: 5.0431\n",
      "  unzipping: 5.0431\n",
      "  unzipping software: 5.0431\n",
      "  unzipping software since: 5.0431\n",
      "  without: 3.3383\n",
      "  without both: 5.0431\n",
      "  without both but: 5.0431\n",
      "  x: 9.2752\n",
      "  x for: 5.0431\n",
      "  x for example: 5.0431\n",
      "  x is: 5.0431\n",
      "  x is the: 5.0431\n",
      "  you: 5.0431\n",
      "  you can: 5.0431\n",
      "  you can not: 5.0431\n",
      "  zip: 10.0861\n",
      "  zip file: 5.0431\n",
      "  zip file and: 5.0431\n",
      "  zip files: 5.0431\n",
      "  zip files compressed: 5.0431\n",
      "\n",
      "Document 17:\n",
      "  aipowered: 9.2752\n",
      "  aipowered audiovideo: 5.0431\n",
      "  aipowered audiovideo compression: 5.0431\n",
      "  aipowered image: 5.0431\n",
      "  aipowered image compression: 5.0431\n",
      "  aivc: 5.0431\n",
      "  aivc examples: 5.0431\n",
      "  aivc examples of: 5.0431\n",
      "  and: 1.2144\n",
      "  and highfidelity: 5.0431\n",
      "  and highfidelity generative: 5.0431\n",
      "  audiovideo: 5.0431\n",
      "  audiovideo compression: 5.0431\n",
      "  audiovideo compression software: 5.0431\n",
      "  can: 2.1809\n",
      "  can perform: 5.0431\n",
      "  can perform aipowered: 5.0431\n",
      "  compression: 11.3709\n",
      "  compression include: 5.0431\n",
      "  compression include opencv: 5.0431\n",
      "  compression software: 5.0431\n",
      "  compression software include: 5.0431\n",
      "  examples: 6.1943\n",
      "  examples of: 10.0861\n",
      "  examples of aipowered: 5.0431\n",
      "  examples of software: 5.0431\n",
      "  generative: 5.0431\n",
      "  generative image: 5.0431\n",
      "  generative image compression: 5.0431\n",
      "  highfidelity: 5.0431\n",
      "  highfidelity generative: 5.0431\n",
      "  highfidelity generative image: 5.0431\n",
      "  image: 11.8333\n",
      "  image compression: 9.2752\n",
      "  image compression include: 5.0431\n",
      "  image processing: 5.0431\n",
      "  image processing toolbox: 5.0431\n",
      "  include: 6.8672\n",
      "  include nvidia: 5.0431\n",
      "  include nvidia maxine: 5.0431\n",
      "  include opencv: 5.0431\n",
      "  include opencv tensorflow: 5.0431\n",
      "  ipt: 5.0431\n",
      "  ipt and: 5.0431\n",
      "  ipt and highfidelity: 5.0431\n",
      "  matlabs: 5.0431\n",
      "  matlabs image: 5.0431\n",
      "  matlabs image processing: 5.0431\n",
      "  maxine: 5.0431\n",
      "  maxine aivc: 5.0431\n",
      "  maxine aivc examples: 5.0431\n",
      "  nvidia: 5.0431\n",
      "  nvidia maxine: 5.0431\n",
      "  nvidia maxine aivc: 5.0431\n",
      "  of: 2.4288\n",
      "  of aipowered: 4.6376\n",
      "  of aipowered audiovideo: 5.0431\n",
      "  of software: 5.0431\n",
      "  of software that: 5.0431\n",
      "  opencv: 5.0431\n",
      "  opencv tensorflow: 5.0431\n",
      "  opencv tensorflow matlabs: 5.0431\n",
      "  perform: 3.2513\n",
      "  perform aipowered: 5.0431\n",
      "  perform aipowered image: 5.0431\n",
      "  processing: 3.6568\n",
      "  processing toolbox: 5.0431\n",
      "  processing toolbox ipt: 5.0431\n",
      "  software: 7.8889\n",
      "  software include: 5.0431\n",
      "  software include nvidia: 5.0431\n",
      "  software that: 4.6376\n",
      "  software that can: 5.0431\n",
      "  tensorflow: 5.0431\n",
      "  tensorflow matlabs: 5.0431\n",
      "  tensorflow matlabs image: 5.0431\n",
      "  that: 1.6758\n",
      "  that can: 3.9444\n",
      "  that can perform: 5.0431\n",
      "  toolbox: 5.0431\n",
      "  toolbox ipt: 5.0431\n",
      "  toolbox ipt and: 5.0431\n",
      "\n",
      "Document 18:\n",
      "  and: 1.2144\n",
      "  and finds: 5.0431\n",
      "  and finds widespread: 5.0431\n",
      "  as: 1.8444\n",
      "  as image: 5.0431\n",
      "  as image compression: 5.0431\n",
      "  be: 2.0726\n",
      "  be utilized: 5.0431\n",
      "  be utilized to: 5.0431\n",
      "  by: 1.9076\n",
      "  by grouping: 5.0431\n",
      "  by grouping similar: 5.0431\n",
      "  can: 2.1809\n",
      "  can be: 2.7405\n",
      "  can be utilized: 5.0431\n",
      "  clustering: 3.9444\n",
      "  clustering can: 5.0431\n",
      "  clustering can be: 5.0431\n",
      "  clusters: 4.3499\n",
      "  clusters this: 5.0431\n",
      "  clusters this technique: 5.0431\n",
      "  compress: 5.0431\n",
      "  compress data: 5.0431\n",
      "  compress data by: 5.0431\n",
      "  compression: 3.7903\n",
      "  data: 3.7300\n",
      "  data by: 5.0431\n",
      "  data by grouping: 5.0431\n",
      "  data points: 4.6376\n",
      "  data points into: 5.0431\n",
      "  datasets: 4.3499\n",
      "  datasets that: 5.0431\n",
      "  datasets that lack: 5.0431\n",
      "  extensive: 4.6376\n",
      "  extensive datasets: 4.6376\n",
      "  extensive datasets that: 5.0431\n",
      "  fields: 3.9444\n",
      "  fields such: 5.0431\n",
      "  fields such as: 5.0431\n",
      "  finds: 4.3499\n",
      "  finds widespread: 5.0431\n",
      "  finds widespread use: 5.0431\n",
      "  grouping: 5.0431\n",
      "  grouping similar: 5.0431\n",
      "  grouping similar data: 5.0431\n",
      "  handling: 5.0431\n",
      "  handling extensive: 5.0431\n",
      "  handling extensive datasets: 5.0431\n",
      "  image: 3.9444\n",
      "  image compression: 4.6376\n",
      "  in: 2.6835\n",
      "  in fields: 4.6376\n",
      "  in fields such: 5.0431\n",
      "  in unsupervised: 4.6376\n",
      "  in unsupervised machine: 5.0431\n",
      "  into: 2.9636\n",
      "  into clusters: 5.0431\n",
      "  into clusters this: 5.0431\n",
      "  kmeans: 4.6376\n",
      "  kmeans clustering: 4.6376\n",
      "  kmeans clustering can: 5.0431\n",
      "  labels: 3.9444\n",
      "  labels and: 4.6376\n",
      "  labels and finds: 5.0431\n",
      "  lack: 4.3499\n",
      "  lack predefined: 5.0431\n",
      "  lack predefined labels: 5.0431\n",
      "  learning: 1.2819\n",
      "  learning kmeans: 5.0431\n",
      "  learning kmeans clustering: 5.0431\n",
      "  machine: 1.4735\n",
      "  machine learning: 1.5618\n",
      "  machine learning kmeans: 5.0431\n",
      "  points: 4.1268\n",
      "  points into: 5.0431\n",
      "  points into clusters: 5.0431\n",
      "  predefined: 4.6376\n",
      "  predefined labels: 5.0431\n",
      "  predefined labels and: 5.0431\n",
      "  similar: 3.9444\n",
      "  similar data: 5.0431\n",
      "  similar data points: 5.0431\n",
      "  simplifies: 5.0431\n",
      "  simplifies handling: 5.0431\n",
      "  simplifies handling extensive: 5.0431\n",
      "  such: 2.4781\n",
      "  such as: 2.8458\n",
      "  such as image: 5.0431\n",
      "  technique: 4.3499\n",
      "  technique simplifies: 5.0431\n",
      "  technique simplifies handling: 5.0431\n",
      "  that: 1.6758\n",
      "  that lack: 5.0431\n",
      "  that lack predefined: 5.0431\n",
      "  this: 2.6007\n",
      "  this technique: 4.6376\n",
      "  this technique simplifies: 5.0431\n",
      "  to: 1.2253\n",
      "  to compress: 5.0431\n",
      "  to compress data: 5.0431\n",
      "  unsupervised: 3.2513\n",
      "  unsupervised machine: 4.3499\n",
      "  unsupervised machine learning: 4.3499\n",
      "  use: 3.3383\n",
      "  use in: 5.0431\n",
      "  use in fields: 5.0431\n",
      "  utilized: 5.0431\n",
      "  utilized to: 5.0431\n",
      "  utilized to compress: 5.0431\n",
      "  widespread: 5.0431\n",
      "  widespread use: 5.0431\n",
      "  widespread use in: 5.0431\n",
      "\n",
      "Document 19:\n",
      "  a: 3.7766\n",
      "  a dataset: 5.0431\n",
      "  a dataset into: 5.0431\n",
      "  a more: 5.0431\n",
      "  a more compact: 5.0431\n",
      "  a specified: 5.0431\n",
      "  a specified number: 5.0431\n",
      "  aids: 5.0431\n",
      "  aids in: 5.0431\n",
      "  aids in data: 5.0431\n",
      "  aims: 5.0431\n",
      "  aims to: 5.0431\n",
      "  aims to reduce: 5.0431\n",
      "  algorithm: 2.9030\n",
      "  algorithm is: 4.3499\n",
      "  algorithm is employed: 5.0431\n",
      "  an: 2.1527\n",
      "  an unsupervised: 5.0431\n",
      "  an unsupervised machine: 5.0431\n",
      "  and: 2.4288\n",
      "  and signal: 5.0431\n",
      "  and signal processing: 5.0431\n",
      "  and speeding: 5.0431\n",
      "  and speeding up: 5.0431\n",
      "  beneficial: 5.0431\n",
      "  beneficial in: 5.0431\n",
      "  beneficial in image: 5.0431\n",
      "  by: 3.8151\n",
      "  by replacing: 5.0431\n",
      "  by replacing groups: 5.0431\n",
      "  by the: 3.2513\n",
      "  by the centroid: 5.0431\n",
      "  centroid: 5.0431\n",
      "  centroid of: 5.0431\n",
      "  centroid of its: 5.0431\n",
      "  centroids: 5.0431\n",
      "  centroids thereby: 5.0431\n",
      "  centroids thereby preserving: 5.0431\n",
      "  clustering: 7.8889\n",
      "  clustering aids: 5.0431\n",
      "  clustering aids in: 5.0431\n",
      "  clustering an: 5.0431\n",
      "  clustering an unsupervised: 5.0431\n",
      "  clusters: 4.3499\n",
      "  clusters k: 5.0431\n",
      "  clusters k each: 5.0431\n",
      "  compact: 5.0431\n",
      "  compact set: 5.0431\n",
      "  compact set of: 5.0431\n",
      "  compression: 3.7903\n",
      "  compression aims: 5.0431\n",
      "  compression aims to: 5.0431\n",
      "  condenses: 5.0431\n",
      "  condenses extensive: 5.0431\n",
      "  condenses extensive datasets: 5.0431\n",
      "  core: 4.6376\n",
      "  core information: 5.0431\n",
      "  core information of: 5.0431\n",
      "  data: 11.1900\n",
      "  data compression: 4.6376\n",
      "  data compression aims: 5.0431\n",
      "  data files: 5.0431\n",
      "  data files enhancing: 5.0431\n",
      "  data points: 4.6376\n",
      "  data points with: 5.0431\n",
      "  data reduction: 5.0431\n",
      "  data reduction by: 5.0431\n",
      "  data transmission: 5.0431\n",
      "  data transmission kmeans: 5.0431\n",
      "  data while: 5.0431\n",
      "  data while significantly: 5.0431\n",
      "  dataset: 4.3499\n",
      "  dataset into: 5.0431\n",
      "  dataset into a: 5.0431\n",
      "  datasets: 4.3499\n",
      "  datasets into: 5.0431\n",
      "  datasets into a: 5.0431\n",
      "  decreasing: 5.0431\n",
      "  decreasing the: 5.0431\n",
      "  decreasing the required: 5.0431\n",
      "  each: 3.0971\n",
      "  each represented: 5.0431\n",
      "  each represented by: 5.0431\n",
      "  efficiency: 4.3499\n",
      "  efficiency and: 5.0431\n",
      "  efficiency and speeding: 5.0431\n",
      "  employed: 4.3499\n",
      "  employed to: 5.0431\n",
      "  employed to partition: 5.0431\n",
      "  enhancing: 5.0431\n",
      "  enhancing storage: 5.0431\n",
      "  enhancing storage efficiency: 5.0431\n",
      "  extensive: 4.6376\n",
      "  extensive datasets: 4.6376\n",
      "  extensive datasets into: 5.0431\n",
      "  files: 4.6376\n",
      "  files enhancing: 5.0431\n",
      "  files enhancing storage: 5.0431\n",
      "  groups: 4.6376\n",
      "  groups of: 5.0431\n",
      "  groups of data: 5.0431\n",
      "  image: 3.9444\n",
      "  image and: 5.0431\n",
      "  image and signal: 5.0431\n",
      "  in: 2.6835\n",
      "  in data: 4.1268\n",
      "  in data reduction: 5.0431\n",
      "  in image: 4.6376\n",
      "  in image and: 5.0431\n",
      "  information: 3.7903\n",
      "  information of: 5.0431\n",
      "  information of the: 5.0431\n",
      "  into: 5.9272\n",
      "  into a: 10.0861\n",
      "  into a more: 5.0431\n",
      "  into a specified: 5.0431\n",
      "  is: 1.5167\n",
      "  is employed: 5.0431\n",
      "  is employed to: 5.0431\n",
      "  its: 2.9636\n",
      "  its points: 5.0431\n",
      "  its points this: 5.0431\n",
      "  k: 4.6376\n",
      "  k each: 5.0431\n",
      "  k each represented: 5.0431\n",
      "  kmeans: 9.2752\n",
      "  kmeans clustering: 9.2752\n",
      "  kmeans clustering aids: 5.0431\n",
      "  kmeans clustering an: 5.0431\n",
      "  learning: 1.2819\n",
      "  learning algorithm: 3.9444\n",
      "  learning algorithm is: 4.6376\n",
      "  machine: 1.4735\n",
      "  machine learning: 1.5618\n",
      "  machine learning algorithm: 4.1268\n",
      "  more: 3.1712\n",
      "  more compact: 5.0431\n",
      "  more compact set: 5.0431\n",
      "  number: 4.1268\n",
      "  number of: 4.3499\n",
      "  number of clusters: 5.0431\n",
      "  of: 7.2865\n",
      "  of clusters: 5.0431\n",
      "  of clusters k: 5.0431\n",
      "  of data: 7.3135\n",
      "  of data files: 5.0431\n",
      "  of data points: 5.0431\n",
      "  of its: 3.9444\n",
      "  of its points: 5.0431\n",
      "  of representative: 5.0431\n",
      "  of representative points: 5.0431\n",
      "  of the: 2.3022\n",
      "  of the original: 5.0431\n",
      "  original: 4.6376\n",
      "  original data: 5.0431\n",
      "  original data while: 5.0431\n",
      "  particularly: 4.1268\n",
      "  particularly beneficial: 5.0431\n",
      "  particularly beneficial in: 5.0431\n",
      "  partition: 5.0431\n",
      "  partition a: 5.0431\n",
      "  partition a dataset: 5.0431\n",
      "  points: 12.3803\n",
      "  points particularly: 5.0431\n",
      "  points particularly beneficial: 5.0431\n",
      "  points this: 5.0431\n",
      "  points this process: 5.0431\n",
      "  points with: 5.0431\n",
      "  points with their: 5.0431\n",
      "  preserving: 5.0431\n",
      "  preserving the: 5.0431\n",
      "  preserving the core: 5.0431\n",
      "  process: 3.4336\n",
      "  process condenses: 5.0431\n",
      "  process condenses extensive: 5.0431\n",
      "  processing: 3.6568\n",
      "  processing kmeans: 5.0431\n",
      "  processing kmeans clustering: 5.0431\n",
      "  reduce: 4.1268\n",
      "  reduce the: 4.6376\n",
      "  reduce the size: 5.0431\n",
      "  reduction: 4.3499\n",
      "  reduction by: 5.0431\n",
      "  reduction by replacing: 5.0431\n",
      "  replacing: 5.0431\n",
      "  replacing groups: 5.0431\n",
      "  replacing groups of: 5.0431\n",
      "  representative: 3.9444\n",
      "  representative points: 5.0431\n",
      "  representative points particularly: 5.0431\n",
      "  represented: 3.6568\n",
      "  represented by: 4.3499\n",
      "  represented by the: 4.6376\n",
      "  required: 4.6376\n",
      "  required storage: 5.0431\n",
      "  required storage space: 5.0431\n",
      "  set: 2.6007\n",
      "  set of: 3.0281\n",
      "  set of representative: 5.0431\n",
      "  signal: 3.9444\n",
      "  signal processing: 5.0431\n",
      "  signal processing kmeans: 5.0431\n",
      "  significantly: 4.3499\n",
      "  significantly decreasing: 5.0431\n",
      "  significantly decreasing the: 5.0431\n",
      "  size: 4.6376\n",
      "  size of: 5.0431\n",
      "  size of data: 5.0431\n",
      "  space: 3.7903\n",
      "  specified: 5.0431\n",
      "  specified number: 5.0431\n",
      "  specified number of: 5.0431\n",
      "  speeding: 5.0431\n",
      "  speeding up: 5.0431\n",
      "  speeding up data: 5.0431\n",
      "  storage: 10.0861\n",
      "  storage efficiency: 5.0431\n",
      "  storage efficiency and: 5.0431\n",
      "  storage space: 5.0431\n",
      "  the: 5.9645\n",
      "  the centroid: 5.0431\n",
      "  the centroid of: 5.0431\n",
      "  the core: 5.0431\n",
      "  the core information: 5.0431\n",
      "  the original: 4.6376\n",
      "  the original data: 5.0431\n",
      "  the required: 5.0431\n",
      "  the required storage: 5.0431\n",
      "  the size: 5.0431\n",
      "  the size of: 5.0431\n",
      "  their: 2.7918\n",
      "  their centroids: 5.0431\n",
      "  their centroids thereby: 5.0431\n",
      "  thereby: 4.1268\n",
      "  thereby preserving: 5.0431\n",
      "  thereby preserving the: 5.0431\n",
      "  this: 2.6007\n",
      "  this process: 5.0431\n",
      "  this process condenses: 5.0431\n",
      "  to: 2.4507\n",
      "  to partition: 5.0431\n",
      "  to partition a: 5.0431\n",
      "  to reduce: 4.1268\n",
      "  to reduce the: 4.6376\n",
      "  transmission: 5.0431\n",
      "  transmission kmeans: 5.0431\n",
      "  transmission kmeans clustering: 5.0431\n",
      "  unsupervised: 3.2513\n",
      "  unsupervised machine: 4.3499\n",
      "  unsupervised machine learning: 4.3499\n",
      "  up: 3.7903\n",
      "  up data: 5.0431\n",
      "  up data transmission: 5.0431\n",
      "  while: 3.4336\n",
      "  while significantly: 5.0431\n",
      "  while significantly decreasing: 5.0431\n",
      "  with: 2.0726\n",
      "  with their: 5.0431\n",
      "  with their centroids: 5.0431\n",
      "\n",
      "Document 20:\n",
      "  a: 3.7766\n",
      "  a major: 5.0431\n",
      "  a major exception: 5.0431\n",
      "  a preprocessing: 4.6376\n",
      "  a preprocessing step: 4.6376\n",
      "  a typical: 5.0431\n",
      "  a typical kdd: 5.0431\n",
      "  ability: 4.6376\n",
      "  ability to: 5.0431\n",
      "  ability to reproduce: 5.0431\n",
      "  accuracy: 3.6568\n",
      "  accuracy much: 5.0431\n",
      "  accuracy much of: 5.0431\n",
      "  also: 2.6452\n",
      "  also employs: 5.0431\n",
      "  also employs data: 5.0431\n",
      "  an: 2.1527\n",
      "  an uninformed: 5.0431\n",
      "  an uninformed unsupervised: 5.0431\n",
      "  analysis: 3.1712\n",
      "  analysis step: 5.0431\n",
      "  analysis step of: 5.0431\n",
      "  and: 4.8576\n",
      "  and data: 9.2752\n",
      "  and data mining: 10.0861\n",
      "  and overlap: 5.0431\n",
      "  and overlap significantly: 5.0431\n",
      "  and separate: 5.0431\n",
      "  and separate journals: 5.0431\n",
      "  as: 3.6888\n",
      "  as a: 2.9030\n",
      "  as a preprocessing: 4.6376\n",
      "  as unsupervised: 5.0431\n",
      "  as unsupervised learning: 5.0431\n",
      "  assumptions: 4.6376\n",
      "  assumptions they: 5.0431\n",
      "  assumptions they work: 5.0431\n",
      "  based: 3.4336\n",
      "  based on: 3.4336\n",
      "  based on known: 5.0431\n",
      "  basic: 4.6376\n",
      "  basic assumptions: 5.0431\n",
      "  basic assumptions they: 5.0431\n",
      "  be: 4.1453\n",
      "  be outperformed: 5.0431\n",
      "  be outperformed by: 5.0431\n",
      "  be used: 3.4336\n",
      "  be used due: 5.0431\n",
      "  being: 3.7903\n",
      "  being a: 5.0431\n",
      "  being a major: 5.0431\n",
      "  between: 2.9636\n",
      "  between these: 5.0431\n",
      "  between these two: 5.0431\n",
      "  but: 6.0563\n",
      "  but while: 5.0431\n",
      "  but while machine: 5.0431\n",
      "  but with: 5.0431\n",
      "  but with different: 5.0431\n",
      "  by: 1.9076\n",
      "  by other: 5.0431\n",
      "  by other supervised: 5.0431\n",
      "  cannot: 3.7903\n",
      "  cannot be: 4.6376\n",
      "  cannot be used: 5.0431\n",
      "  comes: 5.0431\n",
      "  comes from: 5.0431\n",
      "  comes from the: 5.0431\n",
      "  communities: 4.6376\n",
      "  communities which: 5.0431\n",
      "  communities which do: 5.0431\n",
      "  conferences: 5.0431\n",
      "  conferences and: 5.0431\n",
      "  conferences and separate: 5.0431\n",
      "  confusion: 5.0431\n",
      "  confusion between: 5.0431\n",
      "  confusion between these: 5.0431\n",
      "  data: 14.9200\n",
      "  data data: 4.3499\n",
      "  data data mining: 5.0431\n",
      "  data mining: 20.6338\n",
      "  data mining focuses: 5.0431\n",
      "  data mining kdd: 5.0431\n",
      "  data mining methods: 5.0431\n",
      "  data mining often: 5.0431\n",
      "  data mining uses: 5.0431\n",
      "  data this: 5.0431\n",
      "  data this is: 5.0431\n",
      "  databases: 4.6376\n",
      "  databases data: 5.0431\n",
      "  databases data mining: 5.0431\n",
      "  different: 3.9444\n",
      "  different goals: 5.0431\n",
      "  different goals on: 5.0431\n",
      "  discovery: 18.5503\n",
      "  discovery and: 5.0431\n",
      "  discovery and data: 5.0431\n",
      "  discovery in: 5.0431\n",
      "  discovery in databases: 5.0431\n",
      "  discovery of: 10.0861\n",
      "  discovery of previously: 10.0861\n",
      "  do: 3.6568\n",
      "  do often: 5.0431\n",
      "  do often have: 5.0431\n",
      "  due: 4.6376\n",
      "  due to: 4.6376\n",
      "  due to the: 5.0431\n",
      "  easily: 5.0431\n",
      "  easily be: 5.0431\n",
      "  easily be outperformed: 5.0431\n",
      "  ecml: 5.0431\n",
      "  ecml pkdd: 5.0431\n",
      "  ecml pkdd being: 5.0431\n",
      "  employ: 5.0431\n",
      "  employ the: 5.0431\n",
      "  employ the same: 5.0431\n",
      "  employs: 5.0431\n",
      "  employs data: 5.0431\n",
      "  employs data mining: 5.0431\n",
      "  evaluated: 9.2752\n",
      "  evaluated with: 10.0861\n",
      "  evaluated with respect: 10.0861\n",
      "  exception: 5.0431\n",
      "  exception comes: 5.0431\n",
      "  exception comes from: 5.0431\n",
      "  focuses: 10.0861\n",
      "  focuses on: 10.0861\n",
      "  focuses on prediction: 5.0431\n",
      "  focuses on the: 5.0431\n",
      "  from: 4.1453\n",
      "  from the: 6.6766\n",
      "  from the basic: 5.0431\n",
      "  from the training: 4.6376\n",
      "  goals: 5.0431\n",
      "  goals on: 5.0431\n",
      "  goals on the: 5.0431\n",
      "  hand: 5.0431\n",
      "  hand machine: 5.0431\n",
      "  hand machine learning: 5.0431\n",
      "  have: 2.4781\n",
      "  have separate: 5.0431\n",
      "  have separate conferences: 5.0431\n",
      "  improve: 4.1268\n",
      "  improve learner: 5.0431\n",
      "  improve learner accuracy: 5.0431\n",
      "  in: 6.7087\n",
      "  in a: 3.0971\n",
      "  in a typical: 5.0431\n",
      "  in databases: 4.6376\n",
      "  in databases data: 5.0431\n",
      "  in knowledge: 5.0431\n",
      "  in knowledge discovery: 5.0431\n",
      "  in machine: 3.6568\n",
      "  in machine learning: 3.6568\n",
      "  in the: 2.4404\n",
      "  in the data: 4.3499\n",
      "  is: 4.5501\n",
      "  is the: 6.6766\n",
      "  is the analysis: 5.0431\n",
      "  is the discovery: 5.0431\n",
      "  is usually: 5.0431\n",
      "  is usually evaluated: 5.0431\n",
      "  journals: 5.0431\n",
      "  journals ecml: 5.0431\n",
      "  journals ecml pkdd: 5.0431\n",
      "  kdd: 10.0861\n",
      "  kdd task: 5.0431\n",
      "  kdd task supervised: 5.0431\n",
      "  kdd the: 5.0431\n",
      "  kdd the key: 5.0431\n",
      "  key: 3.9444\n",
      "  key task: 5.0431\n",
      "  key task is: 5.0431\n",
      "  knowledge: 18.9514\n",
      "  knowledge an: 5.0431\n",
      "  knowledge an uninformed: 5.0431\n",
      "  knowledge discovery: 10.0861\n",
      "  knowledge discovery and: 5.0431\n",
      "  knowledge discovery in: 5.0431\n",
      "  knowledge evaluated: 5.0431\n",
      "  knowledge evaluated with: 5.0431\n",
      "  knowledge while: 5.0431\n",
      "  knowledge while in: 5.0431\n",
      "  known: 10.6169\n",
      "  known knowledge: 10.0861\n",
      "  known knowledge an: 5.0431\n",
      "  known knowledge while: 5.0431\n",
      "  known properties: 5.0431\n",
      "  known properties learned: 5.0431\n",
      "  learned: 3.7903\n",
      "  learned from: 4.6376\n",
      "  learned from the: 5.0431\n",
      "  learner: 4.3499\n",
      "  learner accuracy: 5.0431\n",
      "  learner accuracy much: 5.0431\n",
      "  learning: 7.6911\n",
      "  learning also: 4.6376\n",
      "  learning also employs: 5.0431\n",
      "  learning and: 3.6568\n",
      "  learning and data: 5.0431\n",
      "  learning focuses: 5.0431\n",
      "  learning focuses on: 5.0431\n",
      "  learning methods: 4.3499\n",
      "  learning methods but: 5.0431\n",
      "  learning or: 4.6376\n",
      "  learning or as: 5.0431\n",
      "  learning performance: 5.0431\n",
      "  learning performance is: 5.0431\n",
      "  machine: 7.3676\n",
      "  machine learning: 7.8091\n",
      "  machine learning also: 4.6376\n",
      "  machine learning and: 4.1268\n",
      "  machine learning focuses: 5.0431\n",
      "  machine learning methods: 4.6376\n",
      "  machine learning performance: 5.0431\n",
      "  major: 5.0431\n",
      "  major exception: 5.0431\n",
      "  major exception comes: 5.0431\n",
      "  many: 2.9030\n",
      "  many machine: 5.0431\n",
      "  many machine learning: 5.0431\n",
      "  method: 3.6568\n",
      "  method will: 5.0431\n",
      "  method will easily: 5.0431\n",
      "  methods: 13.7023\n",
      "  methods and: 4.6376\n",
      "  methods and overlap: 5.0431\n",
      "  methods as: 4.6376\n",
      "  methods as unsupervised: 5.0431\n",
      "  methods but: 4.6376\n",
      "  methods but with: 5.0431\n",
      "  methods cannot: 5.0431\n",
      "  methods cannot be: 5.0431\n",
      "  methods while: 5.0431\n",
      "  methods while in: 5.0431\n",
      "  mining: 19.7222\n",
      "  mining focuses: 5.0431\n",
      "  mining focuses on: 5.0431\n",
      "  mining kdd: 5.0431\n",
      "  mining kdd the: 5.0431\n",
      "  mining methods: 5.0431\n",
      "  mining methods as: 5.0431\n",
      "  mining often: 5.0431\n",
      "  mining often employ: 5.0431\n",
      "  mining uses: 5.0431\n",
      "  mining uses many: 5.0431\n",
      "  much: 4.6376\n",
      "  much of: 5.0431\n",
      "  much of the: 5.0431\n",
      "  of: 6.0720\n",
      "  of knowledge: 5.0431\n",
      "  of knowledge discovery: 5.0431\n",
      "  of previously: 10.0861\n",
      "  of previously unknown: 10.0861\n",
      "  of the: 2.3022\n",
      "  of the confusion: 5.0431\n",
      "  of training: 4.1268\n",
      "  of training data: 5.0431\n",
      "  often: 6.1943\n",
      "  often employ: 5.0431\n",
      "  often employ the: 5.0431\n",
      "  often have: 5.0431\n",
      "  often have separate: 5.0431\n",
      "  on: 8.1893\n",
      "  on known: 5.0431\n",
      "  on known properties: 5.0431\n",
      "  on prediction: 5.0431\n",
      "  on prediction based: 5.0431\n",
      "  on the: 6.5026\n",
      "  on the discovery: 5.0431\n",
      "  on the other: 5.0431\n",
      "  or: 2.0226\n",
      "  or as: 5.0431\n",
      "  or as a: 5.0431\n",
      "  other: 5.5835\n",
      "  other hand: 5.0431\n",
      "  other hand machine: 5.0431\n",
      "  other supervised: 5.0431\n",
      "  other supervised methods: 5.0431\n",
      "  outperformed: 5.0431\n",
      "  outperformed by: 5.0431\n",
      "  outperformed by other: 5.0431\n",
      "  overlap: 5.0431\n",
      "  overlap significantly: 5.0431\n",
      "  overlap significantly but: 5.0431\n",
      "  performance: 3.4336\n",
      "  performance is: 4.6376\n",
      "  performance is usually: 5.0431\n",
      "  pkdd: 5.0431\n",
      "  pkdd being: 5.0431\n",
      "  pkdd being a: 5.0431\n",
      "  prediction: 3.7903\n",
      "  prediction based: 5.0431\n",
      "  prediction based on: 5.0431\n",
      "  preprocessing: 4.6376\n",
      "  preprocessing step: 4.6376\n",
      "  preprocessing step to: 5.0431\n",
      "  previously: 8.6998\n",
      "  previously unknown: 10.0861\n",
      "  previously unknown knowledge: 5.0431\n",
      "  previously unknown properties: 5.0431\n",
      "  properties: 9.2752\n",
      "  properties in: 5.0431\n",
      "  properties in the: 5.0431\n",
      "  properties learned: 5.0431\n",
      "  properties learned from: 5.0431\n",
      "  reproduce: 5.0431\n",
      "  reproduce known: 5.0431\n",
      "  reproduce known knowledge: 5.0431\n",
      "  research: 3.4336\n",
      "  research communities: 5.0431\n",
      "  research communities which: 5.0431\n",
      "  respect: 9.2752\n",
      "  respect to: 9.2752\n",
      "  respect to known: 5.0431\n",
      "  respect to the: 5.0431\n",
      "  same: 3.9444\n",
      "  same methods: 5.0431\n",
      "  same methods and: 5.0431\n",
      "  separate: 9.2752\n",
      "  separate conferences: 5.0431\n",
      "  separate conferences and: 5.0431\n",
      "  separate journals: 5.0431\n",
      "  separate journals ecml: 5.0431\n",
      "  significantly: 4.3499\n",
      "  significantly but: 5.0431\n",
      "  significantly but while: 5.0431\n",
      "  step: 9.2752\n",
      "  step of: 5.0431\n",
      "  step of knowledge: 5.0431\n",
      "  step to: 5.0431\n",
      "  step to improve: 5.0431\n",
      "  supervised: 6.5026\n",
      "  supervised methods: 10.0861\n",
      "  supervised methods cannot: 5.0431\n",
      "  supervised methods while: 5.0431\n",
      "  task: 7.8889\n",
      "  task is: 4.6376\n",
      "  task is the: 5.0431\n",
      "  task supervised: 5.0431\n",
      "  task supervised methods: 5.0431\n",
      "  the: 14.3148\n",
      "  the ability: 4.6376\n",
      "  the ability to: 5.0431\n",
      "  the analysis: 5.0431\n",
      "  the analysis step: 5.0431\n",
      "  the basic: 5.0431\n",
      "  the basic assumptions: 5.0431\n",
      "  the confusion: 5.0431\n",
      "  the confusion between: 5.0431\n",
      "  the data: 3.0971\n",
      "  the data this: 5.0431\n",
      "  the discovery: 10.0861\n",
      "  the discovery of: 10.0861\n",
      "  the key: 4.3499\n",
      "  the key task: 5.0431\n",
      "  the other: 4.3499\n",
      "  the other hand: 5.0431\n",
      "  the same: 3.9444\n",
      "  the same methods: 5.0431\n",
      "  the training: 3.3383\n",
      "  the training data: 4.3499\n",
      "  the unavailability: 5.0431\n",
      "  the unavailability of: 5.0431\n",
      "  these: 2.9030\n",
      "  these two: 5.0431\n",
      "  these two research: 5.0431\n",
      "  they: 3.4336\n",
      "  they work: 5.0431\n",
      "  they work with: 5.0431\n",
      "  this: 2.6007\n",
      "  this is: 4.3499\n",
      "  this is the: 5.0431\n",
      "  to: 6.1267\n",
      "  to improve: 4.3499\n",
      "  to improve learner: 5.0431\n",
      "  to known: 5.0431\n",
      "  to known knowledge: 5.0431\n",
      "  to reproduce: 5.0431\n",
      "  to reproduce known: 5.0431\n",
      "  to the: 6.3425\n",
      "  to the ability: 5.0431\n",
      "  to the unavailability: 5.0431\n",
      "  training: 5.1163\n",
      "  training data: 7.5806\n",
      "  training data data: 5.0431\n",
      "  two: 3.5390\n",
      "  two research: 5.0431\n",
      "  two research communities: 5.0431\n",
      "  typical: 5.0431\n",
      "  typical kdd: 5.0431\n",
      "  typical kdd task: 5.0431\n",
      "  unavailability: 5.0431\n",
      "  unavailability of: 5.0431\n",
      "  unavailability of training: 5.0431\n",
      "  uninformed: 5.0431\n",
      "  uninformed unsupervised: 5.0431\n",
      "  uninformed unsupervised method: 5.0431\n",
      "  unknown: 8.6998\n",
      "  unknown knowledge: 5.0431\n",
      "  unknown knowledge evaluated: 5.0431\n",
      "  unknown properties: 5.0431\n",
      "  unknown properties in: 5.0431\n",
      "  unsupervised: 6.5026\n",
      "  unsupervised learning: 3.7903\n",
      "  unsupervised learning or: 5.0431\n",
      "  unsupervised method: 5.0431\n",
      "  unsupervised method will: 5.0431\n",
      "  used: 2.3350\n",
      "  used due: 5.0431\n",
      "  used due to: 5.0431\n",
      "  uses: 4.1268\n",
      "  uses many: 5.0431\n",
      "  uses many machine: 5.0431\n",
      "  usually: 4.6376\n",
      "  usually evaluated: 5.0431\n",
      "  usually evaluated with: 5.0431\n",
      "  which: 2.6917\n",
      "  which do: 4.6376\n",
      "  which do often: 5.0431\n",
      "  while: 10.3008\n",
      "  while in: 10.0861\n",
      "  while in a: 5.0431\n",
      "  while in knowledge: 5.0431\n",
      "  while machine: 4.6376\n",
      "  while machine learning: 4.6376\n",
      "  will: 3.7903\n",
      "  will easily: 5.0431\n",
      "  will easily be: 5.0431\n",
      "  with: 8.2905\n",
      "  with different: 5.0431\n",
      "  with different goals: 5.0431\n",
      "  with in: 5.0431\n",
      "  with in machine: 5.0431\n",
      "  with respect: 9.2752\n",
      "  with respect to: 9.2752\n",
      "  work: 4.1268\n",
      "  work with: 5.0431\n",
      "  work with in: 5.0431\n",
      "\n",
      "Document 21:\n",
      "  a: 3.7766\n",
      "  a label: 5.0431\n",
      "  a label to: 5.0431\n",
      "  a set: 3.2513\n",
      "  a set of: 3.2513\n",
      "  a training: 4.3499\n",
      "  a training set: 5.0431\n",
      "  actual: 5.0431\n",
      "  actual problem: 5.0431\n",
      "  actual problem instances: 5.0431\n",
      "  also: 2.6452\n",
      "  also has: 5.0431\n",
      "  also has intimate: 5.0431\n",
      "  and: 2.4288\n",
      "  and models: 4.6376\n",
      "  and models are: 5.0431\n",
      "  and the: 3.3383\n",
      "  and the actual: 5.0431\n",
      "  are: 3.9500\n",
      "  are formulated: 5.0431\n",
      "  are formulated as: 5.0431\n",
      "  are trained: 4.6376\n",
      "  are trained to: 5.0431\n",
      "  as: 1.8444\n",
      "  as minimisation: 5.0431\n",
      "  as minimisation of: 5.0431\n",
      "  assign: 5.0431\n",
      "  assign a: 5.0431\n",
      "  assign a label: 5.0431\n",
      "  being: 3.7903\n",
      "  being trained: 4.6376\n",
      "  being trained and: 5.0431\n",
      "  between: 2.9636\n",
      "  between the: 5.0431\n",
      "  between the predictions: 5.0431\n",
      "  classification: 2.9636\n",
      "  classification one: 5.0431\n",
      "  classification one wants: 5.0431\n",
      "  correctly: 4.3499\n",
      "  correctly predict: 5.0431\n",
      "  correctly predict the: 5.0431\n",
      "  discrepancy: 5.0431\n",
      "  discrepancy between: 5.0431\n",
      "  discrepancy between the: 5.0431\n",
      "  example: 2.9636\n",
      "  example in: 4.1268\n",
      "  example in classification: 5.0431\n",
      "  examples: 6.1943\n",
      "  examples loss: 5.0431\n",
      "  examples loss functions: 5.0431\n",
      "  express: 5.0431\n",
      "  express the: 5.0431\n",
      "  express the discrepancy: 5.0431\n",
      "  for: 1.7289\n",
      "  for example: 3.2513\n",
      "  for example in: 4.1268\n",
      "  formulated: 5.0431\n",
      "  formulated as: 5.0431\n",
      "  formulated as minimisation: 5.0431\n",
      "  function: 3.4336\n",
      "  function on: 5.0431\n",
      "  function on a: 5.0431\n",
      "  functions: 4.1268\n",
      "  functions express: 5.0431\n",
      "  functions express the: 5.0431\n",
      "  has: 2.8458\n",
      "  has intimate: 5.0431\n",
      "  has intimate ties: 5.0431\n",
      "  in: 1.3417\n",
      "  in classification: 4.6376\n",
      "  in classification one: 5.0431\n",
      "  instances: 8.6998\n",
      "  instances and: 5.0431\n",
      "  instances and models: 5.0431\n",
      "  instances for: 5.0431\n",
      "  instances for example: 5.0431\n",
      "  intimate: 5.0431\n",
      "  intimate ties: 5.0431\n",
      "  intimate ties to: 5.0431\n",
      "  label: 4.6376\n",
      "  label to: 5.0431\n",
      "  label to instances: 5.0431\n",
      "  labels: 3.9444\n",
      "  labels of: 5.0431\n",
      "  labels of a: 5.0431\n",
      "  learning: 2.5637\n",
      "  learning also: 4.6376\n",
      "  learning also has: 5.0431\n",
      "  learning problems: 5.0431\n",
      "  learning problems are: 5.0431\n",
      "  loss: 10.0861\n",
      "  loss function: 5.0431\n",
      "  loss function on: 5.0431\n",
      "  loss functions: 5.0431\n",
      "  loss functions express: 5.0431\n",
      "  machine: 1.4735\n",
      "  machine learning: 1.5618\n",
      "  machine learning also: 4.6376\n",
      "  many: 2.9030\n",
      "  many learning: 5.0431\n",
      "  many learning problems: 5.0431\n",
      "  minimisation: 5.0431\n",
      "  minimisation of: 5.0431\n",
      "  minimisation of some: 5.0431\n",
      "  model: 2.3350\n",
      "  model being: 5.0431\n",
      "  model being trained: 5.0431\n",
      "  models: 2.5581\n",
      "  models are: 4.1268\n",
      "  models are trained: 5.0431\n",
      "  of: 6.0720\n",
      "  of a: 3.0281\n",
      "  of a set: 4.1268\n",
      "  of examples: 9.2752\n",
      "  of examples loss: 5.0431\n",
      "  of some: 5.0431\n",
      "  of some loss: 5.0431\n",
      "  of the: 2.3022\n",
      "  of the model: 4.6376\n",
      "  on: 2.0473\n",
      "  on a: 3.5390\n",
      "  on a training: 5.0431\n",
      "  one: 3.0971\n",
      "  one wants: 5.0431\n",
      "  one wants to: 5.0431\n",
      "  optimisation: 3.7903\n",
      "  optimisation many: 5.0431\n",
      "  optimisation many learning: 5.0431\n",
      "  preassigned: 5.0431\n",
      "  preassigned labels: 5.0431\n",
      "  preassigned labels of: 5.0431\n",
      "  predict: 3.9444\n",
      "  predict the: 4.1268\n",
      "  predict the preassigned: 5.0431\n",
      "  predictions: 3.3383\n",
      "  predictions of: 5.0431\n",
      "  predictions of the: 5.0431\n",
      "  problem: 3.9444\n",
      "  problem instances: 5.0431\n",
      "  problem instances for: 5.0431\n",
      "  problems: 3.1712\n",
      "  problems are: 5.0431\n",
      "  problems are formulated: 5.0431\n",
      "  set: 5.2014\n",
      "  set of: 6.0563\n",
      "  set of examples: 9.2752\n",
      "  some: 2.9636\n",
      "  some loss: 5.0431\n",
      "  some loss function: 5.0431\n",
      "  the: 5.9645\n",
      "  the actual: 5.0431\n",
      "  the actual problem: 5.0431\n",
      "  the discrepancy: 5.0431\n",
      "  the discrepancy between: 5.0431\n",
      "  the model: 3.9444\n",
      "  the model being: 5.0431\n",
      "  the preassigned: 5.0431\n",
      "  the preassigned labels: 5.0431\n",
      "  the predictions: 5.0431\n",
      "  the predictions of: 5.0431\n",
      "  ties: 5.0431\n",
      "  ties to: 5.0431\n",
      "  ties to optimisation: 5.0431\n",
      "  to: 4.9014\n",
      "  to assign: 5.0431\n",
      "  to assign a: 5.0431\n",
      "  to correctly: 4.6376\n",
      "  to correctly predict: 5.0431\n",
      "  to instances: 5.0431\n",
      "  to instances and: 5.0431\n",
      "  to optimisation: 5.0431\n",
      "  to optimisation many: 5.0431\n",
      "  trained: 6.6766\n",
      "  trained and: 5.0431\n",
      "  trained and the: 5.0431\n",
      "  trained to: 5.0431\n",
      "  trained to correctly: 5.0431\n",
      "  training: 2.5581\n",
      "  training set: 4.1268\n",
      "  training set of: 5.0431\n",
      "  wants: 5.0431\n",
      "  wants to: 5.0431\n",
      "  wants to assign: 5.0431\n",
      "\n",
      "Document 22:\n",
      "  active: 4.6376\n",
      "  active topic: 5.0431\n",
      "  active topic of: 5.0431\n",
      "  algorithms: 4.7378\n",
      "  algorithms is: 4.6376\n",
      "  algorithms is an: 5.0431\n",
      "  an: 2.1527\n",
      "  an active: 5.0431\n",
      "  an active topic: 5.0431\n",
      "  characterizing: 5.0431\n",
      "  characterizing the: 5.0431\n",
      "  characterizing the generalisation: 5.0431\n",
      "  current: 4.3499\n",
      "  current research: 5.0431\n",
      "  current research especially: 5.0431\n",
      "  deep: 3.6568\n",
      "  deep learning: 3.7903\n",
      "  deep learning algorithms: 4.6376\n",
      "  especially: 4.1268\n",
      "  especially for: 5.0431\n",
      "  especially for deep: 5.0431\n",
      "  for: 1.7289\n",
      "  for deep: 4.6376\n",
      "  for deep learning: 4.6376\n",
      "  generalisation: 4.1268\n",
      "  generalisation of: 5.0431\n",
      "  generalisation of various: 5.0431\n",
      "  is: 1.5167\n",
      "  is an: 3.6568\n",
      "  is an active: 5.0431\n",
      "  learning: 2.5637\n",
      "  learning algorithms: 5.8060\n",
      "  learning algorithms is: 5.0431\n",
      "  of: 2.4288\n",
      "  of current: 5.0431\n",
      "  of current research: 5.0431\n",
      "  of various: 4.3499\n",
      "  of various learning: 5.0431\n",
      "  research: 3.4336\n",
      "  research especially: 5.0431\n",
      "  research especially for: 5.0431\n",
      "  the: 1.1929\n",
      "  the generalisation: 5.0431\n",
      "  the generalisation of: 5.0431\n",
      "  topic: 4.6376\n",
      "  topic of: 5.0431\n",
      "  topic of current: 5.0431\n",
      "  various: 3.4336\n",
      "  various learning: 5.0431\n",
      "  various learning algorithms: 5.0431\n",
      "\n",
      "Document 23:\n",
      "  a: 3.7766\n",
      "  a long: 5.0431\n",
      "  a long prehistory: 5.0431\n",
      "  a placeholder: 5.0431\n",
      "  a placeholder to: 5.0431\n",
      "  a sample: 5.0431\n",
      "  a sample while: 5.0431\n",
      "  according: 3.9444\n",
      "  according to: 3.9444\n",
      "  according to michael: 5.0431\n",
      "  also: 2.6452\n",
      "  also suggested: 5.0431\n",
      "  also suggested the: 5.0431\n",
      "  and: 1.2144\n",
      "  and statistics: 4.6376\n",
      "  and statistics are: 5.0431\n",
      "  are: 1.9750\n",
      "  are closely: 5.0431\n",
      "  are closely related: 5.0431\n",
      "  as: 1.8444\n",
      "  as a: 2.9030\n",
      "  as a placeholder: 5.0431\n",
      "  but: 3.0281\n",
      "  but distinct: 5.0431\n",
      "  but distinct in: 5.0431\n",
      "  call: 4.6376\n",
      "  call the: 5.0431\n",
      "  call the overall: 5.0431\n",
      "  closely: 4.6376\n",
      "  closely related: 4.6376\n",
      "  closely related fields: 5.0431\n",
      "  data: 1.8650\n",
      "  data science: 5.0431\n",
      "  data science as: 5.0431\n",
      "  distinct: 5.0431\n",
      "  distinct in: 5.0431\n",
      "  distinct in their: 5.0431\n",
      "  draws: 5.0431\n",
      "  draws population: 5.0431\n",
      "  draws population inferences: 5.0431\n",
      "  field: 2.9636\n",
      "  fields: 3.9444\n",
      "  fields in: 5.0431\n",
      "  fields in terms: 5.0431\n",
      "  finds: 4.3499\n",
      "  finds generalisable: 5.0431\n",
      "  finds generalisable predictive: 5.0431\n",
      "  from: 4.1453\n",
      "  from a: 3.7903\n",
      "  from a sample: 5.0431\n",
      "  from methodological: 5.0431\n",
      "  from methodological principles: 5.0431\n",
      "  generalisable: 5.0431\n",
      "  generalisable predictive: 5.0431\n",
      "  generalisable predictive patterns: 5.0431\n",
      "  goal: 4.1268\n",
      "  goal statistics: 5.0431\n",
      "  goal statistics draws: 5.0431\n",
      "  had: 3.6568\n",
      "  had a: 5.0431\n",
      "  had a long: 5.0431\n",
      "  have: 2.4781\n",
      "  have had: 5.0431\n",
      "  have had a: 5.0431\n",
      "  he: 4.6376\n",
      "  he also: 5.0431\n",
      "  he also suggested: 5.0431\n",
      "  i: 5.0431\n",
      "  i jordan: 5.0431\n",
      "  i jordan the: 5.0431\n",
      "  ideas: 5.0431\n",
      "  ideas of: 5.0431\n",
      "  ideas of machine: 5.0431\n",
      "  in: 4.0252\n",
      "  in statistics: 4.6376\n",
      "  in statistics he: 5.0431\n",
      "  in terms: 4.6376\n",
      "  in terms of: 4.6376\n",
      "  in their: 4.6376\n",
      "  in their principal: 5.0431\n",
      "  inferences: 5.0431\n",
      "  inferences from: 5.0431\n",
      "  inferences from a: 5.0431\n",
      "  jordan: 5.0431\n",
      "  jordan the: 5.0431\n",
      "  jordan the ideas: 5.0431\n",
      "  learning: 3.8456\n",
      "  learning and: 3.6568\n",
      "  learning and statistics: 5.0431\n",
      "  learning finds: 5.0431\n",
      "  learning finds generalisable: 5.0431\n",
      "  learning from: 5.0431\n",
      "  learning from methodological: 5.0431\n",
      "  long: 5.0431\n",
      "  long prehistory: 5.0431\n",
      "  long prehistory in: 5.0431\n",
      "  machine: 4.4206\n",
      "  machine learning: 4.6854\n",
      "  machine learning and: 4.1268\n",
      "  machine learning finds: 5.0431\n",
      "  machine learning from: 5.0431\n",
      "  methodological: 5.0431\n",
      "  methodological principles: 5.0431\n",
      "  methodological principles to: 5.0431\n",
      "  methods: 2.7405\n",
      "  methods but: 4.6376\n",
      "  methods but distinct: 5.0431\n",
      "  michael: 5.0431\n",
      "  michael i: 5.0431\n",
      "  michael i jordan: 5.0431\n",
      "  of: 2.4288\n",
      "  of machine: 3.0281\n",
      "  of machine learning: 3.0281\n",
      "  of methods: 5.0431\n",
      "  of methods but: 5.0431\n",
      "  overall: 4.6376\n",
      "  overall field: 5.0431\n",
      "  patterns: 3.4336\n",
      "  patterns according: 5.0431\n",
      "  patterns according to: 5.0431\n",
      "  placeholder: 5.0431\n",
      "  placeholder to: 5.0431\n",
      "  placeholder to call: 5.0431\n",
      "  population: 4.6376\n",
      "  population inferences: 5.0431\n",
      "  population inferences from: 5.0431\n",
      "  predictive: 4.1268\n",
      "  predictive patterns: 5.0431\n",
      "  predictive patterns according: 5.0431\n",
      "  prehistory: 5.0431\n",
      "  prehistory in: 5.0431\n",
      "  prehistory in statistics: 5.0431\n",
      "  principal: 4.3499\n",
      "  principal goal: 5.0431\n",
      "  principal goal statistics: 5.0431\n",
      "  principles: 5.0431\n",
      "  principles to: 5.0431\n",
      "  principles to theoretical: 5.0431\n",
      "  related: 3.6568\n",
      "  related fields: 5.0431\n",
      "  related fields in: 5.0431\n",
      "  sample: 4.6376\n",
      "  sample while: 5.0431\n",
      "  sample while machine: 5.0431\n",
      "  science: 4.3499\n",
      "  science as: 5.0431\n",
      "  science as a: 5.0431\n",
      "  statistics: 10.9703\n",
      "  statistics are: 5.0431\n",
      "  statistics are closely: 5.0431\n",
      "  statistics draws: 5.0431\n",
      "  statistics draws population: 5.0431\n",
      "  statistics he: 5.0431\n",
      "  statistics he also: 5.0431\n",
      "  suggested: 5.0431\n",
      "  suggested the: 5.0431\n",
      "  suggested the term: 5.0431\n",
      "  term: 3.7903\n",
      "  term data: 5.0431\n",
      "  term data science: 5.0431\n",
      "  terms: 4.3499\n",
      "  terms of: 4.6376\n",
      "  terms of methods: 5.0431\n",
      "  the: 3.5787\n",
      "  the ideas: 5.0431\n",
      "  the ideas of: 5.0431\n",
      "  the overall: 5.0431\n",
      "  the overall field: 5.0431\n",
      "  the term: 3.9444\n",
      "  the term data: 5.0431\n",
      "  their: 2.7918\n",
      "  their principal: 5.0431\n",
      "  their principal goal: 5.0431\n",
      "  theoretical: 3.6568\n",
      "  theoretical tools: 5.0431\n",
      "  theoretical tools have: 5.0431\n",
      "  to: 3.6760\n",
      "  to call: 5.0431\n",
      "  to call the: 5.0431\n",
      "  to michael: 5.0431\n",
      "  to michael i: 5.0431\n",
      "  to theoretical: 5.0431\n",
      "  to theoretical tools: 5.0431\n",
      "  tools: 4.1268\n",
      "  tools have: 5.0431\n",
      "  tools have had: 5.0431\n",
      "  while: 3.4336\n",
      "  while machine: 4.6376\n",
      "  while machine learning: 4.6376\n",
      "\n",
      "Document 24:\n",
      "  a: 3.7766\n",
      "  a model: 3.9444\n",
      "  a model most: 5.0431\n",
      "  a prestructured: 5.0431\n",
      "  a prestructured model: 5.0431\n",
      "  a priori: 5.0431\n",
      "  a priori selection: 5.0431\n",
      "  accurate: 4.3499\n",
      "  accurate the: 5.0431\n",
      "  accurate the ultimate: 5.0431\n",
      "  addition: 3.7903\n",
      "  addition only: 5.0431\n",
      "  addition only significant: 5.0431\n",
      "  analyses: 5.0431\n",
      "  analyses require: 5.0431\n",
      "  analyses require the: 5.0431\n",
      "  analysis: 3.1712\n",
      "  analysis in: 5.0431\n",
      "  analysis in contrast: 5.0431\n",
      "  are: 1.9750\n",
      "  are included: 5.0431\n",
      "  are included for: 5.0431\n",
      "  based: 3.4336\n",
      "  based on: 3.4336\n",
      "  based on previous: 5.0431\n",
      "  be: 2.0726\n",
      "  built: 4.1268\n",
      "  built on: 5.0431\n",
      "  built on a: 5.0431\n",
      "  by: 1.9076\n",
      "  by detecting: 5.0431\n",
      "  by detecting underlying: 5.0431\n",
      "  contrast: 4.1268\n",
      "  contrast machine: 5.0431\n",
      "  contrast machine learning: 5.0431\n",
      "  conventional: 4.6376\n",
      "  conventional statistical: 5.0431\n",
      "  conventional statistical analyses: 5.0431\n",
      "  data: 3.7300\n",
      "  data set: 4.3499\n",
      "  data set in: 5.0431\n",
      "  data shape: 5.0431\n",
      "  data shape the: 5.0431\n",
      "  detecting: 5.0431\n",
      "  detecting underlying: 5.0431\n",
      "  detecting underlying patterns: 5.0431\n",
      "  experience: 4.3499\n",
      "  experience are: 5.0431\n",
      "  experience are included: 5.0431\n",
      "  for: 3.4577\n",
      "  for analysis: 5.0431\n",
      "  for analysis in: 5.0431\n",
      "  for the: 4.1268\n",
      "  for the study: 5.0431\n",
      "  in: 2.6835\n",
      "  in addition: 3.7903\n",
      "  in addition only: 5.0431\n",
      "  in contrast: 4.1268\n",
      "  in contrast machine: 5.0431\n",
      "  included: 5.0431\n",
      "  included for: 5.0431\n",
      "  included for analysis: 5.0431\n",
      "  input: 3.0281\n",
      "  input used: 5.0431\n",
      "  input used to: 5.0431\n",
      "  is: 1.5167\n",
      "  is not: 4.6376\n",
      "  is not built: 5.0431\n",
      "  learning: 1.2819\n",
      "  learning is: 3.0281\n",
      "  learning is not: 4.6376\n",
      "  machine: 1.4735\n",
      "  machine learning: 1.5618\n",
      "  machine learning is: 3.6568\n",
      "  model: 11.6750\n",
      "  model by: 4.6376\n",
      "  model by detecting: 5.0431\n",
      "  model most: 5.0431\n",
      "  model most suitable: 5.0431\n",
      "  model rather: 5.0431\n",
      "  model rather the: 5.0431\n",
      "  model the: 4.3499\n",
      "  model the more: 5.0431\n",
      "  model will: 5.0431\n",
      "  model will be: 5.0431\n",
      "  more: 6.3425\n",
      "  more accurate: 5.0431\n",
      "  more accurate the: 5.0431\n",
      "  more variables: 5.0431\n",
      "  more variables input: 5.0431\n",
      "  most: 4.3499\n",
      "  most suitable: 5.0431\n",
      "  most suitable for: 5.0431\n",
      "  not: 2.6007\n",
      "  not built: 5.0431\n",
      "  not built on: 5.0431\n",
      "  of: 1.2144\n",
      "  of a: 3.0281\n",
      "  of a model: 5.0431\n",
      "  on: 4.0946\n",
      "  on a: 3.5390\n",
      "  on a prestructured: 5.0431\n",
      "  on previous: 5.0431\n",
      "  on previous experience: 5.0431\n",
      "  only: 3.6568\n",
      "  only significant: 5.0431\n",
      "  only significant or: 5.0431\n",
      "  or: 2.0226\n",
      "  or theoretically: 5.0431\n",
      "  or theoretically relevant: 5.0431\n",
      "  patterns: 3.4336\n",
      "  patterns the: 5.0431\n",
      "  patterns the more: 5.0431\n",
      "  prestructured: 5.0431\n",
      "  prestructured model: 5.0431\n",
      "  prestructured model rather: 5.0431\n",
      "  previous: 4.1268\n",
      "  previous experience: 5.0431\n",
      "  previous experience are: 5.0431\n",
      "  priori: 5.0431\n",
      "  priori selection: 5.0431\n",
      "  priori selection of: 5.0431\n",
      "  rather: 4.3499\n",
      "  rather the: 5.0431\n",
      "  rather the data: 5.0431\n",
      "  relevant: 5.0431\n",
      "  relevant variables: 5.0431\n",
      "  relevant variables based: 5.0431\n",
      "  require: 4.1268\n",
      "  require the: 5.0431\n",
      "  require the a: 5.0431\n",
      "  selection: 4.1268\n",
      "  selection of: 4.6376\n",
      "  selection of a: 5.0431\n",
      "  set: 2.6007\n",
      "  set in: 4.6376\n",
      "  set in addition: 5.0431\n",
      "  shape: 5.0431\n",
      "  shape the: 5.0431\n",
      "  shape the model: 5.0431\n",
      "  significant: 4.6376\n",
      "  significant or: 5.0431\n",
      "  significant or theoretically: 5.0431\n",
      "  statistical: 3.4336\n",
      "  statistical analyses: 5.0431\n",
      "  statistical analyses require: 5.0431\n",
      "  study: 3.6568\n",
      "  study data: 5.0431\n",
      "  study data set: 5.0431\n",
      "  suitable: 4.6376\n",
      "  suitable for: 5.0431\n",
      "  suitable for the: 5.0431\n",
      "  the: 9.5432\n",
      "  the a: 5.0431\n",
      "  the a priori: 5.0431\n",
      "  the data: 3.0971\n",
      "  the data shape: 5.0431\n",
      "  the model: 7.8889\n",
      "  the model by: 5.0431\n",
      "  the model the: 5.0431\n",
      "  the more: 9.2752\n",
      "  the more accurate: 5.0431\n",
      "  the more variables: 5.0431\n",
      "  the study: 5.0431\n",
      "  the study data: 5.0431\n",
      "  the ultimate: 5.0431\n",
      "  the ultimate model: 5.0431\n",
      "  theoretically: 5.0431\n",
      "  theoretically relevant: 5.0431\n",
      "  theoretically relevant variables: 5.0431\n",
      "  to: 1.2253\n",
      "  to train: 4.3499\n",
      "  to train the: 5.0431\n",
      "  train: 4.3499\n",
      "  train the: 5.0431\n",
      "  train the model: 5.0431\n",
      "  ultimate: 5.0431\n",
      "  ultimate model: 5.0431\n",
      "  ultimate model will: 5.0431\n",
      "  underlying: 3.9444\n",
      "  underlying patterns: 4.6376\n",
      "  underlying patterns the: 5.0431\n",
      "  used: 2.3350\n",
      "  used to: 3.3383\n",
      "  used to train: 5.0431\n",
      "  variables: 7.3135\n",
      "  variables based: 5.0431\n",
      "  variables based on: 5.0431\n",
      "  variables input: 5.0431\n",
      "  variables input used: 5.0431\n",
      "  will: 3.7903\n",
      "  will be: 4.6376\n",
      "\n",
      "Document 25:\n",
      "  algorithmic: 7.8889\n",
      "  algorithmic model: 10.0861\n",
      "  algorithmic model means: 5.0431\n",
      "  algorithmic model wherein: 5.0431\n",
      "  algorithms: 2.3689\n",
      "  algorithms like: 5.0431\n",
      "  algorithms like random: 5.0431\n",
      "  and: 1.2144\n",
      "  and algorithmic: 5.0431\n",
      "  and algorithmic model: 5.0431\n",
      "  breiman: 5.0431\n",
      "  breiman distinguished: 5.0431\n",
      "  breiman distinguished two: 5.0431\n",
      "  data: 1.8650\n",
      "  data model: 5.0431\n",
      "  data model and: 5.0431\n",
      "  distinguished: 5.0431\n",
      "  distinguished two: 5.0431\n",
      "  distinguished two statistical: 5.0431\n",
      "  forest: 4.6376\n",
      "  learning: 1.2819\n",
      "  learning algorithms: 2.9030\n",
      "  learning algorithms like: 5.0431\n",
      "  leo: 5.0431\n",
      "  leo breiman: 5.0431\n",
      "  leo breiman distinguished: 5.0431\n",
      "  less: 4.6376\n",
      "  less the: 5.0431\n",
      "  less the machine: 5.0431\n",
      "  like: 3.3383\n",
      "  like random: 5.0431\n",
      "  like random forest: 5.0431\n",
      "  machine: 1.4735\n",
      "  machine learning: 1.5618\n",
      "  machine learning algorithms: 3.4336\n",
      "  means: 5.0431\n",
      "  means more: 5.0431\n",
      "  means more or: 5.0431\n",
      "  model: 7.0050\n",
      "  model and: 5.0431\n",
      "  model and algorithmic: 5.0431\n",
      "  model means: 5.0431\n",
      "  model means more: 5.0431\n",
      "  model wherein: 5.0431\n",
      "  model wherein algorithmic: 5.0431\n",
      "  modelling: 4.3499\n",
      "  modelling paradigms: 5.0431\n",
      "  modelling paradigms data: 5.0431\n",
      "  more: 3.1712\n",
      "  more or: 5.0431\n",
      "  more or less: 5.0431\n",
      "  or: 2.0226\n",
      "  or less: 5.0431\n",
      "  or less the: 5.0431\n",
      "  paradigms: 4.6376\n",
      "  paradigms data: 5.0431\n",
      "  paradigms data model: 5.0431\n",
      "  random: 3.9444\n",
      "  random forest: 4.6376\n",
      "  statistical: 3.4336\n",
      "  statistical modelling: 5.0431\n",
      "  statistical modelling paradigms: 5.0431\n",
      "  the: 1.1929\n",
      "  the machine: 4.1268\n",
      "  the machine learning: 4.3499\n",
      "  two: 3.5390\n",
      "  two statistical: 5.0431\n",
      "  two statistical modelling: 5.0431\n",
      "  wherein: 5.0431\n",
      "  wherein algorithmic: 5.0431\n",
      "  wherein algorithmic model: 5.0431\n",
      "\n",
      "Document 26:\n",
      "  a: 1.2589\n",
      "  a combined: 5.0431\n",
      "  a combined field: 5.0431\n",
      "  adopted: 4.6376\n",
      "  adopted methods: 5.0431\n",
      "  adopted methods from: 5.0431\n",
      "  call: 4.6376\n",
      "  call statistical: 5.0431\n",
      "  call statistical learning: 5.0431\n",
      "  combined: 4.3499\n",
      "  combined field: 5.0431\n",
      "  combined field that: 5.0431\n",
      "  field: 2.9636\n",
      "  field that: 4.6376\n",
      "  field that they: 5.0431\n",
      "  from: 2.0726\n",
      "  from machine: 5.0431\n",
      "  from machine learning: 5.0431\n",
      "  have: 2.4781\n",
      "  have adopted: 5.0431\n",
      "  have adopted methods: 5.0431\n",
      "  leading: 4.1268\n",
      "  leading to: 4.1268\n",
      "  leading to a: 5.0431\n",
      "  learning: 2.5637\n",
      "  learning leading: 5.0431\n",
      "  learning leading to: 5.0431\n",
      "  machine: 1.4735\n",
      "  machine learning: 1.5618\n",
      "  machine learning leading: 5.0431\n",
      "  methods: 2.7405\n",
      "  methods from: 5.0431\n",
      "  methods from machine: 5.0431\n",
      "  some: 2.9636\n",
      "  some statisticians: 5.0431\n",
      "  some statisticians have: 5.0431\n",
      "  statistical: 3.4336\n",
      "  statistical learning: 5.0431\n",
      "  statisticians: 5.0431\n",
      "  statisticians have: 5.0431\n",
      "  statisticians have adopted: 5.0431\n",
      "  that: 1.6758\n",
      "  that they: 5.0431\n",
      "  that they call: 5.0431\n",
      "  they: 3.4336\n",
      "  they call: 5.0431\n",
      "  they call statistical: 5.0431\n",
      "  to: 1.2253\n",
      "  to a: 3.1712\n",
      "  to a combined: 5.0431\n",
      "\n",
      "Document 27:\n",
      "  analyse: 4.6376\n",
      "  analyse the: 5.0431\n",
      "  analyse the weight: 5.0431\n",
      "  analytical: 5.0431\n",
      "  analytical and: 5.0431\n",
      "  analytical and computational: 5.0431\n",
      "  and: 1.2144\n",
      "  and computational: 5.0431\n",
      "  and computational techniques: 5.0431\n",
      "  applications: 3.7903\n",
      "  applications in: 4.6376\n",
      "  applications in the: 5.0431\n",
      "  area: 3.9444\n",
      "  area of: 4.1268\n",
      "  area of medical: 5.0431\n",
      "  be: 2.0726\n",
      "  be extended: 5.0431\n",
      "  be extended to: 5.0431\n",
      "  can: 2.1809\n",
      "  can be: 2.7405\n",
      "  can be extended: 5.0431\n",
      "  computational: 4.1268\n",
      "  computational techniques: 5.0431\n",
      "  computational techniques derived: 5.0431\n",
      "  deep: 3.6568\n",
      "  deep neural: 4.6376\n",
      "  deep neural networks: 4.6376\n",
      "  deeprooted: 5.0431\n",
      "  deeprooted physics: 5.0431\n",
      "  deeprooted physics of: 5.0431\n",
      "  derived: 4.6376\n",
      "  derived from: 4.6376\n",
      "  derived from deeprooted: 5.0431\n",
      "  diagnostics: 5.0431\n",
      "  disordered: 5.0431\n",
      "  disordered systems: 5.0431\n",
      "  disordered systems can: 5.0431\n",
      "  eg: 3.9444\n",
      "  eg to: 5.0431\n",
      "  eg to analyse: 5.0431\n",
      "  extended: 4.3499\n",
      "  extended to: 5.0431\n",
      "  extended to largescale: 5.0431\n",
      "  finding: 4.3499\n",
      "  finding applications: 5.0431\n",
      "  finding applications in: 5.0431\n",
      "  from: 2.0726\n",
      "  from deeprooted: 5.0431\n",
      "  from deeprooted physics: 5.0431\n",
      "  in: 1.3417\n",
      "  in the: 2.4404\n",
      "  in the area: 5.0431\n",
      "  including: 3.4336\n",
      "  including machine: 5.0431\n",
      "  including machine learning: 5.0431\n",
      "  is: 1.5167\n",
      "  is thus: 5.0431\n",
      "  is thus finding: 5.0431\n",
      "  largescale: 4.1268\n",
      "  largescale problems: 5.0431\n",
      "  largescale problems including: 5.0431\n",
      "  learning: 1.2819\n",
      "  learning eg: 5.0431\n",
      "  learning eg to: 5.0431\n",
      "  machine: 1.4735\n",
      "  machine learning: 1.5618\n",
      "  machine learning eg: 5.0431\n",
      "  medical: 3.7903\n",
      "  medical diagnostics: 5.0431\n",
      "  networks: 3.0971\n",
      "  networks statistical: 5.0431\n",
      "  networks statistical physics: 5.0431\n",
      "  neural: 3.0281\n",
      "  neural networks: 3.2513\n",
      "  neural networks statistical: 5.0431\n",
      "  of: 3.6432\n",
      "  of deep: 4.3499\n",
      "  of deep neural: 5.0431\n",
      "  of disordered: 5.0431\n",
      "  of disordered systems: 5.0431\n",
      "  of medical: 4.6376\n",
      "  of medical diagnostics: 5.0431\n",
      "  physics: 10.0861\n",
      "  physics is: 5.0431\n",
      "  physics is thus: 5.0431\n",
      "  physics of: 5.0431\n",
      "  physics of disordered: 5.0431\n",
      "  problems: 3.1712\n",
      "  problems including: 5.0431\n",
      "  problems including machine: 5.0431\n",
      "  space: 3.7903\n",
      "  space of: 4.6376\n",
      "  space of deep: 5.0431\n",
      "  statistical: 3.4336\n",
      "  statistical physics: 5.0431\n",
      "  statistical physics is: 5.0431\n",
      "  systems: 2.6917\n",
      "  systems can: 5.0431\n",
      "  systems can be: 5.0431\n",
      "  techniques: 3.3383\n",
      "  techniques derived: 5.0431\n",
      "  techniques derived from: 5.0431\n",
      "  the: 2.3858\n",
      "  the area: 4.6376\n",
      "  the area of: 4.6376\n",
      "  the weight: 4.6376\n",
      "  the weight space: 5.0431\n",
      "  thus: 4.3499\n",
      "  thus finding: 5.0431\n",
      "  thus finding applications: 5.0431\n",
      "  to: 2.4507\n",
      "  to analyse: 4.6376\n",
      "  to analyse the: 5.0431\n",
      "  to largescale: 5.0431\n",
      "  to largescale problems: 5.0431\n",
      "  weight: 4.6376\n",
      "  weight space: 5.0431\n",
      "  weight space of: 5.0431\n",
      "\n",
      "Document 28:\n",
      "  a: 6.2943\n",
      "  a core: 5.0431\n",
      "  a core objective: 5.0431\n",
      "  a general: 4.1268\n",
      "  a general model: 5.0431\n",
      "  a learner: 5.0431\n",
      "  a learner is: 5.0431\n",
      "  a learning: 8.6998\n",
      "  a learning data: 5.0431\n",
      "  a learning machine: 5.0431\n",
      "  ability: 4.6376\n",
      "  ability of: 5.0431\n",
      "  ability of a: 5.0431\n",
      "  about: 3.6568\n",
      "  about this: 5.0431\n",
      "  about this space: 5.0431\n",
      "  accurate: 4.3499\n",
      "  accurate predictions: 4.6376\n",
      "  accurate predictions in: 5.0431\n",
      "  accurately: 5.0431\n",
      "  accurately on: 5.0431\n",
      "  accurately on new: 5.0431\n",
      "  after: 3.7903\n",
      "  after having: 5.0431\n",
      "  after having experienced: 5.0431\n",
      "  and: 1.2144\n",
      "  and the: 3.3383\n",
      "  and the learner: 5.0431\n",
      "  build: 4.3499\n",
      "  build a: 4.6376\n",
      "  build a general: 5.0431\n",
      "  cases: 4.6376\n",
      "  come: 4.3499\n",
      "  come from: 5.0431\n",
      "  come from some: 5.0431\n",
      "  considered: 3.7903\n",
      "  considered representative: 5.0431\n",
      "  considered representative of: 5.0431\n",
      "  context: 4.3499\n",
      "  context is: 5.0431\n",
      "  context is the: 5.0431\n",
      "  core: 4.6376\n",
      "  core objective: 5.0431\n",
      "  core objective of: 5.0431\n",
      "  data: 1.8650\n",
      "  data set: 4.3499\n",
      "  data set the: 5.0431\n",
      "  distribution: 3.9444\n",
      "  distribution considered: 5.0431\n",
      "  distribution considered representative: 5.0431\n",
      "  enables: 4.6376\n",
      "  enables it: 5.0431\n",
      "  enables it to: 5.0431\n",
      "  examples: 3.0971\n",
      "  examples come: 5.0431\n",
      "  examples come from: 5.0431\n",
      "  examplestasks: 5.0431\n",
      "  examplestasks after: 5.0431\n",
      "  examplestasks after having: 5.0431\n",
      "  experience: 4.3499\n",
      "  experience generalisation: 5.0431\n",
      "  experience generalisation in: 5.0431\n",
      "  experienced: 5.0431\n",
      "  experienced a: 5.0431\n",
      "  experienced a learning: 5.0431\n",
      "  from: 4.1453\n",
      "  from its: 5.0431\n",
      "  from its experience: 5.0431\n",
      "  from some: 5.0431\n",
      "  from some generally: 5.0431\n",
      "  general: 3.9444\n",
      "  general model: 5.0431\n",
      "  general model about: 5.0431\n",
      "  generalisation: 4.1268\n",
      "  generalisation in: 5.0431\n",
      "  generalisation in this: 5.0431\n",
      "  generalise: 4.6376\n",
      "  generalise from: 5.0431\n",
      "  generalise from its: 5.0431\n",
      "  generally: 4.6376\n",
      "  generally unknown: 5.0431\n",
      "  generally unknown probability: 5.0431\n",
      "  has: 2.8458\n",
      "  has to: 5.0431\n",
      "  has to build: 5.0431\n",
      "  having: 4.3499\n",
      "  having experienced: 5.0431\n",
      "  having experienced a: 5.0431\n",
      "  in: 2.6835\n",
      "  in new: 5.0431\n",
      "  in new cases: 5.0431\n",
      "  in this: 4.3499\n",
      "  in this context: 5.0431\n",
      "  is: 3.0334\n",
      "  is the: 3.3383\n",
      "  is the ability: 5.0431\n",
      "  is to: 3.9444\n",
      "  is to generalise: 5.0431\n",
      "  it: 2.2705\n",
      "  it to: 4.3499\n",
      "  it to produce: 5.0431\n",
      "  its: 2.9636\n",
      "  its experience: 5.0431\n",
      "  its experience generalisation: 5.0431\n",
      "  learner: 8.6998\n",
      "  learner has: 5.0431\n",
      "  learner has to: 5.0431\n",
      "  learner is: 5.0431\n",
      "  learner is to: 5.0431\n",
      "  learning: 2.5637\n",
      "  learning data: 4.6376\n",
      "  learning data set: 5.0431\n",
      "  learning machine: 4.6376\n",
      "  learning machine to: 5.0431\n",
      "  machine: 1.4735\n",
      "  machine to: 4.6376\n",
      "  machine to perform: 5.0431\n",
      "  model: 2.3350\n",
      "  model about: 5.0431\n",
      "  model about this: 5.0431\n",
      "  new: 6.5026\n",
      "  new cases: 5.0431\n",
      "  new unseen: 5.0431\n",
      "  new unseen examplestasks: 5.0431\n",
      "  objective: 4.6376\n",
      "  objective of: 5.0431\n",
      "  objective of a: 5.0431\n",
      "  occurrences: 5.0431\n",
      "  occurrences and: 5.0431\n",
      "  occurrences and the: 5.0431\n",
      "  of: 4.8576\n",
      "  of a: 6.0563\n",
      "  of a learner: 5.0431\n",
      "  of a learning: 5.0431\n",
      "  of occurrences: 5.0431\n",
      "  of occurrences and: 5.0431\n",
      "  of the: 2.3022\n",
      "  of the space: 5.0431\n",
      "  on: 2.0473\n",
      "  on new: 4.6376\n",
      "  on new unseen: 5.0431\n",
      "  perform: 3.2513\n",
      "  perform accurately: 5.0431\n",
      "  perform accurately on: 5.0431\n",
      "  predictions: 3.3383\n",
      "  predictions in: 5.0431\n",
      "  predictions in new: 5.0431\n",
      "  probability: 4.3499\n",
      "  probability distribution: 5.0431\n",
      "  probability distribution considered: 5.0431\n",
      "  produce: 4.3499\n",
      "  produce sufficiently: 5.0431\n",
      "  produce sufficiently accurate: 5.0431\n",
      "  representative: 3.9444\n",
      "  representative of: 5.0431\n",
      "  representative of the: 5.0431\n",
      "  set: 2.6007\n",
      "  set the: 5.0431\n",
      "  set the training: 5.0431\n",
      "  some: 2.9636\n",
      "  some generally: 5.0431\n",
      "  some generally unknown: 5.0431\n",
      "  space: 7.5806\n",
      "  space of: 4.6376\n",
      "  space of occurrences: 5.0431\n",
      "  space that: 5.0431\n",
      "  space that enables: 5.0431\n",
      "  sufficiently: 4.6376\n",
      "  sufficiently accurate: 5.0431\n",
      "  sufficiently accurate predictions: 5.0431\n",
      "  that: 1.6758\n",
      "  that enables: 5.0431\n",
      "  that enables it: 5.0431\n",
      "  the: 4.7716\n",
      "  the ability: 4.6376\n",
      "  the ability of: 5.0431\n",
      "  the learner: 5.0431\n",
      "  the learner has: 5.0431\n",
      "  the space: 5.0431\n",
      "  the space of: 5.0431\n",
      "  the training: 3.3383\n",
      "  the training examples: 4.6376\n",
      "  this: 5.2014\n",
      "  this context: 5.0431\n",
      "  this context is: 5.0431\n",
      "  this space: 5.0431\n",
      "  this space that: 5.0431\n",
      "  to: 4.9014\n",
      "  to build: 4.6376\n",
      "  to build a: 5.0431\n",
      "  to generalise: 5.0431\n",
      "  to generalise from: 5.0431\n",
      "  to perform: 3.9444\n",
      "  to perform accurately: 5.0431\n",
      "  to produce: 4.6376\n",
      "  to produce sufficiently: 5.0431\n",
      "  training: 2.5581\n",
      "  training examples: 4.1268\n",
      "  training examples come: 5.0431\n",
      "  unknown: 4.3499\n",
      "  unknown probability: 5.0431\n",
      "  unknown probability distribution: 5.0431\n",
      "  unseen: 4.3499\n",
      "  unseen examplestasks: 5.0431\n",
      "  unseen examplestasks after: 5.0431\n",
      "\n",
      "Document 29:\n",
      "  a: 1.2589\n",
      "  a branch: 4.6376\n",
      "  a branch of: 4.6376\n",
      "  algorithms: 4.7378\n",
      "  algorithms and: 4.6376\n",
      "  algorithms and their: 5.0431\n",
      "  algorithms instead: 5.0431\n",
      "  algorithms instead probabilistic: 5.0431\n",
      "  analysis: 3.1712\n",
      "  analysis of: 5.0431\n",
      "  analysis of machine: 5.0431\n",
      "  and: 2.4288\n",
      "  and the: 3.3383\n",
      "  and the future: 5.0431\n",
      "  and their: 3.9444\n",
      "  and their performance: 5.0431\n",
      "  approximately: 4.3499\n",
      "  approximately correct: 4.6376\n",
      "  approximately correct learning: 4.6376\n",
      "  are: 3.9500\n",
      "  are finite: 5.0431\n",
      "  are finite and: 5.0431\n",
      "  are quite: 5.0431\n",
      "  are quite common: 5.0431\n",
      "  as: 1.8444\n",
      "  as computational: 5.0431\n",
      "  as computational learning: 5.0431\n",
      "  because: 4.3499\n",
      "  because training: 5.0431\n",
      "  because training sets: 5.0431\n",
      "  biasvariance: 5.0431\n",
      "  biasvariance decomposition: 5.0431\n",
      "  biasvariance decomposition is: 5.0431\n",
      "  bounds: 4.6376\n",
      "  bounds on: 5.0431\n",
      "  bounds on the: 5.0431\n",
      "  branch: 4.6376\n",
      "  branch of: 4.6376\n",
      "  branch of theoretical: 5.0431\n",
      "  common: 3.9444\n",
      "  common the: 5.0431\n",
      "  common the biasvariance: 5.0431\n",
      "  computational: 8.2535\n",
      "  computational analysis: 5.0431\n",
      "  computational analysis of: 5.0431\n",
      "  computational learning: 4.6376\n",
      "  computational learning theory: 4.6376\n",
      "  computer: 3.2513\n",
      "  computer science: 4.6376\n",
      "  computer science known: 5.0431\n",
      "  correct: 4.6376\n",
      "  correct learning: 4.6376\n",
      "  correct learning model: 5.0431\n",
      "  decomposition: 5.0431\n",
      "  decomposition is: 5.0431\n",
      "  decomposition is one: 5.0431\n",
      "  does: 4.3499\n",
      "  does not: 4.3499\n",
      "  does not yield: 5.0431\n",
      "  error: 4.6376\n",
      "  finite: 4.6376\n",
      "  finite and: 5.0431\n",
      "  finite and the: 5.0431\n",
      "  future: 4.1268\n",
      "  future is: 5.0431\n",
      "  future is uncertain: 5.0431\n",
      "  generalisation: 4.1268\n",
      "  generalisation error: 5.0431\n",
      "  guarantees: 5.0431\n",
      "  guarantees of: 5.0431\n",
      "  guarantees of the: 5.0431\n",
      "  instead: 4.1268\n",
      "  instead probabilistic: 5.0431\n",
      "  instead probabilistic bounds: 5.0431\n",
      "  is: 4.5501\n",
      "  is a: 2.5173\n",
      "  is a branch: 4.6376\n",
      "  is one: 4.3499\n",
      "  is one way: 5.0431\n",
      "  is uncertain: 5.0431\n",
      "  is uncertain learning: 5.0431\n",
      "  known: 3.5390\n",
      "  known as: 3.7903\n",
      "  known as computational: 5.0431\n",
      "  learning: 5.1274\n",
      "  learning algorithms: 2.9030\n",
      "  learning algorithms and: 4.6376\n",
      "  learning model: 4.1268\n",
      "  learning model because: 5.0431\n",
      "  learning theory: 9.2752\n",
      "  learning theory usually: 5.0431\n",
      "  learning theory via: 5.0431\n",
      "  machine: 1.4735\n",
      "  machine learning: 1.5618\n",
      "  machine learning algorithms: 3.4336\n",
      "  model: 2.3350\n",
      "  model because: 5.0431\n",
      "  model because training: 5.0431\n",
      "  not: 2.6007\n",
      "  not yield: 5.0431\n",
      "  not yield guarantees: 5.0431\n",
      "  of: 4.8576\n",
      "  of algorithms: 5.0431\n",
      "  of algorithms instead: 5.0431\n",
      "  of machine: 3.0281\n",
      "  of machine learning: 3.0281\n",
      "  of the: 2.3022\n",
      "  of the performance: 5.0431\n",
      "  of theoretical: 5.0431\n",
      "  of theoretical computer: 5.0431\n",
      "  on: 2.0473\n",
      "  on the: 3.2513\n",
      "  on the performance: 5.0431\n",
      "  one: 3.0971\n",
      "  one way: 5.0431\n",
      "  one way to: 5.0431\n",
      "  performance: 10.3008\n",
      "  performance are: 5.0431\n",
      "  performance are quite: 5.0431\n",
      "  performance is: 4.6376\n",
      "  performance is a: 5.0431\n",
      "  performance of: 4.3499\n",
      "  performance of algorithms: 5.0431\n",
      "  probabilistic: 3.9444\n",
      "  probabilistic bounds: 5.0431\n",
      "  probabilistic bounds on: 5.0431\n",
      "  probably: 4.6376\n",
      "  probably approximately: 4.6376\n",
      "  probably approximately correct: 4.6376\n",
      "  quantify: 5.0431\n",
      "  quantify generalisation: 5.0431\n",
      "  quantify generalisation error: 5.0431\n",
      "  quite: 5.0431\n",
      "  quite common: 5.0431\n",
      "  quite common the: 5.0431\n",
      "  science: 4.3499\n",
      "  science known: 5.0431\n",
      "  science known as: 5.0431\n",
      "  sets: 4.1268\n",
      "  sets are: 5.0431\n",
      "  sets are finite: 5.0431\n",
      "  the: 7.1574\n",
      "  the biasvariance: 5.0431\n",
      "  the biasvariance decomposition: 5.0431\n",
      "  the computational: 4.6376\n",
      "  the computational analysis: 5.0431\n",
      "  the future: 5.0431\n",
      "  the future is: 5.0431\n",
      "  the performance: 8.6998\n",
      "  the performance are: 5.0431\n",
      "  the performance of: 4.3499\n",
      "  the probably: 5.0431\n",
      "  the probably approximately: 5.0431\n",
      "  their: 2.7918\n",
      "  their performance: 5.0431\n",
      "  their performance is: 5.0431\n",
      "  theoretical: 3.6568\n",
      "  theoretical computer: 5.0431\n",
      "  theoretical computer science: 5.0431\n",
      "  theory: 6.6766\n",
      "  theory usually: 5.0431\n",
      "  theory usually does: 5.0431\n",
      "  theory via: 5.0431\n",
      "  theory via the: 5.0431\n",
      "  to: 1.2253\n",
      "  to quantify: 5.0431\n",
      "  to quantify generalisation: 5.0431\n",
      "  training: 2.5581\n",
      "  training sets: 4.3499\n",
      "  training sets are: 5.0431\n",
      "  uncertain: 5.0431\n",
      "  uncertain learning: 5.0431\n",
      "  uncertain learning theory: 5.0431\n",
      "  usually: 4.6376\n",
      "  usually does: 5.0431\n",
      "  usually does not: 5.0431\n",
      "  via: 4.3499\n",
      "  via the: 5.0431\n",
      "  via the probably: 5.0431\n",
      "  way: 3.9444\n",
      "  way to: 4.6376\n",
      "  way to quantify: 5.0431\n",
      "  yield: 5.0431\n",
      "  yield guarantees: 5.0431\n",
      "  yield guarantees of: 5.0431\n",
      "\n",
      "Document 30:\n",
      "  and: 1.2144\n",
      "  and generalisation: 5.0431\n",
      "  and generalisation will: 5.0431\n",
      "  be: 2.0726\n",
      "  be poorer: 5.0431\n",
      "  best: 3.6568\n",
      "  best performance: 5.0431\n",
      "  best performance in: 5.0431\n",
      "  but: 3.0281\n",
      "  but if: 5.0431\n",
      "  but if the: 5.0431\n",
      "  complex: 9.2752\n",
      "  complex than: 5.0431\n",
      "  complex than the: 5.0431\n",
      "  complex then: 5.0431\n",
      "  complex then the: 5.0431\n",
      "  complexity: 13.0497\n",
      "  complexity of: 13.9128\n",
      "  complexity of the: 15.1292\n",
      "  context: 4.3499\n",
      "  context of: 4.6376\n",
      "  context of generalisation: 5.0431\n",
      "  data: 3.7300\n",
      "  data if: 10.0861\n",
      "  data if the: 10.0861\n",
      "  decreases: 4.6376\n",
      "  decreases but: 5.0431\n",
      "  decreases but if: 5.0431\n",
      "  error: 4.6376\n",
      "  error decreases: 5.0431\n",
      "  error decreases but: 5.0431\n",
      "  fitted: 5.0431\n",
      "  fitted the: 5.0431\n",
      "  fitted the data: 5.0431\n",
      "  for: 1.7289\n",
      "  for the: 4.1268\n",
      "  for the best: 5.0431\n",
      "  function: 6.8672\n",
      "  function then: 5.0431\n",
      "  function then the: 5.0431\n",
      "  function underlying: 5.0431\n",
      "  function underlying the: 5.0431\n",
      "  generalisation: 8.2535\n",
      "  generalisation the: 5.0431\n",
      "  generalisation the complexity: 5.0431\n",
      "  generalisation will: 5.0431\n",
      "  generalisation will be: 5.0431\n",
      "  has: 2.8458\n",
      "  has under: 5.0431\n",
      "  has under fitted: 5.0431\n",
      "  hypothesis: 13.9128\n",
      "  hypothesis is: 10.0861\n",
      "  hypothesis is less: 5.0431\n",
      "  hypothesis is too: 5.0431\n",
      "  hypothesis should: 5.0431\n",
      "  hypothesis should match: 5.0431\n",
      "  if: 10.9703\n",
      "  if the: 13.9128\n",
      "  if the complexity: 5.0431\n",
      "  if the hypothesis: 10.0861\n",
      "  in: 2.6835\n",
      "  in response: 5.0431\n",
      "  in response then: 5.0431\n",
      "  in the: 2.4404\n",
      "  in the context: 4.6376\n",
      "  increased: 4.6376\n",
      "  increased in: 5.0431\n",
      "  increased in response: 5.0431\n",
      "  is: 6.0668\n",
      "  is increased: 5.0431\n",
      "  is increased in: 5.0431\n",
      "  is less: 5.0431\n",
      "  is less complex: 5.0431\n",
      "  is subject: 5.0431\n",
      "  is subject to: 5.0431\n",
      "  is too: 5.0431\n",
      "  is too complex: 5.0431\n",
      "  less: 4.6376\n",
      "  less complex: 5.0431\n",
      "  less complex than: 5.0431\n",
      "  match: 5.0431\n",
      "  match the: 5.0431\n",
      "  match the complexity: 5.0431\n",
      "  model: 7.0050\n",
      "  model has: 4.6376\n",
      "  model has under: 5.0431\n",
      "  model is: 8.6998\n",
      "  model is increased: 5.0431\n",
      "  model is subject: 5.0431\n",
      "  of: 4.8576\n",
      "  of generalisation: 5.0431\n",
      "  of generalisation the: 5.0431\n",
      "  of the: 6.9066\n",
      "  of the function: 5.0431\n",
      "  of the hypothesis: 5.0431\n",
      "  of the model: 4.6376\n",
      "  overfitting: 3.7903\n",
      "  overfitting and: 4.6376\n",
      "  overfitting and generalisation: 5.0431\n",
      "  performance: 3.4336\n",
      "  performance in: 5.0431\n",
      "  performance in the: 5.0431\n",
      "  poorer: 5.0431\n",
      "  response: 4.6376\n",
      "  response then: 5.0431\n",
      "  response then the: 5.0431\n",
      "  should: 5.0431\n",
      "  should match: 5.0431\n",
      "  should match the: 5.0431\n",
      "  subject: 5.0431\n",
      "  subject to: 5.0431\n",
      "  subject to overfitting: 5.0431\n",
      "  than: 4.1268\n",
      "  than the: 5.0431\n",
      "  than the function: 5.0431\n",
      "  the: 19.0865\n",
      "  the best: 4.1268\n",
      "  the best performance: 5.0431\n",
      "  the complexity: 15.1292\n",
      "  the complexity of: 15.1292\n",
      "  the context: 4.6376\n",
      "  the context of: 4.6376\n",
      "  the data: 6.1943\n",
      "  the data if: 10.0861\n",
      "  the function: 9.2752\n",
      "  the function then: 5.0431\n",
      "  the function underlying: 5.0431\n",
      "  the hypothesis: 15.1292\n",
      "  the hypothesis is: 10.0861\n",
      "  the hypothesis should: 5.0431\n",
      "  the model: 11.8333\n",
      "  the model has: 5.0431\n",
      "  the model is: 10.0861\n",
      "  the training: 3.3383\n",
      "  the training error: 5.0431\n",
      "  then: 11.8333\n",
      "  then the: 15.1292\n",
      "  then the model: 10.0861\n",
      "  then the training: 5.0431\n",
      "  to: 1.2253\n",
      "  to overfitting: 5.0431\n",
      "  to overfitting and: 5.0431\n",
      "  too: 4.6376\n",
      "  too complex: 5.0431\n",
      "  too complex then: 5.0431\n",
      "  training: 2.5581\n",
      "  training error: 5.0431\n",
      "  training error decreases: 5.0431\n",
      "  under: 3.4336\n",
      "  under fitted: 5.0431\n",
      "  under fitted the: 5.0431\n",
      "  underlying: 3.9444\n",
      "  underlying the: 5.0431\n",
      "  underlying the data: 5.0431\n",
      "  will: 3.7903\n",
      "  will be: 4.6376\n",
      "  will be poorer: 5.0431\n",
      "\n",
      "Document 31:\n",
      "  a: 2.5177\n",
      "  a certain: 5.0431\n",
      "  a certain class: 5.0431\n",
      "  a computation: 5.0431\n",
      "  a computation is: 5.0431\n",
      "  addition: 3.7903\n",
      "  addition to: 3.9444\n",
      "  addition to performance: 5.0431\n",
      "  and: 1.2144\n",
      "  and feasibility: 5.0431\n",
      "  and feasibility of: 5.0431\n",
      "  are: 1.9750\n",
      "  are two: 5.0431\n",
      "  are two kinds: 5.0431\n",
      "  be: 6.2179\n",
      "  be done: 5.0431\n",
      "  be done in: 5.0431\n",
      "  be learned: 10.0861\n",
      "  be learned in: 10.0861\n",
      "  bounds: 4.6376\n",
      "  bounds learning: 5.0431\n",
      "  bounds learning theorists: 5.0431\n",
      "  can: 4.3617\n",
      "  can be: 5.4809\n",
      "  can be done: 5.0431\n",
      "  can be learned: 5.0431\n",
      "  cannot: 3.7903\n",
      "  cannot be: 4.6376\n",
      "  cannot be learned: 5.0431\n",
      "  certain: 8.2535\n",
      "  certain class: 5.0431\n",
      "  certain class of: 5.0431\n",
      "  certain classes: 5.0431\n",
      "  certain classes cannot: 5.0431\n",
      "  class: 3.5390\n",
      "  class of: 3.9444\n",
      "  class of functions: 5.0431\n",
      "  classes: 4.6376\n",
      "  classes cannot: 5.0431\n",
      "  classes cannot be: 5.0431\n",
      "  complexity: 8.6998\n",
      "  complexity and: 5.0431\n",
      "  complexity and feasibility: 5.0431\n",
      "  complexity results: 5.0431\n",
      "  complexity results positive: 5.0431\n",
      "  computation: 4.3499\n",
      "  computation is: 5.0431\n",
      "  computation is considered: 5.0431\n",
      "  computational: 4.1268\n",
      "  computational learning: 4.6376\n",
      "  computational learning theory: 4.6376\n",
      "  considered: 3.7903\n",
      "  considered feasible: 5.0431\n",
      "  considered feasible if: 5.0431\n",
      "  done: 5.0431\n",
      "  done in: 5.0431\n",
      "  done in polynomial: 5.0431\n",
      "  feasibility: 5.0431\n",
      "  feasibility of: 5.0431\n",
      "  feasibility of learning: 5.0431\n",
      "  feasible: 5.0431\n",
      "  feasible if: 5.0431\n",
      "  feasible if it: 5.0431\n",
      "  functions: 4.1268\n",
      "  functions can: 5.0431\n",
      "  functions can be: 5.0431\n",
      "  if: 3.6568\n",
      "  if it: 5.0431\n",
      "  if it can: 5.0431\n",
      "  in: 6.7087\n",
      "  in addition: 3.7903\n",
      "  in addition to: 3.9444\n",
      "  in computational: 5.0431\n",
      "  in computational learning: 5.0431\n",
      "  in polynomial: 15.1292\n",
      "  in polynomial time: 15.1292\n",
      "  is: 1.5167\n",
      "  is considered: 4.6376\n",
      "  is considered feasible: 5.0431\n",
      "  it: 2.2705\n",
      "  it can: 4.6376\n",
      "  it can be: 5.0431\n",
      "  kinds: 4.6376\n",
      "  kinds of: 4.6376\n",
      "  kinds of time: 5.0431\n",
      "  learned: 7.5806\n",
      "  learned in: 10.0861\n",
      "  learned in polynomial: 10.0861\n",
      "  learning: 3.8456\n",
      "  learning in: 3.6568\n",
      "  learning in computational: 5.0431\n",
      "  learning theorists: 5.0431\n",
      "  learning theorists study: 5.0431\n",
      "  learning theory: 4.6376\n",
      "  learning theory a: 5.0431\n",
      "  negative: 3.9444\n",
      "  negative results: 5.0431\n",
      "  negative results show: 5.0431\n",
      "  of: 3.6432\n",
      "  of functions: 5.0431\n",
      "  of functions can: 5.0431\n",
      "  of learning: 5.0431\n",
      "  of learning in: 5.0431\n",
      "  of time: 4.6376\n",
      "  of time complexity: 5.0431\n",
      "  performance: 3.4336\n",
      "  performance bounds: 5.0431\n",
      "  performance bounds learning: 5.0431\n",
      "  polynomial: 13.9128\n",
      "  polynomial time: 15.1292\n",
      "  polynomial time negative: 5.0431\n",
      "  polynomial time there: 5.0431\n",
      "  positive: 4.1268\n",
      "  positive results: 5.0431\n",
      "  positive results show: 5.0431\n",
      "  results: 13.0497\n",
      "  results positive: 5.0431\n",
      "  results positive results: 5.0431\n",
      "  results show: 10.0861\n",
      "  results show that: 10.0861\n",
      "  show: 9.2752\n",
      "  show that: 10.0861\n",
      "  show that a: 5.0431\n",
      "  show that certain: 5.0431\n",
      "  study: 3.6568\n",
      "  study the: 5.0431\n",
      "  study the time: 5.0431\n",
      "  that: 3.3515\n",
      "  that a: 4.1268\n",
      "  that a certain: 5.0431\n",
      "  that certain: 5.0431\n",
      "  that certain classes: 5.0431\n",
      "  the: 1.1929\n",
      "  the time: 5.0431\n",
      "  the time complexity: 5.0431\n",
      "  theorists: 5.0431\n",
      "  theorists study: 5.0431\n",
      "  theorists study the: 5.0431\n",
      "  theory: 3.3383\n",
      "  theory a: 4.6376\n",
      "  theory a computation: 5.0431\n",
      "  there: 3.6568\n",
      "  there are: 4.1268\n",
      "  there are two: 5.0431\n",
      "  time: 17.6949\n",
      "  time complexity: 10.0861\n",
      "  time complexity and: 5.0431\n",
      "  time complexity results: 5.0431\n",
      "  time negative: 5.0431\n",
      "  time negative results: 5.0431\n",
      "  time there: 5.0431\n",
      "  time there are: 5.0431\n",
      "  to: 1.2253\n",
      "  to performance: 5.0431\n",
      "  to performance bounds: 5.0431\n",
      "  two: 3.5390\n",
      "  two kinds: 5.0431\n",
      "  two kinds of: 5.0431\n",
      "\n",
      "Document 32:\n",
      "\n",
      "Document 33:\n",
      "  approaches: 3.5390\n",
      "  approaches are: 5.0431\n",
      "  approaches are traditionally: 5.0431\n",
      "  are: 1.9750\n",
      "  are traditionally: 5.0431\n",
      "  are traditionally divided: 5.0431\n",
      "  available: 5.0431\n",
      "  available to: 5.0431\n",
      "  available to the: 5.0431\n",
      "  broad: 4.3499\n",
      "  broad categories: 4.6376\n",
      "  broad categories which: 5.0431\n",
      "  categories: 4.1268\n",
      "  categories which: 5.0431\n",
      "  categories which correspond: 5.0431\n",
      "  correspond: 5.0431\n",
      "  correspond to: 5.0431\n",
      "  correspond to learning: 5.0431\n",
      "  depending: 4.6376\n",
      "  depending on: 4.6376\n",
      "  depending on the: 5.0431\n",
      "  divided: 5.0431\n",
      "  divided into: 5.0431\n",
      "  divided into three: 5.0431\n",
      "  feedback: 4.6376\n",
      "  feedback available: 5.0431\n",
      "  feedback available to: 5.0431\n",
      "  into: 2.9636\n",
      "  into three: 5.0431\n",
      "  into three broad: 5.0431\n",
      "  learning: 3.8456\n",
      "  learning approaches: 3.9444\n",
      "  learning approaches are: 5.0431\n",
      "  learning paradigms: 5.0431\n",
      "  learning paradigms depending: 5.0431\n",
      "  learning system: 4.1268\n",
      "  machine: 1.4735\n",
      "  machine learning: 1.5618\n",
      "  machine learning approaches: 3.9444\n",
      "  nature: 4.1268\n",
      "  nature of: 4.6376\n",
      "  nature of the: 5.0431\n",
      "  of: 1.2144\n",
      "  of the: 2.3022\n",
      "  of the signal: 4.6376\n",
      "  on: 2.0473\n",
      "  on the: 3.2513\n",
      "  on the nature: 5.0431\n",
      "  or: 2.0226\n",
      "  or feedback: 5.0431\n",
      "  or feedback available: 5.0431\n",
      "  paradigms: 4.6376\n",
      "  paradigms depending: 5.0431\n",
      "  paradigms depending on: 5.0431\n",
      "  signal: 3.9444\n",
      "  signal or: 5.0431\n",
      "  signal or feedback: 5.0431\n",
      "  system: 3.0281\n",
      "  the: 3.5787\n",
      "  the learning: 5.0431\n",
      "  the learning system: 5.0431\n",
      "  the nature: 5.0431\n",
      "  the nature of: 5.0431\n",
      "  the signal: 4.6376\n",
      "  the signal or: 5.0431\n",
      "  three: 4.3499\n",
      "  three broad: 4.6376\n",
      "  three broad categories: 4.6376\n",
      "  to: 2.4507\n",
      "  to learning: 5.0431\n",
      "  to learning paradigms: 5.0431\n",
      "  to the: 3.1712\n",
      "  to the learning: 5.0431\n",
      "  traditionally: 5.0431\n",
      "  traditionally divided: 5.0431\n",
      "  traditionally divided into: 5.0431\n",
      "  which: 2.6917\n",
      "  which correspond: 5.0431\n",
      "  which correspond to: 5.0431\n",
      "\n",
      "Document 34:\n",
      "  advantages: 5.0431\n",
      "  advantages and: 5.0431\n",
      "  advantages and limitations: 5.0431\n",
      "  algorithm: 5.8060\n",
      "  algorithm has: 5.0431\n",
      "  algorithm has advantages: 5.0431\n",
      "  algorithm works: 5.0431\n",
      "  algorithm works for: 5.0431\n",
      "  all: 3.5390\n",
      "  all problems: 5.0431\n",
      "  although: 4.1268\n",
      "  although each: 5.0431\n",
      "  although each algorithm: 5.0431\n",
      "  and: 1.2144\n",
      "  and limitations: 5.0431\n",
      "  and limitations no: 5.0431\n",
      "  each: 3.0971\n",
      "  each algorithm: 5.0431\n",
      "  each algorithm has: 5.0431\n",
      "  for: 1.7289\n",
      "  for all: 4.6376\n",
      "  for all problems: 5.0431\n",
      "  has: 2.8458\n",
      "  has advantages: 5.0431\n",
      "  has advantages and: 5.0431\n",
      "  limitations: 5.0431\n",
      "  limitations no: 5.0431\n",
      "  limitations no single: 5.0431\n",
      "  no: 4.6376\n",
      "  no single: 5.0431\n",
      "  no single algorithm: 5.0431\n",
      "  problems: 3.1712\n",
      "  single: 4.1268\n",
      "  single algorithm: 5.0431\n",
      "  single algorithm works: 5.0431\n",
      "  works: 5.0431\n",
      "  works for: 5.0431\n",
      "  works for all: 5.0431\n",
      "\n",
      "Document 35:\n",
      "  a: 10.0709\n",
      "  a feature: 4.6376\n",
      "  a feature vector: 5.0431\n",
      "  a function: 5.0431\n",
      "  a function that: 5.0431\n",
      "  a mathematical: 4.6376\n",
      "  a mathematical model: 5.0431\n",
      "  a matrix: 5.0431\n",
      "  a matrix through: 5.0431\n",
      "  a part: 5.0431\n",
      "  a part of: 5.0431\n",
      "  a set: 6.5026\n",
      "  a set of: 6.5026\n",
      "  a supervisory: 5.0431\n",
      "  a supervisory signal: 5.0431\n",
      "  accuracy: 3.6568\n",
      "  accuracy of: 4.6376\n",
      "  accuracy of its: 4.6376\n",
      "  algorithm: 5.8060\n",
      "  algorithm that: 4.3499\n",
      "  algorithm that improves: 5.0431\n",
      "  algorithm to: 5.0431\n",
      "  algorithm to correctly: 5.0431\n",
      "  algorithms: 4.7378\n",
      "  algorithms build: 5.0431\n",
      "  algorithms build a: 5.0431\n",
      "  algorithms learn: 5.0431\n",
      "  algorithms learn a: 5.0431\n",
      "  allows: 4.6376\n",
      "  allows the: 5.0431\n",
      "  allows the algorithm: 5.0431\n",
      "  also: 2.6452\n",
      "  also known: 4.3499\n",
      "  also known as: 4.3499\n",
      "  an: 8.6107\n",
      "  an algorithm: 5.0431\n",
      "  an algorithm that: 5.0431\n",
      "  an array: 5.0431\n",
      "  an array or: 5.0431\n",
      "  an objective: 5.0431\n",
      "  an objective function: 5.0431\n",
      "  an optimal: 4.6376\n",
      "  an optimal function: 5.0431\n",
      "  and: 3.6432\n",
      "  and the: 10.0149\n",
      "  and the desired: 10.0861\n",
      "  and the training: 5.0431\n",
      "  array: 4.6376\n",
      "  array or: 5.0431\n",
      "  array or vector: 5.0431\n",
      "  as: 3.6888\n",
      "  as a: 2.9030\n",
      "  as a supervisory: 5.0431\n",
      "  as training: 4.6376\n",
      "  as training data: 5.0431\n",
      "  associated: 3.7903\n",
      "  associated with: 4.3499\n",
      "  associated with new: 5.0431\n",
      "  be: 2.0726\n",
      "  be used: 3.4336\n",
      "  be used to: 3.9444\n",
      "  both: 3.7903\n",
      "  both the: 4.6376\n",
      "  both the inputs: 5.0431\n",
      "  build: 4.3499\n",
      "  build a: 4.6376\n",
      "  build a mathematical: 5.0431\n",
      "  by: 3.8151\n",
      "  by a: 4.1268\n",
      "  by a matrix: 5.0431\n",
      "  by an: 4.6376\n",
      "  by an array: 5.0431\n",
      "  called: 3.2513\n",
      "  called a: 5.0431\n",
      "  called a feature: 5.0431\n",
      "  can: 2.1809\n",
      "  can be: 2.7405\n",
      "  can be used: 3.6568\n",
      "  consists: 4.6376\n",
      "  consists of: 4.6376\n",
      "  consists of a: 5.0431\n",
      "  contains: 4.6376\n",
      "  contains both: 4.6376\n",
      "  contains both the: 5.0431\n",
      "  correctly: 4.3499\n",
      "  correctly determine: 5.0431\n",
      "  correctly determine the: 5.0431\n",
      "  data: 9.3250\n",
      "  data an: 5.0431\n",
      "  data an algorithm: 5.0431\n",
      "  data consists: 5.0431\n",
      "  data consists of: 5.0431\n",
      "  data is: 4.6376\n",
      "  data is represented: 5.0431\n",
      "  data known: 5.0431\n",
      "  data known as: 5.0431\n",
      "  data that: 4.6376\n",
      "  data that contains: 5.0431\n",
      "  desired: 10.0861\n",
      "  desired output: 5.0431\n",
      "  desired output also: 5.0431\n",
      "  desired outputs: 5.0431\n",
      "  desired outputs the: 5.0431\n",
      "  determine: 4.6376\n",
      "  determine the: 4.6376\n",
      "  determine the output: 5.0431\n",
      "  each: 6.1943\n",
      "  each training: 10.0861\n",
      "  each training example: 10.0861\n",
      "  example: 5.9272\n",
      "  example has: 5.0431\n",
      "  example has one: 5.0431\n",
      "  example is: 4.3499\n",
      "  example is represented: 4.6376\n",
      "  examples: 3.0971\n",
      "  examples each: 4.6376\n",
      "  examples each training: 5.0431\n",
      "  feature: 3.4336\n",
      "  feature vector: 5.0431\n",
      "  feature vector and: 5.0431\n",
      "  for: 1.7289\n",
      "  for inputs: 5.0431\n",
      "  for inputs that: 5.0431\n",
      "  function: 10.3008\n",
      "  function allows: 5.0431\n",
      "  function allows the: 5.0431\n",
      "  function supervised: 5.0431\n",
      "  function supervised learning: 5.0431\n",
      "  function that: 4.6376\n",
      "  function that can: 5.0431\n",
      "  has: 2.8458\n",
      "  has one: 5.0431\n",
      "  has one or: 5.0431\n",
      "  have: 2.4781\n",
      "  have learned: 5.0431\n",
      "  have learned to: 5.0431\n",
      "  improves: 4.6376\n",
      "  improves the: 5.0431\n",
      "  improves the accuracy: 5.0431\n",
      "  in: 1.3417\n",
      "  in the: 2.4404\n",
      "  in the mathematical: 5.0431\n",
      "  inputs: 16.5070\n",
      "  inputs an: 5.0431\n",
      "  inputs an optimal: 5.0431\n",
      "  inputs and: 10.0861\n",
      "  inputs and the: 10.0861\n",
      "  inputs that: 5.0431\n",
      "  inputs that were: 5.0431\n",
      "  is: 4.5501\n",
      "  is represented: 9.2752\n",
      "  is represented by: 10.0861\n",
      "  is said: 4.6376\n",
      "  is said to: 4.6376\n",
      "  iterative: 5.0431\n",
      "  iterative optimisation: 5.0431\n",
      "  iterative optimisation of: 5.0431\n",
      "  its: 2.9636\n",
      "  its outputs: 5.0431\n",
      "  its outputs or: 5.0431\n",
      "  known: 7.0779\n",
      "  known as: 7.5806\n",
      "  known as a: 5.0431\n",
      "  known as training: 5.0431\n",
      "  learn: 3.3383\n",
      "  learn a: 5.0431\n",
      "  learn a function: 5.0431\n",
      "  learned: 3.7903\n",
      "  learned to: 5.0431\n",
      "  learned to perform: 5.0431\n",
      "  learning: 2.5637\n",
      "  learning algorithms: 5.8060\n",
      "  learning algorithms build: 5.0431\n",
      "  learning algorithms learn: 5.0431\n",
      "  mathematical: 7.0779\n",
      "  mathematical model: 8.2535\n",
      "  mathematical model each: 5.0431\n",
      "  mathematical model of: 4.6376\n",
      "  matrix: 3.9444\n",
      "  matrix through: 5.0431\n",
      "  matrix through iterative: 5.0431\n",
      "  model: 4.6700\n",
      "  model each: 5.0431\n",
      "  model each training: 5.0431\n",
      "  model of: 4.3499\n",
      "  model of a: 5.0431\n",
      "  more: 3.1712\n",
      "  more inputs: 5.0431\n",
      "  more inputs and: 5.0431\n",
      "  new: 3.2513\n",
      "  new inputs: 5.0431\n",
      "  new inputs an: 5.0431\n",
      "  not: 2.6007\n",
      "  not a: 4.6376\n",
      "  not a part: 5.0431\n",
      "  objective: 4.6376\n",
      "  objective function: 5.0431\n",
      "  objective function supervised: 5.0431\n",
      "  of: 8.5009\n",
      "  of a: 6.0563\n",
      "  of a set: 8.2535\n",
      "  of an: 4.3499\n",
      "  of an objective: 5.0431\n",
      "  of data: 3.6568\n",
      "  of data that: 5.0431\n",
      "  of its: 3.9444\n",
      "  of its outputs: 5.0431\n",
      "  of the: 2.3022\n",
      "  of the training: 4.3499\n",
      "  of training: 4.1268\n",
      "  of training examples: 4.6376\n",
      "  one: 3.0971\n",
      "  one or: 4.6376\n",
      "  one or more: 4.6376\n",
      "  optimal: 4.3499\n",
      "  optimal function: 5.0431\n",
      "  optimal function allows: 5.0431\n",
      "  optimisation: 3.7903\n",
      "  optimisation of: 5.0431\n",
      "  optimisation of an: 5.0431\n",
      "  or: 6.0679\n",
      "  or more: 4.6376\n",
      "  or more inputs: 5.0431\n",
      "  or predictions: 4.3499\n",
      "  or predictions over: 5.0431\n",
      "  or vector: 5.0431\n",
      "  or vector sometimes: 5.0431\n",
      "  output: 10.0149\n",
      "  output also: 5.0431\n",
      "  output also known: 5.0431\n",
      "  output associated: 5.0431\n",
      "  output associated with: 5.0431\n",
      "  output for: 5.0431\n",
      "  output for inputs: 5.0431\n",
      "  outputs: 8.6998\n",
      "  outputs or: 5.0431\n",
      "  outputs or predictions: 5.0431\n",
      "  outputs the: 5.0431\n",
      "  outputs the data: 5.0431\n",
      "  over: 4.3499\n",
      "  over time: 4.3499\n",
      "  over time is: 5.0431\n",
      "  part: 4.6376\n",
      "  part of: 4.6376\n",
      "  part of the: 5.0431\n",
      "  perform: 3.2513\n",
      "  perform that: 5.0431\n",
      "  perform that task: 5.0431\n",
      "  predict: 3.9444\n",
      "  predict the: 4.1268\n",
      "  predict the output: 5.0431\n",
      "  predictions: 3.3383\n",
      "  predictions over: 5.0431\n",
      "  predictions over time: 5.0431\n",
      "  represented: 7.3135\n",
      "  represented by: 8.6998\n",
      "  represented by a: 5.0431\n",
      "  represented by an: 4.6376\n",
      "  said: 4.3499\n",
      "  said to: 4.6376\n",
      "  said to have: 5.0431\n",
      "  set: 5.2014\n",
      "  set of: 6.0563\n",
      "  set of data: 5.0431\n",
      "  set of training: 4.6376\n",
      "  signal: 3.9444\n",
      "  signal in: 5.0431\n",
      "  signal in the: 5.0431\n",
      "  sometimes: 4.3499\n",
      "  sometimes called: 5.0431\n",
      "  sometimes called a: 5.0431\n",
      "  supervised: 6.5026\n",
      "  supervised learning: 7.3135\n",
      "  supervised learning algorithms: 10.0861\n",
      "  supervisory: 4.6376\n",
      "  supervisory signal: 4.6376\n",
      "  supervisory signal in: 5.0431\n",
      "  task: 3.9444\n",
      "  that: 8.3788\n",
      "  that can: 3.9444\n",
      "  that can be: 4.6376\n",
      "  that contains: 4.6376\n",
      "  that contains both: 4.6376\n",
      "  that improves: 5.0431\n",
      "  that improves the: 5.0431\n",
      "  that task: 5.0431\n",
      "  that were: 4.6376\n",
      "  that were not: 5.0431\n",
      "  the: 13.1219\n",
      "  the accuracy: 4.6376\n",
      "  the accuracy of: 4.6376\n",
      "  the algorithm: 4.6376\n",
      "  the algorithm to: 5.0431\n",
      "  the data: 3.0971\n",
      "  the data known: 5.0431\n",
      "  the desired: 10.0861\n",
      "  the desired output: 5.0431\n",
      "  the desired outputs: 5.0431\n",
      "  the inputs: 4.6376\n",
      "  the inputs and: 5.0431\n",
      "  the mathematical: 4.6376\n",
      "  the mathematical model: 4.6376\n",
      "  the output: 7.8889\n",
      "  the output associated: 5.0431\n",
      "  the output for: 5.0431\n",
      "  the training: 6.6766\n",
      "  the training data: 8.6998\n",
      "  through: 4.1268\n",
      "  through iterative: 5.0431\n",
      "  through iterative optimisation: 5.0431\n",
      "  time: 3.5390\n",
      "  time is: 5.0431\n",
      "  time is said: 5.0431\n",
      "  to: 4.9014\n",
      "  to correctly: 4.6376\n",
      "  to correctly determine: 5.0431\n",
      "  to have: 4.3499\n",
      "  to have learned: 5.0431\n",
      "  to perform: 3.9444\n",
      "  to perform that: 5.0431\n",
      "  to predict: 4.1268\n",
      "  to predict the: 4.3499\n",
      "  training: 15.3489\n",
      "  training data: 11.3709\n",
      "  training data an: 5.0431\n",
      "  training data consists: 5.0431\n",
      "  training data is: 4.6376\n",
      "  training example: 9.2752\n",
      "  training example has: 5.0431\n",
      "  training example is: 4.6376\n",
      "  training examples: 4.1268\n",
      "  training examples each: 4.6376\n",
      "  used: 2.3350\n",
      "  used to: 3.3383\n",
      "  used to predict: 5.0431\n",
      "  vector: 8.6998\n",
      "  vector and: 5.0431\n",
      "  vector and the: 5.0431\n",
      "  vector sometimes: 5.0431\n",
      "  vector sometimes called: 5.0431\n",
      "  were: 3.7903\n",
      "  were not: 4.6376\n",
      "  were not a: 5.0431\n",
      "  with: 2.0726\n",
      "  with new: 5.0431\n",
      "  with new inputs: 5.0431\n",
      "\n",
      "Document 36:\n",
      "  a: 5.0354\n",
      "  a classification: 5.0431\n",
      "  a classification algorithm: 5.0431\n",
      "  a limited: 5.0431\n",
      "  a limited set: 5.0431\n",
      "  a persons: 5.0431\n",
      "  a persons height: 5.0431\n",
      "  a range: 5.0431\n",
      "  a range for: 5.0431\n",
      "  active: 4.6376\n",
      "  active learning: 5.0431\n",
      "  active learning classification: 5.0431\n",
      "  age: 5.0431\n",
      "  age and: 5.0431\n",
      "  age and genetics: 5.0431\n",
      "  algorithm: 2.9030\n",
      "  algorithm that: 4.3499\n",
      "  algorithm that filters: 5.0431\n",
      "  algorithms: 7.1067\n",
      "  algorithms are: 8.6998\n",
      "  algorithms are used: 9.2752\n",
      "  algorithms include: 4.6376\n",
      "  algorithms include active: 5.0431\n",
      "  an: 2.1527\n",
      "  an incoming: 5.0431\n",
      "  an incoming email: 5.0431\n",
      "  and: 3.6432\n",
      "  and genetics: 5.0431\n",
      "  and genetics or: 5.0431\n",
      "  and regression: 4.6376\n",
      "  and regression classification: 5.0431\n",
      "  and the: 3.3383\n",
      "  and the output: 4.6376\n",
      "  any: 3.6568\n",
      "  any numerical: 5.0431\n",
      "  any numerical value: 5.0431\n",
      "  are: 5.9250\n",
      "  are restricted: 5.0431\n",
      "  are restricted to: 5.0431\n",
      "  are used: 9.2752\n",
      "  are used when: 9.2752\n",
      "  as: 1.8444\n",
      "  as predicting: 4.6376\n",
      "  as predicting a: 5.0431\n",
      "  based: 6.8672\n",
      "  based on: 6.8672\n",
      "  based on factors: 5.0431\n",
      "  based on historical: 5.0431\n",
      "  can: 2.1809\n",
      "  can take: 4.6376\n",
      "  can take any: 5.0431\n",
      "  classification: 8.8908\n",
      "  classification algorithm: 5.0431\n",
      "  classification algorithm that: 5.0431\n",
      "  classification algorithms: 5.0431\n",
      "  classification algorithms are: 5.0431\n",
      "  classification and: 4.6376\n",
      "  classification and regression: 4.6376\n",
      "  contrast: 4.1268\n",
      "  contrast regression: 5.0431\n",
      "  contrast regression is: 5.0431\n",
      "  data: 1.8650\n",
      "  email: 9.2752\n",
      "  email and: 5.0431\n",
      "  email and the: 5.0431\n",
      "  email in: 5.0431\n",
      "  email in contrast: 5.0431\n",
      "  emails: 5.0431\n",
      "  emails the: 5.0431\n",
      "  emails the input: 5.0431\n",
      "  example: 2.9636\n",
      "  example in: 4.1268\n",
      "  example in a: 5.0431\n",
      "  factors: 4.6376\n",
      "  factors like: 5.0431\n",
      "  factors like age: 5.0431\n",
      "  file: 4.6376\n",
      "  file the: 5.0431\n",
      "  file the email: 5.0431\n",
      "  filters: 5.0431\n",
      "  filters emails: 5.0431\n",
      "  filters emails the: 5.0431\n",
      "  folder: 5.0431\n",
      "  folder in: 5.0431\n",
      "  folder in which: 5.0431\n",
      "  for: 3.4577\n",
      "  for example: 3.2513\n",
      "  for example in: 4.1268\n",
      "  for tasks: 5.0431\n",
      "  for tasks such: 5.0431\n",
      "  forecasting: 5.0431\n",
      "  forecasting future: 5.0431\n",
      "  forecasting future temperatures: 5.0431\n",
      "  future: 4.1268\n",
      "  future temperatures: 5.0431\n",
      "  future temperatures based: 5.0431\n",
      "  genetics: 5.0431\n",
      "  genetics or: 5.0431\n",
      "  genetics or forecasting: 5.0431\n",
      "  height: 5.0431\n",
      "  height based: 5.0431\n",
      "  height based on: 5.0431\n",
      "  historical: 4.6376\n",
      "  historical data: 5.0431\n",
      "  in: 4.0252\n",
      "  in a: 3.0971\n",
      "  in a classification: 5.0431\n",
      "  in contrast: 4.1268\n",
      "  in contrast regression: 5.0431\n",
      "  in which: 3.7903\n",
      "  in which to: 5.0431\n",
      "  include: 3.4336\n",
      "  include active: 5.0431\n",
      "  include active learning: 5.0431\n",
      "  incoming: 5.0431\n",
      "  incoming email: 5.0431\n",
      "  incoming email and: 5.0431\n",
      "  input: 3.0281\n",
      "  input is: 5.0431\n",
      "  input is an: 5.0431\n",
      "  is: 4.5501\n",
      "  is an: 3.6568\n",
      "  is an incoming: 5.0431\n",
      "  is the: 3.3383\n",
      "  is the folder: 5.0431\n",
      "  is used: 4.1268\n",
      "  is used for: 5.0431\n",
      "  learning: 1.2819\n",
      "  learning classification: 5.0431\n",
      "  learning classification and: 5.0431\n",
      "  like: 3.3383\n",
      "  like age: 5.0431\n",
      "  like age and: 5.0431\n",
      "  limited: 4.3499\n",
      "  limited set: 5.0431\n",
      "  limited set of: 5.0431\n",
      "  numerical: 5.0431\n",
      "  numerical value: 5.0431\n",
      "  numerical value within: 5.0431\n",
      "  of: 2.4288\n",
      "  of supervisedlearning: 5.0431\n",
      "  of supervisedlearning algorithms: 5.0431\n",
      "  of values: 4.6376\n",
      "  of values while: 5.0431\n",
      "  on: 4.0946\n",
      "  on factors: 5.0431\n",
      "  on factors like: 5.0431\n",
      "  on historical: 5.0431\n",
      "  on historical data: 5.0431\n",
      "  or: 2.0226\n",
      "  or forecasting: 5.0431\n",
      "  or forecasting future: 5.0431\n",
      "  output: 3.3383\n",
      "  output is: 4.6376\n",
      "  output is the: 5.0431\n",
      "  outputs: 8.6998\n",
      "  outputs are: 4.6376\n",
      "  outputs are restricted: 5.0431\n",
      "  outputs can: 5.0431\n",
      "  outputs can take: 5.0431\n",
      "  persons: 5.0431\n",
      "  persons height: 5.0431\n",
      "  persons height based: 5.0431\n",
      "  predicting: 4.6376\n",
      "  predicting a: 5.0431\n",
      "  predicting a persons: 5.0431\n",
      "  range: 4.3499\n",
      "  range for: 5.0431\n",
      "  range for example: 5.0431\n",
      "  regression: 10.9703\n",
      "  regression algorithms: 5.0431\n",
      "  regression algorithms are: 5.0431\n",
      "  regression classification: 5.0431\n",
      "  regression classification algorithms: 5.0431\n",
      "  regression is: 5.0431\n",
      "  regression is used: 5.0431\n",
      "  restricted: 5.0431\n",
      "  restricted to: 5.0431\n",
      "  restricted to a: 5.0431\n",
      "  set: 2.6007\n",
      "  set of: 3.0281\n",
      "  set of values: 4.6376\n",
      "  such: 2.4781\n",
      "  such as: 2.8458\n",
      "  such as predicting: 4.6376\n",
      "  supervisedlearning: 5.0431\n",
      "  supervisedlearning algorithms: 5.0431\n",
      "  supervisedlearning algorithms include: 5.0431\n",
      "  take: 4.1268\n",
      "  take any: 5.0431\n",
      "  take any numerical: 5.0431\n",
      "  tasks: 3.4336\n",
      "  tasks such: 4.1268\n",
      "  tasks such as: 4.1268\n",
      "  temperatures: 5.0431\n",
      "  temperatures based: 5.0431\n",
      "  temperatures based on: 5.0431\n",
      "  that: 1.6758\n",
      "  that filters: 5.0431\n",
      "  that filters emails: 5.0431\n",
      "  the: 7.1574\n",
      "  the email: 5.0431\n",
      "  the email in: 5.0431\n",
      "  the folder: 5.0431\n",
      "  the folder in: 5.0431\n",
      "  the input: 4.6376\n",
      "  the input is: 5.0431\n",
      "  the output: 3.9444\n",
      "  the output is: 5.0431\n",
      "  the outputs: 10.0861\n",
      "  the outputs are: 5.0431\n",
      "  the outputs can: 5.0431\n",
      "  to: 2.4507\n",
      "  to a: 3.1712\n",
      "  to a limited: 5.0431\n",
      "  to file: 5.0431\n",
      "  to file the: 5.0431\n",
      "  types: 4.3499\n",
      "  types of: 4.3499\n",
      "  types of supervisedlearning: 5.0431\n",
      "  used: 7.0050\n",
      "  used for: 4.1268\n",
      "  used for tasks: 5.0431\n",
      "  used when: 9.2752\n",
      "  used when the: 10.0861\n",
      "  value: 4.3499\n",
      "  value within: 5.0431\n",
      "  value within a: 5.0431\n",
      "  values: 4.6376\n",
      "  values while: 5.0431\n",
      "  values while regression: 5.0431\n",
      "  when: 6.6766\n",
      "  when the: 10.0861\n",
      "  when the outputs: 10.0861\n",
      "  which: 2.6917\n",
      "  which to: 5.0431\n",
      "  which to file: 5.0431\n",
      "  while: 3.4336\n",
      "  while regression: 5.0431\n",
      "  while regression algorithms: 5.0431\n",
      "  within: 3.4336\n",
      "  within a: 4.3499\n",
      "  within a range: 5.0431\n",
      "\n",
      "Document 37:\n",
      "  a: 1.2589\n",
      "  a similarity: 5.0431\n",
      "  a similarity function: 5.0431\n",
      "  an: 2.1527\n",
      "  an area: 4.6376\n",
      "  an area of: 4.6376\n",
      "  and: 2.4288\n",
      "  and classification: 5.0431\n",
      "  and classification but: 5.0431\n",
      "  and speaker: 5.0431\n",
      "  and speaker verification: 5.0431\n",
      "  applications: 3.7903\n",
      "  applications in: 4.6376\n",
      "  applications in ranking: 5.0431\n",
      "  are: 1.9750\n",
      "  are it: 5.0431\n",
      "  are it has: 5.0431\n",
      "  area: 3.9444\n",
      "  area of: 4.1268\n",
      "  area of supervised: 5.0431\n",
      "  but: 3.0281\n",
      "  but the: 4.1268\n",
      "  but the goal: 5.0431\n",
      "  classification: 2.9636\n",
      "  classification but: 5.0431\n",
      "  classification but the: 5.0431\n",
      "  closely: 4.6376\n",
      "  closely related: 4.6376\n",
      "  closely related to: 5.0431\n",
      "  examples: 3.0971\n",
      "  examples using: 5.0431\n",
      "  examples using a: 5.0431\n",
      "  face: 5.0431\n",
      "  face verification: 5.0431\n",
      "  face verification and: 5.0431\n",
      "  from: 2.0726\n",
      "  from examples: 5.0431\n",
      "  from examples using: 5.0431\n",
      "  function: 3.4336\n",
      "  function that: 4.6376\n",
      "  function that measures: 5.0431\n",
      "  goal: 4.1268\n",
      "  goal is: 5.0431\n",
      "  goal is to: 5.0431\n",
      "  has: 2.8458\n",
      "  has applications: 5.0431\n",
      "  has applications in: 5.0431\n",
      "  how: 3.5390\n",
      "  how similar: 5.0431\n",
      "  how similar or: 5.0431\n",
      "  identity: 5.0431\n",
      "  identity tracking: 5.0431\n",
      "  identity tracking face: 5.0431\n",
      "  in: 1.3417\n",
      "  in ranking: 5.0431\n",
      "  in ranking recommendation: 5.0431\n",
      "  is: 3.0334\n",
      "  is an: 3.6568\n",
      "  is an area: 4.6376\n",
      "  is to: 3.9444\n",
      "  is to learn: 5.0431\n",
      "  it: 2.2705\n",
      "  it has: 4.3499\n",
      "  it has applications: 5.0431\n",
      "  learn: 3.3383\n",
      "  learn from: 4.1268\n",
      "  learn from examples: 5.0431\n",
      "  learning: 2.5637\n",
      "  learning closely: 5.0431\n",
      "  learning closely related: 5.0431\n",
      "  learning is: 3.0281\n",
      "  learning is an: 4.3499\n",
      "  machine: 1.4735\n",
      "  machine learning: 1.5618\n",
      "  machine learning closely: 5.0431\n",
      "  measures: 4.6376\n",
      "  measures how: 5.0431\n",
      "  measures how similar: 5.0431\n",
      "  objects: 4.3499\n",
      "  objects are: 4.6376\n",
      "  objects are it: 5.0431\n",
      "  of: 1.2144\n",
      "  of supervised: 5.0431\n",
      "  of supervised machine: 5.0431\n",
      "  or: 2.0226\n",
      "  or related: 5.0431\n",
      "  or related two: 5.0431\n",
      "  ranking: 5.0431\n",
      "  ranking recommendation: 5.0431\n",
      "  ranking recommendation systems: 5.0431\n",
      "  recommendation: 4.6376\n",
      "  recommendation systems: 5.0431\n",
      "  recommendation systems visual: 5.0431\n",
      "  regression: 3.6568\n",
      "  regression and: 5.0431\n",
      "  regression and classification: 5.0431\n",
      "  related: 7.3135\n",
      "  related to: 4.3499\n",
      "  related to regression: 5.0431\n",
      "  related two: 5.0431\n",
      "  related two objects: 5.0431\n",
      "  similar: 3.9444\n",
      "  similar or: 5.0431\n",
      "  similar or related: 5.0431\n",
      "  similarity: 8.2535\n",
      "  similarity function: 5.0431\n",
      "  similarity function that: 5.0431\n",
      "  similarity learning: 5.0431\n",
      "  similarity learning is: 5.0431\n",
      "  speaker: 5.0431\n",
      "  speaker verification: 5.0431\n",
      "  supervised: 3.2513\n",
      "  supervised machine: 5.0431\n",
      "  supervised machine learning: 5.0431\n",
      "  systems: 2.6917\n",
      "  systems visual: 5.0431\n",
      "  systems visual identity: 5.0431\n",
      "  that: 1.6758\n",
      "  that measures: 5.0431\n",
      "  that measures how: 5.0431\n",
      "  the: 1.1929\n",
      "  the goal: 5.0431\n",
      "  the goal is: 5.0431\n",
      "  to: 2.4507\n",
      "  to learn: 4.3499\n",
      "  to learn from: 4.6376\n",
      "  to regression: 5.0431\n",
      "  to regression and: 5.0431\n",
      "  tracking: 5.0431\n",
      "  tracking face: 5.0431\n",
      "  tracking face verification: 5.0431\n",
      "  two: 3.5390\n",
      "  two objects: 5.0431\n",
      "  two objects are: 5.0431\n",
      "  using: 3.2513\n",
      "  using a: 4.6376\n",
      "  using a similarity: 5.0431\n",
      "  verification: 10.0861\n",
      "  verification and: 5.0431\n",
      "  verification and speaker: 5.0431\n",
      "  visual: 5.0431\n",
      "  visual identity: 5.0431\n",
      "  visual identity tracking: 5.0431\n",
      "\n",
      "Document 38:\n",
      "  absence: 5.0431\n",
      "  absence of: 5.0431\n",
      "  absence of such: 5.0431\n",
      "  algorithms: 4.7378\n",
      "  algorithms find: 5.0431\n",
      "  algorithms find structures: 5.0431\n",
      "  algorithms identify: 5.0431\n",
      "  algorithms identify commonalities: 5.0431\n",
      "  and: 2.4288\n",
      "  and density: 5.0431\n",
      "  and density estimation: 5.0431\n",
      "  and react: 5.0431\n",
      "  and react based: 5.0431\n",
      "  applications: 3.7903\n",
      "  applications of: 4.6376\n",
      "  applications of unsupervised: 5.0431\n",
      "  based: 3.4336\n",
      "  based on: 3.4336\n",
      "  based on the: 4.3499\n",
      "  been: 2.6917\n",
      "  been labelled: 4.6376\n",
      "  been labelled classified: 5.0431\n",
      "  categorised: 5.0431\n",
      "  categorised instead: 5.0431\n",
      "  categorised instead of: 5.0431\n",
      "  central: 5.0431\n",
      "  central applications: 5.0431\n",
      "  central applications of: 5.0431\n",
      "  classified: 5.0431\n",
      "  classified or: 5.0431\n",
      "  classified or categorised: 5.0431\n",
      "  clustering: 3.9444\n",
      "  clustering dimensionality: 5.0431\n",
      "  clustering dimensionality reduction: 5.0431\n",
      "  commonalities: 10.0861\n",
      "  commonalities in: 10.0861\n",
      "  commonalities in each: 5.0431\n",
      "  commonalities in the: 5.0431\n",
      "  data: 5.5950\n",
      "  data and: 3.5390\n",
      "  data and react: 5.0431\n",
      "  data central: 5.0431\n",
      "  data central applications: 5.0431\n",
      "  data that: 4.6376\n",
      "  data that has: 5.0431\n",
      "  density: 4.6376\n",
      "  density estimation: 5.0431\n",
      "  dimensionality: 4.6376\n",
      "  dimensionality reduction: 4.6376\n",
      "  dimensionality reduction and: 5.0431\n",
      "  each: 3.0971\n",
      "  each new: 5.0431\n",
      "  each new piece: 5.0431\n",
      "  estimation: 4.6376\n",
      "  feedback: 4.6376\n",
      "  feedback unsupervised: 5.0431\n",
      "  feedback unsupervised learning: 5.0431\n",
      "  find: 4.6376\n",
      "  find structures: 5.0431\n",
      "  find structures in: 5.0431\n",
      "  has: 2.8458\n",
      "  has not: 4.3499\n",
      "  has not been: 5.0431\n",
      "  identify: 4.1268\n",
      "  identify commonalities: 5.0431\n",
      "  identify commonalities in: 5.0431\n",
      "  in: 4.0252\n",
      "  in data: 4.1268\n",
      "  in data that: 5.0431\n",
      "  in each: 4.6376\n",
      "  in each new: 5.0431\n",
      "  in the: 2.4404\n",
      "  in the data: 4.3499\n",
      "  include: 3.4336\n",
      "  include clustering: 5.0431\n",
      "  include clustering dimensionality: 5.0431\n",
      "  instead: 4.1268\n",
      "  instead of: 5.0431\n",
      "  instead of responding: 5.0431\n",
      "  labelled: 4.1268\n",
      "  labelled classified: 5.0431\n",
      "  labelled classified or: 5.0431\n",
      "  learning: 3.8456\n",
      "  learning algorithms: 5.8060\n",
      "  learning algorithms find: 5.0431\n",
      "  learning algorithms identify: 5.0431\n",
      "  learning include: 5.0431\n",
      "  learning include clustering: 5.0431\n",
      "  machine: 1.4735\n",
      "  machine learning: 1.5618\n",
      "  machine learning include: 5.0431\n",
      "  new: 3.2513\n",
      "  new piece: 5.0431\n",
      "  new piece of: 5.0431\n",
      "  not: 2.6007\n",
      "  not been: 5.0431\n",
      "  not been labelled: 5.0431\n",
      "  of: 4.8576\n",
      "  of data: 3.6568\n",
      "  of data central: 5.0431\n",
      "  of responding: 5.0431\n",
      "  of responding to: 5.0431\n",
      "  of such: 4.6376\n",
      "  of such commonalities: 5.0431\n",
      "  of unsupervised: 4.6376\n",
      "  of unsupervised machine: 5.0431\n",
      "  on: 2.0473\n",
      "  on the: 3.2513\n",
      "  on the presence: 5.0431\n",
      "  or: 4.0453\n",
      "  or absence: 5.0431\n",
      "  or absence of: 5.0431\n",
      "  or categorised: 5.0431\n",
      "  or categorised instead: 5.0431\n",
      "  piece: 5.0431\n",
      "  piece of: 5.0431\n",
      "  piece of data: 5.0431\n",
      "  presence: 4.6376\n",
      "  presence or: 5.0431\n",
      "  presence or absence: 5.0431\n",
      "  react: 5.0431\n",
      "  react based: 5.0431\n",
      "  react based on: 5.0431\n",
      "  reduction: 4.3499\n",
      "  reduction and: 5.0431\n",
      "  reduction and density: 5.0431\n",
      "  responding: 5.0431\n",
      "  responding to: 5.0431\n",
      "  responding to feedback: 5.0431\n",
      "  structures: 4.6376\n",
      "  structures in: 5.0431\n",
      "  structures in data: 5.0431\n",
      "  such: 2.4781\n",
      "  such commonalities: 5.0431\n",
      "  such commonalities in: 5.0431\n",
      "  that: 1.6758\n",
      "  that has: 4.6376\n",
      "  that has not: 5.0431\n",
      "  the: 2.3858\n",
      "  the data: 3.0971\n",
      "  the data and: 5.0431\n",
      "  the presence: 4.6376\n",
      "  the presence or: 5.0431\n",
      "  to: 1.2253\n",
      "  to feedback: 5.0431\n",
      "  to feedback unsupervised: 5.0431\n",
      "  unsupervised: 9.7539\n",
      "  unsupervised learning: 7.5806\n",
      "  unsupervised learning algorithms: 10.0861\n",
      "  unsupervised machine: 4.3499\n",
      "  unsupervised machine learning: 4.3499\n",
      "\n",
      "Document 39:\n",
      "  a: 1.2589\n",
      "  a set: 3.2513\n",
      "  a set of: 3.2513\n",
      "  according: 3.9444\n",
      "  according to: 3.9444\n",
      "  according to one: 5.0431\n",
      "  analysis: 3.1712\n",
      "  analysis is: 5.0431\n",
      "  analysis is the: 5.0431\n",
      "  and: 3.6432\n",
      "  and evaluated: 5.0431\n",
      "  and evaluated for: 5.0431\n",
      "  and graph: 5.0431\n",
      "  and graph connectivity: 5.0431\n",
      "  and separation: 5.0431\n",
      "  and separation the: 5.0431\n",
      "  are: 5.9250\n",
      "  are based: 5.0431\n",
      "  are based on: 5.0431\n",
      "  are dissimilar: 5.0431\n",
      "  are dissimilar different: 5.0431\n",
      "  are similar: 5.0431\n",
      "  are similar according: 5.0431\n",
      "  assignment: 5.0431\n",
      "  assignment of: 5.0431\n",
      "  assignment of a: 5.0431\n",
      "  assumptions: 4.6376\n",
      "  assumptions on: 5.0431\n",
      "  assumptions on the: 5.0431\n",
      "  based: 3.4336\n",
      "  based on: 3.4336\n",
      "  based on estimated: 5.0431\n",
      "  between: 5.9272\n",
      "  between clusters: 5.0431\n",
      "  between clusters other: 5.0431\n",
      "  between members: 5.0431\n",
      "  between members of: 5.0431\n",
      "  by: 3.8151\n",
      "  by internal: 5.0431\n",
      "  by internal compactness: 5.0431\n",
      "  by some: 4.6376\n",
      "  by some similarity: 5.0431\n",
      "  called: 3.2513\n",
      "  called clusters: 5.0431\n",
      "  called clusters so: 5.0431\n",
      "  cluster: 13.0497\n",
      "  cluster analysis: 4.3499\n",
      "  cluster analysis is: 5.0431\n",
      "  cluster and: 5.0431\n",
      "  cluster and separation: 5.0431\n",
      "  cluster are: 5.0431\n",
      "  cluster are similar: 5.0431\n",
      "  clustering: 3.9444\n",
      "  clustering techniques: 5.0431\n",
      "  clustering techniques make: 5.0431\n",
      "  clusters: 13.0497\n",
      "  clusters are: 5.0431\n",
      "  clusters are dissimilar: 5.0431\n",
      "  clusters other: 5.0431\n",
      "  clusters other methods: 5.0431\n",
      "  clusters so: 5.0431\n",
      "  clusters so that: 5.0431\n",
      "  compactness: 5.0431\n",
      "  compactness or: 5.0431\n",
      "  compactness or the: 5.0431\n",
      "  connectivity: 5.0431\n",
      "  criteria: 5.0431\n",
      "  criteria while: 5.0431\n",
      "  criteria while observations: 5.0431\n",
      "  data: 1.8650\n",
      "  data often: 5.0431\n",
      "  data often defined: 5.0431\n",
      "  defined: 4.6376\n",
      "  defined by: 5.0431\n",
      "  defined by some: 5.0431\n",
      "  density: 4.6376\n",
      "  density and: 5.0431\n",
      "  density and graph: 5.0431\n",
      "  difference: 4.6376\n",
      "  difference between: 5.0431\n",
      "  difference between clusters: 5.0431\n",
      "  different: 11.8333\n",
      "  different assumptions: 5.0431\n",
      "  different assumptions on: 5.0431\n",
      "  different clustering: 5.0431\n",
      "  different clustering techniques: 5.0431\n",
      "  different clusters: 5.0431\n",
      "  different clusters are: 5.0431\n",
      "  dissimilar: 5.0431\n",
      "  dissimilar different: 5.0431\n",
      "  dissimilar different clustering: 5.0431\n",
      "  drawn: 4.6376\n",
      "  drawn from: 5.0431\n",
      "  drawn from different: 5.0431\n",
      "  estimated: 4.6376\n",
      "  estimated density: 5.0431\n",
      "  estimated density and: 5.0431\n",
      "  evaluated: 4.6376\n",
      "  evaluated for: 5.0431\n",
      "  evaluated for example: 5.0431\n",
      "  example: 2.9636\n",
      "  example by: 5.0431\n",
      "  example by internal: 5.0431\n",
      "  for: 1.7289\n",
      "  for example: 3.2513\n",
      "  for example by: 5.0431\n",
      "  from: 2.0726\n",
      "  from different: 4.6376\n",
      "  from different clusters: 5.0431\n",
      "  graph: 4.6376\n",
      "  graph connectivity: 5.0431\n",
      "  internal: 4.3499\n",
      "  internal compactness: 5.0431\n",
      "  internal compactness or: 5.0431\n",
      "  into: 2.9636\n",
      "  into subsets: 5.0431\n",
      "  into subsets called: 5.0431\n",
      "  is: 1.5167\n",
      "  is the: 3.3383\n",
      "  is the assignment: 5.0431\n",
      "  make: 3.3383\n",
      "  make different: 5.0431\n",
      "  make different assumptions: 5.0431\n",
      "  members: 4.3499\n",
      "  members of: 4.6376\n",
      "  members of the: 5.0431\n",
      "  methods: 2.7405\n",
      "  methods are: 5.0431\n",
      "  methods are based: 5.0431\n",
      "  metric: 5.0431\n",
      "  metric and: 5.0431\n",
      "  metric and evaluated: 5.0431\n",
      "  more: 3.1712\n",
      "  more predesignated: 5.0431\n",
      "  more predesignated criteria: 5.0431\n",
      "  observations: 13.0497\n",
      "  observations drawn: 5.0431\n",
      "  observations drawn from: 5.0431\n",
      "  observations into: 5.0431\n",
      "  observations into subsets: 5.0431\n",
      "  observations within: 5.0431\n",
      "  observations within the: 5.0431\n",
      "  of: 4.8576\n",
      "  of a: 3.0281\n",
      "  of a set: 4.1268\n",
      "  of observations: 5.0431\n",
      "  of observations into: 5.0431\n",
      "  of the: 4.6044\n",
      "  of the data: 4.1268\n",
      "  of the same: 5.0431\n",
      "  often: 3.0971\n",
      "  often defined: 5.0431\n",
      "  often defined by: 5.0431\n",
      "  on: 4.0946\n",
      "  on estimated: 5.0431\n",
      "  on estimated density: 5.0431\n",
      "  on the: 3.2513\n",
      "  on the structure: 5.0431\n",
      "  one: 3.0971\n",
      "  one or: 4.6376\n",
      "  one or more: 4.6376\n",
      "  or: 4.0453\n",
      "  or more: 4.6376\n",
      "  or more predesignated: 5.0431\n",
      "  or the: 4.6376\n",
      "  or the similarity: 5.0431\n",
      "  other: 2.7918\n",
      "  other methods: 5.0431\n",
      "  other methods are: 5.0431\n",
      "  predesignated: 5.0431\n",
      "  predesignated criteria: 5.0431\n",
      "  predesignated criteria while: 5.0431\n",
      "  same: 7.8889\n",
      "  same cluster: 10.0861\n",
      "  same cluster and: 5.0431\n",
      "  same cluster are: 5.0431\n",
      "  separation: 5.0431\n",
      "  separation the: 5.0431\n",
      "  separation the difference: 5.0431\n",
      "  set: 2.6007\n",
      "  set of: 3.0281\n",
      "  set of observations: 5.0431\n",
      "  similar: 3.9444\n",
      "  similar according: 5.0431\n",
      "  similar according to: 5.0431\n",
      "  similarity: 8.2535\n",
      "  similarity between: 5.0431\n",
      "  similarity between members: 5.0431\n",
      "  similarity metric: 5.0431\n",
      "  similarity metric and: 5.0431\n",
      "  so: 4.1268\n",
      "  so that: 4.6376\n",
      "  so that observations: 5.0431\n",
      "  some: 2.9636\n",
      "  some similarity: 5.0431\n",
      "  some similarity metric: 5.0431\n",
      "  structure: 4.3499\n",
      "  structure of: 5.0431\n",
      "  structure of the: 5.0431\n",
      "  subsets: 4.6376\n",
      "  subsets called: 5.0431\n",
      "  subsets called clusters: 5.0431\n",
      "  techniques: 3.3383\n",
      "  techniques make: 4.6376\n",
      "  techniques make different: 5.0431\n",
      "  that: 1.6758\n",
      "  that observations: 5.0431\n",
      "  that observations within: 5.0431\n",
      "  the: 8.3503\n",
      "  the assignment: 5.0431\n",
      "  the assignment of: 5.0431\n",
      "  the data: 3.0971\n",
      "  the data often: 5.0431\n",
      "  the difference: 5.0431\n",
      "  the difference between: 5.0431\n",
      "  the same: 7.8889\n",
      "  the same cluster: 10.0861\n",
      "  the similarity: 5.0431\n",
      "  the similarity between: 5.0431\n",
      "  the structure: 4.6376\n",
      "  the structure of: 5.0431\n",
      "  to: 1.2253\n",
      "  to one: 4.6376\n",
      "  to one or: 5.0431\n",
      "  while: 3.4336\n",
      "  while observations: 5.0431\n",
      "  while observations drawn: 5.0431\n",
      "  within: 3.4336\n",
      "  within the: 4.6376\n",
      "  within the same: 5.0431\n",
      "\n",
      "Document 40:\n",
      "  a: 2.5177\n",
      "  a model: 3.9444\n",
      "  a model by: 5.0431\n",
      "  a special: 5.0431\n",
      "  a special type: 5.0431\n",
      "  by: 1.9076\n",
      "  by generating: 5.0431\n",
      "  by generating the: 5.0431\n",
      "  called: 3.2513\n",
      "  called selfsupervised: 5.0431\n",
      "  called selfsupervised learning: 5.0431\n",
      "  data: 1.8650\n",
      "  data itself: 5.0431\n",
      "  from: 2.0726\n",
      "  from the: 3.3383\n",
      "  from the data: 5.0431\n",
      "  generating: 4.6376\n",
      "  generating the: 5.0431\n",
      "  generating the supervisory: 5.0431\n",
      "  involves: 4.3499\n",
      "  involves training: 4.6376\n",
      "  involves training a: 4.6376\n",
      "  itself: 5.0431\n",
      "  learning: 2.5637\n",
      "  learning called: 5.0431\n",
      "  learning called selfsupervised: 5.0431\n",
      "  learning involves: 5.0431\n",
      "  learning involves training: 5.0431\n",
      "  model: 2.3350\n",
      "  model by: 4.6376\n",
      "  model by generating: 5.0431\n",
      "  of: 1.2144\n",
      "  of unsupervised: 4.6376\n",
      "  of unsupervised learning: 5.0431\n",
      "  selfsupervised: 5.0431\n",
      "  selfsupervised learning: 5.0431\n",
      "  selfsupervised learning involves: 5.0431\n",
      "  signal: 3.9444\n",
      "  signal from: 4.6376\n",
      "  signal from the: 5.0431\n",
      "  special: 4.6376\n",
      "  special type: 5.0431\n",
      "  special type of: 5.0431\n",
      "  supervisory: 4.6376\n",
      "  supervisory signal: 4.6376\n",
      "  supervisory signal from: 5.0431\n",
      "  the: 2.3858\n",
      "  the data: 3.0971\n",
      "  the data itself: 5.0431\n",
      "  the supervisory: 5.0431\n",
      "  the supervisory signal: 5.0431\n",
      "  training: 2.5581\n",
      "  training a: 4.1268\n",
      "  training a model: 5.0431\n",
      "  type: 4.1268\n",
      "  type of: 4.1268\n",
      "  type of unsupervised: 5.0431\n",
      "  unsupervised: 3.2513\n",
      "  unsupervised learning: 3.7903\n",
      "  unsupervised learning called: 5.0431\n",
      "\n",
      "Document 41:\n",
      "  a: 2.5177\n",
      "  a considerable: 5.0431\n",
      "  a considerable improvement: 5.0431\n",
      "  a small: 5.0431\n",
      "  a small amount: 5.0431\n",
      "  accuracy: 3.6568\n",
      "  amount: 4.6376\n",
      "  amount of: 4.6376\n",
      "  amount of labelled: 5.0431\n",
      "  and: 1.2144\n",
      "  and supervised: 4.6376\n",
      "  and supervised learning: 5.0431\n",
      "  any: 3.6568\n",
      "  any labelled: 5.0431\n",
      "  any labelled training: 5.0431\n",
      "  are: 1.9750\n",
      "  are missing: 5.0431\n",
      "  are missing training: 5.0431\n",
      "  between: 2.9636\n",
      "  between unsupervised: 5.0431\n",
      "  between unsupervised learning: 5.0431\n",
      "  can: 2.1809\n",
      "  can produce: 5.0431\n",
      "  can produce a: 5.0431\n",
      "  completely: 5.0431\n",
      "  completely labelled: 5.0431\n",
      "  completely labelled training: 5.0431\n",
      "  conjunction: 5.0431\n",
      "  conjunction with: 5.0431\n",
      "  conjunction with a: 5.0431\n",
      "  considerable: 5.0431\n",
      "  considerable improvement: 5.0431\n",
      "  considerable improvement in: 5.0431\n",
      "  data: 7.4600\n",
      "  data and: 3.5390\n",
      "  data and supervised: 5.0431\n",
      "  data can: 4.3499\n",
      "  data can produce: 5.0431\n",
      "  data some: 5.0431\n",
      "  data some of: 5.0431\n",
      "  data when: 4.6376\n",
      "  data when used: 5.0431\n",
      "  examples: 3.0971\n",
      "  examples are: 5.0431\n",
      "  examples are missing: 5.0431\n",
      "  falls: 4.3499\n",
      "  falls between: 5.0431\n",
      "  falls between unsupervised: 5.0431\n",
      "  found: 3.7903\n",
      "  found that: 4.6376\n",
      "  found that unlabelled: 5.0431\n",
      "  have: 2.4781\n",
      "  have found: 5.0431\n",
      "  have found that: 5.0431\n",
      "  improvement: 5.0431\n",
      "  improvement in: 5.0431\n",
      "  improvement in learning: 5.0431\n",
      "  in: 2.6835\n",
      "  in conjunction: 5.0431\n",
      "  in conjunction with: 5.0431\n",
      "  in learning: 4.6376\n",
      "  in learning accuracy: 5.0431\n",
      "  labelled: 12.3803\n",
      "  labelled data: 5.0431\n",
      "  labelled data can: 5.0431\n",
      "  labelled training: 10.0861\n",
      "  labelled training data: 10.0861\n",
      "  labels: 3.9444\n",
      "  labels yet: 5.0431\n",
      "  labels yet many: 5.0431\n",
      "  learning: 5.1274\n",
      "  learning accuracy: 5.0431\n",
      "  learning falls: 5.0431\n",
      "  learning falls between: 5.0431\n",
      "  learning with: 5.0431\n",
      "  learning with completely: 5.0431\n",
      "  learning without: 4.6376\n",
      "  learning without any: 4.6376\n",
      "  machinelearning: 4.6376\n",
      "  machinelearning researchers: 5.0431\n",
      "  machinelearning researchers have: 5.0431\n",
      "  many: 2.9030\n",
      "  many machinelearning: 5.0431\n",
      "  many machinelearning researchers: 5.0431\n",
      "  missing: 5.0431\n",
      "  missing training: 5.0431\n",
      "  missing training labels: 5.0431\n",
      "  of: 2.4288\n",
      "  of labelled: 5.0431\n",
      "  of labelled data: 5.0431\n",
      "  of the: 2.3022\n",
      "  of the training: 4.3499\n",
      "  produce: 4.3499\n",
      "  produce a: 5.0431\n",
      "  produce a considerable: 5.0431\n",
      "  researchers: 3.6568\n",
      "  researchers have: 4.6376\n",
      "  researchers have found: 5.0431\n",
      "  semisupervised: 4.6376\n",
      "  semisupervised learning: 5.0431\n",
      "  semisupervised learning falls: 5.0431\n",
      "  small: 4.6376\n",
      "  small amount: 5.0431\n",
      "  small amount of: 5.0431\n",
      "  some: 2.9636\n",
      "  some of: 5.0431\n",
      "  some of the: 5.0431\n",
      "  supervised: 3.2513\n",
      "  supervised learning: 3.6568\n",
      "  supervised learning with: 5.0431\n",
      "  that: 1.6758\n",
      "  that unlabelled: 5.0431\n",
      "  that unlabelled data: 5.0431\n",
      "  the: 1.1929\n",
      "  the training: 3.3383\n",
      "  the training examples: 4.6376\n",
      "  training: 10.2326\n",
      "  training data: 7.5806\n",
      "  training data and: 5.0431\n",
      "  training data some: 5.0431\n",
      "  training examples: 4.1268\n",
      "  training examples are: 5.0431\n",
      "  training labels: 4.6376\n",
      "  training labels yet: 5.0431\n",
      "  unlabelled: 4.3499\n",
      "  unlabelled data: 5.0431\n",
      "  unlabelled data when: 5.0431\n",
      "  unsupervised: 3.2513\n",
      "  unsupervised learning: 3.7903\n",
      "  unsupervised learning without: 5.0431\n",
      "  used: 2.3350\n",
      "  used in: 3.4336\n",
      "  used in conjunction: 5.0431\n",
      "  when: 3.3383\n",
      "  when used: 5.0431\n",
      "  when used in: 5.0431\n",
      "  with: 4.1453\n",
      "  with a: 3.6568\n",
      "  with a small: 5.0431\n",
      "  with completely: 5.0431\n",
      "  with completely labelled: 5.0431\n",
      "  without: 3.3383\n",
      "  without any: 4.6376\n",
      "  without any labelled: 5.0431\n",
      "  yet: 4.3499\n",
      "  yet many: 5.0431\n",
      "  yet many machinelearning: 5.0431\n",
      "\n",
      "Document 42:\n",
      "  are: 3.9500\n",
      "  are noisy: 5.0431\n",
      "  are noisy limited: 5.0431\n",
      "  are often: 4.1268\n",
      "  are often cheaper: 5.0431\n",
      "  cheaper: 5.0431\n",
      "  cheaper to: 5.0431\n",
      "  cheaper to obtain: 5.0431\n",
      "  effective: 4.3499\n",
      "  effective training: 5.0431\n",
      "  effective training sets: 5.0431\n",
      "  however: 3.7903\n",
      "  however these: 4.6376\n",
      "  however these labels: 5.0431\n",
      "  imprecise: 4.6376\n",
      "  imprecise however: 5.0431\n",
      "  imprecise however these: 5.0431\n",
      "  in: 2.6835\n",
      "  in larger: 5.0431\n",
      "  in larger effective: 5.0431\n",
      "  in weakly: 5.0431\n",
      "  in weakly supervised: 5.0431\n",
      "  labels: 7.8889\n",
      "  labels are: 10.0861\n",
      "  labels are noisy: 5.0431\n",
      "  labels are often: 5.0431\n",
      "  larger: 5.0431\n",
      "  larger effective: 5.0431\n",
      "  larger effective training: 5.0431\n",
      "  learning: 1.2819\n",
      "  learning the: 4.3499\n",
      "  learning the training: 5.0431\n",
      "  limited: 4.3499\n",
      "  limited or: 5.0431\n",
      "  limited or imprecise: 5.0431\n",
      "  noisy: 5.0431\n",
      "  noisy limited: 5.0431\n",
      "  noisy limited or: 5.0431\n",
      "  obtain: 5.0431\n",
      "  obtain resulting: 5.0431\n",
      "  obtain resulting in: 5.0431\n",
      "  often: 3.0971\n",
      "  often cheaper: 5.0431\n",
      "  often cheaper to: 5.0431\n",
      "  or: 2.0226\n",
      "  or imprecise: 5.0431\n",
      "  or imprecise however: 5.0431\n",
      "  resulting: 4.6376\n",
      "  resulting in: 5.0431\n",
      "  resulting in larger: 5.0431\n",
      "  sets: 4.1268\n",
      "  supervised: 3.2513\n",
      "  supervised learning: 3.6568\n",
      "  supervised learning the: 5.0431\n",
      "  the: 1.1929\n",
      "  the training: 3.3383\n",
      "  the training labels: 5.0431\n",
      "  these: 2.9030\n",
      "  these labels: 5.0431\n",
      "  these labels are: 5.0431\n",
      "  to: 1.2253\n",
      "  to obtain: 5.0431\n",
      "  to obtain resulting: 5.0431\n",
      "  training: 5.1163\n",
      "  training labels: 4.6376\n",
      "  training labels are: 5.0431\n",
      "  training sets: 4.3499\n",
      "  weakly: 5.0431\n",
      "  weakly supervised: 5.0431\n",
      "  weakly supervised learning: 5.0431\n",
      "\n",
      "Document 43:\n",
      "  a: 3.7766\n",
      "  a game: 5.0431\n",
      "  a game against: 5.0431\n",
      "  a human: 4.3499\n",
      "  a human opponent: 5.0431\n",
      "  a markov: 5.0431\n",
      "  a markov decision: 5.0431\n",
      "  actions: 4.6376\n",
      "  actions in: 5.0431\n",
      "  actions in an: 5.0431\n",
      "  against: 4.6376\n",
      "  against a: 5.0431\n",
      "  against a human: 5.0431\n",
      "  agents: 5.0431\n",
      "  agents ought: 5.0431\n",
      "  agents ought to: 5.0431\n",
      "  algorithms: 9.4756\n",
      "  algorithms are: 4.3499\n",
      "  algorithms are used: 4.6376\n",
      "  algorithms do: 5.0431\n",
      "  algorithms do not: 5.0431\n",
      "  algorithms in: 5.0431\n",
      "  algorithms in reinforcement: 5.0431\n",
      "  algorithms use: 5.0431\n",
      "  algorithms use dynamic: 5.0431\n",
      "  an: 6.4580\n",
      "  an area: 4.6376\n",
      "  an area of: 4.6376\n",
      "  an environment: 4.6376\n",
      "  an environment so: 5.0431\n",
      "  an exact: 5.0431\n",
      "  an exact mathematical: 5.0431\n",
      "  and: 2.4288\n",
      "  and are: 5.0431\n",
      "  and are used: 5.0431\n",
      "  and genetic: 5.0431\n",
      "  and genetic algorithms: 5.0431\n",
      "  are: 5.9250\n",
      "  are infeasible: 5.0431\n",
      "  are infeasible reinforcement: 5.0431\n",
      "  are used: 9.2752\n",
      "  are used in: 5.0431\n",
      "  are used when: 4.6376\n",
      "  area: 3.9444\n",
      "  area of: 4.1268\n",
      "  area of machine: 5.0431\n",
      "  as: 5.5331\n",
      "  as a: 2.9030\n",
      "  as a markov: 5.0431\n",
      "  as game: 5.0431\n",
      "  as game theory: 5.0431\n",
      "  as to: 5.0431\n",
      "  as to maximise: 5.0431\n",
      "  assume: 5.0431\n",
      "  assume knowledge: 5.0431\n",
      "  assume knowledge of: 5.0431\n",
      "  autonomous: 4.6376\n",
      "  autonomous vehicles: 5.0431\n",
      "  autonomous vehicles or: 5.0431\n",
      "  concerned: 4.3499\n",
      "  concerned with: 4.6376\n",
      "  concerned with how: 5.0431\n",
      "  control: 5.0431\n",
      "  control theory: 5.0431\n",
      "  control theory operations: 5.0431\n",
      "  cumulative: 5.0431\n",
      "  cumulative reward: 5.0431\n",
      "  cumulative reward due: 5.0431\n",
      "  decision: 3.6568\n",
      "  decision process: 5.0431\n",
      "  decision process mdp: 5.0431\n",
      "  disciplines: 4.6376\n",
      "  disciplines such: 5.0431\n",
      "  disciplines such as: 5.0431\n",
      "  do: 3.6568\n",
      "  do not: 4.3499\n",
      "  do not assume: 5.0431\n",
      "  due: 4.6376\n",
      "  due to: 4.6376\n",
      "  due to its: 5.0431\n",
      "  dynamic: 4.6376\n",
      "  dynamic programming: 5.0431\n",
      "  dynamic programming techniques: 5.0431\n",
      "  environment: 9.2752\n",
      "  environment is: 5.0431\n",
      "  environment is typically: 5.0431\n",
      "  environment so: 5.0431\n",
      "  environment so as: 5.0431\n",
      "  exact: 10.0861\n",
      "  exact mathematical: 5.0431\n",
      "  exact mathematical model: 5.0431\n",
      "  exact models: 5.0431\n",
      "  exact models are: 5.0431\n",
      "  field: 2.9636\n",
      "  field is: 5.0431\n",
      "  field is studied: 5.0431\n",
      "  game: 10.0861\n",
      "  game against: 5.0431\n",
      "  game against a: 5.0431\n",
      "  game theory: 5.0431\n",
      "  game theory control: 5.0431\n",
      "  generality: 5.0431\n",
      "  generality the: 5.0431\n",
      "  generality the field: 5.0431\n",
      "  genetic: 4.1268\n",
      "  genetic algorithms: 4.6376\n",
      "  genetic algorithms in: 5.0431\n",
      "  how: 3.5390\n",
      "  how software: 5.0431\n",
      "  how software agents: 5.0431\n",
      "  human: 3.6568\n",
      "  human opponent: 5.0431\n",
      "  in: 6.7087\n",
      "  in an: 3.9444\n",
      "  in an environment: 4.6376\n",
      "  in autonomous: 5.0431\n",
      "  in autonomous vehicles: 5.0431\n",
      "  in learning: 4.6376\n",
      "  in learning to: 5.0431\n",
      "  in many: 4.3499\n",
      "  in many other: 4.6376\n",
      "  in reinforcement: 5.0431\n",
      "  in reinforcement learning: 5.0431\n",
      "  infeasible: 5.0431\n",
      "  infeasible reinforcement: 5.0431\n",
      "  infeasible reinforcement learning: 5.0431\n",
      "  information: 3.7903\n",
      "  information theory: 5.0431\n",
      "  information theory simulationbased: 5.0431\n",
      "  intelligence: 3.1712\n",
      "  intelligence statistics: 5.0431\n",
      "  intelligence statistics and: 5.0431\n",
      "  is: 4.5501\n",
      "  is an: 3.6568\n",
      "  is an area: 4.6376\n",
      "  is studied: 5.0431\n",
      "  is studied in: 5.0431\n",
      "  is typically: 5.0431\n",
      "  is typically represented: 5.0431\n",
      "  its: 2.9636\n",
      "  its generality: 5.0431\n",
      "  its generality the: 5.0431\n",
      "  knowledge: 3.7903\n",
      "  knowledge of: 5.0431\n",
      "  knowledge of an: 5.0431\n",
      "  learning: 8.9730\n",
      "  learning algorithms: 8.7090\n",
      "  learning algorithms are: 5.0431\n",
      "  learning algorithms do: 5.0431\n",
      "  learning algorithms use: 5.0431\n",
      "  learning concerned: 5.0431\n",
      "  learning concerned with: 5.0431\n",
      "  learning is: 3.0281\n",
      "  learning is an: 4.3499\n",
      "  learning the: 4.3499\n",
      "  learning the environment: 5.0431\n",
      "  learning to: 4.3499\n",
      "  learning to play: 5.0431\n",
      "  machine: 1.4735\n",
      "  machine learning: 1.5618\n",
      "  machine learning concerned: 5.0431\n",
      "  many: 5.8060\n",
      "  many other: 4.3499\n",
      "  many other disciplines: 5.0431\n",
      "  many reinforcement: 5.0431\n",
      "  many reinforcement learning: 5.0431\n",
      "  markov: 5.0431\n",
      "  markov decision: 5.0431\n",
      "  markov decision process: 5.0431\n",
      "  mathematical: 3.5390\n",
      "  mathematical model: 4.1268\n",
      "  mathematical model of: 4.6376\n",
      "  maximise: 5.0431\n",
      "  maximise some: 5.0431\n",
      "  maximise some notion: 5.0431\n",
      "  mdp: 10.0861\n",
      "  mdp and: 5.0431\n",
      "  mdp and are: 5.0431\n",
      "  mdp many: 5.0431\n",
      "  mdp many reinforcement: 5.0431\n",
      "  model: 2.3350\n",
      "  model of: 4.3499\n",
      "  model of the: 5.0431\n",
      "  models: 2.5581\n",
      "  models are: 4.1268\n",
      "  models are infeasible: 5.0431\n",
      "  multiagent: 5.0431\n",
      "  multiagent systems: 5.0431\n",
      "  multiagent systems swarm: 5.0431\n",
      "  not: 2.6007\n",
      "  not assume: 5.0431\n",
      "  not assume knowledge: 5.0431\n",
      "  notion: 5.0431\n",
      "  notion of: 5.0431\n",
      "  notion of cumulative: 5.0431\n",
      "  of: 4.8576\n",
      "  of an: 4.3499\n",
      "  of an exact: 5.0431\n",
      "  of cumulative: 5.0431\n",
      "  of cumulative reward: 5.0431\n",
      "  of machine: 3.0281\n",
      "  of machine learning: 3.0281\n",
      "  of the: 2.3022\n",
      "  of the mdp: 5.0431\n",
      "  operations: 5.0431\n",
      "  operations research: 5.0431\n",
      "  operations research information: 5.0431\n",
      "  opponent: 5.0431\n",
      "  optimisation: 3.7903\n",
      "  optimisation multiagent: 5.0431\n",
      "  optimisation multiagent systems: 5.0431\n",
      "  or: 2.0226\n",
      "  or in: 5.0431\n",
      "  or in learning: 5.0431\n",
      "  other: 2.7918\n",
      "  other disciplines: 4.6376\n",
      "  other disciplines such: 5.0431\n",
      "  ought: 5.0431\n",
      "  ought to: 5.0431\n",
      "  ought to take: 5.0431\n",
      "  play: 5.0431\n",
      "  play a: 5.0431\n",
      "  play a game: 5.0431\n",
      "  process: 3.4336\n",
      "  process mdp: 5.0431\n",
      "  process mdp many: 5.0431\n",
      "  programming: 4.1268\n",
      "  programming techniques: 5.0431\n",
      "  programming techniques reinforcement: 5.0431\n",
      "  reinforcement: 19.7222\n",
      "  reinforcement learning: 20.6338\n",
      "  reinforcement learning algorithms: 15.1292\n",
      "  reinforcement learning is: 5.0431\n",
      "  reinforcement learning the: 5.0431\n",
      "  represented: 3.6568\n",
      "  represented as: 4.3499\n",
      "  represented as a: 4.3499\n",
      "  research: 3.4336\n",
      "  research information: 5.0431\n",
      "  research information theory: 5.0431\n",
      "  reward: 4.6376\n",
      "  reward due: 5.0431\n",
      "  reward due to: 5.0431\n",
      "  simulationbased: 5.0431\n",
      "  simulationbased optimisation: 5.0431\n",
      "  simulationbased optimisation multiagent: 5.0431\n",
      "  so: 4.1268\n",
      "  so as: 5.0431\n",
      "  so as to: 5.0431\n",
      "  software: 3.9444\n",
      "  software agents: 5.0431\n",
      "  software agents ought: 5.0431\n",
      "  some: 2.9636\n",
      "  some notion: 5.0431\n",
      "  some notion of: 5.0431\n",
      "  statistics: 3.6568\n",
      "  statistics and: 4.6376\n",
      "  statistics and genetic: 5.0431\n",
      "  studied: 4.3499\n",
      "  studied in: 4.6376\n",
      "  studied in many: 5.0431\n",
      "  such: 2.4781\n",
      "  such as: 2.8458\n",
      "  such as game: 5.0431\n",
      "  swarm: 5.0431\n",
      "  swarm intelligence: 5.0431\n",
      "  swarm intelligence statistics: 5.0431\n",
      "  systems: 2.6917\n",
      "  systems swarm: 5.0431\n",
      "  systems swarm intelligence: 5.0431\n",
      "  take: 4.1268\n",
      "  take actions: 5.0431\n",
      "  take actions in: 5.0431\n",
      "  techniques: 3.3383\n",
      "  techniques reinforcement: 5.0431\n",
      "  techniques reinforcement learning: 5.0431\n",
      "  the: 3.5787\n",
      "  the environment: 4.6376\n",
      "  the environment is: 5.0431\n",
      "  the field: 3.4336\n",
      "  the field is: 5.0431\n",
      "  the mdp: 5.0431\n",
      "  the mdp and: 5.0431\n",
      "  theory: 10.0149\n",
      "  theory control: 5.0431\n",
      "  theory control theory: 5.0431\n",
      "  theory operations: 5.0431\n",
      "  theory operations research: 5.0431\n",
      "  theory simulationbased: 5.0431\n",
      "  theory simulationbased optimisation: 5.0431\n",
      "  to: 4.9014\n",
      "  to its: 5.0431\n",
      "  to its generality: 5.0431\n",
      "  to maximise: 5.0431\n",
      "  to maximise some: 5.0431\n",
      "  to play: 5.0431\n",
      "  to play a: 5.0431\n",
      "  to take: 5.0431\n",
      "  to take actions: 5.0431\n",
      "  typically: 3.5390\n",
      "  typically represented: 5.0431\n",
      "  typically represented as: 5.0431\n",
      "  use: 3.3383\n",
      "  use dynamic: 5.0431\n",
      "  use dynamic programming: 5.0431\n",
      "  used: 4.6700\n",
      "  used in: 3.4336\n",
      "  used in autonomous: 5.0431\n",
      "  used when: 4.6376\n",
      "  used when exact: 5.0431\n",
      "  vehicles: 5.0431\n",
      "  vehicles or: 5.0431\n",
      "  vehicles or in: 5.0431\n",
      "  when: 3.3383\n",
      "  when exact: 5.0431\n",
      "  when exact models: 5.0431\n",
      "  with: 2.0726\n",
      "  with how: 4.6376\n",
      "  with how software: 5.0431\n",
      "\n",
      "Document 44:\n",
      "  a: 5.0354\n",
      "  a process: 10.0861\n",
      "  a process of: 10.0861\n",
      "  a set: 3.2513\n",
      "  a set of: 3.2513\n",
      "  a smaller: 5.0431\n",
      "  a smaller space: 5.0431\n",
      "  along: 4.3499\n",
      "  along lowdimensional: 5.0431\n",
      "  along lowdimensional manifolds: 5.0431\n",
      "  also: 2.6452\n",
      "  also called: 4.6376\n",
      "  also called the: 5.0431\n",
      "  analysis: 3.1712\n",
      "  analysis pca: 5.0431\n",
      "  analysis pca pca: 5.0431\n",
      "  and: 2.4288\n",
      "  and manifold: 5.0431\n",
      "  and manifold regularisation: 5.0431\n",
      "  and many: 5.0431\n",
      "  and many dimensionality: 5.0431\n",
      "  area: 3.9444\n",
      "  area of: 4.1268\n",
      "  area of manifold: 5.0431\n",
      "  as: 1.8444\n",
      "  as either: 5.0431\n",
      "  as either feature: 5.0431\n",
      "  assumption: 4.6376\n",
      "  assumption leading: 5.0431\n",
      "  assumption leading to: 5.0431\n",
      "  be: 2.0726\n",
      "  be considered: 4.6376\n",
      "  be considered as: 5.0431\n",
      "  by: 1.9076\n",
      "  by obtaining: 5.0431\n",
      "  by obtaining a: 5.0431\n",
      "  called: 3.2513\n",
      "  called the: 4.6376\n",
      "  called the number: 5.0431\n",
      "  can: 2.1809\n",
      "  can be: 2.7405\n",
      "  can be considered: 5.0431\n",
      "  changing: 4.6376\n",
      "  changing higherdimensional: 5.0431\n",
      "  changing higherdimensional data: 5.0431\n",
      "  component: 3.9444\n",
      "  component analysis: 4.3499\n",
      "  component analysis pca: 5.0431\n",
      "  consideration: 5.0431\n",
      "  consideration by: 5.0431\n",
      "  consideration by obtaining: 5.0431\n",
      "  considered: 3.7903\n",
      "  considered as: 5.0431\n",
      "  considered as either: 5.0431\n",
      "  d: 5.0431\n",
      "  d to: 5.0431\n",
      "  d to a: 5.0431\n",
      "  data: 3.7300\n",
      "  data eg: 5.0431\n",
      "  data eg d: 5.0431\n",
      "  data sets: 5.0431\n",
      "  data sets lie: 5.0431\n",
      "  dimension: 5.0431\n",
      "  dimension of: 5.0431\n",
      "  dimension of the: 5.0431\n",
      "  dimensionality: 18.5503\n",
      "  dimensionality reduction: 18.5503\n",
      "  dimensionality reduction is: 10.0861\n",
      "  dimensionality reduction techniques: 10.0861\n",
      "  dthe: 5.0431\n",
      "  dthe manifold: 5.0431\n",
      "  dthe manifold hypothesis: 5.0431\n",
      "  eg: 7.8889\n",
      "  eg d: 5.0431\n",
      "  eg d to: 5.0431\n",
      "  eg dthe: 5.0431\n",
      "  eg dthe manifold: 5.0431\n",
      "  either: 3.9444\n",
      "  either feature: 5.0431\n",
      "  either feature elimination: 5.0431\n",
      "  elimination: 5.0431\n",
      "  elimination or: 5.0431\n",
      "  elimination or extraction: 5.0431\n",
      "  extraction: 5.0431\n",
      "  extraction one: 5.0431\n",
      "  extraction one of: 5.0431\n",
      "  feature: 6.8672\n",
      "  feature elimination: 5.0431\n",
      "  feature elimination or: 5.0431\n",
      "  feature set: 5.0431\n",
      "  feature set also: 5.0431\n",
      "  features: 3.6568\n",
      "  features most: 5.0431\n",
      "  features most of: 5.0431\n",
      "  highdimensional: 4.6376\n",
      "  highdimensional data: 5.0431\n",
      "  highdimensional data sets: 5.0431\n",
      "  higherdimensional: 4.3499\n",
      "  higherdimensional data: 5.0431\n",
      "  higherdimensional data eg: 5.0431\n",
      "  hypothesis: 4.6376\n",
      "  hypothesis proposes: 5.0431\n",
      "  hypothesis proposes that: 5.0431\n",
      "  in: 1.3417\n",
      "  in other: 4.6376\n",
      "  in other words: 5.0431\n",
      "  involves: 4.3499\n",
      "  involves changing: 5.0431\n",
      "  involves changing higherdimensional: 5.0431\n",
      "  is: 4.5501\n",
      "  is a: 5.0346\n",
      "  is a process: 10.0861\n",
      "  is principal: 5.0431\n",
      "  is principal component: 5.0431\n",
      "  it: 2.2705\n",
      "  it is: 3.5390\n",
      "  it is a: 4.3499\n",
      "  leading: 4.1268\n",
      "  leading to: 4.1268\n",
      "  leading to the: 5.0431\n",
      "  learning: 1.2819\n",
      "  learning and: 3.6568\n",
      "  learning and manifold: 5.0431\n",
      "  lie: 5.0431\n",
      "  lie along: 5.0431\n",
      "  lie along lowdimensional: 5.0431\n",
      "  lowdimensional: 4.6376\n",
      "  lowdimensional manifolds: 5.0431\n",
      "  lowdimensional manifolds and: 5.0431\n",
      "  make: 3.3383\n",
      "  make this: 5.0431\n",
      "  make this assumption: 5.0431\n",
      "  manifold: 13.9128\n",
      "  manifold hypothesis: 5.0431\n",
      "  manifold hypothesis proposes: 5.0431\n",
      "  manifold learning: 4.6376\n",
      "  manifold learning and: 5.0431\n",
      "  manifold regularisation: 5.0431\n",
      "  manifolds: 5.0431\n",
      "  manifolds and: 5.0431\n",
      "  manifolds and many: 5.0431\n",
      "  many: 2.9030\n",
      "  many dimensionality: 5.0431\n",
      "  many dimensionality reduction: 5.0431\n",
      "  methods: 2.7405\n",
      "  methods of: 5.0431\n",
      "  methods of dimensionality: 5.0431\n",
      "  most: 4.3499\n",
      "  most of: 5.0431\n",
      "  most of the: 5.0431\n",
      "  number: 8.2535\n",
      "  number of: 8.6998\n",
      "  number of features: 5.0431\n",
      "  number of random: 5.0431\n",
      "  obtaining: 5.0431\n",
      "  obtaining a: 5.0431\n",
      "  obtaining a set: 5.0431\n",
      "  of: 12.1441\n",
      "  of dimensionality: 5.0431\n",
      "  of dimensionality reduction: 5.0431\n",
      "  of features: 4.3499\n",
      "  of features most: 5.0431\n",
      "  of manifold: 5.0431\n",
      "  of manifold learning: 5.0431\n",
      "  of principal: 5.0431\n",
      "  of principal variables: 5.0431\n",
      "  of random: 4.6376\n",
      "  of random variables: 4.6376\n",
      "  of reducing: 10.0861\n",
      "  of reducing the: 10.0861\n",
      "  of the: 6.9066\n",
      "  of the dimensionality: 5.0431\n",
      "  of the feature: 4.6376\n",
      "  of the popular: 5.0431\n",
      "  one: 3.0971\n",
      "  one of: 4.3499\n",
      "  one of the: 4.6376\n",
      "  or: 2.0226\n",
      "  or extraction: 5.0431\n",
      "  or extraction one: 5.0431\n",
      "  other: 2.7918\n",
      "  other words: 5.0431\n",
      "  other words it: 5.0431\n",
      "  pca: 10.0861\n",
      "  pca involves: 5.0431\n",
      "  pca involves changing: 5.0431\n",
      "  pca pca: 5.0431\n",
      "  pca pca involves: 5.0431\n",
      "  popular: 4.3499\n",
      "  popular methods: 5.0431\n",
      "  popular methods of: 5.0431\n",
      "  principal: 8.6998\n",
      "  principal component: 4.6376\n",
      "  principal component analysis: 4.6376\n",
      "  principal variables: 5.0431\n",
      "  principal variables in: 5.0431\n",
      "  process: 6.8672\n",
      "  process of: 8.6998\n",
      "  process of reducing: 10.0861\n",
      "  proposes: 5.0431\n",
      "  proposes that: 5.0431\n",
      "  proposes that highdimensional: 5.0431\n",
      "  random: 3.9444\n",
      "  random variables: 4.3499\n",
      "  random variables under: 5.0431\n",
      "  reducing: 8.6998\n",
      "  reducing the: 9.2752\n",
      "  reducing the dimension: 5.0431\n",
      "  reducing the number: 5.0431\n",
      "  reduction: 17.3996\n",
      "  reduction is: 10.0861\n",
      "  reduction is a: 5.0431\n",
      "  reduction is principal: 5.0431\n",
      "  reduction techniques: 10.0861\n",
      "  reduction techniques can: 5.0431\n",
      "  reduction techniques make: 5.0431\n",
      "  regularisation: 4.6376\n",
      "  set: 5.2014\n",
      "  set also: 5.0431\n",
      "  set also called: 5.0431\n",
      "  set of: 3.0281\n",
      "  set of principal: 5.0431\n",
      "  sets: 4.1268\n",
      "  sets lie: 5.0431\n",
      "  sets lie along: 5.0431\n",
      "  smaller: 4.6376\n",
      "  smaller space: 5.0431\n",
      "  smaller space eg: 5.0431\n",
      "  space: 3.7903\n",
      "  space eg: 5.0431\n",
      "  space eg dthe: 5.0431\n",
      "  techniques: 6.6766\n",
      "  techniques can: 5.0431\n",
      "  techniques can be: 5.0431\n",
      "  techniques make: 4.6376\n",
      "  techniques make this: 5.0431\n",
      "  that: 1.6758\n",
      "  that highdimensional: 5.0431\n",
      "  that highdimensional data: 5.0431\n",
      "  the: 8.3503\n",
      "  the area: 4.6376\n",
      "  the area of: 4.6376\n",
      "  the dimension: 5.0431\n",
      "  the dimension of: 5.0431\n",
      "  the dimensionality: 5.0431\n",
      "  the dimensionality reduction: 5.0431\n",
      "  the feature: 4.6376\n",
      "  the feature set: 5.0431\n",
      "  the number: 9.2752\n",
      "  the number of: 9.2752\n",
      "  the popular: 5.0431\n",
      "  the popular methods: 5.0431\n",
      "  this: 2.6007\n",
      "  this assumption: 5.0431\n",
      "  this assumption leading: 5.0431\n",
      "  to: 2.4507\n",
      "  to a: 3.1712\n",
      "  to a smaller: 5.0431\n",
      "  to the: 3.1712\n",
      "  to the area: 5.0431\n",
      "  under: 3.4336\n",
      "  under consideration: 5.0431\n",
      "  under consideration by: 5.0431\n",
      "  variables: 7.3135\n",
      "  variables in: 4.3499\n",
      "  variables in other: 5.0431\n",
      "  variables under: 5.0431\n",
      "  variables under consideration: 5.0431\n",
      "  words: 5.0431\n",
      "  words it: 5.0431\n",
      "  words it is: 5.0431\n",
      "\n",
      "Document 45:\n",
      "  and: 1.2144\n",
      "  and sometimes: 5.0431\n",
      "  and sometimes more: 5.0431\n",
      "  approaches: 3.5390\n",
      "  approaches have: 5.0431\n",
      "  approaches have been: 5.0431\n",
      "  been: 2.6917\n",
      "  been developed: 4.3499\n",
      "  been developed which: 5.0431\n",
      "  by: 1.9076\n",
      "  by the: 3.2513\n",
      "  by the same: 5.0431\n",
      "  categorisation: 5.0431\n",
      "  categorisation and: 5.0431\n",
      "  categorisation and sometimes: 5.0431\n",
      "  developed: 3.7903\n",
      "  developed which: 5.0431\n",
      "  developed which do: 5.0431\n",
      "  do: 3.6568\n",
      "  do not: 4.3499\n",
      "  do not fit: 5.0431\n",
      "  example: 2.9636\n",
      "  example topic: 5.0431\n",
      "  example topic modelling: 5.0431\n",
      "  fit: 4.1268\n",
      "  fit neatly: 5.0431\n",
      "  fit neatly into: 5.0431\n",
      "  for: 1.7289\n",
      "  for example: 3.2513\n",
      "  for example topic: 5.0431\n",
      "  have: 2.4781\n",
      "  have been: 3.5390\n",
      "  have been developed: 4.6376\n",
      "  into: 2.9636\n",
      "  into this: 5.0431\n",
      "  into this threefold: 5.0431\n",
      "  is: 1.5167\n",
      "  is used: 4.1268\n",
      "  is used by: 5.0431\n",
      "  learning: 1.2819\n",
      "  learning system: 4.1268\n",
      "  learning system for: 5.0431\n",
      "  machine: 1.4735\n",
      "  machine learning: 1.5618\n",
      "  machine learning system: 4.3499\n",
      "  metalearning: 4.6376\n",
      "  modelling: 4.3499\n",
      "  modelling metalearning: 5.0431\n",
      "  more: 3.1712\n",
      "  more than: 5.0431\n",
      "  more than one: 5.0431\n",
      "  neatly: 5.0431\n",
      "  neatly into: 5.0431\n",
      "  neatly into this: 5.0431\n",
      "  not: 2.6007\n",
      "  not fit: 5.0431\n",
      "  not fit neatly: 5.0431\n",
      "  one: 3.0971\n",
      "  one is: 4.3499\n",
      "  one is used: 5.0431\n",
      "  other: 2.7918\n",
      "  other approaches: 5.0431\n",
      "  other approaches have: 5.0431\n",
      "  same: 3.9444\n",
      "  same machine: 5.0431\n",
      "  same machine learning: 5.0431\n",
      "  sometimes: 4.3499\n",
      "  sometimes more: 5.0431\n",
      "  sometimes more than: 5.0431\n",
      "  system: 3.0281\n",
      "  system for: 5.0431\n",
      "  system for example: 5.0431\n",
      "  than: 4.1268\n",
      "  than one: 5.0431\n",
      "  than one is: 5.0431\n",
      "  the: 1.1929\n",
      "  the same: 3.9444\n",
      "  the same machine: 5.0431\n",
      "  this: 2.6007\n",
      "  this threefold: 5.0431\n",
      "  this threefold categorisation: 5.0431\n",
      "  threefold: 5.0431\n",
      "  threefold categorisation: 5.0431\n",
      "  threefold categorisation and: 5.0431\n",
      "  topic: 4.6376\n",
      "  topic modelling: 5.0431\n",
      "  topic modelling metalearning: 5.0431\n",
      "  used: 2.3350\n",
      "  used by: 4.3499\n",
      "  used by the: 5.0431\n",
      "  which: 2.6917\n",
      "  which do: 4.6376\n",
      "  which do not: 5.0431\n",
      "\n",
      "Document 46:\n",
      "  a: 7.5532\n",
      "  a crossbar: 5.0431\n",
      "  a crossbar fashion: 5.0431\n",
      "  a machine: 3.4336\n",
      "  a machine learning: 3.5390\n",
      "  a memory: 5.0431\n",
      "  a memory matrix: 5.0431\n",
      "  a neural: 5.0431\n",
      "  a neural network: 5.0431\n",
      "  a selflearning: 5.0431\n",
      "  a selflearning agent: 5.0431\n",
      "  a solution: 5.0431\n",
      "  a solution to: 5.0431\n",
      "  about: 7.3135\n",
      "  about actions: 5.0431\n",
      "  about actions and: 5.0431\n",
      "  about consequence: 5.0431\n",
      "  about consequence situations: 5.0431\n",
      "  actions: 4.6376\n",
      "  actions and: 5.0431\n",
      "  actions and emotions: 5.0431\n",
      "  adaptive: 5.0431\n",
      "  adaptive array: 5.0431\n",
      "  adaptive array caa: 5.0431\n",
      "  agent: 5.0431\n",
      "  agent the: 5.0431\n",
      "  agent the caa: 5.0431\n",
      "  algorithm: 5.8060\n",
      "  algorithm computes: 5.0431\n",
      "  algorithm computes in: 5.0431\n",
      "  algorithm updates: 5.0431\n",
      "  algorithm updates a: 5.0431\n",
      "  along: 4.3499\n",
      "  along with: 4.6376\n",
      "  along with a: 5.0431\n",
      "  an: 2.1527\n",
      "  an internal: 5.0431\n",
      "  an internal reward: 5.0431\n",
      "  and: 2.4288\n",
      "  and emotions: 5.0431\n",
      "  and emotions feelings: 5.0431\n",
      "  and emotionthe: 5.0431\n",
      "  and emotionthe selflearning: 5.0431\n",
      "  any: 3.6568\n",
      "  any external: 5.0431\n",
      "  any external reward: 5.0431\n",
      "  array: 4.6376\n",
      "  array caa: 5.0431\n",
      "  array caa it: 5.0431\n",
      "  as: 5.5331\n",
      "  as a: 2.9030\n",
      "  as a machine: 5.0431\n",
      "  as an: 4.6376\n",
      "  as an internal: 5.0431\n",
      "  as state: 5.0431\n",
      "  as state evaluation: 5.0431\n",
      "  between: 2.9636\n",
      "  between cognition: 5.0431\n",
      "  between cognition and: 5.0431\n",
      "  both: 3.7903\n",
      "  both decisions: 5.0431\n",
      "  both decisions about: 5.0431\n",
      "  by: 3.8151\n",
      "  by introducing: 5.0431\n",
      "  by introducing emotion: 5.0431\n",
      "  by the: 3.2513\n",
      "  by the interaction: 5.0431\n",
      "  caa: 9.2752\n",
      "  caa it: 5.0431\n",
      "  caa it gives: 5.0431\n",
      "  caa selflearning: 5.0431\n",
      "  caa selflearning algorithm: 5.0431\n",
      "  capable: 5.0431\n",
      "  capable of: 5.0431\n",
      "  capable of selflearning: 5.0431\n",
      "  cognition: 5.0431\n",
      "  cognition and: 5.0431\n",
      "  cognition and emotionthe: 5.0431\n",
      "  computes: 5.0431\n",
      "  computes in: 5.0431\n",
      "  computes in a: 5.0431\n",
      "  consequence: 4.6376\n",
      "  consequence situations: 5.0431\n",
      "  consequence situations the: 5.0431\n",
      "  crossbar: 10.0861\n",
      "  crossbar adaptive: 5.0431\n",
      "  crossbar adaptive array: 5.0431\n",
      "  crossbar fashion: 5.0431\n",
      "  crossbar fashion both: 5.0431\n",
      "  decisions: 3.6568\n",
      "  decisions about: 4.6376\n",
      "  decisions about actions: 5.0431\n",
      "  driven: 5.0431\n",
      "  driven by: 5.0431\n",
      "  driven by the: 5.0431\n",
      "  each: 3.0971\n",
      "  each iteration: 5.0431\n",
      "  each iteration executes: 5.0431\n",
      "  emotion: 9.2752\n",
      "  emotion as: 5.0431\n",
      "  emotion as an: 5.0431\n",
      "  emotion is: 5.0431\n",
      "  emotion is used: 5.0431\n",
      "  emotions: 4.6376\n",
      "  emotions feelings: 5.0431\n",
      "  emotions feelings about: 5.0431\n",
      "  emotionthe: 5.0431\n",
      "  emotionthe selflearning: 5.0431\n",
      "  emotionthe selflearning algorithm: 5.0431\n",
      "  evaluation: 4.3499\n",
      "  evaluation of: 5.0431\n",
      "  evaluation of a: 5.0431\n",
      "  executes: 5.0431\n",
      "  executes the: 5.0431\n",
      "  executes the following: 5.0431\n",
      "  external: 5.0431\n",
      "  external reward: 5.0431\n",
      "  external reward by: 5.0431\n",
      "  fashion: 5.0431\n",
      "  fashion both: 5.0431\n",
      "  fashion both decisions: 5.0431\n",
      "  feelings: 5.0431\n",
      "  feelings about: 5.0431\n",
      "  feelings about consequence: 5.0431\n",
      "  following: 4.6376\n",
      "  following machine: 5.0431\n",
      "  following machine learning: 5.0431\n",
      "  gives: 5.0431\n",
      "  gives a: 5.0431\n",
      "  gives a solution: 5.0431\n",
      "  in: 4.0252\n",
      "  in a: 3.0971\n",
      "  in a crossbar: 5.0431\n",
      "  in along: 5.0431\n",
      "  in along with: 5.0431\n",
      "  in each: 4.6376\n",
      "  in each iteration: 5.0431\n",
      "  interaction: 4.6376\n",
      "  interaction between: 5.0431\n",
      "  interaction between cognition: 5.0431\n",
      "  internal: 4.3499\n",
      "  internal reward: 5.0431\n",
      "  internal reward emotion: 5.0431\n",
      "  introduced: 4.3499\n",
      "  introduced in: 4.6376\n",
      "  introduced in along: 5.0431\n",
      "  introducing: 5.0431\n",
      "  introducing emotion: 5.0431\n",
      "  introducing emotion as: 5.0431\n",
      "  is: 3.0334\n",
      "  is driven: 5.0431\n",
      "  is driven by: 5.0431\n",
      "  is used: 4.1268\n",
      "  is used as: 5.0431\n",
      "  it: 2.2705\n",
      "  it gives: 5.0431\n",
      "  it gives a: 5.0431\n",
      "  iteration: 5.0431\n",
      "  iteration executes: 5.0431\n",
      "  iteration executes the: 5.0431\n",
      "  learning: 3.8456\n",
      "  learning paradigm: 5.0431\n",
      "  learning paradigm was: 5.0431\n",
      "  learning routine: 5.0431\n",
      "  learning without: 4.6376\n",
      "  learning without any: 4.6376\n",
      "  machine: 2.9470\n",
      "  machine learning: 3.1236\n",
      "  machine learning paradigm: 5.0431\n",
      "  machine learning routine: 5.0431\n",
      "  matrix: 3.9444\n",
      "  matrix w: 5.0431\n",
      "  matrix w was: 5.0431\n",
      "  memory: 4.3499\n",
      "  memory matrix: 5.0431\n",
      "  memory matrix w: 5.0431\n",
      "  named: 5.0431\n",
      "  named crossbar: 5.0431\n",
      "  named crossbar adaptive: 5.0431\n",
      "  network: 3.5390\n",
      "  network capable: 5.0431\n",
      "  network capable of: 5.0431\n",
      "  neural: 3.0281\n",
      "  neural network: 4.1268\n",
      "  neural network capable: 5.0431\n",
      "  of: 2.4288\n",
      "  of a: 3.0281\n",
      "  of a selflearning: 5.0431\n",
      "  of selflearning: 5.0431\n",
      "  of selflearning named: 5.0431\n",
      "  paradigm: 5.0431\n",
      "  paradigm was: 5.0431\n",
      "  paradigm was introduced: 5.0431\n",
      "  problem: 3.9444\n",
      "  problem learning: 5.0431\n",
      "  problem learning without: 5.0431\n",
      "  reward: 9.2752\n",
      "  reward by: 5.0431\n",
      "  reward by introducing: 5.0431\n",
      "  reward emotion: 5.0431\n",
      "  reward emotion is: 5.0431\n",
      "  routine: 5.0431\n",
      "  selflearning: 25.2153\n",
      "  selflearning agent: 5.0431\n",
      "  selflearning agent the: 5.0431\n",
      "  selflearning algorithm: 10.0861\n",
      "  selflearning algorithm computes: 5.0431\n",
      "  selflearning algorithm updates: 5.0431\n",
      "  selflearning as: 5.0431\n",
      "  selflearning as a: 5.0431\n",
      "  selflearning named: 5.0431\n",
      "  selflearning named crossbar: 5.0431\n",
      "  situations: 4.6376\n",
      "  situations the: 5.0431\n",
      "  situations the system: 5.0431\n",
      "  solution: 5.0431\n",
      "  solution to: 5.0431\n",
      "  solution to the: 5.0431\n",
      "  state: 5.0431\n",
      "  state evaluation: 5.0431\n",
      "  state evaluation of: 5.0431\n",
      "  such: 2.4781\n",
      "  such that: 4.3499\n",
      "  such that in: 5.0431\n",
      "  system: 3.0281\n",
      "  system is: 4.6376\n",
      "  system is driven: 5.0431\n",
      "  that: 1.6758\n",
      "  that in: 5.0431\n",
      "  that in each: 5.0431\n",
      "  the: 5.9645\n",
      "  the caa: 4.6376\n",
      "  the caa selflearning: 5.0431\n",
      "  the following: 4.6376\n",
      "  the following machine: 5.0431\n",
      "  the interaction: 5.0431\n",
      "  the interaction between: 5.0431\n",
      "  the problem: 4.3499\n",
      "  the problem learning: 5.0431\n",
      "  the system: 4.3499\n",
      "  the system is: 5.0431\n",
      "  to: 1.2253\n",
      "  to the: 3.1712\n",
      "  to the problem: 5.0431\n",
      "  updates: 5.0431\n",
      "  updates a: 5.0431\n",
      "  updates a memory: 5.0431\n",
      "  used: 2.3350\n",
      "  used as: 4.1268\n",
      "  used as state: 5.0431\n",
      "  w: 5.0431\n",
      "  w was: 5.0431\n",
      "  w was such: 5.0431\n",
      "  was: 6.6766\n",
      "  was introduced: 4.6376\n",
      "  was introduced in: 4.6376\n",
      "  was such: 5.0431\n",
      "  was such that: 5.0431\n",
      "  with: 2.0726\n",
      "  with a: 3.6568\n",
      "  with a neural: 5.0431\n",
      "  without: 3.3383\n",
      "  without any: 4.6376\n",
      "  without any external: 5.0431\n",
      "\n",
      "Document 47:\n",
      "  a: 5.0354\n",
      "  a goalseeking: 5.0431\n",
      "  a goalseeking behaviour: 5.0431\n",
      "  a separate: 5.0431\n",
      "  a separate reinforcement: 5.0431\n",
      "  a system: 4.3499\n",
      "  a system with: 5.0431\n",
      "  a there: 5.0431\n",
      "  a there is: 5.0431\n",
      "  about: 3.6568\n",
      "  about situations: 5.0431\n",
      "  about situations to: 5.0431\n",
      "  action: 5.0431\n",
      "  action or: 5.0431\n",
      "  action or behaviour: 5.0431\n",
      "  advice: 5.0431\n",
      "  advice input: 5.0431\n",
      "  advice input from: 5.0431\n",
      "  after: 3.7903\n",
      "  after receiving: 5.0431\n",
      "  after receiving the: 5.0431\n",
      "  an: 4.3054\n",
      "  an advice: 5.0431\n",
      "  an advice input: 5.0431\n",
      "  an environment: 4.6376\n",
      "  an environment that: 5.0431\n",
      "  and: 4.8576\n",
      "  and only: 10.0861\n",
      "  and only once: 5.0431\n",
      "  and only one: 5.0431\n",
      "  and the: 3.3383\n",
      "  and the other: 5.0431\n",
      "  and undesirable: 5.0431\n",
      "  and undesirable situations: 5.0431\n",
      "  backpropagated: 5.0431\n",
      "  backpropagated value: 5.0431\n",
      "  backpropagated value secondary: 5.0431\n",
      "  be: 2.0726\n",
      "  be encountered: 5.0431\n",
      "  be encountered in: 5.0431\n",
      "  behaves: 5.0431\n",
      "  behaves and: 5.0431\n",
      "  behaves and the: 5.0431\n",
      "  behaviour: 8.6998\n",
      "  behaviour a: 5.0431\n",
      "  behaviour a there: 5.0431\n",
      "  behaviour in: 5.0431\n",
      "  behaviour in an: 5.0431\n",
      "  behavioural: 10.0861\n",
      "  behavioural environment: 10.0861\n",
      "  behavioural environment after: 5.0431\n",
      "  behavioural environment where: 5.0431\n",
      "  both: 3.7903\n",
      "  both desirable: 5.0431\n",
      "  both desirable and: 5.0431\n",
      "  caa: 9.2752\n",
      "  caa exists: 5.0431\n",
      "  caa exists in: 5.0431\n",
      "  caa learns: 5.0431\n",
      "  caa learns a: 5.0431\n",
      "  consequence: 4.6376\n",
      "  consequence situation: 5.0431\n",
      "  consequence situation the: 5.0431\n",
      "  contains: 4.6376\n",
      "  contains both: 4.6376\n",
      "  contains both desirable: 5.0431\n",
      "  desirable: 5.0431\n",
      "  desirable and: 5.0431\n",
      "  desirable and undesirable: 5.0431\n",
      "  emotion: 4.6376\n",
      "  emotion toward: 5.0431\n",
      "  emotion toward the: 5.0431\n",
      "  emotions: 4.6376\n",
      "  emotions about: 5.0431\n",
      "  emotions about situations: 5.0431\n",
      "  encountered: 5.0431\n",
      "  encountered in: 5.0431\n",
      "  encountered in the: 5.0431\n",
      "  environment: 27.8255\n",
      "  environment after: 5.0431\n",
      "  environment after receiving: 5.0431\n",
      "  environment that: 5.0431\n",
      "  environment that contains: 5.0431\n",
      "  environment the: 10.0861\n",
      "  environment the backpropagated: 5.0431\n",
      "  environment the caa: 5.0431\n",
      "  environment where: 5.0431\n",
      "  environment where it: 5.0431\n",
      "  environment wherefrom: 5.0431\n",
      "  environment wherefrom it: 5.0431\n",
      "  environments: 4.6376\n",
      "  environments one: 5.0431\n",
      "  environments one is: 5.0431\n",
      "  exists: 5.0431\n",
      "  exists in: 5.0431\n",
      "  exists in two: 5.0431\n",
      "  from: 4.1453\n",
      "  from the: 6.6766\n",
      "  from the environment: 5.0431\n",
      "  from the genetic: 5.0431\n",
      "  genetic: 8.2535\n",
      "  genetic environment: 10.0861\n",
      "  genetic environment the: 5.0431\n",
      "  genetic environment wherefrom: 5.0431\n",
      "  genome: 5.0431\n",
      "  genome species: 5.0431\n",
      "  genome species vector: 5.0431\n",
      "  goalseeking: 5.0431\n",
      "  goalseeking behaviour: 5.0431\n",
      "  goalseeking behaviour in: 5.0431\n",
      "  in: 4.0252\n",
      "  in an: 3.9444\n",
      "  in an environment: 4.6376\n",
      "  in the: 2.4404\n",
      "  in the behavioural: 5.0431\n",
      "  in two: 5.0431\n",
      "  in two environments: 5.0431\n",
      "  initial: 4.6376\n",
      "  initial emotions: 5.0431\n",
      "  initial emotions about: 5.0431\n",
      "  initially: 5.0431\n",
      "  initially and: 5.0431\n",
      "  initially and only: 5.0431\n",
      "  input: 9.0844\n",
      "  input from: 5.0431\n",
      "  input from the: 5.0431\n",
      "  input nor: 5.0431\n",
      "  input nor an: 5.0431\n",
      "  input situation: 5.0431\n",
      "  input situation and: 5.0431\n",
      "  is: 7.5835\n",
      "  is a: 2.5173\n",
      "  is a system: 5.0431\n",
      "  is neither: 5.0431\n",
      "  is neither a: 5.0431\n",
      "  is the: 10.0149\n",
      "  is the behavioural: 5.0431\n",
      "  is the emotion: 5.0431\n",
      "  is the genetic: 5.0431\n",
      "  it: 6.8114\n",
      "  it behaves: 5.0431\n",
      "  it behaves and: 5.0431\n",
      "  it initially: 5.0431\n",
      "  it initially and: 5.0431\n",
      "  it is: 3.5390\n",
      "  it is a: 4.3499\n",
      "  learns: 3.9444\n",
      "  learns a: 4.6376\n",
      "  learns a goalseeking: 5.0431\n",
      "  neither: 5.0431\n",
      "  neither a: 5.0431\n",
      "  neither a separate: 5.0431\n",
      "  nor: 5.0431\n",
      "  nor an: 5.0431\n",
      "  nor an advice: 5.0431\n",
      "  once: 4.3499\n",
      "  once receives: 5.0431\n",
      "  once receives initial: 5.0431\n",
      "  one: 9.2914\n",
      "  one input: 5.0431\n",
      "  one input situation: 5.0431\n",
      "  one is: 4.3499\n",
      "  one is the: 5.0431\n",
      "  one output: 5.0431\n",
      "  one output action: 5.0431\n",
      "  only: 10.9703\n",
      "  only once: 5.0431\n",
      "  only once receives: 5.0431\n",
      "  only one: 10.0861\n",
      "  only one input: 5.0431\n",
      "  only one output: 5.0431\n",
      "  or: 2.0226\n",
      "  or behaviour: 5.0431\n",
      "  or behaviour a: 5.0431\n",
      "  other: 2.7918\n",
      "  other is: 5.0431\n",
      "  other is the: 5.0431\n",
      "  output: 3.3383\n",
      "  output action: 5.0431\n",
      "  output action or: 5.0431\n",
      "  receives: 4.6376\n",
      "  receives initial: 5.0431\n",
      "  receives initial emotions: 5.0431\n",
      "  receiving: 5.0431\n",
      "  receiving the: 5.0431\n",
      "  receiving the genome: 5.0431\n",
      "  reinforcement: 7.8889\n",
      "  reinforcement input: 5.0431\n",
      "  reinforcement input nor: 5.0431\n",
      "  reinforcement is: 5.0431\n",
      "  reinforcement is the: 5.0431\n",
      "  secondary: 5.0431\n",
      "  secondary reinforcement: 5.0431\n",
      "  secondary reinforcement is: 5.0431\n",
      "  separate: 4.6376\n",
      "  separate reinforcement: 5.0431\n",
      "  separate reinforcement input: 5.0431\n",
      "  situation: 9.2752\n",
      "  situation and: 5.0431\n",
      "  situation and only: 5.0431\n",
      "  situation the: 5.0431\n",
      "  situation the caa: 5.0431\n",
      "  situations: 9.2752\n",
      "  situations to: 5.0431\n",
      "  situations to be: 5.0431\n",
      "  species: 5.0431\n",
      "  species vector: 5.0431\n",
      "  species vector from: 5.0431\n",
      "  system: 3.0281\n",
      "  system with: 5.0431\n",
      "  system with only: 5.0431\n",
      "  that: 1.6758\n",
      "  that contains: 4.6376\n",
      "  that contains both: 4.6376\n",
      "  the: 14.3148\n",
      "  the backpropagated: 5.0431\n",
      "  the backpropagated value: 5.0431\n",
      "  the behavioural: 10.0861\n",
      "  the behavioural environment: 10.0861\n",
      "  the caa: 9.2752\n",
      "  the caa exists: 5.0431\n",
      "  the caa learns: 5.0431\n",
      "  the consequence: 5.0431\n",
      "  the consequence situation: 5.0431\n",
      "  the emotion: 5.0431\n",
      "  the emotion toward: 5.0431\n",
      "  the environment: 4.6376\n",
      "  the environment the: 5.0431\n",
      "  the genetic: 10.0861\n",
      "  the genetic environment: 10.0861\n",
      "  the genome: 5.0431\n",
      "  the genome species: 5.0431\n",
      "  the other: 4.3499\n",
      "  the other is: 5.0431\n",
      "  there: 3.6568\n",
      "  there is: 4.3499\n",
      "  there is neither: 5.0431\n",
      "  to: 1.2253\n",
      "  to be: 3.4336\n",
      "  to be encountered: 5.0431\n",
      "  toward: 4.3499\n",
      "  toward the: 5.0431\n",
      "  toward the consequence: 5.0431\n",
      "  two: 3.5390\n",
      "  two environments: 5.0431\n",
      "  two environments one: 5.0431\n",
      "  undesirable: 5.0431\n",
      "  undesirable situations: 5.0431\n",
      "  value: 4.3499\n",
      "  value secondary: 5.0431\n",
      "  value secondary reinforcement: 5.0431\n",
      "  vector: 4.3499\n",
      "  vector from: 5.0431\n",
      "  vector from the: 5.0431\n",
      "  where: 3.2513\n",
      "  where it: 4.6376\n",
      "  where it behaves: 5.0431\n",
      "  wherefrom: 5.0431\n",
      "  wherefrom it: 5.0431\n",
      "  wherefrom it initially: 5.0431\n",
      "  with: 2.0726\n",
      "  with only: 5.0431\n",
      "  with only one: 5.0431\n",
      "\n",
      "Document 48:\n",
      "  a: 5.0354\n",
      "  a machine: 3.4336\n",
      "  a machine to: 5.0431\n",
      "  a preprocessing: 4.6376\n",
      "  a preprocessing step: 4.6376\n",
      "  a specific: 4.3499\n",
      "  a specific task: 5.0431\n",
      "  a way: 4.6376\n",
      "  a way that: 5.0431\n",
      "  aim: 4.6376\n",
      "  aim at: 5.0431\n",
      "  aim at discovering: 5.0431\n",
      "  algorithms: 7.1067\n",
      "  algorithms aim: 4.6376\n",
      "  algorithms aim at: 5.0431\n",
      "  algorithms also: 5.0431\n",
      "  algorithms also called: 5.0431\n",
      "  algorithms often: 5.0431\n",
      "  algorithms often attempt: 5.0431\n",
      "  allows: 9.2752\n",
      "  allows a: 5.0431\n",
      "  allows a machine: 5.0431\n",
      "  allows reconstruction: 5.0431\n",
      "  allows reconstruction of: 5.0431\n",
      "  also: 5.2903\n",
      "  also called: 4.6376\n",
      "  also called representation: 5.0431\n",
      "  also transform: 5.0431\n",
      "  also transform it: 5.0431\n",
      "  analysis: 6.3425\n",
      "  analysis and: 5.0431\n",
      "  analysis and cluster: 5.0431\n",
      "  analysis feature: 5.0431\n",
      "  analysis feature learning: 5.0431\n",
      "  and: 3.6432\n",
      "  and allows: 5.0431\n",
      "  and allows a: 5.0431\n",
      "  and cluster: 5.0431\n",
      "  and cluster analysis: 5.0431\n",
      "  and use: 5.0431\n",
      "  and use them: 5.0431\n",
      "  are: 1.9750\n",
      "  are implausible: 5.0431\n",
      "  are implausible under: 5.0431\n",
      "  as: 1.8444\n",
      "  as a: 2.9030\n",
      "  as a preprocessing: 4.6376\n",
      "  at: 3.9444\n",
      "  at discovering: 5.0431\n",
      "  at discovering better: 5.0431\n",
      "  attempt: 4.3499\n",
      "  attempt to: 4.3499\n",
      "  attempt to preserve: 5.0431\n",
      "  before: 5.0431\n",
      "  before performing: 5.0431\n",
      "  before performing classification: 5.0431\n",
      "  being: 3.7903\n",
      "  being necessarily: 5.0431\n",
      "  being necessarily faithful: 5.0431\n",
      "  better: 4.1268\n",
      "  better representations: 5.0431\n",
      "  better representations of: 5.0431\n",
      "  both: 3.7903\n",
      "  both learn: 5.0431\n",
      "  both learn the: 5.0431\n",
      "  but: 3.0281\n",
      "  but also: 4.6376\n",
      "  but also transform: 5.0431\n",
      "  called: 3.2513\n",
      "  called representation: 5.0431\n",
      "  called representation learning: 5.0431\n",
      "  classic: 5.0431\n",
      "  classic examples: 5.0431\n",
      "  classic examples include: 5.0431\n",
      "  classification: 2.9636\n",
      "  classification or: 4.6376\n",
      "  classification or predictions: 5.0431\n",
      "  cluster: 4.3499\n",
      "  cluster analysis: 4.3499\n",
      "  cluster analysis feature: 5.0431\n",
      "  coming: 5.0431\n",
      "  coming from: 5.0431\n",
      "  coming from the: 5.0431\n",
      "  component: 3.9444\n",
      "  component analysis: 4.3499\n",
      "  component analysis and: 5.0431\n",
      "  configurations: 5.0431\n",
      "  configurations that: 5.0431\n",
      "  configurations that are: 5.0431\n",
      "  datagenerating: 5.0431\n",
      "  datagenerating distribution: 5.0431\n",
      "  datagenerating distribution while: 5.0431\n",
      "  discovering: 4.3499\n",
      "  discovering better: 5.0431\n",
      "  discovering better representations: 5.0431\n",
      "  distribution: 7.8889\n",
      "  distribution this: 5.0431\n",
      "  distribution this replaces: 5.0431\n",
      "  distribution while: 5.0431\n",
      "  distribution while not: 5.0431\n",
      "  during: 4.1268\n",
      "  during training: 4.6376\n",
      "  during training classic: 5.0431\n",
      "  engineering: 4.1268\n",
      "  engineering and: 4.6376\n",
      "  engineering and allows: 5.0431\n",
      "  examples: 3.0971\n",
      "  examples include: 4.6376\n",
      "  examples include principal: 5.0431\n",
      "  faithful: 5.0431\n",
      "  faithful to: 5.0431\n",
      "  faithful to configurations: 5.0431\n",
      "  feature: 6.8672\n",
      "  feature engineering: 4.6376\n",
      "  feature engineering and: 4.6376\n",
      "  feature learning: 4.1268\n",
      "  feature learning algorithms: 5.0431\n",
      "  features: 3.6568\n",
      "  features and: 5.0431\n",
      "  features and use: 5.0431\n",
      "  from: 2.0726\n",
      "  from the: 3.3383\n",
      "  from the unknown: 5.0431\n",
      "  implausible: 5.0431\n",
      "  implausible under: 5.0431\n",
      "  implausible under that: 5.0431\n",
      "  in: 2.6835\n",
      "  in a: 3.0971\n",
      "  in a way: 5.0431\n",
      "  in their: 4.6376\n",
      "  in their input: 5.0431\n",
      "  include: 3.4336\n",
      "  include principal: 5.0431\n",
      "  include principal component: 5.0431\n",
      "  information: 3.7903\n",
      "  information in: 5.0431\n",
      "  information in their: 5.0431\n",
      "  input: 3.0281\n",
      "  input but: 5.0431\n",
      "  input but also: 5.0431\n",
      "  inputs: 8.2535\n",
      "  inputs coming: 5.0431\n",
      "  inputs coming from: 5.0431\n",
      "  inputs provided: 5.0431\n",
      "  inputs provided during: 5.0431\n",
      "  it: 4.5409\n",
      "  it in: 4.6376\n",
      "  it in a: 5.0431\n",
      "  it useful: 4.6376\n",
      "  it useful often: 5.0431\n",
      "  learn: 3.3383\n",
      "  learn the: 5.0431\n",
      "  learn the features: 5.0431\n",
      "  learning: 3.8456\n",
      "  learning algorithms: 8.7090\n",
      "  learning algorithms aim: 4.6376\n",
      "  learning algorithms also: 5.0431\n",
      "  learning algorithms often: 5.0431\n",
      "  machine: 1.4735\n",
      "  machine to: 4.6376\n",
      "  machine to both: 5.0431\n",
      "  makes: 4.3499\n",
      "  makes it: 5.0431\n",
      "  makes it useful: 5.0431\n",
      "  manual: 5.0431\n",
      "  manual feature: 5.0431\n",
      "  manual feature engineering: 5.0431\n",
      "  necessarily: 4.6376\n",
      "  necessarily faithful: 5.0431\n",
      "  necessarily faithful to: 5.0431\n",
      "  not: 2.6007\n",
      "  not being: 4.6376\n",
      "  not being necessarily: 5.0431\n",
      "  of: 2.4288\n",
      "  of the: 4.6044\n",
      "  of the inputs: 10.0861\n",
      "  often: 6.1943\n",
      "  often as: 4.6376\n",
      "  often as a: 5.0431\n",
      "  often attempt: 5.0431\n",
      "  often attempt to: 5.0431\n",
      "  or: 2.0226\n",
      "  or predictions: 4.3499\n",
      "  or predictions this: 5.0431\n",
      "  perform: 3.2513\n",
      "  perform a: 4.6376\n",
      "  perform a specific: 5.0431\n",
      "  performing: 3.9444\n",
      "  performing classification: 5.0431\n",
      "  performing classification or: 5.0431\n",
      "  predictions: 3.3383\n",
      "  predictions this: 5.0431\n",
      "  predictions this technique: 5.0431\n",
      "  preprocessing: 4.6376\n",
      "  preprocessing step: 4.6376\n",
      "  preprocessing step before: 5.0431\n",
      "  preserve: 5.0431\n",
      "  preserve the: 5.0431\n",
      "  preserve the information: 5.0431\n",
      "  principal: 4.3499\n",
      "  principal component: 4.6376\n",
      "  principal component analysis: 4.6376\n",
      "  provided: 4.1268\n",
      "  provided during: 5.0431\n",
      "  provided during training: 5.0431\n",
      "  reconstruction: 5.0431\n",
      "  reconstruction of: 5.0431\n",
      "  reconstruction of the: 5.0431\n",
      "  replaces: 5.0431\n",
      "  replaces manual: 5.0431\n",
      "  replaces manual feature: 5.0431\n",
      "  representation: 3.9444\n",
      "  representation learning: 5.0431\n",
      "  representation learning algorithms: 5.0431\n",
      "  representations: 4.3499\n",
      "  representations of: 5.0431\n",
      "  representations of the: 5.0431\n",
      "  several: 3.9444\n",
      "  several learning: 5.0431\n",
      "  several learning algorithms: 5.0431\n",
      "  specific: 3.7903\n",
      "  specific task: 5.0431\n",
      "  step: 4.6376\n",
      "  step before: 5.0431\n",
      "  step before performing: 5.0431\n",
      "  task: 3.9444\n",
      "  technique: 4.3499\n",
      "  technique allows: 5.0431\n",
      "  technique allows reconstruction: 5.0431\n",
      "  that: 5.0273\n",
      "  that are: 3.7903\n",
      "  that are implausible: 5.0431\n",
      "  that distribution: 5.0431\n",
      "  that distribution this: 5.0431\n",
      "  that makes: 5.0431\n",
      "  that makes it: 5.0431\n",
      "  the: 5.9645\n",
      "  the features: 5.0431\n",
      "  the features and: 5.0431\n",
      "  the information: 5.0431\n",
      "  the information in: 5.0431\n",
      "  the inputs: 9.2752\n",
      "  the inputs coming: 5.0431\n",
      "  the inputs provided: 5.0431\n",
      "  the unknown: 5.0431\n",
      "  the unknown datagenerating: 5.0431\n",
      "  their: 2.7918\n",
      "  their input: 5.0431\n",
      "  their input but: 5.0431\n",
      "  them: 4.3499\n",
      "  them to: 5.0431\n",
      "  them to perform: 5.0431\n",
      "  this: 5.2014\n",
      "  this replaces: 5.0431\n",
      "  this replaces manual: 5.0431\n",
      "  this technique: 4.6376\n",
      "  this technique allows: 5.0431\n",
      "  to: 4.9014\n",
      "  to both: 5.0431\n",
      "  to both learn: 5.0431\n",
      "  to configurations: 5.0431\n",
      "  to configurations that: 5.0431\n",
      "  to perform: 3.9444\n",
      "  to perform a: 5.0431\n",
      "  to preserve: 5.0431\n",
      "  to preserve the: 5.0431\n",
      "  training: 2.5581\n",
      "  training classic: 5.0431\n",
      "  training classic examples: 5.0431\n",
      "  transform: 5.0431\n",
      "  transform it: 5.0431\n",
      "  transform it in: 5.0431\n",
      "  under: 3.4336\n",
      "  under that: 5.0431\n",
      "  under that distribution: 5.0431\n",
      "  unknown: 4.3499\n",
      "  unknown datagenerating: 5.0431\n",
      "  unknown datagenerating distribution: 5.0431\n",
      "  use: 3.3383\n",
      "  use them: 5.0431\n",
      "  use them to: 5.0431\n",
      "  useful: 3.9444\n",
      "  useful often: 5.0431\n",
      "  useful often as: 5.0431\n",
      "  way: 3.9444\n",
      "  way that: 4.6376\n",
      "  way that makes: 5.0431\n",
      "  while: 3.4336\n",
      "  while not: 5.0431\n",
      "  while not being: 5.0431\n",
      "\n",
      "Document 49:\n",
      "  analysis: 3.1712\n",
      "  analysis autoencoders: 5.0431\n",
      "  analysis autoencoders matrix: 5.0431\n",
      "  and: 2.4288\n",
      "  and supervised: 4.6376\n",
      "  and supervised dictionary: 5.0431\n",
      "  and various: 5.0431\n",
      "  and various forms: 5.0431\n",
      "  are: 3.9500\n",
      "  are learned: 10.0861\n",
      "  are learned using: 5.0431\n",
      "  are learned with: 5.0431\n",
      "  artificial: 2.7918\n",
      "  artificial neural: 3.7903\n",
      "  artificial neural networks: 4.1268\n",
      "  autoencoders: 5.0431\n",
      "  autoencoders matrix: 5.0431\n",
      "  autoencoders matrix factorisation: 5.0431\n",
      "  be: 2.0726\n",
      "  be either: 5.0431\n",
      "  be either supervised: 5.0431\n",
      "  can: 2.1809\n",
      "  can be: 2.7405\n",
      "  can be either: 5.0431\n",
      "  clustering: 3.9444\n",
      "  component: 3.9444\n",
      "  component analysis: 4.3499\n",
      "  component analysis autoencoders: 5.0431\n",
      "  data: 3.7300\n",
      "  data examples: 10.0861\n",
      "  data examples include: 10.0861\n",
      "  dictionary: 9.2752\n",
      "  dictionary learning: 9.2752\n",
      "  dictionary learning in: 5.0431\n",
      "  dictionary learning independent: 5.0431\n",
      "  either: 3.9444\n",
      "  either supervised: 4.6376\n",
      "  either supervised or: 5.0431\n",
      "  examples: 6.1943\n",
      "  examples include: 9.2752\n",
      "  examples include artificial: 5.0431\n",
      "  examples include dictionary: 5.0431\n",
      "  factorisation: 4.6376\n",
      "  factorisation and: 5.0431\n",
      "  factorisation and various: 5.0431\n",
      "  feature: 10.3008\n",
      "  feature learning: 12.3803\n",
      "  feature learning can: 5.0431\n",
      "  feature learning features: 10.0861\n",
      "  features: 7.3135\n",
      "  features are: 10.0861\n",
      "  features are learned: 10.0861\n",
      "  forms: 5.0431\n",
      "  forms of: 5.0431\n",
      "  forms of clustering: 5.0431\n",
      "  in: 2.6835\n",
      "  in supervised: 5.0431\n",
      "  in supervised feature: 5.0431\n",
      "  in unsupervised: 4.6376\n",
      "  in unsupervised feature: 5.0431\n",
      "  include: 6.8672\n",
      "  include artificial: 5.0431\n",
      "  include artificial neural: 5.0431\n",
      "  include dictionary: 5.0431\n",
      "  include dictionary learning: 5.0431\n",
      "  independent: 4.6376\n",
      "  independent component: 5.0431\n",
      "  independent component analysis: 5.0431\n",
      "  input: 6.0563\n",
      "  input data: 9.2752\n",
      "  input data examples: 10.0861\n",
      "  labelled: 4.1268\n",
      "  labelled input: 5.0431\n",
      "  labelled input data: 5.0431\n",
      "  learned: 7.5806\n",
      "  learned using: 5.0431\n",
      "  learned using labelled: 5.0431\n",
      "  learned with: 5.0431\n",
      "  learned with unlabelled: 5.0431\n",
      "  learning: 6.4093\n",
      "  learning can: 4.6376\n",
      "  learning can be: 4.6376\n",
      "  learning features: 10.0861\n",
      "  learning features are: 10.0861\n",
      "  learning in: 3.6568\n",
      "  learning in unsupervised: 5.0431\n",
      "  learning independent: 5.0431\n",
      "  learning independent component: 5.0431\n",
      "  matrix: 3.9444\n",
      "  matrix factorisation: 5.0431\n",
      "  matrix factorisation and: 5.0431\n",
      "  multilayer: 5.0431\n",
      "  multilayer perceptrons: 5.0431\n",
      "  multilayer perceptrons and: 5.0431\n",
      "  networks: 3.0971\n",
      "  networks multilayer: 5.0431\n",
      "  networks multilayer perceptrons: 5.0431\n",
      "  neural: 3.0281\n",
      "  neural networks: 3.2513\n",
      "  neural networks multilayer: 5.0431\n",
      "  of: 1.2144\n",
      "  of clustering: 5.0431\n",
      "  or: 2.0226\n",
      "  or unsupervised: 4.6376\n",
      "  or unsupervised in: 5.0431\n",
      "  perceptrons: 4.6376\n",
      "  perceptrons and: 4.6376\n",
      "  perceptrons and supervised: 5.0431\n",
      "  supervised: 9.7539\n",
      "  supervised dictionary: 5.0431\n",
      "  supervised dictionary learning: 5.0431\n",
      "  supervised feature: 5.0431\n",
      "  supervised feature learning: 5.0431\n",
      "  supervised or: 5.0431\n",
      "  supervised or unsupervised: 5.0431\n",
      "  unlabelled: 4.3499\n",
      "  unlabelled input: 5.0431\n",
      "  unlabelled input data: 5.0431\n",
      "  unsupervised: 6.5026\n",
      "  unsupervised feature: 5.0431\n",
      "  unsupervised feature learning: 5.0431\n",
      "  unsupervised in: 5.0431\n",
      "  unsupervised in supervised: 5.0431\n",
      "  using: 3.2513\n",
      "  using labelled: 5.0431\n",
      "  using labelled input: 5.0431\n",
      "  various: 3.4336\n",
      "  various forms: 5.0431\n",
      "  various forms of: 5.0431\n",
      "  with: 2.0726\n",
      "  with unlabelled: 5.0431\n",
      "  with unlabelled input: 5.0431\n",
      "\n",
      "Document 50:\n",
      "  a: 2.5177\n",
      "  a hierarchy: 5.0431\n",
      "  a hierarchy of: 5.0431\n",
      "  a representation: 5.0431\n",
      "  a representation that: 5.0431\n",
      "  abstract: 5.0431\n",
      "  abstract features: 5.0431\n",
      "  abstract features defined: 5.0431\n",
      "  aim: 4.6376\n",
      "  aim to: 5.0431\n",
      "  aim to learn: 5.0431\n",
      "  algorithms: 9.4756\n",
      "  algorithms aim: 4.6376\n",
      "  algorithms aim to: 5.0431\n",
      "  algorithms attempt: 10.0861\n",
      "  algorithms attempt to: 10.0861\n",
      "  algorithms discover: 5.0431\n",
      "  algorithms discover multiple: 5.0431\n",
      "  an: 2.1527\n",
      "  an intelligent: 5.0431\n",
      "  an intelligent machine: 5.0431\n",
      "  argued: 5.0431\n",
      "  argued that: 5.0431\n",
      "  argued that an: 5.0431\n",
      "  attempt: 8.6998\n",
      "  attempt to: 8.6998\n",
      "  attempt to do: 10.0861\n",
      "  been: 2.6917\n",
      "  been argued: 5.0431\n",
      "  been argued that: 5.0431\n",
      "  coding: 4.6376\n",
      "  coding algorithms: 5.0431\n",
      "  coding algorithms attempt: 5.0431\n",
      "  constraint: 10.0861\n",
      "  constraint that: 10.0861\n",
      "  constraint that the: 10.0861\n",
      "  data: 3.7300\n",
      "  data without: 5.0431\n",
      "  data without reshaping: 5.0431\n",
      "  deep: 3.6568\n",
      "  deep learning: 3.7903\n",
      "  deep learning algorithms: 4.6376\n",
      "  defined: 4.6376\n",
      "  defined in: 5.0431\n",
      "  defined in terms: 5.0431\n",
      "  directly: 4.1268\n",
      "  directly from: 5.0431\n",
      "  directly from tensor: 5.0431\n",
      "  discover: 4.6376\n",
      "  discover multiple: 5.0431\n",
      "  discover multiple levels: 5.0431\n",
      "  disentangles: 5.0431\n",
      "  disentangles the: 5.0431\n",
      "  disentangles the underlying: 5.0431\n",
      "  do: 7.3135\n",
      "  do so: 10.0861\n",
      "  do so under: 10.0861\n",
      "  explain: 4.3499\n",
      "  explain the: 5.0431\n",
      "  explain the observed: 5.0431\n",
      "  factors: 4.6376\n",
      "  factors of: 5.0431\n",
      "  factors of variation: 5.0431\n",
      "  features: 10.9703\n",
      "  features defined: 5.0431\n",
      "  features defined in: 5.0431\n",
      "  features it: 5.0431\n",
      "  features it has: 5.0431\n",
      "  features with: 5.0431\n",
      "  features with higherlevel: 5.0431\n",
      "  for: 1.7289\n",
      "  for multidimensional: 5.0431\n",
      "  for multidimensional data: 5.0431\n",
      "  from: 2.0726\n",
      "  from tensor: 5.0431\n",
      "  from tensor representations: 5.0431\n",
      "  generating: 4.6376\n",
      "  generating lowerlevel: 5.0431\n",
      "  generating lowerlevel features: 5.0431\n",
      "  has: 5.6917\n",
      "  has been: 3.6568\n",
      "  has been argued: 5.0431\n",
      "  has many: 5.0431\n",
      "  has many zeros: 5.0431\n",
      "  hierarchy: 5.0431\n",
      "  hierarchy of: 5.0431\n",
      "  hierarchy of features: 5.0431\n",
      "  higherdimensional: 4.3499\n",
      "  higherdimensional vectors: 5.0431\n",
      "  higherdimensional vectors deep: 5.0431\n",
      "  higherlevel: 5.0431\n",
      "  higherlevel more: 5.0431\n",
      "  higherlevel more abstract: 5.0431\n",
      "  in: 1.3417\n",
      "  in terms: 4.6376\n",
      "  in terms of: 4.6376\n",
      "  intelligent: 5.0431\n",
      "  intelligent machine: 5.0431\n",
      "  intelligent machine is: 5.0431\n",
      "  into: 2.9636\n",
      "  into higherdimensional: 5.0431\n",
      "  into higherdimensional vectors: 5.0431\n",
      "  is: 4.5501\n",
      "  is lowdimensional: 5.0431\n",
      "  is lowdimensional sparse: 5.0431\n",
      "  is one: 4.3499\n",
      "  is one that: 5.0431\n",
      "  is sparse: 5.0431\n",
      "  is sparse meaning: 5.0431\n",
      "  it: 2.2705\n",
      "  it has: 4.3499\n",
      "  it has been: 5.0431\n",
      "  learn: 3.3383\n",
      "  learn lowdimensional: 5.0431\n",
      "  learn lowdimensional representations: 5.0431\n",
      "  learned: 7.5806\n",
      "  learned representation: 10.0861\n",
      "  learned representation is: 10.0861\n",
      "  learning: 3.8456\n",
      "  learning algorithms: 8.7090\n",
      "  learning algorithms aim: 4.6376\n",
      "  learning algorithms attempt: 5.0431\n",
      "  learning algorithms discover: 5.0431\n",
      "  learns: 3.9444\n",
      "  learns a: 4.6376\n",
      "  learns a representation: 5.0431\n",
      "  levels: 4.3499\n",
      "  levels of: 4.3499\n",
      "  levels of representation: 5.0431\n",
      "  lowdimensional: 9.2752\n",
      "  lowdimensional representations: 5.0431\n",
      "  lowdimensional representations directly: 5.0431\n",
      "  lowdimensional sparse: 5.0431\n",
      "  lowdimensional sparse coding: 5.0431\n",
      "  lowerlevel: 5.0431\n",
      "  lowerlevel features: 5.0431\n",
      "  lowerlevel features it: 5.0431\n",
      "  machine: 1.4735\n",
      "  machine is: 5.0431\n",
      "  machine is one: 5.0431\n",
      "  manifold: 4.6376\n",
      "  manifold learning: 4.6376\n",
      "  manifold learning algorithms: 5.0431\n",
      "  many: 2.9030\n",
      "  many zeros: 5.0431\n",
      "  many zeros multilinear: 5.0431\n",
      "  mathematical: 3.5390\n",
      "  mathematical model: 4.1268\n",
      "  mathematical model has: 5.0431\n",
      "  meaning: 4.3499\n",
      "  meaning that: 4.6376\n",
      "  meaning that the: 5.0431\n",
      "  model: 2.3350\n",
      "  model has: 4.6376\n",
      "  model has many: 5.0431\n",
      "  more: 3.1712\n",
      "  more abstract: 5.0431\n",
      "  more abstract features: 5.0431\n",
      "  multidimensional: 4.6376\n",
      "  multidimensional data: 5.0431\n",
      "  multidimensional data without: 5.0431\n",
      "  multilinear: 5.0431\n",
      "  multilinear subspace: 5.0431\n",
      "  multilinear subspace learning: 5.0431\n",
      "  multiple: 3.9444\n",
      "  multiple levels: 5.0431\n",
      "  multiple levels of: 5.0431\n",
      "  observed: 4.3499\n",
      "  observed data: 5.0431\n",
      "  of: 4.8576\n",
      "  of features: 4.3499\n",
      "  of features with: 5.0431\n",
      "  of or: 5.0431\n",
      "  of or generating: 5.0431\n",
      "  of representation: 5.0431\n",
      "  of representation or: 5.0431\n",
      "  of variation: 5.0431\n",
      "  of variation that: 5.0431\n",
      "  one: 3.0971\n",
      "  one that: 5.0431\n",
      "  one that learns: 5.0431\n",
      "  or: 4.0453\n",
      "  or a: 5.0431\n",
      "  or a hierarchy: 5.0431\n",
      "  or generating: 5.0431\n",
      "  or generating lowerlevel: 5.0431\n",
      "  representation: 15.7778\n",
      "  representation is: 10.0861\n",
      "  representation is lowdimensional: 5.0431\n",
      "  representation is sparse: 5.0431\n",
      "  representation or: 5.0431\n",
      "  representation or a: 5.0431\n",
      "  representation that: 5.0431\n",
      "  representation that disentangles: 5.0431\n",
      "  representations: 8.6998\n",
      "  representations directly: 5.0431\n",
      "  representations directly from: 5.0431\n",
      "  representations for: 5.0431\n",
      "  representations for multidimensional: 5.0431\n",
      "  reshaping: 5.0431\n",
      "  reshaping them: 5.0431\n",
      "  reshaping them into: 5.0431\n",
      "  so: 8.2535\n",
      "  so under: 10.0861\n",
      "  so under the: 10.0861\n",
      "  sparse: 9.2752\n",
      "  sparse coding: 5.0431\n",
      "  sparse coding algorithms: 5.0431\n",
      "  sparse meaning: 5.0431\n",
      "  sparse meaning that: 5.0431\n",
      "  subspace: 5.0431\n",
      "  subspace learning: 5.0431\n",
      "  subspace learning algorithms: 5.0431\n",
      "  tensor: 4.6376\n",
      "  tensor representations: 5.0431\n",
      "  tensor representations for: 5.0431\n",
      "  terms: 4.3499\n",
      "  terms of: 4.6376\n",
      "  terms of or: 5.0431\n",
      "  that: 11.7303\n",
      "  that an: 4.3499\n",
      "  that an intelligent: 5.0431\n",
      "  that disentangles: 5.0431\n",
      "  that disentangles the: 5.0431\n",
      "  that explain: 5.0431\n",
      "  that explain the: 5.0431\n",
      "  that learns: 5.0431\n",
      "  that learns a: 5.0431\n",
      "  that the: 11.8333\n",
      "  that the learned: 10.0861\n",
      "  that the mathematical: 5.0431\n",
      "  the: 8.3503\n",
      "  the constraint: 10.0861\n",
      "  the constraint that: 10.0861\n",
      "  the learned: 10.0861\n",
      "  the learned representation: 10.0861\n",
      "  the mathematical: 4.6376\n",
      "  the mathematical model: 4.6376\n",
      "  the observed: 4.6376\n",
      "  the observed data: 5.0431\n",
      "  the underlying: 5.0431\n",
      "  the underlying factors: 5.0431\n",
      "  them: 4.3499\n",
      "  them into: 5.0431\n",
      "  them into higherdimensional: 5.0431\n",
      "  to: 3.6760\n",
      "  to do: 9.2752\n",
      "  to do so: 10.0861\n",
      "  to learn: 4.3499\n",
      "  to learn lowdimensional: 5.0431\n",
      "  under: 6.8672\n",
      "  under the: 8.6998\n",
      "  under the constraint: 10.0861\n",
      "  underlying: 3.9444\n",
      "  underlying factors: 5.0431\n",
      "  underlying factors of: 5.0431\n",
      "  variation: 5.0431\n",
      "  variation that: 5.0431\n",
      "  variation that explain: 5.0431\n",
      "  vectors: 4.6376\n",
      "  vectors deep: 5.0431\n",
      "  vectors deep learning: 5.0431\n",
      "  with: 2.0726\n",
      "  with higherlevel: 5.0431\n",
      "  with higherlevel more: 5.0431\n",
      "  without: 3.3383\n",
      "  without reshaping: 5.0431\n",
      "  without reshaping them: 5.0431\n",
      "  zeros: 5.0431\n",
      "  zeros multilinear: 5.0431\n",
      "  zeros multilinear subspace: 5.0431\n",
      "\n",
      "Document 51:\n",
      "  algorithmically: 5.0431\n",
      "  algorithmically define: 5.0431\n",
      "  algorithmically define specific: 5.0431\n",
      "  algorithms: 2.3689\n",
      "  alternative: 4.6376\n",
      "  alternative is: 5.0431\n",
      "  alternative is to: 5.0431\n",
      "  an: 2.1527\n",
      "  an alternative: 4.6376\n",
      "  an alternative is: 5.0431\n",
      "  and: 2.4288\n",
      "  and computationally: 5.0431\n",
      "  and computationally convenient: 5.0431\n",
      "  and sensory: 5.0431\n",
      "  and sensory data: 5.0431\n",
      "  as: 3.6888\n",
      "  as classification: 5.0431\n",
      "  as classification often: 5.0431\n",
      "  as images: 5.0431\n",
      "  as images video: 5.0431\n",
      "  attempts: 4.6376\n",
      "  attempts to: 4.6376\n",
      "  attempts to algorithmically: 5.0431\n",
      "  by: 1.9076\n",
      "  by the: 3.2513\n",
      "  by the fact: 5.0431\n",
      "  classification: 2.9636\n",
      "  classification often: 5.0431\n",
      "  classification often require: 5.0431\n",
      "  computationally: 5.0431\n",
      "  computationally convenient: 5.0431\n",
      "  computationally convenient to: 5.0431\n",
      "  convenient: 5.0431\n",
      "  convenient to: 5.0431\n",
      "  convenient to process: 5.0431\n",
      "  data: 3.7300\n",
      "  data has: 5.0431\n",
      "  data has not: 5.0431\n",
      "  data such: 5.0431\n",
      "  data such as: 5.0431\n",
      "  define: 4.6376\n",
      "  define specific: 5.0431\n",
      "  define specific features: 5.0431\n",
      "  discover: 4.6376\n",
      "  discover such: 5.0431\n",
      "  discover such features: 5.0431\n",
      "  examination: 4.6376\n",
      "  examination without: 5.0431\n",
      "  examination without relying: 5.0431\n",
      "  explicit: 4.6376\n",
      "  explicit algorithms: 5.0431\n",
      "  fact: 4.6376\n",
      "  fact that: 5.0431\n",
      "  fact that machine: 5.0431\n",
      "  feature: 3.4336\n",
      "  feature learning: 4.1268\n",
      "  feature learning is: 5.0431\n",
      "  features: 7.3135\n",
      "  features an: 5.0431\n",
      "  features an alternative: 5.0431\n",
      "  features or: 5.0431\n",
      "  features or representations: 5.0431\n",
      "  has: 2.8458\n",
      "  has not: 4.3499\n",
      "  has not yielded: 5.0431\n",
      "  however: 3.7903\n",
      "  however realworld: 5.0431\n",
      "  however realworld data: 5.0431\n",
      "  images: 4.1268\n",
      "  images video: 5.0431\n",
      "  images video and: 5.0431\n",
      "  input: 3.0281\n",
      "  input that: 5.0431\n",
      "  input that is: 5.0431\n",
      "  is: 4.5501\n",
      "  is mathematically: 5.0431\n",
      "  is mathematically and: 5.0431\n",
      "  is motivated: 5.0431\n",
      "  is motivated by: 5.0431\n",
      "  is to: 3.9444\n",
      "  is to discover: 5.0431\n",
      "  learning: 2.5637\n",
      "  learning is: 3.0281\n",
      "  learning is motivated: 5.0431\n",
      "  learning tasks: 4.6376\n",
      "  learning tasks such: 4.6376\n",
      "  machine: 1.4735\n",
      "  machine learning: 1.5618\n",
      "  machine learning tasks: 5.0431\n",
      "  mathematically: 5.0431\n",
      "  mathematically and: 5.0431\n",
      "  mathematically and computationally: 5.0431\n",
      "  motivated: 5.0431\n",
      "  motivated by: 5.0431\n",
      "  motivated by the: 5.0431\n",
      "  not: 2.6007\n",
      "  not yielded: 5.0431\n",
      "  not yielded attempts: 5.0431\n",
      "  often: 3.0971\n",
      "  often require: 5.0431\n",
      "  often require input: 5.0431\n",
      "  on: 2.0473\n",
      "  on explicit: 5.0431\n",
      "  on explicit algorithms: 5.0431\n",
      "  or: 2.0226\n",
      "  or representations: 5.0431\n",
      "  or representations through: 5.0431\n",
      "  process: 3.4336\n",
      "  process however: 5.0431\n",
      "  process however realworld: 5.0431\n",
      "  realworld: 4.6376\n",
      "  realworld data: 5.0431\n",
      "  realworld data such: 5.0431\n",
      "  relying: 5.0431\n",
      "  relying on: 5.0431\n",
      "  relying on explicit: 5.0431\n",
      "  representations: 4.3499\n",
      "  representations through: 5.0431\n",
      "  representations through examination: 5.0431\n",
      "  require: 4.1268\n",
      "  require input: 5.0431\n",
      "  require input that: 5.0431\n",
      "  sensory: 5.0431\n",
      "  sensory data: 5.0431\n",
      "  sensory data has: 5.0431\n",
      "  specific: 3.7903\n",
      "  specific features: 5.0431\n",
      "  specific features an: 5.0431\n",
      "  such: 7.4343\n",
      "  such as: 5.6917\n",
      "  such as classification: 5.0431\n",
      "  such as images: 5.0431\n",
      "  such features: 5.0431\n",
      "  such features or: 5.0431\n",
      "  tasks: 3.4336\n",
      "  tasks such: 4.1268\n",
      "  tasks such as: 4.1268\n",
      "  that: 3.3515\n",
      "  that is: 4.3499\n",
      "  that is mathematically: 5.0431\n",
      "  that machine: 5.0431\n",
      "  that machine learning: 5.0431\n",
      "  the: 1.1929\n",
      "  the fact: 5.0431\n",
      "  the fact that: 5.0431\n",
      "  through: 4.1268\n",
      "  through examination: 5.0431\n",
      "  through examination without: 5.0431\n",
      "  to: 3.6760\n",
      "  to algorithmically: 5.0431\n",
      "  to algorithmically define: 5.0431\n",
      "  to discover: 5.0431\n",
      "  to discover such: 5.0431\n",
      "  to process: 5.0431\n",
      "  to process however: 5.0431\n",
      "  video: 4.6376\n",
      "  video and: 5.0431\n",
      "  video and sensory: 5.0431\n",
      "  without: 3.3383\n",
      "  without relying: 5.0431\n",
      "  without relying on: 5.0431\n",
      "  yielded: 5.0431\n",
      "  yielded attempts: 5.0431\n",
      "  yielded attempts to: 5.0431\n",
      "\n",
      "Document 52:\n",
      "  a: 11.3298\n",
      "  a clean: 5.0431\n",
      "  a clean image: 5.0431\n",
      "  a dictionary: 5.0431\n",
      "  a dictionary where: 5.0431\n",
      "  a feature: 4.6376\n",
      "  a feature learning: 5.0431\n",
      "  a linear: 5.0431\n",
      "  a linear combination: 5.0431\n",
      "  a new: 4.3499\n",
      "  a new training: 5.0431\n",
      "  a popular: 5.0431\n",
      "  a popular heuristic: 5.0431\n",
      "  a previously: 5.0431\n",
      "  a previously unseen: 5.0431\n",
      "  a sparse: 5.0431\n",
      "  a sparse matrix: 5.0431\n",
      "  a training: 4.3499\n",
      "  a training example: 5.0431\n",
      "  algorithm: 2.9030\n",
      "  algorithm sparse: 5.0431\n",
      "  algorithm sparse dictionary: 5.0431\n",
      "  already: 4.6376\n",
      "  already been: 5.0431\n",
      "  already been built: 5.0431\n",
      "  also: 2.6452\n",
      "  also been: 5.0431\n",
      "  also been applied: 5.0431\n",
      "  an: 2.1527\n",
      "  an image: 4.6376\n",
      "  an image dictionary: 5.0431\n",
      "  and: 2.4288\n",
      "  and assumed: 5.0431\n",
      "  and assumed to: 5.0431\n",
      "  and difficult: 5.0431\n",
      "  and difficult to: 5.0431\n",
      "  applied: 8.6998\n",
      "  applied in: 9.2752\n",
      "  applied in image: 5.0431\n",
      "  applied in several: 5.0431\n",
      "  approximately: 4.3499\n",
      "  approximately a: 5.0431\n",
      "  approximately a popular: 5.0431\n",
      "  as: 1.8444\n",
      "  as a: 2.9030\n",
      "  as a linear: 5.0431\n",
      "  associated: 3.7903\n",
      "  associated with: 4.3499\n",
      "  associated with the: 5.0431\n",
      "  assumed: 5.0431\n",
      "  assumed to: 5.0431\n",
      "  assumed to be: 5.0431\n",
      "  basis: 4.6376\n",
      "  basis functions: 5.0431\n",
      "  basis functions and: 5.0431\n",
      "  be: 4.1453\n",
      "  be a: 5.0431\n",
      "  be a sparse: 5.0431\n",
      "  be sparsely: 5.0431\n",
      "  be sparsely represented: 5.0431\n",
      "  been: 8.0750\n",
      "  been applied: 9.2752\n",
      "  been applied in: 9.2752\n",
      "  been built: 5.0431\n",
      "  been built a: 5.0431\n",
      "  belongs: 5.0431\n",
      "  belongs for: 5.0431\n",
      "  belongs for a: 5.0431\n",
      "  best: 3.6568\n",
      "  best sparsely: 5.0431\n",
      "  best sparsely represented: 5.0431\n",
      "  built: 4.1268\n",
      "  built a: 5.0431\n",
      "  built a new: 5.0431\n",
      "  but: 3.0281\n",
      "  but the: 4.1268\n",
      "  but the noise: 5.0431\n",
      "  by: 3.8151\n",
      "  by an: 4.6376\n",
      "  by an image: 5.0431\n",
      "  by the: 3.2513\n",
      "  by the corresponding: 5.0431\n",
      "  can: 2.1809\n",
      "  can be: 2.7405\n",
      "  can be sparsely: 5.0431\n",
      "  cannot: 3.7903\n",
      "  class: 10.6169\n",
      "  class has: 5.0431\n",
      "  class has already: 5.0431\n",
      "  class that: 5.0431\n",
      "  class that is: 5.0431\n",
      "  class to: 5.0431\n",
      "  class to which: 5.0431\n",
      "  classification: 2.9636\n",
      "  classification the: 5.0431\n",
      "  classification the problem: 5.0431\n",
      "  clean: 5.0431\n",
      "  clean image: 5.0431\n",
      "  clean image patch: 5.0431\n",
      "  combination: 4.6376\n",
      "  combination of: 5.0431\n",
      "  combination of basis: 5.0431\n",
      "  contexts: 5.0431\n",
      "  contexts in: 5.0431\n",
      "  contexts in classification: 5.0431\n",
      "  corresponding: 4.6376\n",
      "  corresponding dictionary: 5.0431\n",
      "  corresponding dictionary sparse: 5.0431\n",
      "  denoising: 5.0431\n",
      "  denoising the: 5.0431\n",
      "  denoising the key: 5.0431\n",
      "  determine: 4.6376\n",
      "  determine the: 4.6376\n",
      "  determine the class: 5.0431\n",
      "  dictionary: 32.4631\n",
      "  dictionary but: 5.0431\n",
      "  dictionary but the: 5.0431\n",
      "  dictionary learning: 18.5503\n",
      "  dictionary learning has: 10.0861\n",
      "  dictionary learning is: 10.0861\n",
      "  dictionary sparse: 5.0431\n",
      "  dictionary sparse dictionary: 5.0431\n",
      "  dictionary where: 5.0431\n",
      "  dictionary where each: 5.0431\n",
      "  difficult: 5.0431\n",
      "  difficult to: 5.0431\n",
      "  difficult to solve: 5.0431\n",
      "  each: 3.0971\n",
      "  each class: 5.0431\n",
      "  each class has: 5.0431\n",
      "  example: 8.8908\n",
      "  example belongs: 5.0431\n",
      "  example belongs for: 5.0431\n",
      "  example is: 8.6998\n",
      "  example is associated: 5.0431\n",
      "  example is represented: 4.6376\n",
      "  feature: 3.4336\n",
      "  feature learning: 4.1268\n",
      "  feature learning method: 5.0431\n",
      "  for: 3.4577\n",
      "  for a: 4.6376\n",
      "  for a dictionary: 5.0431\n",
      "  for sparse: 5.0431\n",
      "  for sparse dictionary: 5.0431\n",
      "  functions: 4.1268\n",
      "  functions and: 5.0431\n",
      "  functions and assumed: 5.0431\n",
      "  has: 8.5375\n",
      "  has already: 5.0431\n",
      "  has already been: 5.0431\n",
      "  has also: 5.0431\n",
      "  has also been: 5.0431\n",
      "  has been: 3.6568\n",
      "  has been applied: 5.0431\n",
      "  heuristic: 4.6376\n",
      "  heuristic method: 5.0431\n",
      "  heuristic method for: 5.0431\n",
      "  idea: 5.0431\n",
      "  idea is: 5.0431\n",
      "  idea is that: 5.0431\n",
      "  image: 11.8333\n",
      "  image denoising: 5.0431\n",
      "  image denoising the: 5.0431\n",
      "  image dictionary: 5.0431\n",
      "  image dictionary but: 5.0431\n",
      "  image patch: 5.0431\n",
      "  image patch can: 5.0431\n",
      "  in: 4.0252\n",
      "  in classification: 4.6376\n",
      "  in classification the: 5.0431\n",
      "  in image: 4.6376\n",
      "  in image denoising: 5.0431\n",
      "  in several: 5.0431\n",
      "  in several contexts: 5.0431\n",
      "  is: 12.1335\n",
      "  is a: 2.5173\n",
      "  is a feature: 5.0431\n",
      "  is associated: 4.6376\n",
      "  is associated with: 4.6376\n",
      "  is best: 5.0431\n",
      "  is best sparsely: 5.0431\n",
      "  is represented: 4.6376\n",
      "  is represented as: 5.0431\n",
      "  is strongly: 5.0431\n",
      "  is strongly nphard: 5.0431\n",
      "  is that: 4.6376\n",
      "  is that a: 5.0431\n",
      "  is the: 3.3383\n",
      "  is the ksvd: 5.0431\n",
      "  is to: 3.9444\n",
      "  is to determine: 5.0431\n",
      "  key: 3.9444\n",
      "  key idea: 5.0431\n",
      "  key idea is: 5.0431\n",
      "  ksvd: 5.0431\n",
      "  ksvd algorithm: 5.0431\n",
      "  ksvd algorithm sparse: 5.0431\n",
      "  learning: 6.4093\n",
      "  learning has: 8.2535\n",
      "  learning has also: 5.0431\n",
      "  learning has been: 4.3499\n",
      "  learning is: 6.0563\n",
      "  learning is a: 4.1268\n",
      "  learning is the: 5.0431\n",
      "  learning method: 4.1268\n",
      "  learning method where: 5.0431\n",
      "  linear: 3.7903\n",
      "  linear combination: 5.0431\n",
      "  linear combination of: 5.0431\n",
      "  matrix: 3.9444\n",
      "  matrix the: 5.0431\n",
      "  matrix the method: 5.0431\n",
      "  method: 10.9703\n",
      "  method for: 4.6376\n",
      "  method for sparse: 5.0431\n",
      "  method is: 5.0431\n",
      "  method is strongly: 5.0431\n",
      "  method where: 5.0431\n",
      "  method where a: 5.0431\n",
      "  new: 3.2513\n",
      "  new training: 5.0431\n",
      "  new training example: 5.0431\n",
      "  noise: 4.6376\n",
      "  noise cannot: 5.0431\n",
      "  nphard: 5.0431\n",
      "  nphard and: 5.0431\n",
      "  nphard and difficult: 5.0431\n",
      "  of: 1.2144\n",
      "  of basis: 5.0431\n",
      "  of basis functions: 5.0431\n",
      "  patch: 5.0431\n",
      "  patch can: 5.0431\n",
      "  patch can be: 5.0431\n",
      "  popular: 4.3499\n",
      "  popular heuristic: 5.0431\n",
      "  popular heuristic method: 5.0431\n",
      "  previously: 4.3499\n",
      "  previously unseen: 5.0431\n",
      "  previously unseen training: 5.0431\n",
      "  problem: 3.9444\n",
      "  problem is: 5.0431\n",
      "  problem is to: 5.0431\n",
      "  represented: 10.9703\n",
      "  represented as: 4.3499\n",
      "  represented as a: 4.3499\n",
      "  represented by: 8.6998\n",
      "  represented by an: 4.6376\n",
      "  represented by the: 4.6376\n",
      "  several: 3.9444\n",
      "  several contexts: 5.0431\n",
      "  several contexts in: 5.0431\n",
      "  solve: 4.3499\n",
      "  solve approximately: 5.0431\n",
      "  solve approximately a: 5.0431\n",
      "  sparse: 23.1879\n",
      "  sparse dictionary: 20.1722\n",
      "  sparse dictionary learning: 20.1722\n",
      "  sparse matrix: 5.0431\n",
      "  sparse matrix the: 5.0431\n",
      "  sparsely: 10.0861\n",
      "  sparsely represented: 10.0861\n",
      "  sparsely represented by: 10.0861\n",
      "  strongly: 5.0431\n",
      "  strongly nphard: 5.0431\n",
      "  strongly nphard and: 5.0431\n",
      "  that: 3.3515\n",
      "  that a: 4.1268\n",
      "  that a clean: 5.0431\n",
      "  that is: 4.3499\n",
      "  that is best: 5.0431\n",
      "  the: 9.5432\n",
      "  the class: 10.0861\n",
      "  the class that: 5.0431\n",
      "  the class to: 5.0431\n",
      "  the corresponding: 5.0431\n",
      "  the corresponding dictionary: 5.0431\n",
      "  the key: 4.3499\n",
      "  the key idea: 5.0431\n",
      "  the ksvd: 5.0431\n",
      "  the ksvd algorithm: 5.0431\n",
      "  the method: 5.0431\n",
      "  the method is: 5.0431\n",
      "  the noise: 5.0431\n",
      "  the noise cannot: 5.0431\n",
      "  the problem: 4.3499\n",
      "  the problem is: 5.0431\n",
      "  to: 4.9014\n",
      "  to be: 3.4336\n",
      "  to be a: 5.0431\n",
      "  to determine: 5.0431\n",
      "  to determine the: 5.0431\n",
      "  to solve: 4.6376\n",
      "  to solve approximately: 5.0431\n",
      "  to which: 5.0431\n",
      "  to which a: 5.0431\n",
      "  training: 7.6744\n",
      "  training example: 13.9128\n",
      "  training example belongs: 5.0431\n",
      "  training example is: 9.2752\n",
      "  unseen: 4.3499\n",
      "  unseen training: 5.0431\n",
      "  unseen training example: 5.0431\n",
      "  where: 6.5026\n",
      "  where a: 4.6376\n",
      "  where a training: 5.0431\n",
      "  where each: 5.0431\n",
      "  where each class: 5.0431\n",
      "  which: 2.6917\n",
      "  which a: 4.6376\n",
      "  which a previously: 5.0431\n",
      "  with: 2.0726\n",
      "  with the: 3.5390\n",
      "  with the class: 5.0431\n",
      "\n",
      "Document 53:\n",
      "  a: 2.5177\n",
      "  a structural: 5.0431\n",
      "  a structural defect: 5.0431\n",
      "  a text: 5.0431\n",
      "  a text anomalies: 5.0431\n",
      "  also: 2.6452\n",
      "  also known: 4.3499\n",
      "  also known as: 4.3499\n",
      "  an: 2.1527\n",
      "  an issue: 5.0431\n",
      "  an issue such: 5.0431\n",
      "  and: 1.2144\n",
      "  and exceptions: 5.0431\n",
      "  anomalies: 4.6376\n",
      "  anomalies are: 5.0431\n",
      "  anomalies are referred: 5.0431\n",
      "  anomalous: 5.0431\n",
      "  anomalous items: 5.0431\n",
      "  anomalous items represent: 5.0431\n",
      "  anomaly: 4.6376\n",
      "  anomaly detection: 4.6376\n",
      "  anomaly detection also: 5.0431\n",
      "  are: 1.9750\n",
      "  are referred: 5.0431\n",
      "  are referred to: 5.0431\n",
      "  as: 5.5331\n",
      "  as bank: 5.0431\n",
      "  as bank fraud: 5.0431\n",
      "  as outlier: 5.0431\n",
      "  as outlier detection: 5.0431\n",
      "  as outliers: 5.0431\n",
      "  as outliers novelties: 5.0431\n",
      "  bank: 5.0431\n",
      "  bank fraud: 5.0431\n",
      "  bank fraud a: 5.0431\n",
      "  by: 1.9076\n",
      "  by differing: 5.0431\n",
      "  by differing significantly: 5.0431\n",
      "  data: 3.7300\n",
      "  data mining: 4.1268\n",
      "  data mining anomaly: 5.0431\n",
      "  data typically: 5.0431\n",
      "  data typically the: 5.0431\n",
      "  defect: 5.0431\n",
      "  defect medical: 5.0431\n",
      "  defect medical problems: 5.0431\n",
      "  detection: 7.8889\n",
      "  detection also: 5.0431\n",
      "  detection also known: 5.0431\n",
      "  detection is: 5.0431\n",
      "  detection is the: 5.0431\n",
      "  deviations: 4.6376\n",
      "  deviations and: 5.0431\n",
      "  deviations and exceptions: 5.0431\n",
      "  differing: 5.0431\n",
      "  differing significantly: 5.0431\n",
      "  differing significantly from: 5.0431\n",
      "  errors: 4.6376\n",
      "  errors in: 4.6376\n",
      "  errors in a: 5.0431\n",
      "  events: 5.0431\n",
      "  events or: 5.0431\n",
      "  events or observations: 5.0431\n",
      "  exceptions: 5.0431\n",
      "  fraud: 4.6376\n",
      "  fraud a: 5.0431\n",
      "  fraud a structural: 5.0431\n",
      "  from: 2.0726\n",
      "  from the: 3.3383\n",
      "  from the majority: 5.0431\n",
      "  identification: 4.6376\n",
      "  identification of: 5.0431\n",
      "  identification of rare: 5.0431\n",
      "  in: 2.6835\n",
      "  in a: 3.0971\n",
      "  in a text: 5.0431\n",
      "  in data: 4.1268\n",
      "  in data mining: 4.6376\n",
      "  is: 1.5167\n",
      "  is the: 3.3383\n",
      "  is the identification: 4.6376\n",
      "  issue: 5.0431\n",
      "  issue such: 5.0431\n",
      "  issue such as: 5.0431\n",
      "  items: 8.6998\n",
      "  items events: 5.0431\n",
      "  items events or: 5.0431\n",
      "  items represent: 5.0431\n",
      "  items represent an: 5.0431\n",
      "  known: 3.5390\n",
      "  known as: 3.7903\n",
      "  known as outlier: 5.0431\n",
      "  majority: 4.6376\n",
      "  majority of: 4.6376\n",
      "  majority of the: 4.6376\n",
      "  medical: 3.7903\n",
      "  medical problems: 5.0431\n",
      "  medical problems or: 5.0431\n",
      "  mining: 3.9444\n",
      "  mining anomaly: 5.0431\n",
      "  mining anomaly detection: 5.0431\n",
      "  noise: 4.6376\n",
      "  noise deviations: 5.0431\n",
      "  noise deviations and: 5.0431\n",
      "  novelties: 5.0431\n",
      "  novelties noise: 5.0431\n",
      "  novelties noise deviations: 5.0431\n",
      "  observations: 4.3499\n",
      "  observations which: 5.0431\n",
      "  observations which raise: 5.0431\n",
      "  of: 2.4288\n",
      "  of rare: 5.0431\n",
      "  of rare items: 5.0431\n",
      "  of the: 2.3022\n",
      "  of the data: 4.1268\n",
      "  or: 4.0453\n",
      "  or errors: 5.0431\n",
      "  or errors in: 5.0431\n",
      "  or observations: 5.0431\n",
      "  or observations which: 5.0431\n",
      "  outlier: 4.3499\n",
      "  outlier detection: 4.3499\n",
      "  outlier detection is: 5.0431\n",
      "  outliers: 5.0431\n",
      "  outliers novelties: 5.0431\n",
      "  outliers novelties noise: 5.0431\n",
      "  problems: 3.1712\n",
      "  problems or: 5.0431\n",
      "  problems or errors: 5.0431\n",
      "  raise: 5.0431\n",
      "  raise suspicions: 5.0431\n",
      "  raise suspicions by: 5.0431\n",
      "  rare: 4.6376\n",
      "  rare items: 5.0431\n",
      "  rare items events: 5.0431\n",
      "  referred: 4.6376\n",
      "  referred to: 4.6376\n",
      "  referred to as: 4.6376\n",
      "  represent: 4.1268\n",
      "  represent an: 5.0431\n",
      "  represent an issue: 5.0431\n",
      "  significantly: 4.3499\n",
      "  significantly from: 5.0431\n",
      "  significantly from the: 5.0431\n",
      "  structural: 5.0431\n",
      "  structural defect: 5.0431\n",
      "  structural defect medical: 5.0431\n",
      "  such: 2.4781\n",
      "  such as: 2.8458\n",
      "  such as bank: 5.0431\n",
      "  suspicions: 5.0431\n",
      "  suspicions by: 5.0431\n",
      "  suspicions by differing: 5.0431\n",
      "  text: 4.6376\n",
      "  text anomalies: 5.0431\n",
      "  text anomalies are: 5.0431\n",
      "  the: 4.7716\n",
      "  the anomalous: 5.0431\n",
      "  the anomalous items: 5.0431\n",
      "  the data: 3.0971\n",
      "  the data typically: 5.0431\n",
      "  the identification: 4.6376\n",
      "  the identification of: 5.0431\n",
      "  the majority: 4.6376\n",
      "  the majority of: 4.6376\n",
      "  to: 1.2253\n",
      "  to as: 4.6376\n",
      "  to as outliers: 5.0431\n",
      "  typically: 3.5390\n",
      "  typically the: 5.0431\n",
      "  typically the anomalous: 5.0431\n",
      "  which: 2.6917\n",
      "  which raise: 5.0431\n",
      "  which raise suspicions: 5.0431\n",
      "\n",
      "Document 54:\n",
      "  a: 2.5177\n",
      "  a cluster: 5.0431\n",
      "  a cluster analysis: 5.0431\n",
      "  a rare: 5.0431\n",
      "  a rare object: 5.0431\n",
      "  able: 4.6376\n",
      "  able to: 4.6376\n",
      "  able to detect: 5.0431\n",
      "  abuse: 5.0431\n",
      "  abuse and: 5.0431\n",
      "  abuse and network: 5.0431\n",
      "  adhere: 5.0431\n",
      "  adhere to: 5.0431\n",
      "  adhere to the: 5.0431\n",
      "  aggregated: 4.6376\n",
      "  aggregated appropriately: 5.0431\n",
      "  aggregated appropriately instead: 5.0431\n",
      "  algorithm: 2.9030\n",
      "  algorithm may: 5.0431\n",
      "  algorithm may be: 5.0431\n",
      "  algorithms: 2.3689\n",
      "  algorithms will: 5.0431\n",
      "  algorithms will fail: 5.0431\n",
      "  an: 2.1527\n",
      "  an outlier: 5.0431\n",
      "  an outlier as: 5.0431\n",
      "  analysis: 3.1712\n",
      "  analysis algorithm: 5.0431\n",
      "  analysis algorithm may: 5.0431\n",
      "  and: 1.2144\n",
      "  and network: 5.0431\n",
      "  and network intrusion: 5.0431\n",
      "  appropriately: 5.0431\n",
      "  appropriately instead: 5.0431\n",
      "  appropriately instead a: 5.0431\n",
      "  are: 1.9750\n",
      "  are often: 4.1268\n",
      "  are often not: 5.0431\n",
      "  as: 1.8444\n",
      "  as a: 2.9030\n",
      "  as a rare: 5.0431\n",
      "  be: 2.0726\n",
      "  be able: 4.6376\n",
      "  be able to: 4.6376\n",
      "  bursts: 5.0431\n",
      "  bursts of: 5.0431\n",
      "  bursts of inactivity: 5.0431\n",
      "  but: 3.0281\n",
      "  but unexpected: 5.0431\n",
      "  but unexpected bursts: 5.0431\n",
      "  by: 1.9076\n",
      "  by these: 5.0431\n",
      "  by these patterns: 5.0431\n",
      "  cluster: 4.3499\n",
      "  cluster analysis: 4.3499\n",
      "  cluster analysis algorithm: 5.0431\n",
      "  common: 3.9444\n",
      "  common statistical: 5.0431\n",
      "  common statistical definition: 5.0431\n",
      "  context: 4.3499\n",
      "  context of: 4.6376\n",
      "  context of abuse: 5.0431\n",
      "  data: 1.8650\n",
      "  data unless: 5.0431\n",
      "  data unless aggregated: 5.0431\n",
      "  definition: 4.6376\n",
      "  definition of: 4.6376\n",
      "  definition of an: 5.0431\n",
      "  detect: 4.3499\n",
      "  detect the: 5.0431\n",
      "  detect the microclusters: 5.0431\n",
      "  detection: 7.8889\n",
      "  detection methods: 5.0431\n",
      "  detection methods in: 5.0431\n",
      "  detection the: 5.0431\n",
      "  detection the interesting: 5.0431\n",
      "  does: 4.3499\n",
      "  does not: 4.3499\n",
      "  does not adhere: 5.0431\n",
      "  fail: 4.3499\n",
      "  fail on: 5.0431\n",
      "  fail on such: 5.0431\n",
      "  formed: 4.6376\n",
      "  formed by: 4.6376\n",
      "  formed by these: 5.0431\n",
      "  in: 4.0252\n",
      "  in particular: 10.0861\n",
      "  in particular in: 5.0431\n",
      "  in particular unsupervised: 5.0431\n",
      "  in the: 2.4404\n",
      "  in the context: 4.6376\n",
      "  inactivity: 5.0431\n",
      "  inactivity this: 5.0431\n",
      "  inactivity this pattern: 5.0431\n",
      "  instead: 4.1268\n",
      "  instead a: 5.0431\n",
      "  instead a cluster: 5.0431\n",
      "  interesting: 5.0431\n",
      "  interesting objects: 5.0431\n",
      "  interesting objects are: 5.0431\n",
      "  intrusion: 4.6376\n",
      "  intrusion detection: 4.6376\n",
      "  intrusion detection the: 5.0431\n",
      "  many: 2.9030\n",
      "  many outlier: 5.0431\n",
      "  many outlier detection: 5.0431\n",
      "  may: 3.2513\n",
      "  may be: 4.1268\n",
      "  may be able: 5.0431\n",
      "  methods: 2.7405\n",
      "  methods in: 4.6376\n",
      "  methods in particular: 5.0431\n",
      "  microclusters: 5.0431\n",
      "  microclusters formed: 5.0431\n",
      "  microclusters formed by: 5.0431\n",
      "  network: 3.5390\n",
      "  network intrusion: 5.0431\n",
      "  network intrusion detection: 5.0431\n",
      "  not: 5.2014\n",
      "  not adhere: 5.0431\n",
      "  not adhere to: 5.0431\n",
      "  not rare: 5.0431\n",
      "  not rare objects: 5.0431\n",
      "  object: 5.0431\n",
      "  object many: 5.0431\n",
      "  object many outlier: 5.0431\n",
      "  objects: 8.6998\n",
      "  objects are: 4.6376\n",
      "  objects are often: 5.0431\n",
      "  objects but: 5.0431\n",
      "  objects but unexpected: 5.0431\n",
      "  of: 3.6432\n",
      "  of abuse: 5.0431\n",
      "  of abuse and: 5.0431\n",
      "  of an: 4.3499\n",
      "  of an outlier: 5.0431\n",
      "  of inactivity: 5.0431\n",
      "  of inactivity this: 5.0431\n",
      "  often: 3.0971\n",
      "  often not: 5.0431\n",
      "  often not rare: 5.0431\n",
      "  on: 2.0473\n",
      "  on such: 5.0431\n",
      "  on such data: 5.0431\n",
      "  outlier: 8.6998\n",
      "  outlier as: 5.0431\n",
      "  outlier as a: 5.0431\n",
      "  outlier detection: 4.3499\n",
      "  outlier detection methods: 5.0431\n",
      "  particular: 8.6998\n",
      "  particular in: 5.0431\n",
      "  particular in the: 5.0431\n",
      "  particular unsupervised: 5.0431\n",
      "  particular unsupervised algorithms: 5.0431\n",
      "  pattern: 4.1268\n",
      "  pattern does: 5.0431\n",
      "  pattern does not: 5.0431\n",
      "  patterns: 3.4336\n",
      "  rare: 9.2752\n",
      "  rare object: 5.0431\n",
      "  rare object many: 5.0431\n",
      "  rare objects: 5.0431\n",
      "  rare objects but: 5.0431\n",
      "  statistical: 3.4336\n",
      "  statistical definition: 5.0431\n",
      "  statistical definition of: 5.0431\n",
      "  such: 2.4781\n",
      "  such data: 5.0431\n",
      "  such data unless: 5.0431\n",
      "  the: 4.7716\n",
      "  the common: 5.0431\n",
      "  the common statistical: 5.0431\n",
      "  the context: 4.6376\n",
      "  the context of: 4.6376\n",
      "  the interesting: 5.0431\n",
      "  the interesting objects: 5.0431\n",
      "  the microclusters: 5.0431\n",
      "  the microclusters formed: 5.0431\n",
      "  these: 2.9030\n",
      "  these patterns: 4.6376\n",
      "  this: 2.6007\n",
      "  this pattern: 5.0431\n",
      "  this pattern does: 5.0431\n",
      "  to: 2.4507\n",
      "  to detect: 4.6376\n",
      "  to detect the: 5.0431\n",
      "  to the: 3.1712\n",
      "  to the common: 5.0431\n",
      "  unexpected: 5.0431\n",
      "  unexpected bursts: 5.0431\n",
      "  unexpected bursts of: 5.0431\n",
      "  unless: 4.6376\n",
      "  unless aggregated: 5.0431\n",
      "  unless aggregated appropriately: 5.0431\n",
      "  unsupervised: 3.2513\n",
      "  unsupervised algorithms: 5.0431\n",
      "  unsupervised algorithms will: 5.0431\n",
      "  will: 3.7903\n",
      "  will fail: 5.0431\n",
      "  will fail on: 5.0431\n",
      "\n",
      "Document 55:\n",
      "  a: 6.2943\n",
      "  a classifier: 5.0431\n",
      "  a classifier the: 5.0431\n",
      "  a data: 5.0431\n",
      "  a data set: 5.0431\n",
      "  a given: 4.3499\n",
      "  a given normal: 5.0431\n",
      "  a model: 3.9444\n",
      "  a model representing: 5.0431\n",
      "  a test: 5.0431\n",
      "  a test instance: 5.0431\n",
      "  abnormal: 5.0431\n",
      "  abnormal and: 5.0431\n",
      "  abnormal and involves: 5.0431\n",
      "  an: 2.1527\n",
      "  an unlabelled: 5.0431\n",
      "  an unlabelled test: 5.0431\n",
      "  and: 3.6432\n",
      "  and abnormal: 5.0431\n",
      "  and abnormal and: 5.0431\n",
      "  and involves: 5.0431\n",
      "  and involves training: 5.0431\n",
      "  and then: 4.3499\n",
      "  and then test: 5.0431\n",
      "  anomalies: 4.6376\n",
      "  anomalies in: 5.0431\n",
      "  anomalies in an: 5.0431\n",
      "  anomaly: 18.5503\n",
      "  anomaly detection: 18.5503\n",
      "  anomaly detection techniques: 20.1722\n",
      "  are: 1.9750\n",
      "  are normal: 5.0431\n",
      "  are normal by: 5.0431\n",
      "  as: 1.8444\n",
      "  as normal: 5.0431\n",
      "  as normal and: 5.0431\n",
      "  assumption: 4.6376\n",
      "  assumption that: 5.0431\n",
      "  assumption that the: 5.0431\n",
      "  be: 2.0726\n",
      "  be generated: 5.0431\n",
      "  be generated by: 5.0431\n",
      "  been: 2.6917\n",
      "  been labelled: 4.6376\n",
      "  been labelled as: 5.0431\n",
      "  behaviour: 4.3499\n",
      "  behaviour from: 5.0431\n",
      "  behaviour from a: 5.0431\n",
      "  broad: 4.3499\n",
      "  broad categories: 4.6376\n",
      "  broad categories of: 5.0431\n",
      "  by: 3.8151\n",
      "  by looking: 4.6376\n",
      "  by looking for: 5.0431\n",
      "  by the: 3.2513\n",
      "  by the model: 5.0431\n",
      "  categories: 4.1268\n",
      "  categories of: 5.0431\n",
      "  categories of anomaly: 5.0431\n",
      "  classification: 2.9636\n",
      "  classification problems: 5.0431\n",
      "  classification problems is: 5.0431\n",
      "  classifier: 3.7903\n",
      "  classifier the: 5.0431\n",
      "  classifier the key: 5.0431\n",
      "  construct: 5.0431\n",
      "  construct a: 5.0431\n",
      "  construct a model: 5.0431\n",
      "  data: 9.3250\n",
      "  data set: 21.7495\n",
      "  data set and: 5.0431\n",
      "  data set are: 5.0431\n",
      "  data set supervised: 5.0431\n",
      "  data set that: 5.0431\n",
      "  data set under: 5.0431\n",
      "  detect: 4.3499\n",
      "  detect anomalies: 5.0431\n",
      "  detect anomalies in: 5.0431\n",
      "  detection: 19.7222\n",
      "  detection semisupervised: 5.0431\n",
      "  detection semisupervised anomaly: 5.0431\n",
      "  detection techniques: 20.1722\n",
      "  detection techniques construct: 5.0431\n",
      "  detection techniques detect: 5.0431\n",
      "  detection techniques exist: 5.0431\n",
      "  detection techniques require: 5.0431\n",
      "  difference: 4.6376\n",
      "  difference from: 5.0431\n",
      "  difference from many: 5.0431\n",
      "  exist: 4.3499\n",
      "  exist unsupervised: 5.0431\n",
      "  exist unsupervised anomaly: 5.0431\n",
      "  fit: 4.1268\n",
      "  fit the: 4.6376\n",
      "  fit the least: 5.0431\n",
      "  for: 1.7289\n",
      "  for instances: 5.0431\n",
      "  for instances that: 5.0431\n",
      "  from: 4.1453\n",
      "  from a: 3.7903\n",
      "  from a given: 5.0431\n",
      "  from many: 5.0431\n",
      "  from many other: 5.0431\n",
      "  generated: 5.0431\n",
      "  generated by: 5.0431\n",
      "  generated by the: 5.0431\n",
      "  given: 3.3383\n",
      "  given normal: 5.0431\n",
      "  given normal training: 5.0431\n",
      "  has: 2.8458\n",
      "  has been: 3.6568\n",
      "  has been labelled: 5.0431\n",
      "  in: 2.6835\n",
      "  in an: 3.9444\n",
      "  in an unlabelled: 5.0431\n",
      "  in the: 2.4404\n",
      "  in the data: 4.3499\n",
      "  inherently: 4.6376\n",
      "  inherently unbalanced: 5.0431\n",
      "  inherently unbalanced nature: 5.0431\n",
      "  instance: 4.3499\n",
      "  instance to: 5.0431\n",
      "  instance to be: 5.0431\n",
      "  instances: 8.6998\n",
      "  instances in: 5.0431\n",
      "  instances in the: 5.0431\n",
      "  instances that: 5.0431\n",
      "  instances that seem: 5.0431\n",
      "  involves: 4.3499\n",
      "  involves training: 4.6376\n",
      "  involves training a: 4.6376\n",
      "  is: 1.5167\n",
      "  is the: 3.3383\n",
      "  is the inherently: 5.0431\n",
      "  key: 3.9444\n",
      "  key difference: 5.0431\n",
      "  key difference from: 5.0431\n",
      "  labelled: 4.1268\n",
      "  labelled as: 5.0431\n",
      "  labelled as normal: 5.0431\n",
      "  least: 4.3499\n",
      "  least to: 5.0431\n",
      "  least to the: 5.0431\n",
      "  likelihood: 5.0431\n",
      "  likelihood of: 5.0431\n",
      "  likelihood of a: 5.0431\n",
      "  looking: 4.6376\n",
      "  looking for: 5.0431\n",
      "  looking for instances: 5.0431\n",
      "  majority: 4.6376\n",
      "  majority of: 4.6376\n",
      "  majority of the: 4.6376\n",
      "  many: 2.9030\n",
      "  many other: 4.3499\n",
      "  many other statistical: 5.0431\n",
      "  model: 4.6700\n",
      "  model representing: 5.0431\n",
      "  model representing normal: 5.0431\n",
      "  nature: 4.1268\n",
      "  nature of: 4.6376\n",
      "  nature of outlier: 5.0431\n",
      "  normal: 18.5503\n",
      "  normal and: 5.0431\n",
      "  normal and abnormal: 5.0431\n",
      "  normal behaviour: 5.0431\n",
      "  normal behaviour from: 5.0431\n",
      "  normal by: 5.0431\n",
      "  normal by looking: 5.0431\n",
      "  normal training: 5.0431\n",
      "  normal training data: 5.0431\n",
      "  of: 6.0720\n",
      "  of a: 3.0281\n",
      "  of a test: 5.0431\n",
      "  of anomaly: 5.0431\n",
      "  of anomaly detection: 5.0431\n",
      "  of outlier: 5.0431\n",
      "  of outlier detection: 5.0431\n",
      "  of the: 4.6044\n",
      "  of the data: 4.1268\n",
      "  of the instances: 5.0431\n",
      "  other: 2.7918\n",
      "  other statistical: 5.0431\n",
      "  other statistical classification: 5.0431\n",
      "  outlier: 4.3499\n",
      "  outlier detection: 4.3499\n",
      "  outlier detection semisupervised: 5.0431\n",
      "  problems: 3.1712\n",
      "  problems is: 4.6376\n",
      "  problems is the: 5.0431\n",
      "  remainder: 5.0431\n",
      "  remainder of: 5.0431\n",
      "  remainder of the: 5.0431\n",
      "  representing: 4.6376\n",
      "  representing normal: 5.0431\n",
      "  representing normal behaviour: 5.0431\n",
      "  require: 4.1268\n",
      "  require a: 4.6376\n",
      "  require a data: 5.0431\n",
      "  seem: 5.0431\n",
      "  seem to: 5.0431\n",
      "  seem to fit: 5.0431\n",
      "  semisupervised: 4.6376\n",
      "  semisupervised anomaly: 5.0431\n",
      "  semisupervised anomaly detection: 5.0431\n",
      "  set: 13.0035\n",
      "  set and: 4.6376\n",
      "  set and then: 5.0431\n",
      "  set are: 5.0431\n",
      "  set are normal: 5.0431\n",
      "  set supervised: 5.0431\n",
      "  set supervised anomaly: 5.0431\n",
      "  set that: 5.0431\n",
      "  set that has: 5.0431\n",
      "  set under: 5.0431\n",
      "  set under the: 5.0431\n",
      "  statistical: 3.4336\n",
      "  statistical classification: 4.6376\n",
      "  statistical classification problems: 5.0431\n",
      "  supervised: 3.2513\n",
      "  supervised anomaly: 5.0431\n",
      "  supervised anomaly detection: 5.0431\n",
      "  techniques: 13.3532\n",
      "  techniques construct: 5.0431\n",
      "  techniques construct a: 5.0431\n",
      "  techniques detect: 5.0431\n",
      "  techniques detect anomalies: 5.0431\n",
      "  techniques exist: 5.0431\n",
      "  techniques exist unsupervised: 5.0431\n",
      "  techniques require: 5.0431\n",
      "  techniques require a: 5.0431\n",
      "  test: 13.9128\n",
      "  test data: 5.0431\n",
      "  test data set: 5.0431\n",
      "  test instance: 5.0431\n",
      "  test instance to: 5.0431\n",
      "  test the: 5.0431\n",
      "  test the likelihood: 5.0431\n",
      "  that: 5.0273\n",
      "  that has: 4.6376\n",
      "  that has been: 5.0431\n",
      "  that seem: 5.0431\n",
      "  that seem to: 5.0431\n",
      "  that the: 3.9444\n",
      "  that the majority: 5.0431\n",
      "  the: 13.1219\n",
      "  the assumption: 5.0431\n",
      "  the assumption that: 5.0431\n",
      "  the data: 6.1943\n",
      "  the data set: 10.0861\n",
      "  the inherently: 5.0431\n",
      "  the inherently unbalanced: 5.0431\n",
      "  the instances: 5.0431\n",
      "  the instances in: 5.0431\n",
      "  the key: 4.3499\n",
      "  the key difference: 5.0431\n",
      "  the least: 5.0431\n",
      "  the least to: 5.0431\n",
      "  the likelihood: 5.0431\n",
      "  the likelihood of: 5.0431\n",
      "  the majority: 4.6376\n",
      "  the majority of: 4.6376\n",
      "  the model: 3.9444\n",
      "  the remainder: 5.0431\n",
      "  the remainder of: 5.0431\n",
      "  then: 3.9444\n",
      "  then test: 5.0431\n",
      "  then test the: 5.0431\n",
      "  three: 4.3499\n",
      "  three broad: 4.6376\n",
      "  three broad categories: 4.6376\n",
      "  to: 3.6760\n",
      "  to be: 3.4336\n",
      "  to be generated: 5.0431\n",
      "  to fit: 4.6376\n",
      "  to fit the: 5.0431\n",
      "  to the: 3.1712\n",
      "  to the remainder: 5.0431\n",
      "  training: 5.1163\n",
      "  training a: 4.1268\n",
      "  training a classifier: 5.0431\n",
      "  training data: 3.7903\n",
      "  training data set: 5.0431\n",
      "  unbalanced: 5.0431\n",
      "  unbalanced nature: 5.0431\n",
      "  unbalanced nature of: 5.0431\n",
      "  under: 3.4336\n",
      "  under the: 4.3499\n",
      "  under the assumption: 5.0431\n",
      "  unlabelled: 4.3499\n",
      "  unlabelled test: 5.0431\n",
      "  unlabelled test data: 5.0431\n",
      "  unsupervised: 3.2513\n",
      "  unsupervised anomaly: 5.0431\n",
      "  unsupervised anomaly detection: 5.0431\n",
      "\n",
      "Document 56:\n",
      "  a: 1.2589\n",
      "  a multitude: 5.0431\n",
      "  a multitude of: 5.0431\n",
      "  and: 1.2144\n",
      "  and finally: 5.0431\n",
      "  and finally metalearning: 5.0431\n",
      "  by: 1.9076\n",
      "  by a: 4.1268\n",
      "  by a multitude: 5.0431\n",
      "  eg: 3.9444\n",
      "  eg maml: 5.0431\n",
      "  finally: 5.0431\n",
      "  finally metalearning: 5.0431\n",
      "  finally metalearning eg: 5.0431\n",
      "  from: 2.0726\n",
      "  from supervised: 5.0431\n",
      "  from supervised learning: 5.0431\n",
      "  inspired: 4.3499\n",
      "  inspired by: 4.3499\n",
      "  inspired by a: 5.0431\n",
      "  is: 1.5167\n",
      "  is inspired: 5.0431\n",
      "  is inspired by: 5.0431\n",
      "  learning: 5.1274\n",
      "  learning and: 3.6568\n",
      "  learning and finally: 5.0431\n",
      "  learning is: 3.0281\n",
      "  learning is inspired: 5.0431\n",
      "  learning methods: 4.3499\n",
      "  learning methods starting: 5.0431\n",
      "  learning reinforcement: 4.6376\n",
      "  learning reinforcement learning: 4.6376\n",
      "  machine: 1.4735\n",
      "  machine learning: 1.5618\n",
      "  machine learning methods: 4.6376\n",
      "  maml: 5.0431\n",
      "  metalearning: 4.6376\n",
      "  metalearning eg: 5.0431\n",
      "  metalearning eg maml: 5.0431\n",
      "  methods: 2.7405\n",
      "  methods starting: 5.0431\n",
      "  methods starting from: 5.0431\n",
      "  multitude: 5.0431\n",
      "  multitude of: 5.0431\n",
      "  multitude of machine: 5.0431\n",
      "  of: 1.2144\n",
      "  of machine: 3.0281\n",
      "  of machine learning: 3.0281\n",
      "  reinforcement: 3.9444\n",
      "  reinforcement learning: 4.1268\n",
      "  reinforcement learning and: 5.0431\n",
      "  robot: 5.0431\n",
      "  robot learning: 5.0431\n",
      "  robot learning is: 5.0431\n",
      "  starting: 5.0431\n",
      "  starting from: 5.0431\n",
      "  starting from supervised: 5.0431\n",
      "  supervised: 3.2513\n",
      "  supervised learning: 3.6568\n",
      "  supervised learning reinforcement: 4.6376\n",
      "\n",
      "Document 57:\n",
      "  a: 1.2589\n",
      "  a rulebased: 4.6376\n",
      "  a rulebased machine: 4.6376\n",
      "  association: 3.9444\n",
      "  association rule: 4.1268\n",
      "  association rule learning: 4.1268\n",
      "  between: 2.9636\n",
      "  between variables: 5.0431\n",
      "  between variables in: 5.0431\n",
      "  databases: 9.2752\n",
      "  databases it: 5.0431\n",
      "  databases it is: 5.0431\n",
      "  databases using: 5.0431\n",
      "  databases using some: 5.0431\n",
      "  discovered: 5.0431\n",
      "  discovered in: 5.0431\n",
      "  discovered in databases: 5.0431\n",
      "  discovering: 4.3499\n",
      "  discovering relationships: 5.0431\n",
      "  discovering relationships between: 5.0431\n",
      "  for: 1.7289\n",
      "  for discovering: 4.6376\n",
      "  for discovering relationships: 5.0431\n",
      "  identify: 4.1268\n",
      "  identify strong: 5.0431\n",
      "  identify strong rules: 5.0431\n",
      "  in: 2.6835\n",
      "  in databases: 4.6376\n",
      "  in databases using: 5.0431\n",
      "  in large: 4.6376\n",
      "  in large databases: 5.0431\n",
      "  intended: 5.0431\n",
      "  intended to: 5.0431\n",
      "  intended to identify: 5.0431\n",
      "  interestingness: 5.0431\n",
      "  is: 3.0334\n",
      "  is a: 2.5173\n",
      "  is a rulebased: 5.0431\n",
      "  is intended: 5.0431\n",
      "  is intended to: 5.0431\n",
      "  it: 2.2705\n",
      "  it is: 3.5390\n",
      "  it is intended: 5.0431\n",
      "  large: 3.9444\n",
      "  large databases: 5.0431\n",
      "  large databases it: 5.0431\n",
      "  learning: 2.5637\n",
      "  learning is: 3.0281\n",
      "  learning is a: 4.1268\n",
      "  learning method: 4.1268\n",
      "  learning method for: 5.0431\n",
      "  machine: 1.4735\n",
      "  machine learning: 1.5618\n",
      "  machine learning method: 4.6376\n",
      "  measure: 4.6376\n",
      "  measure of: 5.0431\n",
      "  measure of interestingness: 5.0431\n",
      "  method: 3.6568\n",
      "  method for: 4.6376\n",
      "  method for discovering: 5.0431\n",
      "  of: 1.2144\n",
      "  of interestingness: 5.0431\n",
      "  relationships: 4.1268\n",
      "  relationships between: 4.1268\n",
      "  relationships between variables: 5.0431\n",
      "  rule: 3.7903\n",
      "  rule learning: 3.9444\n",
      "  rule learning is: 5.0431\n",
      "  rulebased: 4.1268\n",
      "  rulebased machine: 4.1268\n",
      "  rulebased machine learning: 4.1268\n",
      "  rules: 3.6568\n",
      "  rules discovered: 5.0431\n",
      "  rules discovered in: 5.0431\n",
      "  some: 2.9636\n",
      "  some measure: 5.0431\n",
      "  some measure of: 5.0431\n",
      "  strong: 4.6376\n",
      "  strong rules: 4.6376\n",
      "  strong rules discovered: 5.0431\n",
      "  to: 1.2253\n",
      "  to identify: 4.6376\n",
      "  to identify strong: 5.0431\n",
      "  using: 3.2513\n",
      "  using some: 5.0431\n",
      "  using some measure: 5.0431\n",
      "  variables: 3.6568\n",
      "  variables in: 4.3499\n",
      "  variables in large: 5.0431\n",
      "\n",
      "Document 58:\n",
      "  a: 6.2943\n",
      "  a general: 4.1268\n",
      "  a general term: 5.0431\n",
      "  a prediction: 5.0431\n",
      "  a prediction rulebased: 5.0431\n",
      "  a rulebased: 4.6376\n",
      "  a rulebased machine: 4.6376\n",
      "  a set: 3.2513\n",
      "  a set of: 3.2513\n",
      "  a singular: 5.0431\n",
      "  a singular model: 5.0431\n",
      "  algorithm: 2.9030\n",
      "  algorithm is: 4.3499\n",
      "  algorithm is the: 5.0431\n",
      "  algorithms: 2.3689\n",
      "  algorithms that: 4.1268\n",
      "  algorithms that commonly: 5.0431\n",
      "  and: 2.4288\n",
      "  and artificial: 4.6376\n",
      "  and artificial immune: 5.0431\n",
      "  and utilisation: 5.0431\n",
      "  and utilisation of: 5.0431\n",
      "  any: 7.3135\n",
      "  any instance: 5.0431\n",
      "  any instance in: 5.0431\n",
      "  any machine: 5.0431\n",
      "  any machine learning: 5.0431\n",
      "  applied: 4.3499\n",
      "  applied to: 4.6376\n",
      "  applied to any: 5.0431\n",
      "  apply: 4.6376\n",
      "  apply knowledge: 4.6376\n",
      "  apply knowledge the: 5.0431\n",
      "  approaches: 3.5390\n",
      "  approaches include: 5.0431\n",
      "  approaches include learning: 5.0431\n",
      "  artificial: 2.7918\n",
      "  artificial immune: 4.6376\n",
      "  artificial immune systems: 4.6376\n",
      "  association: 3.9444\n",
      "  association rule: 4.1268\n",
      "  association rule learning: 4.1268\n",
      "  be: 2.0726\n",
      "  be universally: 5.0431\n",
      "  be universally applied: 5.0431\n",
      "  by: 1.9076\n",
      "  by the: 3.2513\n",
      "  by the system: 5.0431\n",
      "  can: 2.1809\n",
      "  can be: 2.7405\n",
      "  can be universally: 5.0431\n",
      "  captured: 5.0431\n",
      "  captured by: 5.0431\n",
      "  captured by the: 5.0431\n",
      "  characteristic: 4.6376\n",
      "  characteristic of: 5.0431\n",
      "  characteristic of a: 5.0431\n",
      "  classifier: 3.7903\n",
      "  classifier systems: 4.3499\n",
      "  classifier systems association: 4.6376\n",
      "  collectively: 4.6376\n",
      "  collectively represent: 5.0431\n",
      "  collectively represent the: 5.0431\n",
      "  commonly: 5.0431\n",
      "  commonly identify: 5.0431\n",
      "  commonly identify a: 5.0431\n",
      "  contrast: 4.1268\n",
      "  contrast to: 5.0431\n",
      "  contrast to other: 5.0431\n",
      "  defining: 4.6376\n",
      "  defining characteristic: 5.0431\n",
      "  defining characteristic of: 5.0431\n",
      "  evolves: 5.0431\n",
      "  evolves rules: 5.0431\n",
      "  evolves rules to: 5.0431\n",
      "  for: 1.7289\n",
      "  for any: 5.0431\n",
      "  for any machine: 5.0431\n",
      "  general: 3.9444\n",
      "  general term: 5.0431\n",
      "  general term for: 5.0431\n",
      "  identification: 4.6376\n",
      "  identification and: 5.0431\n",
      "  identification and utilisation: 5.0431\n",
      "  identifies: 5.0431\n",
      "  identifies learns: 5.0431\n",
      "  identifies learns or: 5.0431\n",
      "  identify: 4.1268\n",
      "  identify a: 4.6376\n",
      "  identify a singular: 5.0431\n",
      "  immune: 4.6376\n",
      "  immune systems: 4.6376\n",
      "  in: 2.6835\n",
      "  in contrast: 4.1268\n",
      "  in contrast to: 5.0431\n",
      "  in order: 4.1268\n",
      "  in order to: 4.1268\n",
      "  include: 3.4336\n",
      "  include learning: 5.0431\n",
      "  include learning classifier: 5.0431\n",
      "  instance: 4.3499\n",
      "  instance in: 5.0431\n",
      "  instance in order: 5.0431\n",
      "  is: 4.5501\n",
      "  is a: 2.5173\n",
      "  is a general: 4.6376\n",
      "  is in: 5.0431\n",
      "  is in contrast: 5.0431\n",
      "  is the: 3.3383\n",
      "  is the identification: 4.6376\n",
      "  knowledge: 7.5806\n",
      "  knowledge captured: 5.0431\n",
      "  knowledge captured by: 5.0431\n",
      "  knowledge the: 5.0431\n",
      "  knowledge the defining: 5.0431\n",
      "  learning: 8.9730\n",
      "  learning algorithm: 3.9444\n",
      "  learning algorithm is: 4.6376\n",
      "  learning algorithms: 2.9030\n",
      "  learning algorithms that: 4.6376\n",
      "  learning and: 3.6568\n",
      "  learning and artificial: 5.0431\n",
      "  learning approaches: 3.9444\n",
      "  learning approaches include: 5.0431\n",
      "  learning classifier: 4.3499\n",
      "  learning classifier systems: 4.3499\n",
      "  learning is: 3.0281\n",
      "  learning is a: 4.1268\n",
      "  learning method: 4.1268\n",
      "  learning method that: 4.6376\n",
      "  learns: 3.9444\n",
      "  learns or: 5.0431\n",
      "  learns or evolves: 5.0431\n",
      "  machine: 7.3676\n",
      "  machine learning: 7.8091\n",
      "  machine learning algorithm: 4.1268\n",
      "  machine learning algorithms: 3.4336\n",
      "  machine learning approaches: 3.9444\n",
      "  machine learning is: 3.6568\n",
      "  machine learning method: 4.6376\n",
      "  make: 3.3383\n",
      "  make a: 5.0431\n",
      "  make a prediction: 5.0431\n",
      "  manipulate: 5.0431\n",
      "  manipulate or: 5.0431\n",
      "  manipulate or apply: 5.0431\n",
      "  method: 3.6568\n",
      "  method that: 4.6376\n",
      "  method that identifies: 5.0431\n",
      "  model: 2.3350\n",
      "  model that: 4.1268\n",
      "  model that can: 5.0431\n",
      "  of: 3.6432\n",
      "  of a: 6.0563\n",
      "  of a rulebased: 5.0431\n",
      "  of a set: 4.1268\n",
      "  of relational: 5.0431\n",
      "  of relational rules: 5.0431\n",
      "  or: 4.0453\n",
      "  or apply: 5.0431\n",
      "  or apply knowledge: 5.0431\n",
      "  or evolves: 5.0431\n",
      "  or evolves rules: 5.0431\n",
      "  order: 3.9444\n",
      "  order to: 4.1268\n",
      "  order to make: 4.6376\n",
      "  other: 2.7918\n",
      "  other machine: 4.6376\n",
      "  other machine learning: 4.6376\n",
      "  prediction: 3.7903\n",
      "  prediction rulebased: 5.0431\n",
      "  prediction rulebased machine: 5.0431\n",
      "  relational: 5.0431\n",
      "  relational rules: 5.0431\n",
      "  relational rules that: 5.0431\n",
      "  represent: 4.1268\n",
      "  represent the: 4.6376\n",
      "  represent the knowledge: 5.0431\n",
      "  rule: 3.7903\n",
      "  rule learning: 3.9444\n",
      "  rule learning and: 5.0431\n",
      "  rulebased: 12.3803\n",
      "  rulebased machine: 12.3803\n",
      "  rulebased machine learning: 12.3803\n",
      "  rules: 7.3135\n",
      "  rules that: 4.6376\n",
      "  rules that collectively: 4.6376\n",
      "  rules to: 5.0431\n",
      "  rules to store: 5.0431\n",
      "  set: 2.6007\n",
      "  set of: 3.0281\n",
      "  set of relational: 5.0431\n",
      "  singular: 5.0431\n",
      "  singular model: 5.0431\n",
      "  singular model that: 5.0431\n",
      "  store: 4.3499\n",
      "  store manipulate: 5.0431\n",
      "  store manipulate or: 5.0431\n",
      "  system: 3.0281\n",
      "  system this: 5.0431\n",
      "  system this is: 5.0431\n",
      "  systems: 5.3834\n",
      "  systems association: 4.6376\n",
      "  systems association rule: 4.6376\n",
      "  term: 3.7903\n",
      "  term for: 5.0431\n",
      "  term for any: 5.0431\n",
      "  that: 6.7030\n",
      "  that can: 3.9444\n",
      "  that can be: 4.6376\n",
      "  that collectively: 4.6376\n",
      "  that collectively represent: 5.0431\n",
      "  that commonly: 5.0431\n",
      "  that commonly identify: 5.0431\n",
      "  that identifies: 5.0431\n",
      "  that identifies learns: 5.0431\n",
      "  the: 4.7716\n",
      "  the defining: 5.0431\n",
      "  the defining characteristic: 5.0431\n",
      "  the identification: 4.6376\n",
      "  the identification and: 5.0431\n",
      "  the knowledge: 5.0431\n",
      "  the knowledge captured: 5.0431\n",
      "  the system: 4.3499\n",
      "  the system this: 5.0431\n",
      "  this: 2.6007\n",
      "  this is: 4.3499\n",
      "  this is in: 5.0431\n",
      "  to: 4.9014\n",
      "  to any: 5.0431\n",
      "  to any instance: 5.0431\n",
      "  to make: 3.9444\n",
      "  to make a: 5.0431\n",
      "  to other: 4.6376\n",
      "  to other machine: 4.6376\n",
      "  to store: 5.0431\n",
      "  to store manipulate: 5.0431\n",
      "  universally: 5.0431\n",
      "  universally applied: 5.0431\n",
      "  universally applied to: 5.0431\n",
      "  utilisation: 5.0431\n",
      "  utilisation of: 5.0431\n",
      "  utilisation of a: 5.0431\n",
      "\n",
      "Document 59:\n",
      "  a: 3.7766\n",
      "  a customer: 5.0431\n",
      "  a customer buys: 5.0431\n",
      "  a supermarket: 5.0431\n",
      "  a supermarket would: 5.0431\n",
      "  a transaction: 5.0431\n",
      "  a transaction or: 5.0431\n",
      "  about: 3.6568\n",
      "  about marketing: 5.0431\n",
      "  about marketing activities: 5.0431\n",
      "  across: 5.0431\n",
      "  across transactions: 5.0431\n",
      "  activities: 5.0431\n",
      "  activities such: 5.0431\n",
      "  activities such as: 5.0431\n",
      "  addition: 3.7903\n",
      "  addition to: 3.9444\n",
      "  addition to market: 5.0431\n",
      "  agrawal: 5.0431\n",
      "  agrawal tomasz: 5.0431\n",
      "  agrawal tomasz imieliÅ„ski: 5.0431\n",
      "  also: 2.6452\n",
      "  also buy: 5.0431\n",
      "  also buy hamburger: 5.0431\n",
      "  analysis: 3.1712\n",
      "  analysis association: 5.0431\n",
      "  analysis association rules: 5.0431\n",
      "  and: 3.6432\n",
      "  and arun: 5.0431\n",
      "  and arun swami: 5.0431\n",
      "  and bioinformatics: 5.0431\n",
      "  and bioinformatics in: 5.0431\n",
      "  and potatoes: 5.0431\n",
      "  and potatoes together: 5.0431\n",
      "  application: 4.3499\n",
      "  application areas: 5.0431\n",
      "  application areas including: 5.0431\n",
      "  are: 3.9500\n",
      "  are employed: 5.0431\n",
      "  are employed today: 5.0431\n",
      "  are likely: 4.6376\n",
      "  are likely to: 4.6376\n",
      "  areas: 5.0431\n",
      "  areas including: 5.0431\n",
      "  areas including web: 5.0431\n",
      "  arun: 5.0431\n",
      "  arun swami: 5.0431\n",
      "  arun swami introduced: 5.0431\n",
      "  as: 3.6888\n",
      "  as promotional: 5.0431\n",
      "  as promotional pricing: 5.0431\n",
      "  as the: 4.3499\n",
      "  as the basis: 5.0431\n",
      "  association: 11.8333\n",
      "  association rule: 4.1268\n",
      "  association rule learning: 4.1268\n",
      "  association rules: 10.0861\n",
      "  association rules are: 5.0431\n",
      "  association rules for: 5.0431\n",
      "  based: 3.4336\n",
      "  based on: 3.4336\n",
      "  based on the: 4.3499\n",
      "  basis: 4.6376\n",
      "  basis for: 5.0431\n",
      "  basis for decisions: 5.0431\n",
      "  basket: 5.0431\n",
      "  basket analysis: 5.0431\n",
      "  basket analysis association: 5.0431\n",
      "  be: 2.0726\n",
      "  be used: 3.4336\n",
      "  be used as: 5.0431\n",
      "  between: 2.9636\n",
      "  between products: 5.0431\n",
      "  between products in: 5.0431\n",
      "  bioinformatics: 4.6376\n",
      "  bioinformatics in: 5.0431\n",
      "  bioinformatics in contrast: 5.0431\n",
      "  burger: 5.0431\n",
      "  burger found: 5.0431\n",
      "  burger found in: 5.0431\n",
      "  buy: 5.0431\n",
      "  buy hamburger: 5.0431\n",
      "  buy hamburger meat: 5.0431\n",
      "  buys: 5.0431\n",
      "  buys onions: 5.0431\n",
      "  buys onions and: 5.0431\n",
      "  by: 1.9076\n",
      "  by pointofsale: 5.0431\n",
      "  by pointofsale pos: 5.0431\n",
      "  can: 2.1809\n",
      "  can be: 2.7405\n",
      "  can be used: 3.6568\n",
      "  concept: 4.3499\n",
      "  concept of: 4.6376\n",
      "  concept of strong: 5.0431\n",
      "  consider: 5.0431\n",
      "  consider the: 5.0431\n",
      "  consider the order: 5.0431\n",
      "  continuous: 4.6376\n",
      "  continuous production: 5.0431\n",
      "  continuous production and: 5.0431\n",
      "  contrast: 4.1268\n",
      "  contrast with: 5.0431\n",
      "  contrast with sequence: 5.0431\n",
      "  customer: 4.6376\n",
      "  customer buys: 5.0431\n",
      "  customer buys onions: 5.0431\n",
      "  data: 3.7300\n",
      "  data of: 4.3499\n",
      "  data of a: 5.0431\n",
      "  data recorded: 5.0431\n",
      "  data recorded by: 5.0431\n",
      "  decisions: 3.6568\n",
      "  decisions about: 4.6376\n",
      "  decisions about marketing: 5.0431\n",
      "  detection: 3.9444\n",
      "  detection continuous: 5.0431\n",
      "  detection continuous production: 5.0431\n",
      "  discovering: 4.3499\n",
      "  discovering regularities: 5.0431\n",
      "  discovering regularities between: 5.0431\n",
      "  does: 4.3499\n",
      "  does not: 4.3499\n",
      "  does not consider: 5.0431\n",
      "  either: 3.9444\n",
      "  either within: 5.0431\n",
      "  either within a: 5.0431\n",
      "  employed: 4.3499\n",
      "  employed today: 5.0431\n",
      "  employed today in: 5.0431\n",
      "  example: 2.9636\n",
      "  example the: 4.6376\n",
      "  example the rule: 5.0431\n",
      "  for: 5.1866\n",
      "  for decisions: 5.0431\n",
      "  for decisions about: 5.0431\n",
      "  for discovering: 4.6376\n",
      "  for discovering regularities: 5.0431\n",
      "  for example: 3.2513\n",
      "  for example the: 4.6376\n",
      "  found: 3.7903\n",
      "  found in: 4.6376\n",
      "  found in the: 5.0431\n",
      "  hamburger: 5.0431\n",
      "  hamburger meat: 5.0431\n",
      "  hamburger meat such: 5.0431\n",
      "  if: 3.6568\n",
      "  if a: 5.0431\n",
      "  if a customer: 5.0431\n",
      "  imieliÅ„ski: 5.0431\n",
      "  imieliÅ„ski and: 5.0431\n",
      "  imieliÅ„ski and arun: 5.0431\n",
      "  in: 8.0505\n",
      "  in addition: 3.7903\n",
      "  in addition to: 3.9444\n",
      "  in application: 5.0431\n",
      "  in application areas: 5.0431\n",
      "  in contrast: 4.1268\n",
      "  in contrast with: 5.0431\n",
      "  in largescale: 5.0431\n",
      "  in largescale transaction: 5.0431\n",
      "  in supermarkets: 5.0431\n",
      "  in supermarkets for: 5.0431\n",
      "  in the: 2.4404\n",
      "  in the sales: 5.0431\n",
      "  including: 3.4336\n",
      "  including web: 5.0431\n",
      "  including web usage: 5.0431\n",
      "  indicate: 5.0431\n",
      "  indicate that: 5.0431\n",
      "  indicate that if: 5.0431\n",
      "  information: 3.7903\n",
      "  information can: 5.0431\n",
      "  information can be: 5.0431\n",
      "  introduced: 4.3499\n",
      "  introduced association: 5.0431\n",
      "  introduced association rules: 5.0431\n",
      "  intrusion: 4.6376\n",
      "  intrusion detection: 4.6376\n",
      "  intrusion detection continuous: 5.0431\n",
      "  items: 4.3499\n",
      "  items either: 5.0431\n",
      "  items either within: 5.0431\n",
      "  largescale: 4.1268\n",
      "  largescale transaction: 5.0431\n",
      "  largescale transaction data: 5.0431\n",
      "  learning: 1.2819\n",
      "  learning typically: 5.0431\n",
      "  learning typically does: 5.0431\n",
      "  likely: 4.3499\n",
      "  likely to: 4.3499\n",
      "  likely to also: 5.0431\n",
      "  market: 5.0431\n",
      "  market basket: 5.0431\n",
      "  market basket analysis: 5.0431\n",
      "  marketing: 5.0431\n",
      "  marketing activities: 5.0431\n",
      "  marketing activities such: 5.0431\n",
      "  mathrm: 10.0861\n",
      "  mathrm burger: 5.0431\n",
      "  mathrm burger found: 5.0431\n",
      "  mathrm onionspotatoes: 5.0431\n",
      "  mathrm onionspotatoes rightarrow: 5.0431\n",
      "  meat: 5.0431\n",
      "  meat such: 5.0431\n",
      "  meat such information: 5.0431\n",
      "  mining: 7.8889\n",
      "  mining association: 5.0431\n",
      "  mining association rule: 5.0431\n",
      "  mining intrusion: 5.0431\n",
      "  mining intrusion detection: 5.0431\n",
      "  not: 2.6007\n",
      "  not consider: 5.0431\n",
      "  not consider the: 5.0431\n",
      "  of: 3.6432\n",
      "  of a: 3.0281\n",
      "  of a supermarket: 5.0431\n",
      "  of items: 5.0431\n",
      "  of items either: 5.0431\n",
      "  of strong: 5.0431\n",
      "  of strong rules: 5.0431\n",
      "  on: 2.0473\n",
      "  on the: 3.2513\n",
      "  on the concept: 5.0431\n",
      "  onions: 5.0431\n",
      "  onions and: 5.0431\n",
      "  onions and potatoes: 5.0431\n",
      "  onionspotatoes: 5.0431\n",
      "  onionspotatoes rightarrow: 5.0431\n",
      "  onionspotatoes rightarrow mathrm: 5.0431\n",
      "  onionspotatoesburgerdisplaystyle: 5.0431\n",
      "  onionspotatoesburgerdisplaystyle mathrm: 5.0431\n",
      "  onionspotatoesburgerdisplaystyle mathrm onionspotatoes: 5.0431\n",
      "  or: 4.0453\n",
      "  or across: 5.0431\n",
      "  or across transactions: 5.0431\n",
      "  or product: 5.0431\n",
      "  or product placements: 5.0431\n",
      "  order: 3.9444\n",
      "  order of: 5.0431\n",
      "  order of items: 5.0431\n",
      "  placements: 5.0431\n",
      "  placements in: 5.0431\n",
      "  placements in addition: 5.0431\n",
      "  pointofsale: 5.0431\n",
      "  pointofsale pos: 5.0431\n",
      "  pointofsale pos systems: 5.0431\n",
      "  pos: 5.0431\n",
      "  pos systems: 5.0431\n",
      "  pos systems in: 5.0431\n",
      "  potatoes: 5.0431\n",
      "  potatoes together: 5.0431\n",
      "  potatoes together they: 5.0431\n",
      "  pricing: 5.0431\n",
      "  pricing or: 5.0431\n",
      "  pricing or product: 5.0431\n",
      "  product: 5.0431\n",
      "  product placements: 5.0431\n",
      "  product placements in: 5.0431\n",
      "  production: 5.0431\n",
      "  production and: 5.0431\n",
      "  production and bioinformatics: 5.0431\n",
      "  products: 5.0431\n",
      "  products in: 5.0431\n",
      "  products in largescale: 5.0431\n",
      "  promotional: 5.0431\n",
      "  promotional pricing: 5.0431\n",
      "  promotional pricing or: 5.0431\n",
      "  rakesh: 5.0431\n",
      "  rakesh agrawal: 5.0431\n",
      "  rakesh agrawal tomasz: 5.0431\n",
      "  recorded: 5.0431\n",
      "  recorded by: 5.0431\n",
      "  recorded by pointofsale: 5.0431\n",
      "  regularities: 5.0431\n",
      "  regularities between: 5.0431\n",
      "  regularities between products: 5.0431\n",
      "  rightarrow: 5.0431\n",
      "  rightarrow mathrm: 5.0431\n",
      "  rightarrow mathrm burger: 5.0431\n",
      "  rule: 7.5806\n",
      "  rule learning: 3.9444\n",
      "  rule learning typically: 5.0431\n",
      "  rule onionspotatoesburgerdisplaystyle: 5.0431\n",
      "  rule onionspotatoesburgerdisplaystyle mathrm: 5.0431\n",
      "  rules: 10.9703\n",
      "  rules are: 5.0431\n",
      "  rules are employed: 5.0431\n",
      "  rules for: 5.0431\n",
      "  rules for discovering: 5.0431\n",
      "  rules rakesh: 5.0431\n",
      "  rules rakesh agrawal: 5.0431\n",
      "  sales: 5.0431\n",
      "  sales data: 5.0431\n",
      "  sales data of: 5.0431\n",
      "  sequence: 4.6376\n",
      "  sequence mining: 5.0431\n",
      "  sequence mining association: 5.0431\n",
      "  strong: 4.6376\n",
      "  strong rules: 4.6376\n",
      "  strong rules rakesh: 5.0431\n",
      "  such: 4.9562\n",
      "  such as: 2.8458\n",
      "  such as promotional: 5.0431\n",
      "  such information: 5.0431\n",
      "  such information can: 5.0431\n",
      "  supermarket: 5.0431\n",
      "  supermarket would: 5.0431\n",
      "  supermarket would indicate: 5.0431\n",
      "  supermarkets: 5.0431\n",
      "  supermarkets for: 5.0431\n",
      "  supermarkets for example: 5.0431\n",
      "  swami: 5.0431\n",
      "  swami introduced: 5.0431\n",
      "  swami introduced association: 5.0431\n",
      "  systems: 2.6917\n",
      "  systems in: 5.0431\n",
      "  systems in supermarkets: 5.0431\n",
      "  that: 1.6758\n",
      "  that if: 5.0431\n",
      "  that if a: 5.0431\n",
      "  the: 5.9645\n",
      "  the basis: 5.0431\n",
      "  the basis for: 5.0431\n",
      "  the concept: 4.6376\n",
      "  the concept of: 4.6376\n",
      "  the order: 5.0431\n",
      "  the order of: 5.0431\n",
      "  the rule: 5.0431\n",
      "  the rule onionspotatoesburgerdisplaystyle: 5.0431\n",
      "  the sales: 5.0431\n",
      "  the sales data: 5.0431\n",
      "  they: 3.4336\n",
      "  they are: 4.6376\n",
      "  they are likely: 5.0431\n",
      "  to: 2.4507\n",
      "  to also: 5.0431\n",
      "  to also buy: 5.0431\n",
      "  to market: 5.0431\n",
      "  to market basket: 5.0431\n",
      "  today: 5.0431\n",
      "  today in: 5.0431\n",
      "  today in application: 5.0431\n",
      "  together: 5.0431\n",
      "  together they: 5.0431\n",
      "  together they are: 5.0431\n",
      "  tomasz: 5.0431\n",
      "  tomasz imieliÅ„ski: 5.0431\n",
      "  tomasz imieliÅ„ski and: 5.0431\n",
      "  transaction: 10.0861\n",
      "  transaction data: 5.0431\n",
      "  transaction data recorded: 5.0431\n",
      "  transaction or: 5.0431\n",
      "  transaction or across: 5.0431\n",
      "  transactions: 5.0431\n",
      "  typically: 3.5390\n",
      "  typically does: 5.0431\n",
      "  typically does not: 5.0431\n",
      "  usage: 5.0431\n",
      "  usage mining: 5.0431\n",
      "  usage mining intrusion: 5.0431\n",
      "  used: 2.3350\n",
      "  used as: 4.1268\n",
      "  used as the: 5.0431\n",
      "  web: 5.0431\n",
      "  web usage: 5.0431\n",
      "  web usage mining: 5.0431\n",
      "  with: 2.0726\n",
      "  with sequence: 5.0431\n",
      "  with sequence mining: 5.0431\n",
      "  within: 3.4336\n",
      "  within a: 4.3499\n",
      "  within a transaction: 5.0431\n",
      "  would: 3.9444\n",
      "  would indicate: 5.0431\n",
      "  would indicate that: 5.0431\n",
      "\n",
      "Document 60:\n",
      "  a: 7.5532\n",
      "  a discovery: 5.0431\n",
      "  a discovery component: 5.0431\n",
      "  a family: 5.0431\n",
      "  a family of: 5.0431\n",
      "  a genetic: 4.6376\n",
      "  a genetic algorithm: 4.6376\n",
      "  a learning: 4.3499\n",
      "  a learning component: 5.0431\n",
      "  a piecewise: 5.0431\n",
      "  a piecewise manner: 5.0431\n",
      "  a set: 3.2513\n",
      "  a set of: 3.2513\n",
      "  algorithm: 2.9030\n",
      "  algorithm with: 5.0431\n",
      "  algorithm with a: 5.0431\n",
      "  algorithms: 2.3689\n",
      "  algorithms that: 4.1268\n",
      "  algorithms that combine: 5.0431\n",
      "  and: 1.2144\n",
      "  and apply: 5.0431\n",
      "  and apply knowledge: 5.0431\n",
      "  apply: 4.6376\n",
      "  apply knowledge: 4.6376\n",
      "  apply knowledge in: 5.0431\n",
      "  are: 1.9750\n",
      "  are a: 4.6376\n",
      "  are a family: 5.0431\n",
      "  classifier: 3.7903\n",
      "  classifier systems: 4.3499\n",
      "  classifier systems lcs: 5.0431\n",
      "  collectively: 4.6376\n",
      "  collectively store: 5.0431\n",
      "  collectively store and: 5.0431\n",
      "  combine: 4.6376\n",
      "  combine a: 5.0431\n",
      "  combine a discovery: 5.0431\n",
      "  component: 7.8889\n",
      "  component performing: 5.0431\n",
      "  component performing either: 5.0431\n",
      "  component typically: 5.0431\n",
      "  component typically a: 5.0431\n",
      "  contextdependent: 5.0431\n",
      "  contextdependent rules: 5.0431\n",
      "  contextdependent rules that: 5.0431\n",
      "  discovery: 4.6376\n",
      "  discovery component: 5.0431\n",
      "  discovery component typically: 5.0431\n",
      "  either: 3.9444\n",
      "  either supervised: 4.6376\n",
      "  either supervised learning: 5.0431\n",
      "  family: 5.0431\n",
      "  family of: 5.0431\n",
      "  family of rulebased: 5.0431\n",
      "  genetic: 4.1268\n",
      "  genetic algorithm: 4.6376\n",
      "  genetic algorithm with: 5.0431\n",
      "  identify: 4.1268\n",
      "  identify a: 4.6376\n",
      "  identify a set: 5.0431\n",
      "  in: 2.6835\n",
      "  in a: 3.0971\n",
      "  in a piecewise: 5.0431\n",
      "  in order: 4.1268\n",
      "  in order to: 4.1268\n",
      "  knowledge: 3.7903\n",
      "  knowledge in: 5.0431\n",
      "  knowledge in a: 5.0431\n",
      "  lcs: 5.0431\n",
      "  lcs are: 5.0431\n",
      "  lcs are a: 5.0431\n",
      "  learning: 7.6911\n",
      "  learning algorithms: 2.9030\n",
      "  learning algorithms that: 4.6376\n",
      "  learning classifier: 4.3499\n",
      "  learning classifier systems: 4.3499\n",
      "  learning component: 5.0431\n",
      "  learning component performing: 5.0431\n",
      "  learning or: 4.6376\n",
      "  learning or unsupervised: 5.0431\n",
      "  learning reinforcement: 4.6376\n",
      "  learning reinforcement learning: 4.6376\n",
      "  learning they: 5.0431\n",
      "  learning they seek: 5.0431\n",
      "  machine: 1.4735\n",
      "  machine learning: 1.5618\n",
      "  machine learning algorithms: 3.4336\n",
      "  make: 3.3383\n",
      "  make predictions: 4.3499\n",
      "  manner: 5.0431\n",
      "  manner in: 5.0431\n",
      "  manner in order: 5.0431\n",
      "  of: 2.4288\n",
      "  of contextdependent: 5.0431\n",
      "  of contextdependent rules: 5.0431\n",
      "  of rulebased: 5.0431\n",
      "  of rulebased machine: 5.0431\n",
      "  or: 2.0226\n",
      "  or unsupervised: 4.6376\n",
      "  or unsupervised learning: 5.0431\n",
      "  order: 3.9444\n",
      "  order to: 4.1268\n",
      "  order to make: 4.6376\n",
      "  performing: 3.9444\n",
      "  performing either: 5.0431\n",
      "  performing either supervised: 5.0431\n",
      "  piecewise: 5.0431\n",
      "  piecewise manner: 5.0431\n",
      "  piecewise manner in: 5.0431\n",
      "  predictions: 3.3383\n",
      "  reinforcement: 3.9444\n",
      "  reinforcement learning: 4.1268\n",
      "  reinforcement learning or: 5.0431\n",
      "  rulebased: 4.1268\n",
      "  rulebased machine: 4.1268\n",
      "  rulebased machine learning: 4.1268\n",
      "  rules: 3.6568\n",
      "  rules that: 4.6376\n",
      "  rules that collectively: 4.6376\n",
      "  seek: 5.0431\n",
      "  seek to: 5.0431\n",
      "  seek to identify: 5.0431\n",
      "  set: 2.6007\n",
      "  set of: 3.0281\n",
      "  set of contextdependent: 5.0431\n",
      "  store: 4.3499\n",
      "  store and: 5.0431\n",
      "  store and apply: 5.0431\n",
      "  supervised: 3.2513\n",
      "  supervised learning: 3.6568\n",
      "  supervised learning reinforcement: 4.6376\n",
      "  systems: 2.6917\n",
      "  systems lcs: 5.0431\n",
      "  systems lcs are: 5.0431\n",
      "  that: 3.3515\n",
      "  that collectively: 4.6376\n",
      "  that collectively store: 5.0431\n",
      "  that combine: 5.0431\n",
      "  that combine a: 5.0431\n",
      "  they: 3.4336\n",
      "  they seek: 5.0431\n",
      "  they seek to: 5.0431\n",
      "  to: 2.4507\n",
      "  to identify: 4.6376\n",
      "  to identify a: 5.0431\n",
      "  to make: 3.9444\n",
      "  to make predictions: 4.3499\n",
      "  typically: 3.5390\n",
      "  typically a: 5.0431\n",
      "  typically a genetic: 5.0431\n",
      "  unsupervised: 3.2513\n",
      "  unsupervised learning: 3.7903\n",
      "  unsupervised learning they: 5.0431\n",
      "  with: 2.0726\n",
      "  with a: 3.6568\n",
      "  with a learning: 5.0431\n",
      "\n",
      "Document 61:\n",
      "  a: 6.2943\n",
      "  a hypothesized: 5.0431\n",
      "  a hypothesized logic: 5.0431\n",
      "  a logical: 4.6376\n",
      "  a logical database: 5.0431\n",
      "  a related: 4.6376\n",
      "  a related field: 4.6376\n",
      "  a set: 3.2513\n",
      "  a set of: 3.2513\n",
      "  a uniform: 5.0431\n",
      "  a uniform representation: 5.0431\n",
      "  all: 3.5390\n",
      "  all positive: 5.0431\n",
      "  all positive and: 5.0431\n",
      "  an: 6.4580\n",
      "  an approach: 5.0431\n",
      "  an approach to: 5.0431\n",
      "  an encoding: 5.0431\n",
      "  an encoding of: 5.0431\n",
      "  an ilp: 5.0431\n",
      "  an ilp system: 5.0431\n",
      "  and: 4.8576\n",
      "  and a: 5.0431\n",
      "  and a set: 5.0431\n",
      "  and hypotheses: 5.0431\n",
      "  and hypotheses given: 5.0431\n",
      "  and no: 5.0431\n",
      "  and no negative: 5.0431\n",
      "  and not: 5.0431\n",
      "  and not only: 5.0431\n",
      "  any: 3.6568\n",
      "  any kind: 5.0431\n",
      "  any kind of: 5.0431\n",
      "  approach: 3.6568\n",
      "  approach to: 5.0431\n",
      "  approach to rule: 5.0431\n",
      "  as: 5.5331\n",
      "  as a: 5.8060\n",
      "  as a logical: 5.0431\n",
      "  as a uniform: 5.0431\n",
      "  as functional: 5.0431\n",
      "  as functional programs: 5.0431\n",
      "  background: 10.0861\n",
      "  background knowledge: 10.0861\n",
      "  background knowledge and: 10.0861\n",
      "  considers: 5.0431\n",
      "  considers any: 5.0431\n",
      "  considers any kind: 5.0431\n",
      "  database: 5.0431\n",
      "  database of: 5.0431\n",
      "  database of facts: 5.0431\n",
      "  derive: 5.0431\n",
      "  derive a: 5.0431\n",
      "  derive a hypothesized: 5.0431\n",
      "  encoding: 5.0431\n",
      "  encoding of: 5.0431\n",
      "  encoding of the: 5.0431\n",
      "  entails: 5.0431\n",
      "  entails all: 5.0431\n",
      "  entails all positive: 5.0431\n",
      "  examples: 9.2914\n",
      "  examples background: 5.0431\n",
      "  examples background knowledge: 5.0431\n",
      "  examples inductive: 5.0431\n",
      "  examples inductive programming: 5.0431\n",
      "  examples represented: 5.0431\n",
      "  examples represented as: 5.0431\n",
      "  facts: 4.6376\n",
      "  facts an: 5.0431\n",
      "  facts an ilp: 5.0431\n",
      "  field: 2.9636\n",
      "  field that: 4.6376\n",
      "  field that considers: 5.0431\n",
      "  for: 3.4577\n",
      "  for input: 5.0431\n",
      "  for input examples: 5.0431\n",
      "  for representing: 5.0431\n",
      "  for representing hypotheses: 5.0431\n",
      "  functional: 5.0431\n",
      "  functional programs: 5.0431\n",
      "  given: 3.3383\n",
      "  given an: 5.0431\n",
      "  given an encoding: 5.0431\n",
      "  hypotheses: 10.0861\n",
      "  hypotheses and: 5.0431\n",
      "  hypotheses and not: 5.0431\n",
      "  hypotheses given: 5.0431\n",
      "  hypotheses given an: 5.0431\n",
      "  hypothesized: 5.0431\n",
      "  hypothesized logic: 5.0431\n",
      "  hypothesized logic program: 5.0431\n",
      "  ilp: 10.0861\n",
      "  ilp is: 5.0431\n",
      "  ilp is an: 5.0431\n",
      "  ilp system: 5.0431\n",
      "  ilp system will: 5.0431\n",
      "  inductive: 8.6998\n",
      "  inductive logic: 4.3499\n",
      "  inductive logic programming: 4.6376\n",
      "  inductive programming: 5.0431\n",
      "  inductive programming is: 5.0431\n",
      "  input: 3.0281\n",
      "  input examples: 5.0431\n",
      "  input examples background: 5.0431\n",
      "  is: 3.0334\n",
      "  is a: 2.5173\n",
      "  is a related: 4.6376\n",
      "  is an: 3.6568\n",
      "  is an approach: 5.0431\n",
      "  kind: 4.6376\n",
      "  kind of: 4.6376\n",
      "  kind of programming: 5.0431\n",
      "  knowledge: 7.5806\n",
      "  knowledge and: 10.0861\n",
      "  knowledge and a: 5.0431\n",
      "  knowledge and hypotheses: 5.0431\n",
      "  known: 3.5390\n",
      "  known background: 5.0431\n",
      "  known background knowledge: 5.0431\n",
      "  language: 3.9444\n",
      "  language for: 5.0431\n",
      "  language for representing: 5.0431\n",
      "  learning: 1.2819\n",
      "  learning using: 5.0431\n",
      "  learning using logic: 5.0431\n",
      "  logic: 16.5070\n",
      "  logic program: 5.0431\n",
      "  logic program that: 5.0431\n",
      "  logic programming: 13.9128\n",
      "  logic programming as: 5.0431\n",
      "  logic programming ilp: 5.0431\n",
      "  logic programming such: 5.0431\n",
      "  logical: 4.3499\n",
      "  logical database: 5.0431\n",
      "  logical database of: 5.0431\n",
      "  negative: 3.9444\n",
      "  negative examples: 4.6376\n",
      "  negative examples inductive: 5.0431\n",
      "  no: 4.6376\n",
      "  no negative: 5.0431\n",
      "  no negative examples: 5.0431\n",
      "  not: 2.6007\n",
      "  not only: 5.0431\n",
      "  not only logic: 5.0431\n",
      "  of: 4.8576\n",
      "  of examples: 4.6376\n",
      "  of examples represented: 5.0431\n",
      "  of facts: 5.0431\n",
      "  of facts an: 5.0431\n",
      "  of programming: 5.0431\n",
      "  of programming language: 5.0431\n",
      "  of the: 2.3022\n",
      "  of the known: 5.0431\n",
      "  only: 3.6568\n",
      "  only logic: 5.0431\n",
      "  only logic programming: 5.0431\n",
      "  positive: 4.1268\n",
      "  positive and: 4.6376\n",
      "  positive and no: 5.0431\n",
      "  program: 3.7903\n",
      "  program that: 4.3499\n",
      "  program that entails: 5.0431\n",
      "  programming: 20.6338\n",
      "  programming as: 5.0431\n",
      "  programming as a: 5.0431\n",
      "  programming ilp: 5.0431\n",
      "  programming ilp is: 5.0431\n",
      "  programming is: 4.6376\n",
      "  programming is a: 5.0431\n",
      "  programming language: 5.0431\n",
      "  programming language for: 5.0431\n",
      "  programming such: 5.0431\n",
      "  programming such as: 5.0431\n",
      "  programs: 4.3499\n",
      "  related: 3.6568\n",
      "  related field: 4.6376\n",
      "  related field that: 5.0431\n",
      "  representation: 3.9444\n",
      "  representation for: 5.0431\n",
      "  representation for input: 5.0431\n",
      "  represented: 3.6568\n",
      "  represented as: 4.3499\n",
      "  represented as a: 4.3499\n",
      "  representing: 4.6376\n",
      "  representing hypotheses: 5.0431\n",
      "  representing hypotheses and: 5.0431\n",
      "  rule: 3.7903\n",
      "  rule learning: 3.9444\n",
      "  rule learning using: 5.0431\n",
      "  set: 2.6007\n",
      "  set of: 3.0281\n",
      "  set of examples: 4.6376\n",
      "  such: 2.4781\n",
      "  such as: 2.8458\n",
      "  such as functional: 5.0431\n",
      "  system: 3.0281\n",
      "  system will: 5.0431\n",
      "  system will derive: 5.0431\n",
      "  that: 3.3515\n",
      "  that considers: 5.0431\n",
      "  that considers any: 5.0431\n",
      "  that entails: 5.0431\n",
      "  that entails all: 5.0431\n",
      "  the: 1.1929\n",
      "  the known: 5.0431\n",
      "  the known background: 5.0431\n",
      "  to: 1.2253\n",
      "  to rule: 5.0431\n",
      "  to rule learning: 5.0431\n",
      "  uniform: 5.0431\n",
      "  uniform representation: 5.0431\n",
      "  uniform representation for: 5.0431\n",
      "  using: 3.2513\n",
      "  using logic: 5.0431\n",
      "  using logic programming: 5.0431\n",
      "  will: 3.7903\n",
      "  will derive: 5.0431\n",
      "  will derive a: 5.0431\n",
      "\n",
      "Document 62:\n",
      "  a: 6.2943\n",
      "  a logical: 4.6376\n",
      "  a logical setting: 5.0431\n",
      "  a prolog: 5.0431\n",
      "  a prolog program: 5.0431\n",
      "  a property: 5.0431\n",
      "  a property for: 5.0431\n",
      "  a theory: 4.6376\n",
      "  a theory to: 5.0431\n",
      "  a wellordered: 5.0431\n",
      "  a wellordered set: 5.0431\n",
      "  all: 3.5390\n",
      "  all members: 5.0431\n",
      "  all members of: 5.0431\n",
      "  and: 3.6432\n",
      "  and ehud: 5.0431\n",
      "  and ehud shapiro: 5.0431\n",
      "  and natural: 5.0431\n",
      "  and natural language: 5.0431\n",
      "  and negative: 5.0431\n",
      "  and negative examples: 5.0431\n",
      "  bioinformatics: 4.6376\n",
      "  bioinformatics and: 5.0431\n",
      "  bioinformatics and natural: 5.0431\n",
      "  built: 4.1268\n",
      "  built their: 5.0431\n",
      "  built their first: 5.0431\n",
      "  ehud: 5.0431\n",
      "  ehud shapiro: 5.0431\n",
      "  ehud shapiro laid: 5.0431\n",
      "  examples: 3.0971\n",
      "  examples the: 4.6376\n",
      "  examples the term: 5.0431\n",
      "  explain: 4.3499\n",
      "  explain observed: 5.0431\n",
      "  explain observed facts: 5.0431\n",
      "  facts: 4.6376\n",
      "  facts rather: 5.0431\n",
      "  facts rather than: 5.0431\n",
      "  first: 4.3499\n",
      "  first implementation: 5.0431\n",
      "  first implementation model: 5.0431\n",
      "  for: 3.4577\n",
      "  for all: 4.6376\n",
      "  for all members: 5.0431\n",
      "  for inductive: 5.0431\n",
      "  for inductive machine: 5.0431\n",
      "  foundation: 5.0431\n",
      "  foundation for: 5.0431\n",
      "  foundation for inductive: 5.0431\n",
      "  from: 2.0726\n",
      "  from positive: 5.0431\n",
      "  from positive and: 5.0431\n",
      "  gordon: 5.0431\n",
      "  gordon plotkin: 5.0431\n",
      "  gordon plotkin and: 5.0431\n",
      "  here: 5.0431\n",
      "  here refers: 5.0431\n",
      "  here refers to: 5.0431\n",
      "  implementation: 4.6376\n",
      "  implementation model: 5.0431\n",
      "  implementation model inference: 5.0431\n",
      "  in: 4.0252\n",
      "  in a: 6.1943\n",
      "  in a logical: 5.0431\n",
      "  in a prolog: 5.0431\n",
      "  in bioinformatics: 5.0431\n",
      "  in bioinformatics and: 5.0431\n",
      "  induction: 10.0861\n",
      "  induction proving: 5.0431\n",
      "  induction proving a: 5.0431\n",
      "  induction suggesting: 5.0431\n",
      "  induction suggesting a: 5.0431\n",
      "  inductive: 13.0497\n",
      "  inductive here: 5.0431\n",
      "  inductive here refers: 5.0431\n",
      "  inductive logic: 4.3499\n",
      "  inductive logic programming: 4.6376\n",
      "  inductive machine: 5.0431\n",
      "  inductive machine learning: 5.0431\n",
      "  inductively: 5.0431\n",
      "  inductively inferred: 5.0431\n",
      "  inductively inferred logic: 5.0431\n",
      "  inference: 4.3499\n",
      "  inference system: 5.0431\n",
      "  inference system in: 5.0431\n",
      "  inferred: 5.0431\n",
      "  inferred logic: 5.0431\n",
      "  inferred logic programs: 5.0431\n",
      "  initial: 4.6376\n",
      "  initial theoretical: 5.0431\n",
      "  initial theoretical foundation: 5.0431\n",
      "  is: 1.5167\n",
      "  is particularly: 4.6376\n",
      "  is particularly useful: 4.6376\n",
      "  laid: 5.0431\n",
      "  laid the: 5.0431\n",
      "  laid the initial: 5.0431\n",
      "  language: 3.9444\n",
      "  language processing: 4.6376\n",
      "  language processing gordon: 5.0431\n",
      "  learning: 1.2819\n",
      "  learning in: 3.6568\n",
      "  learning in a: 5.0431\n",
      "  logic: 8.2535\n",
      "  logic programming: 4.6376\n",
      "  logic programming is: 5.0431\n",
      "  logic programs: 5.0431\n",
      "  logic programs from: 5.0431\n",
      "  logical: 4.3499\n",
      "  logical setting: 5.0431\n",
      "  logical setting shapiro: 5.0431\n",
      "  machine: 1.4735\n",
      "  machine learning: 1.5618\n",
      "  machine learning in: 4.1268\n",
      "  mathematical: 3.5390\n",
      "  mathematical induction: 5.0431\n",
      "  mathematical induction proving: 5.0431\n",
      "  members: 4.3499\n",
      "  members of: 4.6376\n",
      "  members of a: 5.0431\n",
      "  model: 2.3350\n",
      "  model inference: 5.0431\n",
      "  model inference system: 5.0431\n",
      "  natural: 4.3499\n",
      "  natural language: 4.6376\n",
      "  natural language processing: 4.6376\n",
      "  negative: 3.9444\n",
      "  negative examples: 4.6376\n",
      "  negative examples the: 5.0431\n",
      "  observed: 4.3499\n",
      "  observed facts: 5.0431\n",
      "  observed facts rather: 5.0431\n",
      "  of: 1.2144\n",
      "  of a: 3.0281\n",
      "  of a wellordered: 5.0431\n",
      "  particularly: 4.1268\n",
      "  particularly useful: 4.6376\n",
      "  particularly useful in: 4.6376\n",
      "  philosophical: 5.0431\n",
      "  philosophical induction: 5.0431\n",
      "  philosophical induction suggesting: 5.0431\n",
      "  plotkin: 5.0431\n",
      "  plotkin and: 5.0431\n",
      "  plotkin and ehud: 5.0431\n",
      "  positive: 4.1268\n",
      "  positive and: 4.6376\n",
      "  positive and negative: 5.0431\n",
      "  processing: 3.6568\n",
      "  processing gordon: 5.0431\n",
      "  processing gordon plotkin: 5.0431\n",
      "  program: 3.7903\n",
      "  program that: 4.3499\n",
      "  program that inductively: 5.0431\n",
      "  programming: 4.1268\n",
      "  programming is: 4.6376\n",
      "  programming is particularly: 5.0431\n",
      "  programs: 4.3499\n",
      "  programs from: 5.0431\n",
      "  programs from positive: 5.0431\n",
      "  prolog: 5.0431\n",
      "  prolog program: 5.0431\n",
      "  prolog program that: 5.0431\n",
      "  property: 4.6376\n",
      "  property for: 5.0431\n",
      "  property for all: 5.0431\n",
      "  proving: 5.0431\n",
      "  proving a: 5.0431\n",
      "  proving a property: 5.0431\n",
      "  rather: 4.3499\n",
      "  rather than: 4.6376\n",
      "  rather than mathematical: 5.0431\n",
      "  refers: 4.1268\n",
      "  refers to: 4.1268\n",
      "  refers to philosophical: 5.0431\n",
      "  set: 2.6007\n",
      "  setting: 4.6376\n",
      "  setting shapiro: 5.0431\n",
      "  setting shapiro built: 5.0431\n",
      "  shapiro: 10.0861\n",
      "  shapiro built: 5.0431\n",
      "  shapiro built their: 5.0431\n",
      "  shapiro laid: 5.0431\n",
      "  shapiro laid the: 5.0431\n",
      "  suggesting: 5.0431\n",
      "  suggesting a: 5.0431\n",
      "  suggesting a theory: 5.0431\n",
      "  system: 3.0281\n",
      "  system in: 5.0431\n",
      "  system in a: 5.0431\n",
      "  term: 3.7903\n",
      "  term inductive: 5.0431\n",
      "  term inductive here: 5.0431\n",
      "  than: 4.1268\n",
      "  than mathematical: 5.0431\n",
      "  than mathematical induction: 5.0431\n",
      "  that: 1.6758\n",
      "  that inductively: 5.0431\n",
      "  that inductively inferred: 5.0431\n",
      "  the: 2.3858\n",
      "  the initial: 5.0431\n",
      "  the initial theoretical: 5.0431\n",
      "  the term: 3.9444\n",
      "  the term inductive: 5.0431\n",
      "  their: 2.7918\n",
      "  their first: 5.0431\n",
      "  their first implementation: 5.0431\n",
      "  theoretical: 3.6568\n",
      "  theoretical foundation: 5.0431\n",
      "  theoretical foundation for: 5.0431\n",
      "  theory: 3.3383\n",
      "  theory to: 5.0431\n",
      "  theory to explain: 5.0431\n",
      "  to: 2.4507\n",
      "  to explain: 5.0431\n",
      "  to explain observed: 5.0431\n",
      "  to philosophical: 5.0431\n",
      "  to philosophical induction: 5.0431\n",
      "  useful: 3.9444\n",
      "  useful in: 4.6376\n",
      "  useful in bioinformatics: 5.0431\n",
      "  wellordered: 5.0431\n",
      "  wellordered set: 5.0431\n",
      "\n",
      "Document 63:\n",
      "  a: 7.5532\n",
      "  a fully: 5.0431\n",
      "  a fully trained: 5.0431\n",
      "  a general: 4.1268\n",
      "  a general class: 5.0431\n",
      "  a given: 4.3499\n",
      "  a given dataset: 5.0431\n",
      "  a learning: 4.3499\n",
      "  a learning algorithm: 5.0431\n",
      "  a machine: 3.4336\n",
      "  a machine learning: 3.5390\n",
      "  a type: 4.6376\n",
      "  a type of: 4.6376\n",
      "  adjusts: 4.6376\n",
      "  adjusts the: 5.0431\n",
      "  adjusts the models: 5.0431\n",
      "  algorithm: 2.9030\n",
      "  algorithm iteratively: 5.0431\n",
      "  algorithm iteratively adjusts: 5.0431\n",
      "  algorithms: 2.3689\n",
      "  algorithms to: 4.6376\n",
      "  algorithms to a: 5.0431\n",
      "  all: 3.5390\n",
      "  all its: 5.0431\n",
      "  all its internal: 5.0431\n",
      "  and: 1.2144\n",
      "  and their: 3.9444\n",
      "  and their associated: 4.6376\n",
      "  associated: 3.7903\n",
      "  associated learning: 5.0431\n",
      "  associated learning algorithms: 5.0431\n",
      "  be: 2.0726\n",
      "  be used: 3.4336\n",
      "  be used to: 3.9444\n",
      "  by: 1.9076\n",
      "  by extension: 5.0431\n",
      "  by extension the: 5.0431\n",
      "  can: 4.3617\n",
      "  can be: 2.7405\n",
      "  can be used: 3.6568\n",
      "  can refer: 5.0431\n",
      "  can refer to: 5.0431\n",
      "  class: 3.5390\n",
      "  class of: 3.9444\n",
      "  class of models: 5.0431\n",
      "  classifications: 5.0431\n",
      "  classifications on: 5.0431\n",
      "  classifications on new: 5.0431\n",
      "  data: 1.8650\n",
      "  data during: 5.0431\n",
      "  data during training: 5.0431\n",
      "  dataset: 4.3499\n",
      "  dataset can: 4.6376\n",
      "  dataset can be: 4.6376\n",
      "  during: 4.1268\n",
      "  during training: 4.6376\n",
      "  during training a: 5.0431\n",
      "  errors: 4.6376\n",
      "  errors in: 4.6376\n",
      "  errors in its: 5.0431\n",
      "  extension: 5.0431\n",
      "  extension the: 5.0431\n",
      "  extension the term: 5.0431\n",
      "  from: 2.0726\n",
      "  from a: 3.7903\n",
      "  from a general: 5.0431\n",
      "  fully: 4.6376\n",
      "  fully trained: 5.0431\n",
      "  fully trained model: 5.0431\n",
      "  general: 3.9444\n",
      "  general class: 5.0431\n",
      "  general class of: 5.0431\n",
      "  given: 3.3383\n",
      "  given dataset: 5.0431\n",
      "  given dataset can: 5.0431\n",
      "  in: 1.3417\n",
      "  in its: 5.0431\n",
      "  in its predictions: 5.0431\n",
      "  internal: 8.6998\n",
      "  internal parameters: 10.0861\n",
      "  internal parameters to: 5.0431\n",
      "  internal parameters tuned: 5.0431\n",
      "  is: 1.5167\n",
      "  is a: 2.5173\n",
      "  is a type: 5.0431\n",
      "  iteratively: 5.0431\n",
      "  iteratively adjusts: 5.0431\n",
      "  iteratively adjusts the: 5.0431\n",
      "  its: 5.9272\n",
      "  its internal: 5.0431\n",
      "  its internal parameters: 5.0431\n",
      "  its predictions: 5.0431\n",
      "  its predictions by: 5.0431\n",
      "  learning: 3.8456\n",
      "  learning algorithm: 3.9444\n",
      "  learning algorithm iteratively: 5.0431\n",
      "  learning algorithms: 2.9030\n",
      "  learning algorithms to: 5.0431\n",
      "  learning model: 4.1268\n",
      "  learning model is: 5.0431\n",
      "  levels: 4.3499\n",
      "  levels of: 4.3499\n",
      "  levels of specificity: 5.0431\n",
      "  machine: 1.4735\n",
      "  machine learning: 1.5618\n",
      "  machine learning model: 4.3499\n",
      "  make: 3.3383\n",
      "  make predictions: 4.3499\n",
      "  make predictions or: 5.0431\n",
      "  mathematical: 3.5390\n",
      "  mathematical model: 4.1268\n",
      "  mathematical model that: 5.0431\n",
      "  minimise: 5.0431\n",
      "  minimise errors: 5.0431\n",
      "  minimise errors in: 5.0431\n",
      "  model: 9.3400\n",
      "  model can: 5.0431\n",
      "  model can refer: 5.0431\n",
      "  model is: 4.3499\n",
      "  model is a: 4.6376\n",
      "  model that: 4.1268\n",
      "  model that once: 5.0431\n",
      "  model with: 5.0431\n",
      "  model with all: 5.0431\n",
      "  models: 5.1163\n",
      "  models and: 5.0431\n",
      "  models and their: 5.0431\n",
      "  models internal: 5.0431\n",
      "  models internal parameters: 5.0431\n",
      "  new: 3.2513\n",
      "  new data: 5.0431\n",
      "  new data during: 5.0431\n",
      "  of: 3.6432\n",
      "  of mathematical: 5.0431\n",
      "  of mathematical model: 5.0431\n",
      "  of models: 4.6376\n",
      "  of models and: 5.0431\n",
      "  of specificity: 5.0431\n",
      "  of specificity from: 5.0431\n",
      "  on: 4.0946\n",
      "  on a: 3.5390\n",
      "  on a given: 5.0431\n",
      "  on new: 4.6376\n",
      "  on new data: 5.0431\n",
      "  once: 4.3499\n",
      "  once trained: 5.0431\n",
      "  once trained on: 5.0431\n",
      "  or: 2.0226\n",
      "  or classifications: 5.0431\n",
      "  or classifications on: 5.0431\n",
      "  parameters: 10.0861\n",
      "  parameters to: 5.0431\n",
      "  parameters to minimise: 5.0431\n",
      "  parameters tuned: 5.0431\n",
      "  predictions: 6.6766\n",
      "  predictions by: 5.0431\n",
      "  predictions by extension: 5.0431\n",
      "  predictions or: 5.0431\n",
      "  predictions or classifications: 5.0431\n",
      "  refer: 5.0431\n",
      "  refer to: 5.0431\n",
      "  refer to several: 5.0431\n",
      "  several: 3.9444\n",
      "  several levels: 5.0431\n",
      "  several levels of: 5.0431\n",
      "  specificity: 4.6376\n",
      "  specificity from: 5.0431\n",
      "  specificity from a: 5.0431\n",
      "  term: 3.7903\n",
      "  term model: 5.0431\n",
      "  term model can: 5.0431\n",
      "  that: 1.6758\n",
      "  that once: 5.0431\n",
      "  that once trained: 5.0431\n",
      "  the: 2.3858\n",
      "  the models: 5.0431\n",
      "  the models internal: 5.0431\n",
      "  the term: 3.9444\n",
      "  the term model: 5.0431\n",
      "  their: 2.7918\n",
      "  their associated: 4.6376\n",
      "  their associated learning: 5.0431\n",
      "  to: 4.9014\n",
      "  to a: 3.1712\n",
      "  to a fully: 5.0431\n",
      "  to make: 3.9444\n",
      "  to make predictions: 4.3499\n",
      "  to minimise: 5.0431\n",
      "  to minimise errors: 5.0431\n",
      "  to several: 5.0431\n",
      "  to several levels: 5.0431\n",
      "  trained: 6.6766\n",
      "  trained model: 5.0431\n",
      "  trained model with: 5.0431\n",
      "  trained on: 3.9444\n",
      "  trained on a: 5.0431\n",
      "  training: 2.5581\n",
      "  training a: 4.1268\n",
      "  training a learning: 5.0431\n",
      "  tuned: 5.0431\n",
      "  type: 4.1268\n",
      "  type of: 4.1268\n",
      "  type of mathematical: 5.0431\n",
      "  used: 2.3350\n",
      "  used to: 3.3383\n",
      "  used to make: 5.0431\n",
      "  with: 2.0726\n",
      "  with all: 5.0431\n",
      "  with all its: 5.0431\n",
      "\n",
      "Document 64:\n",
      "  a: 1.2589\n",
      "  a task: 5.0431\n",
      "  a task is: 5.0431\n",
      "  and: 1.2144\n",
      "  and researched: 5.0431\n",
      "  and researched for: 5.0431\n",
      "  been: 2.6917\n",
      "  been used: 3.9444\n",
      "  been used and: 5.0431\n",
      "  best: 3.6568\n",
      "  best model: 5.0431\n",
      "  best model for: 5.0431\n",
      "  called: 3.2513\n",
      "  called model: 5.0431\n",
      "  called model selection: 5.0431\n",
      "  for: 3.4577\n",
      "  for a: 4.6376\n",
      "  for a task: 5.0431\n",
      "  for machine: 3.9444\n",
      "  for machine learning: 4.1268\n",
      "  have: 2.4781\n",
      "  have been: 3.5390\n",
      "  have been used: 4.3499\n",
      "  is: 1.5167\n",
      "  is called: 4.6376\n",
      "  is called model: 5.0431\n",
      "  learning: 1.2819\n",
      "  learning systems: 5.0431\n",
      "  learning systems picking: 5.0431\n",
      "  machine: 1.4735\n",
      "  machine learning: 1.5618\n",
      "  machine learning systems: 5.0431\n",
      "  model: 4.6700\n",
      "  model for: 5.0431\n",
      "  model for a: 5.0431\n",
      "  model selection: 5.0431\n",
      "  models: 2.5581\n",
      "  models have: 5.0431\n",
      "  models have been: 5.0431\n",
      "  of: 1.2144\n",
      "  of models: 4.6376\n",
      "  of models have: 5.0431\n",
      "  picking: 5.0431\n",
      "  picking the: 5.0431\n",
      "  picking the best: 5.0431\n",
      "  researched: 5.0431\n",
      "  researched for: 5.0431\n",
      "  researched for machine: 5.0431\n",
      "  selection: 4.1268\n",
      "  systems: 2.6917\n",
      "  systems picking: 5.0431\n",
      "  systems picking the: 5.0431\n",
      "  task: 3.9444\n",
      "  task is: 4.6376\n",
      "  task is called: 5.0431\n",
      "  the: 1.1929\n",
      "  the best: 4.1268\n",
      "  the best model: 5.0431\n",
      "  types: 4.3499\n",
      "  types of: 4.3499\n",
      "  types of models: 5.0431\n",
      "  used: 2.3350\n",
      "  used and: 5.0431\n",
      "  used and researched: 5.0431\n",
      "  various: 3.4336\n",
      "  various types: 5.0431\n",
      "  various types of: 5.0431\n",
      "\n",
      "Document 65:\n",
      "  animal: 5.0431\n",
      "  animal brains: 5.0431\n",
      "  animal brains such: 5.0431\n",
      "  anns: 5.0431\n",
      "  anns or: 5.0431\n",
      "  anns or connectionist: 5.0431\n",
      "  any: 3.6568\n",
      "  any taskspecific: 5.0431\n",
      "  any taskspecific rules: 5.0431\n",
      "  are: 1.9750\n",
      "  are computing: 5.0431\n",
      "  are computing systems: 5.0431\n",
      "  artificial: 2.7918\n",
      "  artificial neural: 3.7903\n",
      "  artificial neural networks: 4.1268\n",
      "  being: 3.7903\n",
      "  being programmed: 5.0431\n",
      "  being programmed with: 5.0431\n",
      "  biological: 4.3499\n",
      "  biological neural: 4.6376\n",
      "  biological neural networks: 4.6376\n",
      "  brains: 5.0431\n",
      "  brains such: 5.0431\n",
      "  brains such systems: 5.0431\n",
      "  by: 3.8151\n",
      "  by considering: 5.0431\n",
      "  by considering examples: 5.0431\n",
      "  by the: 3.2513\n",
      "  by the biological: 5.0431\n",
      "  computing: 3.9444\n",
      "  computing systems: 4.6376\n",
      "  computing systems vaguely: 5.0431\n",
      "  connectionist: 5.0431\n",
      "  connectionist systems: 5.0431\n",
      "  connectionist systems are: 5.0431\n",
      "  considering: 4.6376\n",
      "  considering examples: 5.0431\n",
      "  considering examples generally: 5.0431\n",
      "  constitute: 5.0431\n",
      "  constitute animal: 5.0431\n",
      "  constitute animal brains: 5.0431\n",
      "  examples: 3.0971\n",
      "  examples generally: 5.0431\n",
      "  examples generally without: 5.0431\n",
      "  generally: 4.6376\n",
      "  generally without: 5.0431\n",
      "  generally without being: 5.0431\n",
      "  inspired: 4.3499\n",
      "  inspired by: 4.3499\n",
      "  inspired by the: 5.0431\n",
      "  learn: 3.3383\n",
      "  learn to: 5.0431\n",
      "  learn to perform: 5.0431\n",
      "  networks: 6.1943\n",
      "  networks anns: 5.0431\n",
      "  networks anns or: 5.0431\n",
      "  networks that: 4.3499\n",
      "  networks that constitute: 5.0431\n",
      "  neural: 6.0563\n",
      "  neural networks: 6.5026\n",
      "  neural networks anns: 5.0431\n",
      "  neural networks that: 4.6376\n",
      "  or: 2.0226\n",
      "  or connectionist: 5.0431\n",
      "  or connectionist systems: 5.0431\n",
      "  perform: 3.2513\n",
      "  perform tasks: 4.6376\n",
      "  perform tasks by: 5.0431\n",
      "  programmed: 5.0431\n",
      "  programmed with: 5.0431\n",
      "  programmed with any: 5.0431\n",
      "  rules: 3.6568\n",
      "  such: 2.4781\n",
      "  such systems: 5.0431\n",
      "  such systems learn: 5.0431\n",
      "  systems: 8.0750\n",
      "  systems are: 5.0431\n",
      "  systems are computing: 5.0431\n",
      "  systems learn: 5.0431\n",
      "  systems learn to: 5.0431\n",
      "  systems vaguely: 5.0431\n",
      "  systems vaguely inspired: 5.0431\n",
      "  tasks: 3.4336\n",
      "  tasks by: 5.0431\n",
      "  tasks by considering: 5.0431\n",
      "  taskspecific: 5.0431\n",
      "  taskspecific rules: 5.0431\n",
      "  that: 1.6758\n",
      "  that constitute: 5.0431\n",
      "  that constitute animal: 5.0431\n",
      "  the: 1.1929\n",
      "  the biological: 5.0431\n",
      "  the biological neural: 5.0431\n",
      "  to: 1.2253\n",
      "  to perform: 3.9444\n",
      "  to perform tasks: 5.0431\n",
      "  vaguely: 5.0431\n",
      "  vaguely inspired: 5.0431\n",
      "  vaguely inspired by: 5.0431\n",
      "  with: 2.0726\n",
      "  with any: 5.0431\n",
      "  with any taskspecific: 5.0431\n",
      "  without: 3.3383\n",
      "  without being: 5.0431\n",
      "  without being programmed: 5.0431\n",
      "\n",
      "Document 66:\n",
      "  a: 13.8475\n",
      "  a biological: 10.0861\n",
      "  a biological brain: 10.0861\n",
      "  a collection: 4.6376\n",
      "  a collection of: 4.6376\n",
      "  a connection: 9.2752\n",
      "  a connection artificial: 5.0431\n",
      "  a connection between: 5.0431\n",
      "  a model: 3.9444\n",
      "  a model based: 5.0431\n",
      "  a real: 5.0431\n",
      "  a real number: 5.0431\n",
      "  a signal: 10.0861\n",
      "  a signal can: 5.0431\n",
      "  a signal from: 5.0431\n",
      "  a threshold: 5.0431\n",
      "  a threshold such: 5.0431\n",
      "  a weight: 5.0431\n",
      "  a weight that: 5.0431\n",
      "  additional: 4.3499\n",
      "  additional artificial: 5.0431\n",
      "  additional artificial neurons: 5.0431\n",
      "  adjusts: 4.6376\n",
      "  adjusts as: 5.0431\n",
      "  adjusts as learning: 5.0431\n",
      "  after: 3.7903\n",
      "  after traversing: 5.0431\n",
      "  after traversing the: 5.0431\n",
      "  aggregate: 5.0431\n",
      "  aggregate signal: 5.0431\n",
      "  aggregate signal crosses: 5.0431\n",
      "  aggregated: 4.6376\n",
      "  aggregated into: 5.0431\n",
      "  aggregated into layers: 5.0431\n",
      "  an: 4.3054\n",
      "  an ann: 5.0431\n",
      "  an ann is: 5.0431\n",
      "  an artificial: 4.3499\n",
      "  an artificial neuron: 5.0431\n",
      "  and: 3.6432\n",
      "  and edges: 5.0431\n",
      "  and edges typically: 5.0431\n",
      "  and the: 3.3383\n",
      "  and the output: 4.6376\n",
      "  and then: 4.3499\n",
      "  and then signal: 5.0431\n",
      "  ann: 9.2752\n",
      "  ann implementations: 5.0431\n",
      "  ann implementations the: 5.0431\n",
      "  ann is: 5.0431\n",
      "  ann is a: 5.0431\n",
      "  another: 4.1268\n",
      "  another an: 5.0431\n",
      "  another an artificial: 5.0431\n",
      "  are: 3.9500\n",
      "  are aggregated: 5.0431\n",
      "  are aggregated into: 5.0431\n",
      "  are called: 4.3499\n",
      "  are called edges: 5.0431\n",
      "  artificial: 27.9176\n",
      "  artificial neuron: 15.1292\n",
      "  artificial neuron is: 5.0431\n",
      "  artificial neuron that: 5.0431\n",
      "  artificial neuron to: 5.0431\n",
      "  artificial neurons: 32.4631\n",
      "  artificial neurons and: 5.0431\n",
      "  artificial neurons are: 10.0861\n",
      "  artificial neurons connected: 5.0431\n",
      "  artificial neurons is: 5.0431\n",
      "  artificial neurons may: 5.0431\n",
      "  artificial neurons which: 5.0431\n",
      "  as: 1.8444\n",
      "  as learning: 5.0431\n",
      "  as learning proceeds: 5.0431\n",
      "  at: 7.8889\n",
      "  at a: 9.2752\n",
      "  at a connection: 10.0861\n",
      "  based: 3.4336\n",
      "  based on: 3.4336\n",
      "  based on a: 5.0431\n",
      "  between: 5.9272\n",
      "  between artificial: 10.0861\n",
      "  between artificial neurons: 10.0861\n",
      "  biological: 8.6998\n",
      "  biological brain: 10.0861\n",
      "  biological brain can: 5.0431\n",
      "  biological brain each: 5.0431\n",
      "  brain: 8.6998\n",
      "  brain can: 5.0431\n",
      "  brain can transmit: 5.0431\n",
      "  brain each: 5.0431\n",
      "  brain each connection: 5.0431\n",
      "  by: 1.9076\n",
      "  by some: 4.6376\n",
      "  by some nonlinear: 5.0431\n",
      "  called: 6.5026\n",
      "  called artificial: 5.0431\n",
      "  called artificial neurons: 5.0431\n",
      "  called edges: 5.0431\n",
      "  called edges artificial: 5.0431\n",
      "  can: 4.3617\n",
      "  can process: 5.0431\n",
      "  can process it: 5.0431\n",
      "  can transmit: 5.0431\n",
      "  can transmit information: 5.0431\n",
      "  collection: 4.1268\n",
      "  collection of: 4.1268\n",
      "  collection of connected: 5.0431\n",
      "  common: 3.9444\n",
      "  common ann: 5.0431\n",
      "  common ann implementations: 5.0431\n",
      "  computed: 4.6376\n",
      "  computed by: 4.6376\n",
      "  computed by some: 5.0431\n",
      "  connected: 10.0861\n",
      "  connected to: 5.0431\n",
      "  connected to it: 5.0431\n",
      "  connected units: 5.0431\n",
      "  connected units or: 5.0431\n",
      "  connection: 13.0497\n",
      "  connection artificial: 5.0431\n",
      "  connection artificial neurons: 5.0431\n",
      "  connection between: 4.6376\n",
      "  connection between artificial: 5.0431\n",
      "  connection like: 5.0431\n",
      "  connection like the: 5.0431\n",
      "  connections: 4.6376\n",
      "  connections between: 5.0431\n",
      "  connections between artificial: 5.0431\n",
      "  crosses: 5.0431\n",
      "  crosses that: 5.0431\n",
      "  crosses that threshold: 5.0431\n",
      "  decreases: 4.6376\n",
      "  decreases the: 5.0431\n",
      "  decreases the strength: 5.0431\n",
      "  different: 7.8889\n",
      "  different kinds: 5.0431\n",
      "  different kinds of: 5.0431\n",
      "  different layers: 5.0431\n",
      "  different layers may: 5.0431\n",
      "  each: 6.1943\n",
      "  each artificial: 5.0431\n",
      "  each artificial neuron: 5.0431\n",
      "  each connection: 5.0431\n",
      "  each connection like: 5.0431\n",
      "  edges: 10.0861\n",
      "  edges artificial: 5.0431\n",
      "  edges artificial neurons: 5.0431\n",
      "  edges typically: 5.0431\n",
      "  edges typically have: 5.0431\n",
      "  first: 4.3499\n",
      "  first layer: 5.0431\n",
      "  first layer the: 5.0431\n",
      "  from: 4.1453\n",
      "  from one: 5.0431\n",
      "  from one artificial: 5.0431\n",
      "  from the: 3.3383\n",
      "  from the first: 5.0431\n",
      "  function: 3.4336\n",
      "  function of: 4.3499\n",
      "  function of the: 5.0431\n",
      "  have: 4.9562\n",
      "  have a: 8.6998\n",
      "  have a threshold: 5.0431\n",
      "  have a weight: 5.0431\n",
      "  if: 3.6568\n",
      "  if the: 4.6376\n",
      "  if the aggregate: 5.0431\n",
      "  implementations: 4.6376\n",
      "  implementations the: 5.0431\n",
      "  implementations the signal: 5.0431\n",
      "  in: 4.0252\n",
      "  in a: 6.1943\n",
      "  in a biological: 10.0861\n",
      "  in common: 5.0431\n",
      "  in common ann: 5.0431\n",
      "  increases: 4.6376\n",
      "  increases or: 5.0431\n",
      "  increases or decreases: 5.0431\n",
      "  information: 3.7903\n",
      "  information a: 5.0431\n",
      "  information a signal: 5.0431\n",
      "  input: 3.0281\n",
      "  input layer: 5.0431\n",
      "  input layer to: 5.0431\n",
      "  inputs: 8.2535\n",
      "  inputs signals: 5.0431\n",
      "  inputs signals travel: 5.0431\n",
      "  inputs the: 5.0431\n",
      "  inputs the connections: 5.0431\n",
      "  into: 2.9636\n",
      "  into layers: 5.0431\n",
      "  into layers different: 5.0431\n",
      "  is: 6.0668\n",
      "  is a: 5.0346\n",
      "  is a model: 5.0431\n",
      "  is a real: 5.0431\n",
      "  is computed: 5.0431\n",
      "  is computed by: 5.0431\n",
      "  is only: 5.0431\n",
      "  is only sent: 5.0431\n",
      "  it: 4.5409\n",
      "  it and: 5.0431\n",
      "  it and then: 5.0431\n",
      "  it in: 4.6376\n",
      "  it in common: 5.0431\n",
      "  its: 2.9636\n",
      "  its inputs: 5.0431\n",
      "  its inputs the: 5.0431\n",
      "  kinds: 4.6376\n",
      "  kinds of: 4.6376\n",
      "  kinds of transformations: 5.0431\n",
      "  last: 5.0431\n",
      "  last layer: 5.0431\n",
      "  last layer the: 5.0431\n",
      "  layer: 20.1722\n",
      "  layer possibly: 5.0431\n",
      "  layer possibly after: 5.0431\n",
      "  layer the: 10.0861\n",
      "  layer the input: 5.0431\n",
      "  layer the output: 5.0431\n",
      "  layer to: 5.0431\n",
      "  layer to the: 5.0431\n",
      "  layers: 13.0497\n",
      "  layers different: 5.0431\n",
      "  layers different layers: 5.0431\n",
      "  layers may: 5.0431\n",
      "  layers may perform: 5.0431\n",
      "  layers multiple: 5.0431\n",
      "  layers multiple times: 5.0431\n",
      "  learning: 1.2819\n",
      "  learning proceeds: 5.0431\n",
      "  learning proceeds the: 5.0431\n",
      "  like: 3.3383\n",
      "  like the: 4.3499\n",
      "  like the synapses: 5.0431\n",
      "  loosely: 5.0431\n",
      "  loosely model: 5.0431\n",
      "  loosely model the: 5.0431\n",
      "  may: 6.5026\n",
      "  may have: 4.6376\n",
      "  may have a: 5.0431\n",
      "  may perform: 5.0431\n",
      "  may perform different: 5.0431\n",
      "  model: 4.6700\n",
      "  model based: 5.0431\n",
      "  model based on: 5.0431\n",
      "  model the: 4.3499\n",
      "  model the neurons: 5.0431\n",
      "  multiple: 3.9444\n",
      "  multiple times: 5.0431\n",
      "  neuron: 15.1292\n",
      "  neuron is: 5.0431\n",
      "  neuron is computed: 5.0431\n",
      "  neuron that: 5.0431\n",
      "  neuron that receives: 5.0431\n",
      "  neuron to: 5.0431\n",
      "  neuron to another: 5.0431\n",
      "  neurons: 37.1007\n",
      "  neurons and: 5.0431\n",
      "  neurons and edges: 5.0431\n",
      "  neurons are: 10.0861\n",
      "  neurons are aggregated: 5.0431\n",
      "  neurons are called: 5.0431\n",
      "  neurons connected: 5.0431\n",
      "  neurons connected to: 5.0431\n",
      "  neurons in: 5.0431\n",
      "  neurons in a: 5.0431\n",
      "  neurons is: 5.0431\n",
      "  neurons is a: 5.0431\n",
      "  neurons may: 5.0431\n",
      "  neurons may have: 5.0431\n",
      "  neurons which: 5.0431\n",
      "  neurons which loosely: 5.0431\n",
      "  nodes: 4.6376\n",
      "  nodes called: 5.0431\n",
      "  nodes called artificial: 5.0431\n",
      "  nonlinear: 3.9444\n",
      "  nonlinear function: 5.0431\n",
      "  nonlinear function of: 5.0431\n",
      "  number: 4.1268\n",
      "  number and: 5.0431\n",
      "  number and the: 5.0431\n",
      "  of: 7.2865\n",
      "  of connected: 5.0431\n",
      "  of connected units: 5.0431\n",
      "  of each: 5.0431\n",
      "  of each artificial: 5.0431\n",
      "  of its: 3.9444\n",
      "  of its inputs: 5.0431\n",
      "  of the: 4.6044\n",
      "  of the signal: 4.6376\n",
      "  of the sum: 5.0431\n",
      "  of transformations: 5.0431\n",
      "  of transformations on: 5.0431\n",
      "  on: 4.0946\n",
      "  on a: 3.5390\n",
      "  on a collection: 5.0431\n",
      "  on their: 4.6376\n",
      "  on their inputs: 5.0431\n",
      "  one: 3.0971\n",
      "  one artificial: 5.0431\n",
      "  one artificial neuron: 5.0431\n",
      "  only: 3.6568\n",
      "  only sent: 5.0431\n",
      "  only sent if: 5.0431\n",
      "  or: 4.0453\n",
      "  or decreases: 5.0431\n",
      "  or decreases the: 5.0431\n",
      "  or nodes: 5.0431\n",
      "  or nodes called: 5.0431\n",
      "  output: 6.6766\n",
      "  output layer: 5.0431\n",
      "  output layer possibly: 5.0431\n",
      "  output of: 4.6376\n",
      "  output of each: 5.0431\n",
      "  perform: 3.2513\n",
      "  perform different: 5.0431\n",
      "  perform different kinds: 5.0431\n",
      "  possibly: 4.6376\n",
      "  possibly after: 5.0431\n",
      "  possibly after traversing: 5.0431\n",
      "  proceeds: 5.0431\n",
      "  proceeds the: 5.0431\n",
      "  proceeds the weight: 5.0431\n",
      "  process: 3.4336\n",
      "  process it: 5.0431\n",
      "  process it and: 5.0431\n",
      "  real: 4.3499\n",
      "  real number: 5.0431\n",
      "  real number and: 5.0431\n",
      "  receives: 4.6376\n",
      "  receives a: 5.0431\n",
      "  receives a signal: 5.0431\n",
      "  sent: 5.0431\n",
      "  sent if: 5.0431\n",
      "  sent if the: 5.0431\n",
      "  signal: 27.6111\n",
      "  signal additional: 5.0431\n",
      "  signal additional artificial: 5.0431\n",
      "  signal at: 10.0861\n",
      "  signal at a: 10.0861\n",
      "  signal can: 5.0431\n",
      "  signal can process: 5.0431\n",
      "  signal crosses: 5.0431\n",
      "  signal crosses that: 5.0431\n",
      "  signal from: 4.6376\n",
      "  signal from one: 5.0431\n",
      "  signal is: 5.0431\n",
      "  signal is only: 5.0431\n",
      "  signals: 4.3499\n",
      "  signals travel: 5.0431\n",
      "  signals travel from: 5.0431\n",
      "  some: 2.9636\n",
      "  some nonlinear: 5.0431\n",
      "  some nonlinear function: 5.0431\n",
      "  strength: 5.0431\n",
      "  strength of: 5.0431\n",
      "  strength of the: 5.0431\n",
      "  such: 2.4781\n",
      "  such that: 4.3499\n",
      "  such that the: 5.0431\n",
      "  sum: 5.0431\n",
      "  sum of: 5.0431\n",
      "  sum of its: 5.0431\n",
      "  synapses: 4.6376\n",
      "  synapses in: 5.0431\n",
      "  synapses in a: 5.0431\n",
      "  that: 6.7030\n",
      "  that adjusts: 5.0431\n",
      "  that adjusts as: 5.0431\n",
      "  that receives: 5.0431\n",
      "  that receives a: 5.0431\n",
      "  that the: 3.9444\n",
      "  that the signal: 5.0431\n",
      "  that threshold: 5.0431\n",
      "  that threshold typically: 5.0431\n",
      "  the: 19.0865\n",
      "  the aggregate: 5.0431\n",
      "  the aggregate signal: 5.0431\n",
      "  the connections: 5.0431\n",
      "  the connections between: 5.0431\n",
      "  the first: 4.6376\n",
      "  the first layer: 5.0431\n",
      "  the input: 4.6376\n",
      "  the input layer: 5.0431\n",
      "  the last: 5.0431\n",
      "  the last layer: 5.0431\n",
      "  the layers: 5.0431\n",
      "  the layers multiple: 5.0431\n",
      "  the neurons: 5.0431\n",
      "  the neurons in: 5.0431\n",
      "  the output: 7.8889\n",
      "  the output layer: 5.0431\n",
      "  the output of: 5.0431\n",
      "  the signal: 13.9128\n",
      "  the signal at: 10.0861\n",
      "  the signal is: 5.0431\n",
      "  the strength: 5.0431\n",
      "  the strength of: 5.0431\n",
      "  the sum: 5.0431\n",
      "  the sum of: 5.0431\n",
      "  the synapses: 5.0431\n",
      "  the synapses in: 5.0431\n",
      "  the weight: 4.6376\n",
      "  the weight increases: 5.0431\n",
      "  their: 2.7918\n",
      "  their inputs: 4.6376\n",
      "  their inputs signals: 5.0431\n",
      "  then: 3.9444\n",
      "  then signal: 5.0431\n",
      "  then signal additional: 5.0431\n",
      "  threshold: 10.0861\n",
      "  threshold such: 5.0431\n",
      "  threshold such that: 5.0431\n",
      "  threshold typically: 5.0431\n",
      "  threshold typically artificial: 5.0431\n",
      "  times: 5.0431\n",
      "  to: 3.6760\n",
      "  to another: 5.0431\n",
      "  to another an: 5.0431\n",
      "  to it: 5.0431\n",
      "  to it in: 5.0431\n",
      "  to the: 3.1712\n",
      "  to the last: 5.0431\n",
      "  transformations: 5.0431\n",
      "  transformations on: 5.0431\n",
      "  transformations on their: 5.0431\n",
      "  transmit: 5.0431\n",
      "  transmit information: 5.0431\n",
      "  transmit information a: 5.0431\n",
      "  travel: 5.0431\n",
      "  travel from: 5.0431\n",
      "  travel from the: 5.0431\n",
      "  traversing: 5.0431\n",
      "  traversing the: 5.0431\n",
      "  traversing the layers: 5.0431\n",
      "  typically: 7.0779\n",
      "  typically artificial: 5.0431\n",
      "  typically artificial neurons: 5.0431\n",
      "  typically have: 5.0431\n",
      "  typically have a: 5.0431\n",
      "  units: 4.3499\n",
      "  units or: 5.0431\n",
      "  units or nodes: 5.0431\n",
      "  weight: 9.2752\n",
      "  weight increases: 5.0431\n",
      "  weight increases or: 5.0431\n",
      "  weight that: 5.0431\n",
      "  weight that adjusts: 5.0431\n",
      "  which: 2.6917\n",
      "  which loosely: 5.0431\n",
      "  which loosely model: 5.0431\n",
      "\n",
      "Document 67:\n",
      "  a: 2.5177\n",
      "  a human: 4.3499\n",
      "  a human brain: 5.0431\n",
      "  a variety: 4.6376\n",
      "  a variety of: 4.6376\n",
      "  and: 2.4288\n",
      "  and medical: 5.0431\n",
      "  and medical diagnosis: 5.0431\n",
      "  and video: 5.0431\n",
      "  and video games: 5.0431\n",
      "  ann: 4.6376\n",
      "  ann approach: 5.0431\n",
      "  ann approach was: 5.0431\n",
      "  approach: 3.6568\n",
      "  approach was: 5.0431\n",
      "  approach was to: 5.0431\n",
      "  artificial: 2.7918\n",
      "  artificial neural: 3.7903\n",
      "  artificial neural networks: 4.1268\n",
      "  attention: 5.0431\n",
      "  attention moved: 5.0431\n",
      "  attention moved to: 5.0431\n",
      "  been: 2.6917\n",
      "  been used: 3.9444\n",
      "  been used on: 5.0431\n",
      "  biology: 5.0431\n",
      "  biology artificial: 5.0431\n",
      "  biology artificial neural: 5.0431\n",
      "  board: 5.0431\n",
      "  board and: 5.0431\n",
      "  board and video: 5.0431\n",
      "  brain: 4.3499\n",
      "  brain would: 5.0431\n",
      "  brain would however: 5.0431\n",
      "  computer: 3.2513\n",
      "  computer vision: 4.1268\n",
      "  computer vision speech: 4.6376\n",
      "  deviations: 4.6376\n",
      "  deviations from: 5.0431\n",
      "  deviations from biology: 5.0431\n",
      "  diagnosis: 4.6376\n",
      "  filtering: 4.6376\n",
      "  filtering playing: 5.0431\n",
      "  filtering playing board: 5.0431\n",
      "  from: 2.0726\n",
      "  from biology: 5.0431\n",
      "  from biology artificial: 5.0431\n",
      "  games: 5.0431\n",
      "  games and: 5.0431\n",
      "  games and medical: 5.0431\n",
      "  goal: 4.1268\n",
      "  goal of: 5.0431\n",
      "  goal of the: 5.0431\n",
      "  have: 2.4781\n",
      "  have been: 3.5390\n",
      "  have been used: 4.3499\n",
      "  however: 3.7903\n",
      "  however over: 5.0431\n",
      "  however over time: 5.0431\n",
      "  human: 3.6568\n",
      "  human brain: 4.6376\n",
      "  human brain would: 5.0431\n",
      "  in: 1.3417\n",
      "  in the: 2.4404\n",
      "  in the same: 5.0431\n",
      "  including: 3.4336\n",
      "  including computer: 5.0431\n",
      "  including computer vision: 5.0431\n",
      "  leading: 4.1268\n",
      "  leading to: 4.1268\n",
      "  leading to deviations: 5.0431\n",
      "  machine: 1.4735\n",
      "  machine translation: 5.0431\n",
      "  machine translation social: 5.0431\n",
      "  medical: 3.7903\n",
      "  medical diagnosis: 4.6376\n",
      "  moved: 5.0431\n",
      "  moved to: 5.0431\n",
      "  moved to performing: 5.0431\n",
      "  network: 3.5390\n",
      "  network filtering: 5.0431\n",
      "  network filtering playing: 5.0431\n",
      "  networks: 3.0971\n",
      "  networks have: 5.0431\n",
      "  networks have been: 5.0431\n",
      "  neural: 3.0281\n",
      "  neural networks: 3.2513\n",
      "  neural networks have: 5.0431\n",
      "  of: 2.4288\n",
      "  of tasks: 4.6376\n",
      "  of tasks including: 5.0431\n",
      "  of the: 2.3022\n",
      "  of the ann: 5.0431\n",
      "  on: 2.0473\n",
      "  on a: 3.5390\n",
      "  on a variety: 5.0431\n",
      "  original: 4.6376\n",
      "  original goal: 5.0431\n",
      "  original goal of: 5.0431\n",
      "  over: 4.3499\n",
      "  over time: 4.3499\n",
      "  over time attention: 5.0431\n",
      "  performing: 3.9444\n",
      "  performing specific: 5.0431\n",
      "  performing specific tasks: 5.0431\n",
      "  playing: 5.0431\n",
      "  playing board: 5.0431\n",
      "  playing board and: 5.0431\n",
      "  problems: 3.1712\n",
      "  problems in: 5.0431\n",
      "  problems in the: 5.0431\n",
      "  recognition: 3.9444\n",
      "  recognition machine: 5.0431\n",
      "  recognition machine translation: 5.0431\n",
      "  same: 3.9444\n",
      "  same way: 5.0431\n",
      "  same way that: 5.0431\n",
      "  social: 4.6376\n",
      "  social network: 5.0431\n",
      "  social network filtering: 5.0431\n",
      "  solve: 4.3499\n",
      "  solve problems: 5.0431\n",
      "  solve problems in: 5.0431\n",
      "  specific: 3.7903\n",
      "  specific tasks: 5.0431\n",
      "  specific tasks leading: 5.0431\n",
      "  speech: 3.9444\n",
      "  speech recognition: 4.3499\n",
      "  speech recognition machine: 5.0431\n",
      "  tasks: 6.8672\n",
      "  tasks including: 5.0431\n",
      "  tasks including computer: 5.0431\n",
      "  tasks leading: 5.0431\n",
      "  tasks leading to: 5.0431\n",
      "  that: 1.6758\n",
      "  that a: 4.1268\n",
      "  that a human: 5.0431\n",
      "  the: 3.5787\n",
      "  the ann: 5.0431\n",
      "  the ann approach: 5.0431\n",
      "  the original: 4.6376\n",
      "  the original goal: 5.0431\n",
      "  the same: 3.9444\n",
      "  the same way: 5.0431\n",
      "  time: 3.5390\n",
      "  time attention: 5.0431\n",
      "  time attention moved: 5.0431\n",
      "  to: 3.6760\n",
      "  to deviations: 5.0431\n",
      "  to deviations from: 5.0431\n",
      "  to performing: 4.6376\n",
      "  to performing specific: 5.0431\n",
      "  to solve: 4.6376\n",
      "  to solve problems: 5.0431\n",
      "  translation: 5.0431\n",
      "  translation social: 5.0431\n",
      "  translation social network: 5.0431\n",
      "  used: 2.3350\n",
      "  used on: 5.0431\n",
      "  used on a: 5.0431\n",
      "  variety: 4.3499\n",
      "  variety of: 4.3499\n",
      "  variety of tasks: 5.0431\n",
      "  video: 4.6376\n",
      "  video games: 5.0431\n",
      "  video games and: 5.0431\n",
      "  vision: 4.1268\n",
      "  vision speech: 4.6376\n",
      "  vision speech recognition: 4.6376\n",
      "  was: 3.3383\n",
      "  was to: 5.0431\n",
      "  was to solve: 5.0431\n",
      "  way: 3.9444\n",
      "  way that: 4.6376\n",
      "  way that a: 5.0431\n",
      "  would: 3.9444\n",
      "  would however: 5.0431\n",
      "  would however over: 5.0431\n",
      "\n",
      "Document 68:\n",
      "  an: 2.1527\n",
      "  an artificial: 4.3499\n",
      "  an artificial neural: 4.6376\n",
      "  and: 3.6432\n",
      "  and hearing: 5.0431\n",
      "  and hearing some: 5.0431\n",
      "  and sound: 5.0431\n",
      "  and sound into: 5.0431\n",
      "  and speech: 4.6376\n",
      "  and speech recognition: 5.0431\n",
      "  applications: 3.7903\n",
      "  applications of: 4.6376\n",
      "  applications of deep: 5.0431\n",
      "  approach: 3.6568\n",
      "  approach tries: 5.0431\n",
      "  approach tries to: 5.0431\n",
      "  are: 1.9750\n",
      "  are computer: 5.0431\n",
      "  are computer vision: 5.0431\n",
      "  artificial: 2.7918\n",
      "  artificial neural: 3.7903\n",
      "  artificial neural network: 4.6376\n",
      "  brain: 4.3499\n",
      "  brain processes: 5.0431\n",
      "  brain processes light: 5.0431\n",
      "  computer: 3.2513\n",
      "  computer vision: 4.1268\n",
      "  computer vision and: 5.0431\n",
      "  consists: 4.6376\n",
      "  consists of: 4.6376\n",
      "  consists of multiple: 5.0431\n",
      "  deep: 7.3135\n",
      "  deep learning: 7.5806\n",
      "  deep learning are: 5.0431\n",
      "  deep learning consists: 5.0431\n",
      "  hearing: 5.0431\n",
      "  hearing some: 5.0431\n",
      "  hearing some successful: 5.0431\n",
      "  hidden: 4.6376\n",
      "  hidden layers: 5.0431\n",
      "  hidden layers in: 5.0431\n",
      "  human: 3.6568\n",
      "  human brain: 4.6376\n",
      "  human brain processes: 5.0431\n",
      "  in: 1.3417\n",
      "  in an: 3.9444\n",
      "  in an artificial: 5.0431\n",
      "  into: 2.9636\n",
      "  into vision: 5.0431\n",
      "  into vision and: 5.0431\n",
      "  layers: 4.3499\n",
      "  layers in: 5.0431\n",
      "  layers in an: 5.0431\n",
      "  learning: 2.5637\n",
      "  learning are: 5.0431\n",
      "  learning are computer: 5.0431\n",
      "  learning consists: 5.0431\n",
      "  learning consists of: 5.0431\n",
      "  light: 5.0431\n",
      "  light and: 5.0431\n",
      "  light and sound: 5.0431\n",
      "  model: 2.3350\n",
      "  model the: 4.3499\n",
      "  model the way: 5.0431\n",
      "  multiple: 3.9444\n",
      "  multiple hidden: 5.0431\n",
      "  multiple hidden layers: 5.0431\n",
      "  network: 3.5390\n",
      "  network this: 5.0431\n",
      "  network this approach: 5.0431\n",
      "  neural: 3.0281\n",
      "  neural network: 4.1268\n",
      "  neural network this: 5.0431\n",
      "  of: 2.4288\n",
      "  of deep: 4.3499\n",
      "  of deep learning: 4.6376\n",
      "  of multiple: 5.0431\n",
      "  of multiple hidden: 5.0431\n",
      "  processes: 4.3499\n",
      "  processes light: 5.0431\n",
      "  processes light and: 5.0431\n",
      "  recognition: 3.9444\n",
      "  some: 2.9636\n",
      "  some successful: 5.0431\n",
      "  some successful applications: 5.0431\n",
      "  sound: 5.0431\n",
      "  sound into: 5.0431\n",
      "  sound into vision: 5.0431\n",
      "  speech: 3.9444\n",
      "  speech recognition: 4.3499\n",
      "  successful: 4.6376\n",
      "  successful applications: 5.0431\n",
      "  successful applications of: 5.0431\n",
      "  the: 2.3858\n",
      "  the human: 5.0431\n",
      "  the human brain: 5.0431\n",
      "  the way: 5.0431\n",
      "  the way the: 5.0431\n",
      "  this: 2.6007\n",
      "  this approach: 4.6376\n",
      "  this approach tries: 5.0431\n",
      "  to: 1.2253\n",
      "  to model: 5.0431\n",
      "  to model the: 5.0431\n",
      "  tries: 5.0431\n",
      "  tries to: 5.0431\n",
      "  tries to model: 5.0431\n",
      "  vision: 8.2535\n",
      "  vision and: 10.0861\n",
      "  vision and hearing: 5.0431\n",
      "  vision and speech: 5.0431\n",
      "  way: 3.9444\n",
      "  way the: 5.0431\n",
      "  way the human: 5.0431\n",
      "\n",
      "Document 69:\n",
      "  a: 6.2943\n",
      "  a decision: 15.1292\n",
      "  a decision tree: 15.1292\n",
      "  a discrete: 5.0431\n",
      "  a discrete set: 5.0431\n",
      "  a predictive: 5.0431\n",
      "  a predictive model: 5.0431\n",
      "  about: 7.3135\n",
      "  about an: 5.0431\n",
      "  about an item: 5.0431\n",
      "  about the: 4.6376\n",
      "  about the items: 5.0431\n",
      "  an: 4.3054\n",
      "  an input: 4.6376\n",
      "  an input for: 5.0431\n",
      "  an item: 5.0431\n",
      "  an item represented: 5.0431\n",
      "  analysis: 3.1712\n",
      "  analysis a: 5.0431\n",
      "  analysis a decision: 5.0431\n",
      "  and: 4.8576\n",
      "  and branches: 5.0431\n",
      "  and branches represent: 5.0431\n",
      "  and decision: 5.0431\n",
      "  and decision making: 5.0431\n",
      "  and explicitly: 5.0431\n",
      "  and explicitly represent: 5.0431\n",
      "  and machine: 4.3499\n",
      "  and machine learning: 4.3499\n",
      "  approaches: 3.5390\n",
      "  approaches used: 5.0431\n",
      "  approaches used in: 5.0431\n",
      "  are: 3.9500\n",
      "  are called: 8.6998\n",
      "  are called classification: 5.0431\n",
      "  are called regression: 5.0431\n",
      "  as: 1.8444\n",
      "  as a: 2.9030\n",
      "  as a predictive: 5.0431\n",
      "  be: 4.1453\n",
      "  be an: 4.3499\n",
      "  be an input: 5.0431\n",
      "  be used: 3.4336\n",
      "  be used to: 3.9444\n",
      "  branches: 10.0861\n",
      "  branches represent: 5.0431\n",
      "  branches represent conjunctions: 5.0431\n",
      "  branches to: 5.0431\n",
      "  branches to conclusions: 5.0431\n",
      "  but: 3.0281\n",
      "  but the: 4.1268\n",
      "  but the resulting: 5.0431\n",
      "  called: 6.5026\n",
      "  called classification: 5.0431\n",
      "  called classification trees: 5.0431\n",
      "  called regression: 5.0431\n",
      "  called regression trees: 5.0431\n",
      "  can: 8.7234\n",
      "  can be: 5.4809\n",
      "  can be an: 5.0431\n",
      "  can be used: 3.6568\n",
      "  can take: 9.2752\n",
      "  can take a: 5.0431\n",
      "  can take continuous: 5.0431\n",
      "  class: 7.0779\n",
      "  class labels: 10.0861\n",
      "  class labels and: 5.0431\n",
      "  class labels decision: 5.0431\n",
      "  classification: 5.9272\n",
      "  classification tree: 5.0431\n",
      "  classification tree can: 5.0431\n",
      "  classification trees: 5.0431\n",
      "  classification trees in: 5.0431\n",
      "  conclusions: 5.0431\n",
      "  conclusions about: 5.0431\n",
      "  conclusions about the: 5.0431\n",
      "  conjunctions: 5.0431\n",
      "  conjunctions of: 5.0431\n",
      "  conjunctions of features: 5.0431\n",
      "  continuous: 4.6376\n",
      "  continuous values: 5.0431\n",
      "  continuous values typically: 5.0431\n",
      "  data: 5.5950\n",
      "  data but: 4.6376\n",
      "  data but the: 5.0431\n",
      "  data mining: 8.2535\n",
      "  data mining a: 5.0431\n",
      "  data mining and: 5.0431\n",
      "  decision: 25.5973\n",
      "  decision analysis: 5.0431\n",
      "  decision analysis a: 5.0431\n",
      "  decision making: 4.6376\n",
      "  decision making in: 4.6376\n",
      "  decision tree: 18.5503\n",
      "  decision tree as: 5.0431\n",
      "  decision tree can: 5.0431\n",
      "  decision tree describes: 5.0431\n",
      "  decision tree learning: 5.0431\n",
      "  decision trees: 4.6376\n",
      "  decision trees where: 5.0431\n",
      "  decisionmaking: 4.3499\n",
      "  decisions: 3.6568\n",
      "  decisions and: 5.0431\n",
      "  decisions and decision: 5.0431\n",
      "  describes: 5.0431\n",
      "  describes data: 5.0431\n",
      "  describes data but: 5.0431\n",
      "  discrete: 5.0431\n",
      "  discrete set: 5.0431\n",
      "  discrete set of: 5.0431\n",
      "  explicitly: 5.0431\n",
      "  explicitly represent: 5.0431\n",
      "  explicitly represent decisions: 5.0431\n",
      "  features: 3.6568\n",
      "  features that: 5.0431\n",
      "  features that lead: 5.0431\n",
      "  for: 1.7289\n",
      "  for decisionmaking: 4.6376\n",
      "  from: 2.0726\n",
      "  from observations: 5.0431\n",
      "  from observations about: 5.0431\n",
      "  go: 5.0431\n",
      "  go from: 5.0431\n",
      "  go from observations: 5.0431\n",
      "  in: 8.0505\n",
      "  in data: 4.1268\n",
      "  in data mining: 4.6376\n",
      "  in decision: 5.0431\n",
      "  in decision analysis: 5.0431\n",
      "  in statistics: 4.6376\n",
      "  in statistics data: 5.0431\n",
      "  in the: 4.8807\n",
      "  in the branches: 5.0431\n",
      "  in the leaves: 5.0431\n",
      "  in these: 5.0431\n",
      "  in these tree: 5.0431\n",
      "  input: 3.0281\n",
      "  input for: 5.0431\n",
      "  input for decisionmaking: 5.0431\n",
      "  is: 1.5167\n",
      "  is one: 4.3499\n",
      "  is one of: 5.0431\n",
      "  it: 2.2705\n",
      "  it is: 3.5390\n",
      "  it is one: 5.0431\n",
      "  item: 5.0431\n",
      "  item represented: 5.0431\n",
      "  item represented in: 5.0431\n",
      "  items: 4.3499\n",
      "  items target: 5.0431\n",
      "  items target value: 5.0431\n",
      "  labels: 7.8889\n",
      "  labels and: 4.6376\n",
      "  labels and branches: 5.0431\n",
      "  labels decision: 5.0431\n",
      "  labels decision trees: 5.0431\n",
      "  lead: 4.3499\n",
      "  lead to: 4.3499\n",
      "  lead to those: 5.0431\n",
      "  learning: 2.5637\n",
      "  learning tree: 5.0431\n",
      "  learning tree models: 5.0431\n",
      "  learning uses: 5.0431\n",
      "  learning uses a: 5.0431\n",
      "  leaves: 10.0861\n",
      "  leaves it: 5.0431\n",
      "  leaves it is: 5.0431\n",
      "  leaves represent: 5.0431\n",
      "  leaves represent class: 5.0431\n",
      "  machine: 1.4735\n",
      "  machine learning: 1.5618\n",
      "  machine learning tree: 5.0431\n",
      "  making: 4.1268\n",
      "  making in: 4.6376\n",
      "  making in data: 5.0431\n",
      "  mining: 7.8889\n",
      "  mining a: 5.0431\n",
      "  mining a decision: 5.0431\n",
      "  mining and: 5.0431\n",
      "  mining and machine: 5.0431\n",
      "  model: 2.3350\n",
      "  model to: 4.3499\n",
      "  model to go: 5.0431\n",
      "  modelling: 4.3499\n",
      "  modelling approaches: 5.0431\n",
      "  modelling approaches used: 5.0431\n",
      "  models: 2.5581\n",
      "  models where: 5.0431\n",
      "  models where the: 5.0431\n",
      "  numbers: 5.0431\n",
      "  numbers are: 5.0431\n",
      "  numbers are called: 5.0431\n",
      "  observations: 4.3499\n",
      "  observations about: 5.0431\n",
      "  observations about an: 5.0431\n",
      "  of: 3.6432\n",
      "  of features: 4.3499\n",
      "  of features that: 5.0431\n",
      "  of the: 2.3022\n",
      "  of the predictive: 5.0431\n",
      "  of values: 4.6376\n",
      "  of values are: 5.0431\n",
      "  one: 3.0971\n",
      "  one of: 4.3499\n",
      "  one of the: 4.6376\n",
      "  predictive: 8.2535\n",
      "  predictive model: 5.0431\n",
      "  predictive model to: 5.0431\n",
      "  predictive modelling: 5.0431\n",
      "  predictive modelling approaches: 5.0431\n",
      "  real: 4.3499\n",
      "  real numbers: 5.0431\n",
      "  real numbers are: 5.0431\n",
      "  regression: 3.6568\n",
      "  regression trees: 5.0431\n",
      "  regression trees in: 5.0431\n",
      "  represent: 12.3803\n",
      "  represent class: 5.0431\n",
      "  represent class labels: 5.0431\n",
      "  represent conjunctions: 5.0431\n",
      "  represent conjunctions of: 5.0431\n",
      "  represent decisions: 5.0431\n",
      "  represent decisions and: 5.0431\n",
      "  represented: 7.3135\n",
      "  represented in: 9.2752\n",
      "  represented in the: 9.2752\n",
      "  resulting: 4.6376\n",
      "  resulting classification: 5.0431\n",
      "  resulting classification tree: 5.0431\n",
      "  set: 2.6007\n",
      "  set of: 3.0281\n",
      "  set of values: 4.6376\n",
      "  statistics: 3.6568\n",
      "  statistics data: 5.0431\n",
      "  statistics data mining: 5.0431\n",
      "  structures: 4.6376\n",
      "  structures leaves: 5.0431\n",
      "  structures leaves represent: 5.0431\n",
      "  take: 8.2535\n",
      "  take a: 5.0431\n",
      "  take a discrete: 5.0431\n",
      "  take continuous: 5.0431\n",
      "  take continuous values: 5.0431\n",
      "  target: 13.9128\n",
      "  target value: 5.0431\n",
      "  target value represented: 5.0431\n",
      "  target variable: 10.0861\n",
      "  target variable can: 10.0861\n",
      "  that: 1.6758\n",
      "  that lead: 5.0431\n",
      "  that lead to: 5.0431\n",
      "  the: 8.3503\n",
      "  the branches: 5.0431\n",
      "  the branches to: 5.0431\n",
      "  the items: 5.0431\n",
      "  the items target: 5.0431\n",
      "  the leaves: 5.0431\n",
      "  the leaves it: 5.0431\n",
      "  the predictive: 5.0431\n",
      "  the predictive modelling: 5.0431\n",
      "  the resulting: 5.0431\n",
      "  the resulting classification: 5.0431\n",
      "  the target: 10.0861\n",
      "  the target variable: 10.0861\n",
      "  these: 2.9030\n",
      "  these tree: 5.0431\n",
      "  these tree structures: 5.0431\n",
      "  those: 4.3499\n",
      "  those class: 5.0431\n",
      "  those class labels: 5.0431\n",
      "  to: 4.9014\n",
      "  to conclusions: 5.0431\n",
      "  to conclusions about: 5.0431\n",
      "  to go: 5.0431\n",
      "  to go from: 5.0431\n",
      "  to those: 5.0431\n",
      "  to those class: 5.0431\n",
      "  to visually: 5.0431\n",
      "  to visually and: 5.0431\n",
      "  tree: 32.4631\n",
      "  tree as: 5.0431\n",
      "  tree as a: 5.0431\n",
      "  tree can: 10.0861\n",
      "  tree can be: 10.0861\n",
      "  tree describes: 5.0431\n",
      "  tree describes data: 5.0431\n",
      "  tree learning: 5.0431\n",
      "  tree learning uses: 5.0431\n",
      "  tree models: 5.0431\n",
      "  tree models where: 5.0431\n",
      "  tree structures: 5.0431\n",
      "  tree structures leaves: 5.0431\n",
      "  trees: 13.9128\n",
      "  trees in: 10.0861\n",
      "  trees in decision: 5.0431\n",
      "  trees in these: 5.0431\n",
      "  trees where: 5.0431\n",
      "  trees where the: 5.0431\n",
      "  typically: 3.5390\n",
      "  typically real: 5.0431\n",
      "  typically real numbers: 5.0431\n",
      "  used: 4.6700\n",
      "  used in: 3.4336\n",
      "  used in statistics: 5.0431\n",
      "  used to: 3.3383\n",
      "  used to visually: 5.0431\n",
      "  uses: 4.1268\n",
      "  uses a: 5.0431\n",
      "  uses a decision: 5.0431\n",
      "  value: 4.3499\n",
      "  value represented: 5.0431\n",
      "  value represented in: 5.0431\n",
      "  values: 9.2752\n",
      "  values are: 5.0431\n",
      "  values are called: 5.0431\n",
      "  values typically: 5.0431\n",
      "  values typically real: 5.0431\n",
      "  variable: 10.0861\n",
      "  variable can: 10.0861\n",
      "  variable can take: 10.0861\n",
      "  visually: 5.0431\n",
      "  visually and: 5.0431\n",
      "  visually and explicitly: 5.0431\n",
      "  where: 6.5026\n",
      "  where the: 9.2752\n",
      "  where the target: 10.0861\n",
      "\n",
      "Document 70:\n",
      "  accuracy: 7.3135\n",
      "  accuracy and: 5.0431\n",
      "  accuracy and to: 5.0431\n",
      "  accuracy rfr: 5.0431\n",
      "  accuracy rfr generates: 5.0431\n",
      "  achieve: 5.0431\n",
      "  achieve accuracy: 5.0431\n",
      "  achieve accuracy rfr: 5.0431\n",
      "  an: 2.1527\n",
      "  an ensemble: 4.6376\n",
      "  an ensemble learning: 5.0431\n",
      "  and: 4.8576\n",
      "  and achieve: 5.0431\n",
      "  and achieve accuracy: 5.0431\n",
      "  and averages: 5.0431\n",
      "  and averages their: 5.0431\n",
      "  and it: 4.3499\n",
      "  and it can: 5.0431\n",
      "  and to: 5.0431\n",
      "  and to avoid: 5.0431\n",
      "  application: 4.3499\n",
      "  as: 1.8444\n",
      "  as well: 4.1268\n",
      "  as well multiple: 5.0431\n",
      "  averages: 5.0431\n",
      "  averages their: 5.0431\n",
      "  averages their predictions: 5.0431\n",
      "  avoid: 5.0431\n",
      "  avoid overfitting: 5.0431\n",
      "  avoid overfitting to: 5.0431\n",
      "  be: 2.0726\n",
      "  be used: 3.4336\n",
      "  be used in: 5.0431\n",
      "  bias: 3.7903\n",
      "  bias predictions: 5.0431\n",
      "  bias predictions and: 5.0431\n",
      "  bootstrapped: 5.0431\n",
      "  bootstrapped sampling: 5.0431\n",
      "  bootstrapped sampling for: 5.0431\n",
      "  build: 4.3499\n",
      "  build decision: 5.0431\n",
      "  build decision trees: 5.0431\n",
      "  builds: 4.6376\n",
      "  builds multiple: 5.0431\n",
      "  builds multiple decision: 5.0431\n",
      "  can: 2.1809\n",
      "  can work: 5.0431\n",
      "  can work on: 5.0431\n",
      "  compatible: 5.0431\n",
      "  compatible to: 5.0431\n",
      "  compatible to be: 5.0431\n",
      "  data: 3.7300\n",
      "  data as: 5.0431\n",
      "  data as well: 5.0431\n",
      "  data of: 4.3499\n",
      "  data of from: 5.0431\n",
      "  decision: 18.2838\n",
      "  decision tree: 4.6376\n",
      "  decision tree is: 5.0431\n",
      "  decision treebased: 5.0431\n",
      "  decision treebased models: 5.0431\n",
      "  decision trees: 13.9128\n",
      "  decision trees and: 10.0861\n",
      "  decision trees rfr: 5.0431\n",
      "  each: 3.0971\n",
      "  each decision: 5.0431\n",
      "  each decision tree: 5.0431\n",
      "  enables: 4.6376\n",
      "  enables model: 5.0431\n",
      "  enables model to: 5.0431\n",
      "  ensemble: 4.3499\n",
      "  ensemble learning: 5.0431\n",
      "  ensemble learning method: 5.0431\n",
      "  falls: 4.3499\n",
      "  falls under: 5.0431\n",
      "  falls under umbrella: 5.0431\n",
      "  for: 3.4577\n",
      "  for instance: 5.0431\n",
      "  for instance each: 5.0431\n",
      "  for training: 4.1268\n",
      "  for training enables: 5.0431\n",
      "  forest: 4.6376\n",
      "  forest regression: 5.0431\n",
      "  forest regression rfr: 5.0431\n",
      "  from: 2.0726\n",
      "  from training: 5.0431\n",
      "  from training set: 5.0431\n",
      "  generates: 4.6376\n",
      "  generates independent: 5.0431\n",
      "  generates independent decision: 5.0431\n",
      "  improve: 4.1268\n",
      "  improve accuracy: 5.0431\n",
      "  improve accuracy and: 5.0431\n",
      "  in: 1.3417\n",
      "  in various: 5.0431\n",
      "  in various application: 5.0431\n",
      "  independent: 4.6376\n",
      "  independent decision: 5.0431\n",
      "  independent decision trees: 5.0431\n",
      "  instance: 4.3499\n",
      "  instance each: 5.0431\n",
      "  instance each decision: 5.0431\n",
      "  is: 3.0334\n",
      "  is an: 3.6568\n",
      "  is an ensemble: 5.0431\n",
      "  is trained: 5.0431\n",
      "  is trained on: 5.0431\n",
      "  it: 2.2705\n",
      "  it can: 4.6376\n",
      "  it can work: 5.0431\n",
      "  learning: 1.2819\n",
      "  learning method: 4.1268\n",
      "  learning method that: 4.6376\n",
      "  makes: 4.3499\n",
      "  makes rfr: 5.0431\n",
      "  makes rfr compatible: 5.0431\n",
      "  method: 3.6568\n",
      "  method that: 4.6376\n",
      "  method that builds: 5.0431\n",
      "  model: 2.3350\n",
      "  model to: 4.3499\n",
      "  model to reduce: 5.0431\n",
      "  models: 2.5581\n",
      "  models rfr: 5.0431\n",
      "  models rfr is: 5.0431\n",
      "  multiple: 7.8889\n",
      "  multiple decision: 5.0431\n",
      "  multiple decision trees: 5.0431\n",
      "  multiple regressor: 5.0431\n",
      "  multiple regressor task: 5.0431\n",
      "  of: 3.6432\n",
      "  of decision: 5.0431\n",
      "  of decision treebased: 5.0431\n",
      "  of from: 5.0431\n",
      "  of from training: 5.0431\n",
      "  of rfr: 5.0431\n",
      "  of rfr for: 5.0431\n",
      "  on: 4.0946\n",
      "  on random: 5.0431\n",
      "  on random data: 5.0431\n",
      "  on single: 5.0431\n",
      "  on single output: 5.0431\n",
      "  output: 3.3383\n",
      "  output data: 5.0431\n",
      "  output data as: 5.0431\n",
      "  overfitting: 3.7903\n",
      "  overfitting to: 5.0431\n",
      "  overfitting to build: 5.0431\n",
      "  predictions: 6.6766\n",
      "  predictions and: 5.0431\n",
      "  predictions and achieve: 5.0431\n",
      "  predictions to: 5.0431\n",
      "  predictions to improve: 5.0431\n",
      "  random: 11.8333\n",
      "  random data: 5.0431\n",
      "  random data of: 5.0431\n",
      "  random forest: 4.6376\n",
      "  random forest regression: 5.0431\n",
      "  random selection: 5.0431\n",
      "  random selection of: 5.0431\n",
      "  reduce: 4.1268\n",
      "  reduce bias: 5.0431\n",
      "  reduce bias predictions: 5.0431\n",
      "  regression: 3.6568\n",
      "  regression rfr: 5.0431\n",
      "  regression rfr falls: 5.0431\n",
      "  regressor: 5.0431\n",
      "  regressor task: 5.0431\n",
      "  regressor task this: 5.0431\n",
      "  rfr: 30.2583\n",
      "  rfr compatible: 5.0431\n",
      "  rfr compatible to: 5.0431\n",
      "  rfr falls: 5.0431\n",
      "  rfr falls under: 5.0431\n",
      "  rfr for: 5.0431\n",
      "  rfr for training: 5.0431\n",
      "  rfr generates: 5.0431\n",
      "  rfr generates independent: 5.0431\n",
      "  rfr is: 5.0431\n",
      "  rfr is an: 5.0431\n",
      "  rfr uses: 5.0431\n",
      "  rfr uses bootstrapped: 5.0431\n",
      "  sampling: 5.0431\n",
      "  sampling for: 5.0431\n",
      "  sampling for instance: 5.0431\n",
      "  selection: 4.1268\n",
      "  selection of: 4.6376\n",
      "  selection of rfr: 5.0431\n",
      "  set: 2.6007\n",
      "  set this: 5.0431\n",
      "  set this random: 5.0431\n",
      "  single: 4.1268\n",
      "  single output: 5.0431\n",
      "  single output data: 5.0431\n",
      "  task: 3.9444\n",
      "  task this: 5.0431\n",
      "  task this makes: 5.0431\n",
      "  that: 1.6758\n",
      "  that builds: 5.0431\n",
      "  that builds multiple: 5.0431\n",
      "  their: 2.7918\n",
      "  their predictions: 5.0431\n",
      "  their predictions to: 5.0431\n",
      "  this: 5.2014\n",
      "  this makes: 5.0431\n",
      "  this makes rfr: 5.0431\n",
      "  this random: 5.0431\n",
      "  this random selection: 5.0431\n",
      "  to: 6.1267\n",
      "  to avoid: 5.0431\n",
      "  to avoid overfitting: 5.0431\n",
      "  to be: 3.4336\n",
      "  to be used: 5.0431\n",
      "  to build: 4.6376\n",
      "  to build decision: 5.0431\n",
      "  to improve: 4.3499\n",
      "  to improve accuracy: 5.0431\n",
      "  to reduce: 4.1268\n",
      "  to reduce bias: 5.0431\n",
      "  trained: 3.3383\n",
      "  trained on: 3.9444\n",
      "  trained on random: 5.0431\n",
      "  training: 5.1163\n",
      "  training enables: 5.0431\n",
      "  training enables model: 5.0431\n",
      "  training set: 4.1268\n",
      "  training set this: 5.0431\n",
      "  tree: 4.6376\n",
      "  tree is: 5.0431\n",
      "  tree is trained: 5.0431\n",
      "  treebased: 5.0431\n",
      "  treebased models: 5.0431\n",
      "  treebased models rfr: 5.0431\n",
      "  trees: 13.9128\n",
      "  trees and: 10.0861\n",
      "  trees and averages: 5.0431\n",
      "  trees and it: 5.0431\n",
      "  trees rfr: 5.0431\n",
      "  trees rfr uses: 5.0431\n",
      "  umbrella: 5.0431\n",
      "  umbrella of: 5.0431\n",
      "  umbrella of decision: 5.0431\n",
      "  under: 3.4336\n",
      "  under umbrella: 5.0431\n",
      "  under umbrella of: 5.0431\n",
      "  used: 2.3350\n",
      "  used in: 3.4336\n",
      "  used in various: 5.0431\n",
      "  uses: 4.1268\n",
      "  uses bootstrapped: 5.0431\n",
      "  uses bootstrapped sampling: 5.0431\n",
      "  various: 3.4336\n",
      "  various application: 5.0431\n",
      "  well: 3.9444\n",
      "  well multiple: 5.0431\n",
      "  well multiple regressor: 5.0431\n",
      "  work: 4.1268\n",
      "  work on: 4.6376\n",
      "  work on single: 5.0431\n",
      "\n",
      "Document 71:\n",
      "  a: 8.8120\n",
      "  a model: 3.9444\n",
      "  a model that: 5.0431\n",
      "  a new: 4.3499\n",
      "  a new example: 5.0431\n",
      "  a nonlinear: 5.0431\n",
      "  a nonlinear classification: 5.0431\n",
      "  a nonprobabilistic: 5.0431\n",
      "  a nonprobabilistic binary: 5.0431\n",
      "  a probabilistic: 4.6376\n",
      "  a probabilistic classification: 5.0431\n",
      "  a set: 6.5026\n",
      "  a set of: 6.5026\n",
      "  addition: 3.7903\n",
      "  addition to: 3.9444\n",
      "  addition to performing: 5.0431\n",
      "  algorithm: 5.8060\n",
      "  algorithm builds: 5.0431\n",
      "  algorithm builds a: 5.0431\n",
      "  algorithm is: 4.3499\n",
      "  algorithm is a: 5.0431\n",
      "  also: 2.6452\n",
      "  also known: 4.3499\n",
      "  also known as: 4.3499\n",
      "  although: 4.1268\n",
      "  although methods: 5.0431\n",
      "  although methods such: 5.0431\n",
      "  an: 4.3054\n",
      "  an svm: 10.0861\n",
      "  an svm training: 10.0861\n",
      "  and: 1.2144\n",
      "  and regression: 4.6376\n",
      "  and regression given: 5.0431\n",
      "  are: 1.9750\n",
      "  are a: 4.6376\n",
      "  are a set: 5.0431\n",
      "  as: 5.5331\n",
      "  as belonging: 5.0431\n",
      "  as belonging to: 5.0431\n",
      "  as platt: 5.0431\n",
      "  as platt scaling: 5.0431\n",
      "  as supportvector: 5.0431\n",
      "  as supportvector networks: 5.0431\n",
      "  belonging: 5.0431\n",
      "  belonging to: 5.0431\n",
      "  belonging to one: 5.0431\n",
      "  binary: 5.0431\n",
      "  binary linear: 5.0431\n",
      "  binary linear classifier: 5.0431\n",
      "  builds: 4.6376\n",
      "  builds a: 5.0431\n",
      "  builds a model: 5.0431\n",
      "  called: 3.2513\n",
      "  called the: 4.6376\n",
      "  called the kernel: 5.0431\n",
      "  can: 2.1809\n",
      "  can efficiently: 5.0431\n",
      "  can efficiently perform: 5.0431\n",
      "  categories: 4.1268\n",
      "  categories an: 5.0431\n",
      "  categories an svm: 5.0431\n",
      "  category: 5.0431\n",
      "  category an: 5.0431\n",
      "  category an svm: 5.0431\n",
      "  classification: 11.8544\n",
      "  classification and: 4.6376\n",
      "  classification and regression: 4.6376\n",
      "  classification setting: 5.0431\n",
      "  classification setting in: 5.0431\n",
      "  classification svms: 5.0431\n",
      "  classification svms can: 5.0431\n",
      "  classification using: 5.0431\n",
      "  classification using what: 5.0431\n",
      "  classifier: 3.7903\n",
      "  classifier although: 5.0431\n",
      "  classifier although methods: 5.0431\n",
      "  each: 3.0971\n",
      "  each marked: 5.0431\n",
      "  each marked as: 5.0431\n",
      "  efficiently: 5.0431\n",
      "  efficiently perform: 5.0431\n",
      "  efficiently perform a: 5.0431\n",
      "  example: 2.9636\n",
      "  example falls: 5.0431\n",
      "  example falls into: 5.0431\n",
      "  examples: 3.0971\n",
      "  examples each: 4.6376\n",
      "  examples each marked: 5.0431\n",
      "  exist: 4.3499\n",
      "  exist to: 5.0431\n",
      "  exist to use: 5.0431\n",
      "  falls: 4.3499\n",
      "  falls into: 5.0431\n",
      "  falls into one: 5.0431\n",
      "  feature: 3.4336\n",
      "  feature spaces: 4.6376\n",
      "  for: 1.7289\n",
      "  for classification: 4.6376\n",
      "  for classification and: 5.0431\n",
      "  given: 3.3383\n",
      "  given a: 4.6376\n",
      "  given a set: 4.6376\n",
      "  highdimensional: 4.6376\n",
      "  highdimensional feature: 5.0431\n",
      "  highdimensional feature spaces: 5.0431\n",
      "  implicitly: 4.3499\n",
      "  implicitly mapping: 5.0431\n",
      "  implicitly mapping their: 5.0431\n",
      "  in: 2.6835\n",
      "  in a: 3.0971\n",
      "  in a probabilistic: 5.0431\n",
      "  in addition: 3.7903\n",
      "  in addition to: 3.9444\n",
      "  inputs: 4.1268\n",
      "  inputs into: 5.0431\n",
      "  inputs into highdimensional: 5.0431\n",
      "  into: 5.9272\n",
      "  into highdimensional: 5.0431\n",
      "  into highdimensional feature: 5.0431\n",
      "  into one: 5.0431\n",
      "  into one category: 5.0431\n",
      "  is: 3.0334\n",
      "  is a: 2.5173\n",
      "  is a nonprobabilistic: 5.0431\n",
      "  is called: 4.6376\n",
      "  is called the: 5.0431\n",
      "  kernel: 4.3499\n",
      "  kernel trick: 4.6376\n",
      "  kernel trick implicitly: 5.0431\n",
      "  known: 3.5390\n",
      "  known as: 3.7903\n",
      "  known as supportvector: 5.0431\n",
      "  learning: 1.2819\n",
      "  learning methods: 4.3499\n",
      "  learning methods used: 5.0431\n",
      "  linear: 7.5806\n",
      "  linear classification: 5.0431\n",
      "  linear classification svms: 5.0431\n",
      "  linear classifier: 5.0431\n",
      "  linear classifier although: 5.0431\n",
      "  machines: 3.6568\n",
      "  machines svms: 5.0431\n",
      "  machines svms also: 5.0431\n",
      "  mapping: 5.0431\n",
      "  mapping their: 5.0431\n",
      "  mapping their inputs: 5.0431\n",
      "  marked: 5.0431\n",
      "  marked as: 5.0431\n",
      "  marked as belonging: 5.0431\n",
      "  methods: 5.4809\n",
      "  methods such: 4.6376\n",
      "  methods such as: 4.6376\n",
      "  methods used: 5.0431\n",
      "  methods used for: 5.0431\n",
      "  model: 2.3350\n",
      "  model that: 4.1268\n",
      "  model that predicts: 5.0431\n",
      "  networks: 3.0971\n",
      "  networks are: 5.0431\n",
      "  networks are a: 5.0431\n",
      "  new: 3.2513\n",
      "  new example: 5.0431\n",
      "  new example falls: 5.0431\n",
      "  nonlinear: 3.9444\n",
      "  nonlinear classification: 5.0431\n",
      "  nonlinear classification using: 5.0431\n",
      "  nonprobabilistic: 5.0431\n",
      "  nonprobabilistic binary: 5.0431\n",
      "  nonprobabilistic binary linear: 5.0431\n",
      "  of: 3.6432\n",
      "  of related: 5.0431\n",
      "  of related supervised: 5.0431\n",
      "  of training: 4.1268\n",
      "  of training examples: 4.6376\n",
      "  of two: 5.0431\n",
      "  of two categories: 5.0431\n",
      "  one: 6.1943\n",
      "  one category: 5.0431\n",
      "  one category an: 5.0431\n",
      "  one of: 4.3499\n",
      "  one of two: 5.0431\n",
      "  perform: 3.2513\n",
      "  perform a: 4.6376\n",
      "  perform a nonlinear: 5.0431\n",
      "  performing: 3.9444\n",
      "  performing linear: 5.0431\n",
      "  performing linear classification: 5.0431\n",
      "  platt: 5.0431\n",
      "  platt scaling: 5.0431\n",
      "  platt scaling exist: 5.0431\n",
      "  predicts: 4.6376\n",
      "  predicts whether: 5.0431\n",
      "  predicts whether a: 5.0431\n",
      "  probabilistic: 3.9444\n",
      "  probabilistic classification: 5.0431\n",
      "  probabilistic classification setting: 5.0431\n",
      "  regression: 3.6568\n",
      "  regression given: 5.0431\n",
      "  regression given a: 5.0431\n",
      "  related: 3.6568\n",
      "  related supervised: 5.0431\n",
      "  related supervised learning: 5.0431\n",
      "  scaling: 5.0431\n",
      "  scaling exist: 5.0431\n",
      "  scaling exist to: 5.0431\n",
      "  set: 5.2014\n",
      "  set of: 6.0563\n",
      "  set of related: 5.0431\n",
      "  set of training: 4.6376\n",
      "  setting: 4.6376\n",
      "  setting in: 5.0431\n",
      "  setting in addition: 5.0431\n",
      "  spaces: 4.6376\n",
      "  such: 2.4781\n",
      "  such as: 2.8458\n",
      "  such as platt: 5.0431\n",
      "  supervised: 3.2513\n",
      "  supervised learning: 3.6568\n",
      "  supervised learning methods: 5.0431\n",
      "  supportvector: 10.0861\n",
      "  supportvector machines: 5.0431\n",
      "  supportvector machines svms: 5.0431\n",
      "  supportvector networks: 5.0431\n",
      "  supportvector networks are: 5.0431\n",
      "  svm: 15.1292\n",
      "  svm in: 5.0431\n",
      "  svm in a: 5.0431\n",
      "  svm training: 10.0861\n",
      "  svm training algorithm: 10.0861\n",
      "  svms: 10.0861\n",
      "  svms also: 5.0431\n",
      "  svms also known: 5.0431\n",
      "  svms can: 5.0431\n",
      "  svms can efficiently: 5.0431\n",
      "  that: 1.6758\n",
      "  that predicts: 4.6376\n",
      "  that predicts whether: 5.0431\n",
      "  the: 1.1929\n",
      "  the kernel: 4.6376\n",
      "  the kernel trick: 4.6376\n",
      "  their: 2.7918\n",
      "  their inputs: 4.6376\n",
      "  their inputs into: 5.0431\n",
      "  to: 3.6760\n",
      "  to one: 4.6376\n",
      "  to one of: 5.0431\n",
      "  to performing: 4.6376\n",
      "  to performing linear: 5.0431\n",
      "  to use: 4.6376\n",
      "  to use svm: 5.0431\n",
      "  training: 7.6744\n",
      "  training algorithm: 10.0861\n",
      "  training algorithm builds: 5.0431\n",
      "  training algorithm is: 5.0431\n",
      "  training examples: 4.1268\n",
      "  training examples each: 4.6376\n",
      "  trick: 4.6376\n",
      "  trick implicitly: 5.0431\n",
      "  trick implicitly mapping: 5.0431\n",
      "  two: 3.5390\n",
      "  two categories: 5.0431\n",
      "  two categories an: 5.0431\n",
      "  use: 3.3383\n",
      "  use svm: 5.0431\n",
      "  use svm in: 5.0431\n",
      "  used: 2.3350\n",
      "  used for: 4.1268\n",
      "  used for classification: 5.0431\n",
      "  using: 3.2513\n",
      "  using what: 5.0431\n",
      "  using what is: 5.0431\n",
      "  what: 4.3499\n",
      "  what is: 5.0431\n",
      "  what is called: 5.0431\n",
      "  whether: 5.0431\n",
      "  whether a: 5.0431\n",
      "  whether a new: 5.0431\n",
      "\n",
      "Document 72:\n",
      "  a: 3.7766\n",
      "  a large: 4.6376\n",
      "  a large variety: 5.0431\n",
      "  a mathematical: 4.6376\n",
      "  a mathematical criterion: 5.0431\n",
      "  a single: 4.6376\n",
      "  a single line: 5.0431\n",
      "  according: 3.9444\n",
      "  according to: 3.9444\n",
      "  according to a: 5.0431\n",
      "  advantage: 5.0431\n",
      "  advantage of: 5.0431\n",
      "  advantage of the: 5.0431\n",
      "  analysis: 3.1712\n",
      "  analysis encompasses: 5.0431\n",
      "  analysis encompasses a: 5.0431\n",
      "  and: 2.4288\n",
      "  and bias: 5.0431\n",
      "  and bias as: 5.0431\n",
      "  and their: 3.9444\n",
      "  and their associated: 4.6376\n",
      "  as: 3.6888\n",
      "  as in: 5.0431\n",
      "  as in ridge: 5.0431\n",
      "  as ordinary: 5.0431\n",
      "  as ordinary least: 5.0431\n",
      "  associated: 3.7903\n",
      "  associated features: 5.0431\n",
      "  associated features its: 5.0431\n",
      "  best: 3.6568\n",
      "  best fit: 5.0431\n",
      "  best fit the: 5.0431\n",
      "  between: 2.9636\n",
      "  between input: 5.0431\n",
      "  between input variables: 5.0431\n",
      "  bias: 3.7903\n",
      "  bias as: 5.0431\n",
      "  bias as in: 5.0431\n",
      "  by: 3.8151\n",
      "  by regularisation: 5.0431\n",
      "  by regularisation methods: 5.0431\n",
      "  by taking: 5.0431\n",
      "  by taking advantage: 5.0431\n",
      "  classification: 2.9636\n",
      "  classification or: 4.6376\n",
      "  classification or even: 5.0431\n",
      "  common: 3.9444\n",
      "  common form: 5.0431\n",
      "  common form is: 5.0431\n",
      "  criterion: 5.0431\n",
      "  criterion such: 5.0431\n",
      "  criterion such as: 5.0431\n",
      "  data: 1.8650\n",
      "  data according: 5.0431\n",
      "  data according to: 5.0431\n",
      "  dealing: 4.6376\n",
      "  dealing with: 5.0431\n",
      "  dealing with nonlinear: 5.0431\n",
      "  drawn: 4.6376\n",
      "  drawn to: 5.0431\n",
      "  drawn to best: 5.0431\n",
      "  encompasses: 5.0431\n",
      "  encompasses a: 5.0431\n",
      "  encompasses a large: 5.0431\n",
      "  estimate: 5.0431\n",
      "  estimate the: 5.0431\n",
      "  estimate the relationship: 5.0431\n",
      "  even: 3.9444\n",
      "  even kernel: 5.0431\n",
      "  even kernel regression: 5.0431\n",
      "  example: 2.9636\n",
      "  example used: 5.0431\n",
      "  example used for: 5.0431\n",
      "  excel: 5.0431\n",
      "  excel logistic: 5.0431\n",
      "  excel logistic regression: 5.0431\n",
      "  extended: 4.3499\n",
      "  extended by: 5.0431\n",
      "  extended by regularisation: 5.0431\n",
      "  features: 3.6568\n",
      "  features its: 5.0431\n",
      "  features its most: 5.0431\n",
      "  fit: 4.1268\n",
      "  fit the: 4.6376\n",
      "  fit the given: 5.0431\n",
      "  fitting: 4.6376\n",
      "  fitting in: 5.0431\n",
      "  fitting in microsoft: 5.0431\n",
      "  for: 3.4577\n",
      "  for example: 3.2513\n",
      "  for example used: 5.0431\n",
      "  for trendline: 5.0431\n",
      "  for trendline fitting: 5.0431\n",
      "  form: 4.3499\n",
      "  form is: 5.0431\n",
      "  form is linear: 5.0431\n",
      "  given: 3.3383\n",
      "  given data: 5.0431\n",
      "  given data according: 5.0431\n",
      "  goto: 5.0431\n",
      "  goto models: 5.0431\n",
      "  goto models include: 5.0431\n",
      "  higherdimensional: 4.3499\n",
      "  higherdimensional space: 5.0431\n",
      "  implicitly: 4.3499\n",
      "  implicitly map: 4.6376\n",
      "  implicitly map input: 5.0431\n",
      "  in: 4.0252\n",
      "  in microsoft: 4.6376\n",
      "  in microsoft excel: 5.0431\n",
      "  in ridge: 5.0431\n",
      "  in ridge regression: 5.0431\n",
      "  in statistical: 5.0431\n",
      "  in statistical classification: 5.0431\n",
      "  include: 3.4336\n",
      "  include polynomial: 5.0431\n",
      "  include polynomial regression: 5.0431\n",
      "  input: 6.0563\n",
      "  input variables: 9.2752\n",
      "  input variables and: 4.6376\n",
      "  input variables to: 5.0431\n",
      "  introduces: 5.0431\n",
      "  introduces nonlinearity: 5.0431\n",
      "  introduces nonlinearity by: 5.0431\n",
      "  is: 4.5501\n",
      "  is drawn: 5.0431\n",
      "  is drawn to: 5.0431\n",
      "  is linear: 5.0431\n",
      "  is linear regression: 5.0431\n",
      "  is often: 5.0431\n",
      "  is often extended: 5.0431\n",
      "  its: 2.9636\n",
      "  its most: 5.0431\n",
      "  its most common: 5.0431\n",
      "  kernel: 8.6998\n",
      "  kernel regression: 5.0431\n",
      "  kernel regression which: 5.0431\n",
      "  kernel trick: 4.6376\n",
      "  kernel trick to: 5.0431\n",
      "  large: 3.9444\n",
      "  large variety: 5.0431\n",
      "  large variety of: 5.0431\n",
      "  latter: 5.0431\n",
      "  latter is: 5.0431\n",
      "  latter is often: 5.0431\n",
      "  least: 4.3499\n",
      "  least squares: 5.0431\n",
      "  least squares the: 5.0431\n",
      "  line: 4.6376\n",
      "  line is: 5.0431\n",
      "  line is drawn: 5.0431\n",
      "  linear: 3.7903\n",
      "  linear regression: 4.6376\n",
      "  linear regression where: 5.0431\n",
      "  logistic: 5.0431\n",
      "  logistic regression: 5.0431\n",
      "  logistic regression often: 5.0431\n",
      "  map: 4.6376\n",
      "  map input: 5.0431\n",
      "  map input variables: 5.0431\n",
      "  mathematical: 3.5390\n",
      "  mathematical criterion: 5.0431\n",
      "  mathematical criterion such: 5.0431\n",
      "  methods: 5.4809\n",
      "  methods to: 9.2752\n",
      "  methods to estimate: 5.0431\n",
      "  methods to mitigate: 5.0431\n",
      "  microsoft: 4.6376\n",
      "  microsoft excel: 5.0431\n",
      "  microsoft excel logistic: 5.0431\n",
      "  mitigate: 5.0431\n",
      "  mitigate overfitting: 5.0431\n",
      "  mitigate overfitting and: 5.0431\n",
      "  models: 2.5581\n",
      "  models include: 5.0431\n",
      "  models include polynomial: 5.0431\n",
      "  most: 4.3499\n",
      "  most common: 5.0431\n",
      "  most common form: 5.0431\n",
      "  nonlinear: 3.9444\n",
      "  nonlinear problems: 5.0431\n",
      "  nonlinear problems goto: 5.0431\n",
      "  nonlinearity: 5.0431\n",
      "  nonlinearity by: 5.0431\n",
      "  nonlinearity by taking: 5.0431\n",
      "  of: 2.4288\n",
      "  of statistical: 4.6376\n",
      "  of statistical methods: 5.0431\n",
      "  of the: 2.3022\n",
      "  of the kernel: 5.0431\n",
      "  often: 6.1943\n",
      "  often extended: 5.0431\n",
      "  often extended by: 5.0431\n",
      "  often used: 5.0431\n",
      "  often used in: 5.0431\n",
      "  or: 2.0226\n",
      "  or even: 5.0431\n",
      "  or even kernel: 5.0431\n",
      "  ordinary: 5.0431\n",
      "  ordinary least: 5.0431\n",
      "  ordinary least squares: 5.0431\n",
      "  overfitting: 3.7903\n",
      "  overfitting and: 4.6376\n",
      "  overfitting and bias: 5.0431\n",
      "  polynomial: 4.6376\n",
      "  polynomial regression: 5.0431\n",
      "  polynomial regression for: 5.0431\n",
      "  problems: 3.1712\n",
      "  problems goto: 5.0431\n",
      "  problems goto models: 5.0431\n",
      "  regression: 21.9405\n",
      "  regression analysis: 5.0431\n",
      "  regression analysis encompasses: 5.0431\n",
      "  regression for: 5.0431\n",
      "  regression for example: 5.0431\n",
      "  regression often: 5.0431\n",
      "  regression often used: 5.0431\n",
      "  regression when: 5.0431\n",
      "  regression when dealing: 5.0431\n",
      "  regression where: 5.0431\n",
      "  regression where a: 5.0431\n",
      "  regression which: 5.0431\n",
      "  regression which introduces: 5.0431\n",
      "  regularisation: 4.6376\n",
      "  regularisation methods: 5.0431\n",
      "  regularisation methods to: 5.0431\n",
      "  relationship: 4.6376\n",
      "  relationship between: 4.6376\n",
      "  relationship between input: 5.0431\n",
      "  ridge: 5.0431\n",
      "  ridge regression: 5.0431\n",
      "  ridge regression when: 5.0431\n",
      "  single: 4.1268\n",
      "  single line: 5.0431\n",
      "  single line is: 5.0431\n",
      "  space: 3.7903\n",
      "  squares: 5.0431\n",
      "  squares the: 5.0431\n",
      "  squares the latter: 5.0431\n",
      "  statistical: 6.8672\n",
      "  statistical classification: 4.6376\n",
      "  statistical classification or: 5.0431\n",
      "  statistical methods: 5.0431\n",
      "  statistical methods to: 5.0431\n",
      "  such: 2.4781\n",
      "  such as: 2.8458\n",
      "  such as ordinary: 5.0431\n",
      "  taking: 5.0431\n",
      "  taking advantage: 5.0431\n",
      "  taking advantage of: 5.0431\n",
      "  the: 4.7716\n",
      "  the given: 5.0431\n",
      "  the given data: 5.0431\n",
      "  the kernel: 4.6376\n",
      "  the kernel trick: 4.6376\n",
      "  the latter: 5.0431\n",
      "  the latter is: 5.0431\n",
      "  the relationship: 5.0431\n",
      "  the relationship between: 5.0431\n",
      "  their: 2.7918\n",
      "  their associated: 4.6376\n",
      "  their associated features: 5.0431\n",
      "  to: 7.3520\n",
      "  to a: 3.1712\n",
      "  to a mathematical: 5.0431\n",
      "  to best: 5.0431\n",
      "  to best fit: 5.0431\n",
      "  to estimate: 5.0431\n",
      "  to estimate the: 5.0431\n",
      "  to higherdimensional: 5.0431\n",
      "  to higherdimensional space: 5.0431\n",
      "  to implicitly: 5.0431\n",
      "  to implicitly map: 5.0431\n",
      "  to mitigate: 5.0431\n",
      "  to mitigate overfitting: 5.0431\n",
      "  trendline: 4.6376\n",
      "  trendline fitting: 5.0431\n",
      "  trendline fitting in: 5.0431\n",
      "  trick: 4.6376\n",
      "  trick to: 5.0431\n",
      "  trick to implicitly: 5.0431\n",
      "  used: 4.6700\n",
      "  used for: 4.1268\n",
      "  used for trendline: 5.0431\n",
      "  used in: 3.4336\n",
      "  used in statistical: 5.0431\n",
      "  variables: 7.3135\n",
      "  variables and: 4.3499\n",
      "  variables and their: 4.6376\n",
      "  variables to: 5.0431\n",
      "  variables to higherdimensional: 5.0431\n",
      "  variety: 4.3499\n",
      "  variety of: 4.3499\n",
      "  variety of statistical: 5.0431\n",
      "  when: 3.3383\n",
      "  when dealing: 5.0431\n",
      "  when dealing with: 5.0431\n",
      "  where: 3.2513\n",
      "  where a: 4.6376\n",
      "  where a single: 5.0431\n",
      "  which: 2.6917\n",
      "  which introduces: 5.0431\n",
      "  which introduces nonlinearity: 5.0431\n",
      "  with: 2.0726\n",
      "  with nonlinear: 5.0431\n",
      "  with nonlinear problems: 5.0431\n",
      "\n",
      "Document 73:\n",
      "  a: 2.5177\n",
      "  a multidimensional: 5.0431\n",
      "  a multidimensional linear: 5.0431\n",
      "  a set: 3.2513\n",
      "  a set of: 3.2513\n",
      "  and: 1.2144\n",
      "  and several: 5.0431\n",
      "  and several output: 5.0431\n",
      "  approach: 3.6568\n",
      "  approach estimates: 5.0431\n",
      "  approach estimates the: 5.0431\n",
      "  are: 3.9500\n",
      "  are inherently: 5.0431\n",
      "  are inherently multidimensional: 5.0431\n",
      "  are interdependent: 5.0431\n",
      "  are interdependent or: 5.0431\n",
      "  as: 1.8444\n",
      "  as predicting: 4.6376\n",
      "  as predicting multiple: 5.0431\n",
      "  between: 2.9636\n",
      "  between a: 5.0431\n",
      "  between a set: 5.0431\n",
      "  by: 1.9076\n",
      "  by fitting: 5.0431\n",
      "  by fitting a: 5.0431\n",
      "  concept: 4.3499\n",
      "  concept of: 4.6376\n",
      "  concept of linear: 5.0431\n",
      "  dependent: 4.6376\n",
      "  dependent variables: 5.0431\n",
      "  dependent variables simultaneously: 5.0431\n",
      "  economic: 5.0431\n",
      "  economic indicators: 5.0431\n",
      "  economic indicators or: 5.0431\n",
      "  estimates: 5.0431\n",
      "  estimates the: 5.0431\n",
      "  estimates the relationships: 5.0431\n",
      "  extends: 5.0431\n",
      "  extends the: 5.0431\n",
      "  extends the concept: 5.0431\n",
      "  fitting: 4.6376\n",
      "  fitting a: 5.0431\n",
      "  fitting a multidimensional: 5.0431\n",
      "  handle: 4.6376\n",
      "  handle multiple: 5.0431\n",
      "  handle multiple dependent: 5.0431\n",
      "  images: 4.1268\n",
      "  images which: 5.0431\n",
      "  images which are: 5.0431\n",
      "  in: 1.3417\n",
      "  in scenarios: 5.0431\n",
      "  in scenarios where: 5.0431\n",
      "  indicators: 4.6376\n",
      "  indicators or: 5.0431\n",
      "  indicators or reconstructing: 5.0431\n",
      "  inherently: 4.6376\n",
      "  inherently multidimensional: 5.0431\n",
      "  input: 3.0281\n",
      "  input variables: 4.6376\n",
      "  input variables and: 4.6376\n",
      "  interdependent: 5.0431\n",
      "  interdependent or: 5.0431\n",
      "  interdependent or share: 5.0431\n",
      "  is: 1.5167\n",
      "  is particularly: 4.6376\n",
      "  is particularly useful: 4.6376\n",
      "  it: 2.2705\n",
      "  it is: 3.5390\n",
      "  it is particularly: 5.0431\n",
      "  linear: 11.3709\n",
      "  linear model: 5.0431\n",
      "  linear model it: 5.0431\n",
      "  linear regression: 9.2752\n",
      "  linear regression extends: 5.0431\n",
      "  linear regression to: 5.0431\n",
      "  model: 2.3350\n",
      "  model it: 5.0431\n",
      "  model it is: 5.0431\n",
      "  multidimensional: 9.2752\n",
      "  multidimensional linear: 5.0431\n",
      "  multidimensional linear model: 5.0431\n",
      "  multiple: 7.8889\n",
      "  multiple dependent: 5.0431\n",
      "  multiple dependent variables: 5.0431\n",
      "  multiple economic: 5.0431\n",
      "  multiple economic indicators: 5.0431\n",
      "  multivariate: 4.6376\n",
      "  multivariate linear: 5.0431\n",
      "  multivariate linear regression: 5.0431\n",
      "  of: 2.4288\n",
      "  of input: 5.0431\n",
      "  of input variables: 5.0431\n",
      "  of linear: 5.0431\n",
      "  of linear regression: 5.0431\n",
      "  or: 4.0453\n",
      "  or reconstructing: 5.0431\n",
      "  or reconstructing images: 5.0431\n",
      "  or share: 5.0431\n",
      "  or share underlying: 5.0431\n",
      "  output: 3.3383\n",
      "  output variables: 5.0431\n",
      "  output variables by: 5.0431\n",
      "  outputs: 4.3499\n",
      "  outputs are: 4.6376\n",
      "  outputs are interdependent: 5.0431\n",
      "  particularly: 4.1268\n",
      "  particularly useful: 4.6376\n",
      "  particularly useful in: 4.6376\n",
      "  patterns: 3.4336\n",
      "  patterns such: 5.0431\n",
      "  patterns such as: 5.0431\n",
      "  predicting: 4.6376\n",
      "  predicting multiple: 5.0431\n",
      "  predicting multiple economic: 5.0431\n",
      "  reconstructing: 5.0431\n",
      "  reconstructing images: 5.0431\n",
      "  reconstructing images which: 5.0431\n",
      "  regression: 7.3135\n",
      "  regression extends: 5.0431\n",
      "  regression extends the: 5.0431\n",
      "  regression to: 5.0431\n",
      "  regression to handle: 5.0431\n",
      "  relationships: 4.1268\n",
      "  relationships between: 4.1268\n",
      "  relationships between a: 5.0431\n",
      "  scenarios: 5.0431\n",
      "  scenarios where: 5.0431\n",
      "  scenarios where outputs: 5.0431\n",
      "  set: 2.6007\n",
      "  set of: 3.0281\n",
      "  set of input: 5.0431\n",
      "  several: 3.9444\n",
      "  several output: 5.0431\n",
      "  several output variables: 5.0431\n",
      "  share: 5.0431\n",
      "  share underlying: 5.0431\n",
      "  share underlying patterns: 5.0431\n",
      "  simultaneously: 5.0431\n",
      "  simultaneously this: 5.0431\n",
      "  simultaneously this approach: 5.0431\n",
      "  such: 2.4781\n",
      "  such as: 2.8458\n",
      "  such as predicting: 4.6376\n",
      "  the: 2.3858\n",
      "  the concept: 4.6376\n",
      "  the concept of: 4.6376\n",
      "  the relationships: 5.0431\n",
      "  the relationships between: 5.0431\n",
      "  this: 2.6007\n",
      "  this approach: 4.6376\n",
      "  this approach estimates: 5.0431\n",
      "  to: 1.2253\n",
      "  to handle: 5.0431\n",
      "  to handle multiple: 5.0431\n",
      "  underlying: 3.9444\n",
      "  underlying patterns: 4.6376\n",
      "  underlying patterns such: 5.0431\n",
      "  useful: 3.9444\n",
      "  useful in: 4.6376\n",
      "  useful in scenarios: 5.0431\n",
      "  variables: 10.9703\n",
      "  variables and: 4.3499\n",
      "  variables and several: 5.0431\n",
      "  variables by: 5.0431\n",
      "  variables by fitting: 5.0431\n",
      "  variables simultaneously: 5.0431\n",
      "  variables simultaneously this: 5.0431\n",
      "  where: 3.2513\n",
      "  where outputs: 5.0431\n",
      "  where outputs are: 5.0431\n",
      "  which: 2.6917\n",
      "  which are: 5.0431\n",
      "  which are inherently: 5.0431\n",
      "\n",
      "Document 74:\n",
      "  a: 6.2943\n",
      "  a bayesian: 10.0861\n",
      "  a bayesian network: 10.0861\n",
      "  a directed: 5.0431\n",
      "  a directed acyclic: 5.0431\n",
      "  a probabilistic: 4.6376\n",
      "  a probabilistic graphical: 5.0431\n",
      "  a set: 3.2513\n",
      "  a set of: 3.2513\n",
      "  acyclic: 10.0861\n",
      "  acyclic graph: 5.0431\n",
      "  acyclic graph dag: 5.0431\n",
      "  acyclic graphical: 5.0431\n",
      "  acyclic graphical model: 5.0431\n",
      "  algorithms: 2.3689\n",
      "  algorithms exist: 5.0431\n",
      "  algorithms exist that: 5.0431\n",
      "  and: 4.8576\n",
      "  and learning: 5.0431\n",
      "  and learning bayesian: 5.0431\n",
      "  and solve: 5.0431\n",
      "  and solve decision: 5.0431\n",
      "  and symptoms: 5.0431\n",
      "  and symptoms given: 5.0431\n",
      "  and their: 3.9444\n",
      "  and their conditional: 5.0431\n",
      "  are: 3.9500\n",
      "  are called: 8.6998\n",
      "  are called dynamic: 5.0431\n",
      "  are called influence: 5.0431\n",
      "  bayesian: 21.7495\n",
      "  bayesian network: 10.0861\n",
      "  bayesian network belief: 5.0431\n",
      "  bayesian network could: 5.0431\n",
      "  bayesian networks: 15.1292\n",
      "  bayesian networks generalisations: 5.0431\n",
      "  bayesian networks that: 10.0861\n",
      "  be: 2.0726\n",
      "  be used: 3.4336\n",
      "  be used to: 3.9444\n",
      "  belief: 4.6376\n",
      "  belief network: 5.0431\n",
      "  belief network or: 5.0431\n",
      "  between: 2.9636\n",
      "  between diseases: 5.0431\n",
      "  between diseases and: 5.0431\n",
      "  called: 6.5026\n",
      "  called dynamic: 5.0431\n",
      "  called dynamic bayesian: 5.0431\n",
      "  called influence: 5.0431\n",
      "  called influence diagrams: 5.0431\n",
      "  can: 4.3617\n",
      "  can be: 2.7405\n",
      "  can be used: 3.6568\n",
      "  can represent: 5.0431\n",
      "  can represent and: 5.0431\n",
      "  compute: 4.3499\n",
      "  compute the: 5.0431\n",
      "  compute the probabilities: 5.0431\n",
      "  conditional: 5.0431\n",
      "  conditional independence: 5.0431\n",
      "  conditional independence with: 5.0431\n",
      "  could: 4.3499\n",
      "  could represent: 5.0431\n",
      "  could represent the: 5.0431\n",
      "  dag: 5.0431\n",
      "  dag for: 5.0431\n",
      "  dag for example: 5.0431\n",
      "  decision: 3.6568\n",
      "  decision problems: 5.0431\n",
      "  decision problems under: 5.0431\n",
      "  diagrams: 5.0431\n",
      "  directed: 10.0861\n",
      "  directed acyclic: 10.0861\n",
      "  directed acyclic graph: 5.0431\n",
      "  directed acyclic graphical: 5.0431\n",
      "  diseases: 10.0861\n",
      "  diseases and: 5.0431\n",
      "  diseases and symptoms: 5.0431\n",
      "  diseases efficient: 5.0431\n",
      "  diseases efficient algorithms: 5.0431\n",
      "  dynamic: 4.6376\n",
      "  dynamic bayesian: 5.0431\n",
      "  dynamic bayesian networks: 5.0431\n",
      "  efficient: 4.3499\n",
      "  efficient algorithms: 5.0431\n",
      "  efficient algorithms exist: 5.0431\n",
      "  example: 2.9636\n",
      "  example a: 5.0431\n",
      "  example a bayesian: 5.0431\n",
      "  exist: 4.3499\n",
      "  exist that: 5.0431\n",
      "  exist that perform: 5.0431\n",
      "  for: 1.7289\n",
      "  for example: 3.2513\n",
      "  for example a: 5.0431\n",
      "  generalisations: 5.0431\n",
      "  generalisations of: 5.0431\n",
      "  generalisations of bayesian: 5.0431\n",
      "  given: 3.3383\n",
      "  given symptoms: 5.0431\n",
      "  given symptoms the: 5.0431\n",
      "  graph: 4.6376\n",
      "  graph dag: 5.0431\n",
      "  graph dag for: 5.0431\n",
      "  graphical: 10.0861\n",
      "  graphical model: 10.0861\n",
      "  graphical model is: 5.0431\n",
      "  graphical model that: 5.0431\n",
      "  independence: 5.0431\n",
      "  independence with: 5.0431\n",
      "  independence with a: 5.0431\n",
      "  inference: 4.3499\n",
      "  inference and: 5.0431\n",
      "  inference and learning: 5.0431\n",
      "  influence: 5.0431\n",
      "  influence diagrams: 5.0431\n",
      "  is: 1.5167\n",
      "  is a: 2.5173\n",
      "  is a probabilistic: 5.0431\n",
      "  learning: 1.2819\n",
      "  learning bayesian: 5.0431\n",
      "  learning bayesian networks: 5.0431\n",
      "  like: 3.3383\n",
      "  like speech: 5.0431\n",
      "  like speech signals: 5.0431\n",
      "  model: 7.0050\n",
      "  model is: 4.3499\n",
      "  model is a: 4.6376\n",
      "  model sequences: 5.0431\n",
      "  model sequences of: 5.0431\n",
      "  model that: 4.1268\n",
      "  model that represents: 5.0431\n",
      "  network: 14.1559\n",
      "  network belief: 5.0431\n",
      "  network belief network: 5.0431\n",
      "  network can: 5.0431\n",
      "  network can be: 5.0431\n",
      "  network could: 5.0431\n",
      "  network could represent: 5.0431\n",
      "  network or: 5.0431\n",
      "  network or directed: 5.0431\n",
      "  networks: 9.2914\n",
      "  networks generalisations: 5.0431\n",
      "  networks generalisations of: 5.0431\n",
      "  networks that: 8.6998\n",
      "  networks that can: 5.0431\n",
      "  networks that model: 5.0431\n",
      "  of: 6.0720\n",
      "  of bayesian: 5.0431\n",
      "  of bayesian networks: 5.0431\n",
      "  of random: 4.6376\n",
      "  of random variables: 4.6376\n",
      "  of the: 2.3022\n",
      "  of the presence: 5.0431\n",
      "  of variables: 5.0431\n",
      "  of variables like: 5.0431\n",
      "  of various: 4.3499\n",
      "  of various diseases: 5.0431\n",
      "  or: 4.0453\n",
      "  or directed: 5.0431\n",
      "  or directed acyclic: 5.0431\n",
      "  or protein: 5.0431\n",
      "  or protein sequences: 5.0431\n",
      "  perform: 3.2513\n",
      "  perform inference: 5.0431\n",
      "  perform inference and: 5.0431\n",
      "  presence: 4.6376\n",
      "  presence of: 5.0431\n",
      "  presence of various: 5.0431\n",
      "  probabilistic: 7.8889\n",
      "  probabilistic graphical: 5.0431\n",
      "  probabilistic graphical model: 5.0431\n",
      "  probabilistic relationships: 5.0431\n",
      "  probabilistic relationships between: 5.0431\n",
      "  probabilities: 4.3499\n",
      "  probabilities of: 4.6376\n",
      "  probabilities of the: 5.0431\n",
      "  problems: 3.1712\n",
      "  problems under: 5.0431\n",
      "  problems under uncertainty: 5.0431\n",
      "  protein: 5.0431\n",
      "  protein sequences: 5.0431\n",
      "  protein sequences are: 5.0431\n",
      "  random: 3.9444\n",
      "  random variables: 4.3499\n",
      "  random variables and: 5.0431\n",
      "  relationships: 4.1268\n",
      "  relationships between: 4.1268\n",
      "  relationships between diseases: 5.0431\n",
      "  represent: 8.2535\n",
      "  represent and: 5.0431\n",
      "  represent and solve: 5.0431\n",
      "  represent the: 4.6376\n",
      "  represent the probabilistic: 5.0431\n",
      "  represents: 5.0431\n",
      "  represents a: 5.0431\n",
      "  represents a set: 5.0431\n",
      "  sequences: 10.0861\n",
      "  sequences are: 5.0431\n",
      "  sequences are called: 5.0431\n",
      "  sequences of: 5.0431\n",
      "  sequences of variables: 5.0431\n",
      "  set: 2.6007\n",
      "  set of: 3.0281\n",
      "  set of random: 5.0431\n",
      "  signals: 4.3499\n",
      "  signals or: 5.0431\n",
      "  signals or protein: 5.0431\n",
      "  solve: 4.3499\n",
      "  solve decision: 5.0431\n",
      "  solve decision problems: 5.0431\n",
      "  speech: 3.9444\n",
      "  speech signals: 5.0431\n",
      "  speech signals or: 5.0431\n",
      "  symptoms: 10.0861\n",
      "  symptoms given: 5.0431\n",
      "  symptoms given symptoms: 5.0431\n",
      "  symptoms the: 5.0431\n",
      "  symptoms the network: 5.0431\n",
      "  that: 6.7030\n",
      "  that can: 3.9444\n",
      "  that can represent: 5.0431\n",
      "  that model: 4.6376\n",
      "  that model sequences: 5.0431\n",
      "  that perform: 5.0431\n",
      "  that perform inference: 5.0431\n",
      "  that represents: 5.0431\n",
      "  that represents a: 5.0431\n",
      "  the: 4.7716\n",
      "  the network: 5.0431\n",
      "  the network can: 5.0431\n",
      "  the presence: 4.6376\n",
      "  the presence of: 5.0431\n",
      "  the probabilistic: 5.0431\n",
      "  the probabilistic relationships: 5.0431\n",
      "  the probabilities: 5.0431\n",
      "  the probabilities of: 5.0431\n",
      "  their: 2.7918\n",
      "  their conditional: 5.0431\n",
      "  their conditional independence: 5.0431\n",
      "  to: 1.2253\n",
      "  to compute: 5.0431\n",
      "  to compute the: 5.0431\n",
      "  uncertainty: 4.6376\n",
      "  uncertainty are: 5.0431\n",
      "  uncertainty are called: 5.0431\n",
      "  under: 3.4336\n",
      "  under uncertainty: 5.0431\n",
      "  under uncertainty are: 5.0431\n",
      "  used: 2.3350\n",
      "  used to: 3.3383\n",
      "  used to compute: 5.0431\n",
      "  variables: 7.3135\n",
      "  variables and: 4.3499\n",
      "  variables and their: 4.6376\n",
      "  variables like: 5.0431\n",
      "  variables like speech: 5.0431\n",
      "  various: 3.4336\n",
      "  various diseases: 5.0431\n",
      "  various diseases efficient: 5.0431\n",
      "  with: 2.0726\n",
      "  with a: 3.6568\n",
      "  with a directed: 5.0431\n",
      "\n",
      "Document 75:\n",
      "  a: 5.0354\n",
      "  a gaussian: 5.0431\n",
      "  a gaussian process: 5.0431\n",
      "  a multivariate: 5.0431\n",
      "  a multivariate normal: 5.0431\n",
      "  a predefined: 5.0431\n",
      "  a predefined covariance: 5.0431\n",
      "  a stochastic: 5.0431\n",
      "  a stochastic process: 5.0431\n",
      "  and: 1.2144\n",
      "  and it: 4.3499\n",
      "  and it relies: 5.0431\n",
      "  collection: 4.1268\n",
      "  collection of: 4.1268\n",
      "  collection of the: 5.0431\n",
      "  covariance: 5.0431\n",
      "  covariance function: 5.0431\n",
      "  covariance function or: 5.0431\n",
      "  depending: 4.6376\n",
      "  depending on: 4.6376\n",
      "  depending on their: 5.0431\n",
      "  distribution: 3.9444\n",
      "  distribution and: 5.0431\n",
      "  distribution and it: 5.0431\n",
      "  each: 3.0971\n",
      "  each other: 5.0431\n",
      "  each other depending: 5.0431\n",
      "  every: 5.0431\n",
      "  every finite: 5.0431\n",
      "  every finite collection: 5.0431\n",
      "  finite: 4.6376\n",
      "  finite collection: 5.0431\n",
      "  finite collection of: 5.0431\n",
      "  function: 3.4336\n",
      "  function or: 5.0431\n",
      "  function or kernel: 5.0431\n",
      "  gaussian: 4.6376\n",
      "  gaussian process: 5.0431\n",
      "  gaussian process is: 5.0431\n",
      "  has: 2.8458\n",
      "  has a: 5.0431\n",
      "  has a multivariate: 5.0431\n",
      "  how: 3.5390\n",
      "  how pairs: 5.0431\n",
      "  how pairs of: 5.0431\n",
      "  in: 2.6835\n",
      "  in the: 2.4404\n",
      "  in the process: 5.0431\n",
      "  in which: 3.7903\n",
      "  in which every: 5.0431\n",
      "  is: 1.5167\n",
      "  is a: 2.5173\n",
      "  is a stochastic: 5.0431\n",
      "  it: 2.2705\n",
      "  it relies: 5.0431\n",
      "  it relies on: 5.0431\n",
      "  kernel: 4.3499\n",
      "  kernel that: 5.0431\n",
      "  kernel that models: 5.0431\n",
      "  locations: 5.0431\n",
      "  models: 2.5581\n",
      "  models how: 5.0431\n",
      "  models how pairs: 5.0431\n",
      "  multivariate: 4.6376\n",
      "  multivariate normal: 5.0431\n",
      "  multivariate normal distribution: 5.0431\n",
      "  normal: 4.6376\n",
      "  normal distribution: 5.0431\n",
      "  normal distribution and: 5.0431\n",
      "  of: 2.4288\n",
      "  of points: 5.0431\n",
      "  of points relate: 5.0431\n",
      "  of the: 2.3022\n",
      "  of the random: 5.0431\n",
      "  on: 4.0946\n",
      "  on a: 3.5390\n",
      "  on a predefined: 5.0431\n",
      "  on their: 4.6376\n",
      "  on their locations: 5.0431\n",
      "  or: 2.0226\n",
      "  or kernel: 5.0431\n",
      "  or kernel that: 5.0431\n",
      "  other: 2.7918\n",
      "  other depending: 5.0431\n",
      "  other depending on: 5.0431\n",
      "  pairs: 5.0431\n",
      "  pairs of: 5.0431\n",
      "  pairs of points: 5.0431\n",
      "  points: 4.1268\n",
      "  points relate: 5.0431\n",
      "  points relate to: 5.0431\n",
      "  predefined: 4.6376\n",
      "  predefined covariance: 5.0431\n",
      "  predefined covariance function: 5.0431\n",
      "  process: 10.3008\n",
      "  process has: 5.0431\n",
      "  process has a: 5.0431\n",
      "  process in: 5.0431\n",
      "  process in which: 5.0431\n",
      "  process is: 5.0431\n",
      "  process is a: 5.0431\n",
      "  random: 3.9444\n",
      "  random variables: 4.3499\n",
      "  random variables in: 5.0431\n",
      "  relate: 5.0431\n",
      "  relate to: 5.0431\n",
      "  relate to each: 5.0431\n",
      "  relies: 4.6376\n",
      "  relies on: 4.6376\n",
      "  relies on a: 5.0431\n",
      "  stochastic: 5.0431\n",
      "  stochastic process: 5.0431\n",
      "  stochastic process in: 5.0431\n",
      "  that: 1.6758\n",
      "  that models: 5.0431\n",
      "  that models how: 5.0431\n",
      "  the: 2.3858\n",
      "  the process: 4.3499\n",
      "  the process has: 5.0431\n",
      "  the random: 5.0431\n",
      "  the random variables: 5.0431\n",
      "  their: 2.7918\n",
      "  their locations: 5.0431\n",
      "  to: 1.2253\n",
      "  to each: 5.0431\n",
      "  to each other: 5.0431\n",
      "  variables: 3.6568\n",
      "  variables in: 4.3499\n",
      "  variables in the: 5.0431\n",
      "  which: 2.6917\n",
      "  which every: 5.0431\n",
      "  which every finite: 5.0431\n",
      "\n",
      "Document 76:\n",
      "  a: 2.5177\n",
      "  a new: 4.3499\n",
      "  a new point: 5.0431\n",
      "  a set: 3.2513\n",
      "  a set of: 3.2513\n",
      "  and: 2.4288\n",
      "  and the: 6.6766\n",
      "  and the covariances: 5.0431\n",
      "  and the new: 5.0431\n",
      "  as: 1.8444\n",
      "  as function: 5.0431\n",
      "  as function of: 5.0431\n",
      "  be: 2.0726\n",
      "  be directly: 5.0431\n",
      "  be directly computed: 5.0431\n",
      "  between: 2.9636\n",
      "  between those: 5.0431\n",
      "  between those points: 5.0431\n",
      "  by: 1.9076\n",
      "  by looking: 4.6376\n",
      "  by looking like: 5.0431\n",
      "  can: 2.1809\n",
      "  can be: 2.7405\n",
      "  can be directly: 5.0431\n",
      "  computed: 4.6376\n",
      "  computed by: 4.6376\n",
      "  computed by looking: 5.0431\n",
      "  covariances: 5.0431\n",
      "  covariances between: 5.0431\n",
      "  covariances between those: 5.0431\n",
      "  data: 1.8650\n",
      "  data can: 4.3499\n",
      "  data can be: 5.0431\n",
      "  directly: 4.1268\n",
      "  directly computed: 5.0431\n",
      "  directly computed by: 5.0431\n",
      "  distribution: 3.9444\n",
      "  distribution of: 5.0431\n",
      "  distribution of the: 5.0431\n",
      "  examples: 3.0971\n",
      "  examples the: 4.6376\n",
      "  examples the distribution: 5.0431\n",
      "  function: 3.4336\n",
      "  function of: 4.3499\n",
      "  function of its: 5.0431\n",
      "  given: 3.3383\n",
      "  given a: 4.6376\n",
      "  given a set: 4.6376\n",
      "  input: 3.0281\n",
      "  input data: 4.6376\n",
      "  input data can: 5.0431\n",
      "  inputoutput: 5.0431\n",
      "  inputoutput examples: 5.0431\n",
      "  inputoutput examples the: 5.0431\n",
      "  its: 2.9636\n",
      "  its input: 5.0431\n",
      "  its input data: 5.0431\n",
      "  like: 3.3383\n",
      "  like the: 4.3499\n",
      "  like the observed: 5.0431\n",
      "  looking: 4.6376\n",
      "  looking like: 5.0431\n",
      "  looking like the: 5.0431\n",
      "  new: 6.5026\n",
      "  new point: 5.0431\n",
      "  new point as: 5.0431\n",
      "  new unobserved: 5.0431\n",
      "  new unobserved point: 5.0431\n",
      "  observed: 8.6998\n",
      "  observed points: 10.0861\n",
      "  observed points and: 5.0431\n",
      "  observed points or: 5.0431\n",
      "  of: 4.8576\n",
      "  of a: 3.0281\n",
      "  of a new: 5.0431\n",
      "  of its: 3.9444\n",
      "  of its input: 5.0431\n",
      "  of observed: 5.0431\n",
      "  of observed points: 5.0431\n",
      "  of the: 2.3022\n",
      "  of the unobserved: 5.0431\n",
      "  or: 2.0226\n",
      "  or inputoutput: 5.0431\n",
      "  or inputoutput examples: 5.0431\n",
      "  output: 3.3383\n",
      "  output of: 4.6376\n",
      "  output of a: 5.0431\n",
      "  point: 10.0861\n",
      "  point as: 5.0431\n",
      "  point as function: 5.0431\n",
      "  points: 12.3803\n",
      "  points and: 10.0861\n",
      "  points and the: 10.0861\n",
      "  points or: 5.0431\n",
      "  points or inputoutput: 5.0431\n",
      "  set: 2.6007\n",
      "  set of: 3.0281\n",
      "  set of observed: 5.0431\n",
      "  the: 5.9645\n",
      "  the covariances: 5.0431\n",
      "  the covariances between: 5.0431\n",
      "  the distribution: 5.0431\n",
      "  the distribution of: 5.0431\n",
      "  the new: 5.0431\n",
      "  the new unobserved: 5.0431\n",
      "  the observed: 4.6376\n",
      "  the observed points: 5.0431\n",
      "  the unobserved: 5.0431\n",
      "  the unobserved output: 5.0431\n",
      "  those: 4.3499\n",
      "  those points: 5.0431\n",
      "  those points and: 5.0431\n",
      "  unobserved: 10.0861\n",
      "  unobserved output: 5.0431\n",
      "  unobserved output of: 5.0431\n",
      "  unobserved point: 5.0431\n",
      "\n",
      "Document 77:\n",
      "  are: 1.9750\n",
      "  are popular: 5.0431\n",
      "  are popular surrogate: 5.0431\n",
      "  bayesian: 4.3499\n",
      "  bayesian optimisation: 5.0431\n",
      "  bayesian optimisation used: 5.0431\n",
      "  do: 3.6568\n",
      "  do hyperparameter: 5.0431\n",
      "  do hyperparameter optimisation: 5.0431\n",
      "  gaussian: 4.6376\n",
      "  gaussian processes: 5.0431\n",
      "  gaussian processes are: 5.0431\n",
      "  hyperparameter: 5.0431\n",
      "  hyperparameter optimisation: 5.0431\n",
      "  in: 1.3417\n",
      "  in bayesian: 5.0431\n",
      "  in bayesian optimisation: 5.0431\n",
      "  models: 2.5581\n",
      "  models in: 5.0431\n",
      "  models in bayesian: 5.0431\n",
      "  optimisation: 7.5806\n",
      "  optimisation used: 5.0431\n",
      "  optimisation used to: 5.0431\n",
      "  popular: 4.3499\n",
      "  popular surrogate: 5.0431\n",
      "  popular surrogate models: 5.0431\n",
      "  processes: 4.3499\n",
      "  processes are: 5.0431\n",
      "  processes are popular: 5.0431\n",
      "  surrogate: 5.0431\n",
      "  surrogate models: 5.0431\n",
      "  surrogate models in: 5.0431\n",
      "  to: 1.2253\n",
      "  to do: 4.6376\n",
      "  to do hyperparameter: 5.0431\n",
      "  used: 2.3350\n",
      "  used to: 3.3383\n",
      "  used to do: 5.0431\n",
      "\n",
      "Document 78:\n",
      "  a: 3.7766\n",
      "  a genetic: 4.6376\n",
      "  a genetic algorithm: 4.6376\n",
      "  a given: 4.3499\n",
      "  a given problem: 5.0431\n",
      "  a search: 5.0431\n",
      "  a search algorithm: 5.0431\n",
      "  algorithm: 5.8060\n",
      "  algorithm and: 5.0431\n",
      "  algorithm and heuristic: 5.0431\n",
      "  algorithm ga: 5.0431\n",
      "  algorithm ga is: 5.0431\n",
      "  algorithms: 4.7378\n",
      "  algorithms were: 5.0431\n",
      "  algorithms were used: 5.0431\n",
      "  and: 4.8576\n",
      "  and crossover: 5.0431\n",
      "  and crossover to: 5.0431\n",
      "  and evolutionary: 5.0431\n",
      "  and evolutionary algorithms: 5.0431\n",
      "  and heuristic: 5.0431\n",
      "  and heuristic technique: 5.0431\n",
      "  and s: 5.0431\n",
      "  and s conversely: 5.0431\n",
      "  as: 1.8444\n",
      "  as mutation: 5.0431\n",
      "  as mutation and: 5.0431\n",
      "  been: 2.6917\n",
      "  been used: 3.9444\n",
      "  been used to: 5.0431\n",
      "  conversely: 4.6376\n",
      "  conversely machine: 5.0431\n",
      "  conversely machine learning: 5.0431\n",
      "  crossover: 5.0431\n",
      "  crossover to: 5.0431\n",
      "  crossover to generate: 5.0431\n",
      "  evolutionary: 5.0431\n",
      "  evolutionary algorithms: 5.0431\n",
      "  finding: 4.3499\n",
      "  finding good: 5.0431\n",
      "  finding good solutions: 5.0431\n",
      "  ga: 5.0431\n",
      "  ga is: 5.0431\n",
      "  ga is a: 5.0431\n",
      "  generate: 4.6376\n",
      "  generate new: 5.0431\n",
      "  generate new genotypes: 5.0431\n",
      "  genetic: 12.3803\n",
      "  genetic algorithm: 4.6376\n",
      "  genetic algorithm ga: 5.0431\n",
      "  genetic algorithms: 4.6376\n",
      "  genetic algorithms were: 5.0431\n",
      "  genetic and: 5.0431\n",
      "  genetic and evolutionary: 5.0431\n",
      "  genotypes: 5.0431\n",
      "  genotypes in: 5.0431\n",
      "  genotypes in the: 5.0431\n",
      "  given: 3.3383\n",
      "  given problem: 5.0431\n",
      "  given problem in: 5.0431\n",
      "  good: 4.6376\n",
      "  good solutions: 5.0431\n",
      "  good solutions to: 5.0431\n",
      "  have: 2.4781\n",
      "  have been: 3.5390\n",
      "  have been used: 4.3499\n",
      "  heuristic: 4.6376\n",
      "  heuristic technique: 5.0431\n",
      "  heuristic technique that: 5.0431\n",
      "  hope: 5.0431\n",
      "  hope of: 5.0431\n",
      "  hope of finding: 5.0431\n",
      "  improve: 4.1268\n",
      "  improve the: 4.6376\n",
      "  improve the performance: 5.0431\n",
      "  in: 4.0252\n",
      "  in machine: 3.6568\n",
      "  in machine learning: 3.6568\n",
      "  in the: 4.8807\n",
      "  in the hope: 5.0431\n",
      "  in the s: 4.3499\n",
      "  is: 1.5167\n",
      "  is a: 2.5173\n",
      "  is a search: 5.0431\n",
      "  learning: 2.5637\n",
      "  learning genetic: 5.0431\n",
      "  learning genetic algorithms: 5.0431\n",
      "  learning techniques: 5.0431\n",
      "  learning techniques have: 5.0431\n",
      "  machine: 2.9470\n",
      "  machine learning: 3.1236\n",
      "  machine learning genetic: 5.0431\n",
      "  machine learning techniques: 5.0431\n",
      "  methods: 2.7405\n",
      "  methods such: 4.6376\n",
      "  methods such as: 4.6376\n",
      "  mimics: 5.0431\n",
      "  mimics the: 5.0431\n",
      "  mimics the process: 5.0431\n",
      "  mutation: 5.0431\n",
      "  mutation and: 5.0431\n",
      "  mutation and crossover: 5.0431\n",
      "  natural: 4.3499\n",
      "  natural selection: 5.0431\n",
      "  natural selection using: 5.0431\n",
      "  new: 3.2513\n",
      "  new genotypes: 5.0431\n",
      "  new genotypes in: 5.0431\n",
      "  of: 3.6432\n",
      "  of finding: 5.0431\n",
      "  of finding good: 5.0431\n",
      "  of genetic: 5.0431\n",
      "  of genetic and: 5.0431\n",
      "  of natural: 5.0431\n",
      "  of natural selection: 5.0431\n",
      "  performance: 3.4336\n",
      "  performance of: 4.3499\n",
      "  performance of genetic: 5.0431\n",
      "  problem: 3.9444\n",
      "  problem in: 5.0431\n",
      "  problem in machine: 5.0431\n",
      "  process: 3.4336\n",
      "  process of: 4.3499\n",
      "  process of natural: 5.0431\n",
      "  s: 7.8889\n",
      "  s and: 5.0431\n",
      "  s and s: 5.0431\n",
      "  s conversely: 5.0431\n",
      "  s conversely machine: 5.0431\n",
      "  search: 4.3499\n",
      "  search algorithm: 5.0431\n",
      "  search algorithm and: 5.0431\n",
      "  selection: 4.1268\n",
      "  selection using: 5.0431\n",
      "  selection using methods: 5.0431\n",
      "  solutions: 4.6376\n",
      "  solutions to: 5.0431\n",
      "  solutions to a: 5.0431\n",
      "  such: 2.4781\n",
      "  such as: 2.8458\n",
      "  such as mutation: 5.0431\n",
      "  technique: 4.3499\n",
      "  technique that: 5.0431\n",
      "  technique that mimics: 5.0431\n",
      "  techniques: 3.3383\n",
      "  techniques have: 5.0431\n",
      "  techniques have been: 5.0431\n",
      "  that: 1.6758\n",
      "  that mimics: 5.0431\n",
      "  that mimics the: 5.0431\n",
      "  the: 4.7716\n",
      "  the hope: 5.0431\n",
      "  the hope of: 5.0431\n",
      "  the performance: 4.3499\n",
      "  the performance of: 4.3499\n",
      "  the process: 4.3499\n",
      "  the process of: 4.6376\n",
      "  the s: 3.9444\n",
      "  the s and: 5.0431\n",
      "  to: 3.6760\n",
      "  to a: 3.1712\n",
      "  to a given: 5.0431\n",
      "  to generate: 5.0431\n",
      "  to generate new: 5.0431\n",
      "  to improve: 4.3499\n",
      "  to improve the: 5.0431\n",
      "  used: 4.6700\n",
      "  used in: 3.4336\n",
      "  used in the: 4.6376\n",
      "  used to: 3.3383\n",
      "  used to improve: 5.0431\n",
      "  using: 3.2513\n",
      "  using methods: 5.0431\n",
      "  using methods such: 5.0431\n",
      "  were: 3.7903\n",
      "  were used: 5.0431\n",
      "  were used in: 5.0431\n",
      "\n",
      "Document 79:\n",
      "  a: 6.2943\n",
      "  a fusion: 5.0431\n",
      "  a fusion approach: 5.0431\n",
      "  a general: 4.1268\n",
      "  a general framework: 5.0431\n",
      "  a kind: 5.0431\n",
      "  a kind of: 5.0431\n",
      "  a much: 5.0431\n",
      "  a much higher: 5.0431\n",
      "  a pmfbased: 5.0431\n",
      "  a pmfbased bayesian: 5.0431\n",
      "  algorithms: 2.3689\n",
      "  algorithms are: 4.3499\n",
      "  algorithms are dependent: 5.0431\n",
      "  also: 2.6452\n",
      "  also referred: 5.0431\n",
      "  also referred to: 5.0431\n",
      "  ambiguous: 5.0431\n",
      "  ambiguous class: 5.0431\n",
      "  ambiguous class issues: 5.0431\n",
      "  analogous: 5.0431\n",
      "  analogous properties: 5.0431\n",
      "  analogous properties of: 5.0431\n",
      "  and: 6.0720\n",
      "  and ambiguous: 5.0431\n",
      "  and ambiguous class: 5.0431\n",
      "  and can: 5.0431\n",
      "  and can lead: 5.0431\n",
      "  and have: 5.0431\n",
      "  and have some: 5.0431\n",
      "  and imprecise: 5.0431\n",
      "  and imprecise probability: 5.0431\n",
      "  and uncertainty: 5.0431\n",
      "  and uncertainty quantification: 5.0431\n",
      "  approach: 10.9703\n",
      "  approach of: 5.0431\n",
      "  approach of various: 5.0431\n",
      "  approach tend: 5.0431\n",
      "  approach tend to: 5.0431\n",
      "  approach would: 5.0431\n",
      "  approach would combine: 5.0431\n",
      "  approaches: 10.6169\n",
      "  approaches in: 4.6376\n",
      "  approaches in order: 5.0431\n",
      "  approaches that: 5.0431\n",
      "  approaches that are: 5.0431\n",
      "  are: 5.9250\n",
      "  are dependent: 5.0431\n",
      "  are dependent on: 5.0431\n",
      "  are implemented: 5.0431\n",
      "  are implemented within: 5.0431\n",
      "  are many: 4.6376\n",
      "  are many caveats: 5.0431\n",
      "  as: 5.5331\n",
      "  as a: 2.9030\n",
      "  as a kind: 5.0431\n",
      "  as evidence: 5.0431\n",
      "  as evidence theory: 5.0431\n",
      "  as probability: 5.0431\n",
      "  as probability possibility: 5.0431\n",
      "  bayesian: 8.6998\n",
      "  bayesian approach: 5.0431\n",
      "  bayesian approach would: 5.0431\n",
      "  bayesian approaches: 5.0431\n",
      "  bayesian approaches in: 5.0431\n",
      "  be: 2.0726\n",
      "  be thought: 5.0431\n",
      "  be thought of: 5.0431\n",
      "  belief: 9.2752\n",
      "  belief function: 5.0431\n",
      "  belief function approaches: 5.0431\n",
      "  belief functions: 5.0431\n",
      "  belief functions also: 5.0431\n",
      "  beliefs: 5.0431\n",
      "  beliefs functions: 5.0431\n",
      "  beliefs functions when: 5.0431\n",
      "  better: 4.1268\n",
      "  better handle: 5.0431\n",
      "  better handle the: 5.0431\n",
      "  boundary: 5.0431\n",
      "  boundary low: 5.0431\n",
      "  boundary low samples: 5.0431\n",
      "  can: 4.3617\n",
      "  can be: 2.7405\n",
      "  can be thought: 5.0431\n",
      "  can lead: 5.0431\n",
      "  can lead to: 5.0431\n",
      "  caveats: 5.0431\n",
      "  caveats to: 5.0431\n",
      "  caveats to these: 5.0431\n",
      "  class: 3.5390\n",
      "  class issues: 5.0431\n",
      "  class issues that: 5.0431\n",
      "  classes: 4.6376\n",
      "  classes and: 5.0431\n",
      "  classes and can: 5.0431\n",
      "  combination: 4.6376\n",
      "  combination just: 5.0431\n",
      "  combination just like: 5.0431\n",
      "  combine: 4.6376\n",
      "  combine probabilities: 5.0431\n",
      "  combine probabilities however: 5.0431\n",
      "  combined: 4.3499\n",
      "  combined eg: 5.0431\n",
      "  combined eg dempsters: 5.0431\n",
      "  compared: 10.0861\n",
      "  compared to: 10.0861\n",
      "  compared to bayesian: 5.0431\n",
      "  compared to other: 5.0431\n",
      "  complexity: 4.3499\n",
      "  complexity of: 4.6376\n",
      "  complexity of these: 5.0431\n",
      "  computation: 4.3499\n",
      "  computation time: 5.0431\n",
      "  computation time when: 5.0431\n",
      "  computational: 4.1268\n",
      "  computational complexity: 5.0431\n",
      "  computational complexity of: 5.0431\n",
      "  connections: 4.6376\n",
      "  connections to: 5.0431\n",
      "  connections to other: 5.0431\n",
      "  decision: 3.6568\n",
      "  decision boundary: 5.0431\n",
      "  decision boundary low: 5.0431\n",
      "  dempsters: 5.0431\n",
      "  dempsters rule: 5.0431\n",
      "  dempsters rule of: 5.0431\n",
      "  dempstershafer: 5.0431\n",
      "  dempstershafer theory: 5.0431\n",
      "  dempstershafer theory is: 5.0431\n",
      "  dependent: 4.6376\n",
      "  dependent on: 5.0431\n",
      "  dependent on the: 5.0431\n",
      "  difficulty: 5.0431\n",
      "  difficulty resolving: 5.0431\n",
      "  difficulty resolving however: 5.0431\n",
      "  domain: 5.0431\n",
      "  domain typically: 5.0431\n",
      "  domain typically leverage: 5.0431\n",
      "  eg: 3.9444\n",
      "  eg dempsters: 5.0431\n",
      "  eg dempsters rule: 5.0431\n",
      "  ensemble: 4.3499\n",
      "  ensemble methods: 5.0431\n",
      "  ensemble methods to: 5.0431\n",
      "  evidence: 9.2752\n",
      "  evidence is: 5.0431\n",
      "  evidence is combined: 5.0431\n",
      "  evidence theory: 5.0431\n",
      "  evidence theory or: 5.0431\n",
      "  for: 1.7289\n",
      "  for reasoning: 5.0431\n",
      "  for reasoning with: 5.0431\n",
      "  framework: 4.6376\n",
      "  framework for: 4.6376\n",
      "  framework for reasoning: 5.0431\n",
      "  frameworks: 10.0861\n",
      "  frameworks can: 5.0431\n",
      "  frameworks can be: 5.0431\n",
      "  frameworks such: 5.0431\n",
      "  frameworks such as: 5.0431\n",
      "  function: 3.4336\n",
      "  function approaches: 5.0431\n",
      "  function approaches that: 5.0431\n",
      "  functions: 8.2535\n",
      "  functions also: 5.0431\n",
      "  functions also referred: 5.0431\n",
      "  functions when: 5.0431\n",
      "  functions when compared: 5.0431\n",
      "  fusion: 5.0431\n",
      "  fusion approach: 5.0431\n",
      "  fusion approach of: 5.0431\n",
      "  general: 3.9444\n",
      "  general framework: 5.0431\n",
      "  general framework for: 5.0431\n",
      "  handle: 4.6376\n",
      "  handle the: 5.0431\n",
      "  handle the learners: 5.0431\n",
      "  have: 4.9562\n",
      "  have difficulty: 5.0431\n",
      "  have difficulty resolving: 5.0431\n",
      "  have some: 5.0431\n",
      "  have some analogous: 5.0431\n",
      "  higher: 4.6376\n",
      "  higher computation: 5.0431\n",
      "  higher computation time: 5.0431\n",
      "  how: 7.0779\n",
      "  how evidence: 5.0431\n",
      "  how evidence is: 5.0431\n",
      "  how in: 5.0431\n",
      "  how in a: 5.0431\n",
      "  however: 7.5806\n",
      "  however the: 5.0431\n",
      "  however the computational: 5.0431\n",
      "  however there: 5.0431\n",
      "  however there are: 5.0431\n",
      "  ignorance: 5.0431\n",
      "  ignorance and: 5.0431\n",
      "  ignorance and uncertainty: 5.0431\n",
      "  implemented: 4.6376\n",
      "  implemented within: 5.0431\n",
      "  implemented within the: 5.0431\n",
      "  imprecise: 4.6376\n",
      "  imprecise probability: 5.0431\n",
      "  imprecise probability theories: 5.0431\n",
      "  in: 2.6835\n",
      "  in a: 3.0971\n",
      "  in a pmfbased: 5.0431\n",
      "  in order: 4.1268\n",
      "  in order to: 4.1268\n",
      "  incorporate: 5.0431\n",
      "  incorporate ignorance: 5.0431\n",
      "  incorporate ignorance and: 5.0431\n",
      "  is: 3.0334\n",
      "  is a: 2.5173\n",
      "  is a general: 4.6376\n",
      "  is combined: 5.0431\n",
      "  is combined eg: 5.0431\n",
      "  issues: 4.6376\n",
      "  issues that: 5.0431\n",
      "  issues that standard: 5.0431\n",
      "  just: 4.6376\n",
      "  just like: 5.0431\n",
      "  just like how: 5.0431\n",
      "  kind: 4.6376\n",
      "  kind of: 4.6376\n",
      "  kind of learner: 5.0431\n",
      "  lead: 4.3499\n",
      "  lead to: 4.3499\n",
      "  lead to a: 4.6376\n",
      "  learner: 4.3499\n",
      "  learner and: 5.0431\n",
      "  learner and have: 5.0431\n",
      "  learners: 4.6376\n",
      "  learners decision: 5.0431\n",
      "  learners decision boundary: 5.0431\n",
      "  learning: 3.8456\n",
      "  learning approach: 5.0431\n",
      "  learning approach tend: 5.0431\n",
      "  learning approaches: 3.9444\n",
      "  learning domain: 5.0431\n",
      "  learning domain typically: 5.0431\n",
      "  leverage: 4.6376\n",
      "  leverage a: 5.0431\n",
      "  leverage a fusion: 5.0431\n",
      "  like: 3.3383\n",
      "  like how: 5.0431\n",
      "  like how in: 5.0431\n",
      "  low: 5.0431\n",
      "  low samples: 5.0431\n",
      "  low samples and: 5.0431\n",
      "  machine: 4.4206\n",
      "  machine learning: 4.6854\n",
      "  machine learning approach: 5.0431\n",
      "  machine learning approaches: 3.9444\n",
      "  machine learning domain: 5.0431\n",
      "  many: 2.9030\n",
      "  many caveats: 5.0431\n",
      "  many caveats to: 5.0431\n",
      "  methods: 2.7405\n",
      "  methods to: 4.6376\n",
      "  methods to better: 5.0431\n",
      "  much: 4.6376\n",
      "  much higher: 5.0431\n",
      "  much higher computation: 5.0431\n",
      "  number: 4.1268\n",
      "  number of: 4.3499\n",
      "  number of propositions: 5.0431\n",
      "  of: 9.7153\n",
      "  of as: 5.0431\n",
      "  of as a: 5.0431\n",
      "  of belief: 5.0431\n",
      "  of belief functions: 5.0431\n",
      "  of combination: 5.0431\n",
      "  of combination just: 5.0431\n",
      "  of how: 5.0431\n",
      "  of how evidence: 5.0431\n",
      "  of learner: 5.0431\n",
      "  of learner and: 5.0431\n",
      "  of propositions: 5.0431\n",
      "  of propositions classes: 5.0431\n",
      "  of these: 5.0431\n",
      "  of these algorithms: 5.0431\n",
      "  of various: 4.3499\n",
      "  of various ensemble: 5.0431\n",
      "  on: 2.0473\n",
      "  on the: 3.2513\n",
      "  on the number: 5.0431\n",
      "  or: 2.0226\n",
      "  or dempstershafer: 5.0431\n",
      "  or dempstershafer theory: 5.0431\n",
      "  order: 3.9444\n",
      "  order to: 4.1268\n",
      "  order to incorporate: 5.0431\n",
      "  other: 5.5835\n",
      "  other frameworks: 5.0431\n",
      "  other frameworks such: 5.0431\n",
      "  other machine: 4.6376\n",
      "  other machine learning: 4.6376\n",
      "  pmfbased: 5.0431\n",
      "  pmfbased bayesian: 5.0431\n",
      "  pmfbased bayesian approach: 5.0431\n",
      "  possibility: 5.0431\n",
      "  possibility and: 5.0431\n",
      "  possibility and imprecise: 5.0431\n",
      "  probabilities: 4.3499\n",
      "  probabilities however: 5.0431\n",
      "  probabilities however there: 5.0431\n",
      "  probability: 8.6998\n",
      "  probability possibility: 5.0431\n",
      "  probability possibility and: 5.0431\n",
      "  probability theories: 5.0431\n",
      "  probability theories these: 5.0431\n",
      "  properties: 4.6376\n",
      "  properties of: 5.0431\n",
      "  properties of how: 5.0431\n",
      "  propositions: 5.0431\n",
      "  propositions classes: 5.0431\n",
      "  propositions classes and: 5.0431\n",
      "  quantification: 5.0431\n",
      "  quantification these: 5.0431\n",
      "  quantification these belief: 5.0431\n",
      "  reasoning: 4.6376\n",
      "  reasoning with: 5.0431\n",
      "  reasoning with uncertainty: 5.0431\n",
      "  referred: 4.6376\n",
      "  referred to: 4.6376\n",
      "  referred to as: 4.6376\n",
      "  resolving: 5.0431\n",
      "  resolving however: 5.0431\n",
      "  resolving however the: 5.0431\n",
      "  rule: 3.7903\n",
      "  rule of: 5.0431\n",
      "  rule of combination: 5.0431\n",
      "  samples: 4.6376\n",
      "  samples and: 5.0431\n",
      "  samples and ambiguous: 5.0431\n",
      "  some: 2.9636\n",
      "  some analogous: 5.0431\n",
      "  some analogous properties: 5.0431\n",
      "  standard: 5.0431\n",
      "  standard machine: 5.0431\n",
      "  standard machine learning: 5.0431\n",
      "  such: 2.4781\n",
      "  such as: 2.8458\n",
      "  such as probability: 5.0431\n",
      "  tend: 5.0431\n",
      "  tend to: 5.0431\n",
      "  tend to have: 5.0431\n",
      "  that: 3.3515\n",
      "  that are: 3.7903\n",
      "  that are implemented: 5.0431\n",
      "  that standard: 5.0431\n",
      "  that standard machine: 5.0431\n",
      "  the: 5.9645\n",
      "  the computational: 4.6376\n",
      "  the computational complexity: 5.0431\n",
      "  the learners: 5.0431\n",
      "  the learners decision: 5.0431\n",
      "  the machine: 4.1268\n",
      "  the machine learning: 4.3499\n",
      "  the number: 4.6376\n",
      "  the number of: 4.6376\n",
      "  the theory: 4.6376\n",
      "  the theory of: 5.0431\n",
      "  theoretical: 3.6568\n",
      "  theoretical frameworks: 5.0431\n",
      "  theoretical frameworks can: 5.0431\n",
      "  theories: 5.0431\n",
      "  theories these: 5.0431\n",
      "  theories these theoretical: 5.0431\n",
      "  theory: 10.0149\n",
      "  theory is: 4.6376\n",
      "  theory is a: 5.0431\n",
      "  theory of: 5.0431\n",
      "  theory of belief: 5.0431\n",
      "  theory or: 5.0431\n",
      "  theory or dempstershafer: 5.0431\n",
      "  there: 3.6568\n",
      "  there are: 4.1268\n",
      "  there are many: 4.6376\n",
      "  these: 11.6119\n",
      "  these algorithms: 5.0431\n",
      "  these algorithms are: 5.0431\n",
      "  these belief: 5.0431\n",
      "  these belief function: 5.0431\n",
      "  these beliefs: 5.0431\n",
      "  these beliefs functions: 5.0431\n",
      "  these theoretical: 5.0431\n",
      "  these theoretical frameworks: 5.0431\n",
      "  thought: 4.6376\n",
      "  thought of: 5.0431\n",
      "  thought of as: 5.0431\n",
      "  time: 3.5390\n",
      "  time when: 5.0431\n",
      "  time when compared: 5.0431\n",
      "  to: 11.0281\n",
      "  to a: 3.1712\n",
      "  to a much: 5.0431\n",
      "  to as: 4.6376\n",
      "  to as evidence: 5.0431\n",
      "  to bayesian: 5.0431\n",
      "  to bayesian approaches: 5.0431\n",
      "  to better: 4.6376\n",
      "  to better handle: 5.0431\n",
      "  to have: 4.3499\n",
      "  to have difficulty: 5.0431\n",
      "  to incorporate: 5.0431\n",
      "  to incorporate ignorance: 5.0431\n",
      "  to other: 9.2752\n",
      "  to other frameworks: 5.0431\n",
      "  to other machine: 4.6376\n",
      "  to these: 5.0431\n",
      "  to these beliefs: 5.0431\n",
      "  typically: 3.5390\n",
      "  typically leverage: 5.0431\n",
      "  typically leverage a: 5.0431\n",
      "  uncertainty: 9.2752\n",
      "  uncertainty quantification: 5.0431\n",
      "  uncertainty quantification these: 5.0431\n",
      "  uncertainty with: 5.0431\n",
      "  uncertainty with understood: 5.0431\n",
      "  understood: 5.0431\n",
      "  understood connections: 5.0431\n",
      "  understood connections to: 5.0431\n",
      "  various: 3.4336\n",
      "  various ensemble: 5.0431\n",
      "  various ensemble methods: 5.0431\n",
      "  when: 6.6766\n",
      "  when compared: 10.0861\n",
      "  when compared to: 10.0861\n",
      "  with: 4.1453\n",
      "  with uncertainty: 5.0431\n",
      "  with uncertainty with: 5.0431\n",
      "  with understood: 5.0431\n",
      "  with understood connections: 5.0431\n",
      "  within: 3.4336\n",
      "  within the: 4.6376\n",
      "  within the machine: 5.0431\n",
      "  would: 3.9444\n",
      "  would combine: 5.0431\n",
      "  would combine probabilities: 5.0431\n",
      "\n",
      "Document 80:\n",
      "  a: 1.2589\n",
      "  a branch: 4.6376\n",
      "  a branch of: 4.6376\n",
      "  and: 4.8576\n",
      "  and cybersecurity: 5.0431\n",
      "  and cybersecurity key: 5.0431\n",
      "  and evolve: 5.0431\n",
      "  and evolve rules: 5.0431\n",
      "  and learns: 5.0431\n",
      "  and learns rules: 5.0431\n",
      "  and other: 4.6376\n",
      "  and other similar: 5.0431\n",
      "  artificial: 2.7918\n",
      "  artificial immune: 4.6376\n",
      "  artificial immune systems: 4.6376\n",
      "  association: 3.9444\n",
      "  association rule: 4.1268\n",
      "  association rule learning: 4.1268\n",
      "  automatically: 5.0431\n",
      "  automatically discovers: 5.0431\n",
      "  automatically discovers and: 5.0431\n",
      "  branch: 4.6376\n",
      "  branch of: 4.6376\n",
      "  branch of machine: 5.0431\n",
      "  classifier: 3.7903\n",
      "  classifier systems: 4.3499\n",
      "  classifier systems association: 4.6376\n",
      "  cybersecurity: 5.0431\n",
      "  cybersecurity key: 5.0431\n",
      "  cybersecurity key rbml: 5.0431\n",
      "  data: 3.7300\n",
      "  data and: 3.5390\n",
      "  data and evolve: 5.0431\n",
      "  data it: 5.0431\n",
      "  data it provides: 5.0431\n",
      "  decisionmaking: 4.3499\n",
      "  decisionmaking in: 5.0431\n",
      "  decisionmaking in fields: 5.0431\n",
      "  detection: 3.9444\n",
      "  detection and: 5.0431\n",
      "  detection and cybersecurity: 5.0431\n",
      "  discovers: 5.0431\n",
      "  discovers and: 5.0431\n",
      "  discovers and learns: 5.0431\n",
      "  evolve: 5.0431\n",
      "  evolve rules: 5.0431\n",
      "  evolve rules over: 5.0431\n",
      "  extract: 5.0431\n",
      "  extract patterns: 5.0431\n",
      "  extract patterns from: 5.0431\n",
      "  fields: 3.9444\n",
      "  fields like: 5.0431\n",
      "  fields like healthcare: 5.0431\n",
      "  for: 1.7289\n",
      "  for decisionmaking: 4.6376\n",
      "  for decisionmaking in: 5.0431\n",
      "  fraud: 4.6376\n",
      "  fraud detection: 5.0431\n",
      "  fraud detection and: 5.0431\n",
      "  from: 4.1453\n",
      "  from data: 7.8889\n",
      "  from data and: 4.6376\n",
      "  from data it: 5.0431\n",
      "  healthcare: 4.6376\n",
      "  healthcare fraud: 5.0431\n",
      "  healthcare fraud detection: 5.0431\n",
      "  immune: 4.6376\n",
      "  immune systems: 4.6376\n",
      "  immune systems and: 5.0431\n",
      "  in: 1.3417\n",
      "  in fields: 4.6376\n",
      "  in fields like: 5.0431\n",
      "  includes: 4.1268\n",
      "  includes learning: 5.0431\n",
      "  includes learning classifier: 5.0431\n",
      "  interpretable: 4.6376\n",
      "  interpretable models: 5.0431\n",
      "  interpretable models making: 5.0431\n",
      "  is: 1.5167\n",
      "  is a: 2.5173\n",
      "  is a branch: 4.6376\n",
      "  it: 4.5409\n",
      "  it provides: 5.0431\n",
      "  it provides interpretable: 5.0431\n",
      "  it useful: 4.6376\n",
      "  it useful for: 5.0431\n",
      "  key: 3.9444\n",
      "  key rbml: 5.0431\n",
      "  key rbml techniques: 5.0431\n",
      "  learning: 5.1274\n",
      "  learning artificial: 5.0431\n",
      "  learning artificial immune: 5.0431\n",
      "  learning classifier: 4.3499\n",
      "  learning classifier systems: 4.3499\n",
      "  learning rbml: 5.0431\n",
      "  learning rbml is: 5.0431\n",
      "  learning that: 4.3499\n",
      "  learning that automatically: 5.0431\n",
      "  learns: 3.9444\n",
      "  learns rules: 5.0431\n",
      "  learns rules from: 5.0431\n",
      "  like: 3.3383\n",
      "  like healthcare: 5.0431\n",
      "  like healthcare fraud: 5.0431\n",
      "  machine: 2.9470\n",
      "  machine learning: 3.1236\n",
      "  machine learning rbml: 5.0431\n",
      "  machine learning that: 4.3499\n",
      "  making: 4.1268\n",
      "  making it: 5.0431\n",
      "  making it useful: 5.0431\n",
      "  methods: 2.7405\n",
      "  methods extract: 5.0431\n",
      "  methods extract patterns: 5.0431\n",
      "  models: 5.1163\n",
      "  models making: 5.0431\n",
      "  models making it: 5.0431\n",
      "  models these: 5.0431\n",
      "  models these methods: 5.0431\n",
      "  of: 1.2144\n",
      "  of machine: 3.0281\n",
      "  of machine learning: 3.0281\n",
      "  other: 2.7918\n",
      "  other similar: 5.0431\n",
      "  other similar models: 5.0431\n",
      "  over: 4.3499\n",
      "  over time: 4.3499\n",
      "  patterns: 3.4336\n",
      "  patterns from: 5.0431\n",
      "  patterns from data: 5.0431\n",
      "  provides: 4.6376\n",
      "  provides interpretable: 5.0431\n",
      "  provides interpretable models: 5.0431\n",
      "  rbml: 10.0861\n",
      "  rbml is: 5.0431\n",
      "  rbml is a: 5.0431\n",
      "  rbml techniques: 5.0431\n",
      "  rbml techniques includes: 5.0431\n",
      "  rule: 3.7903\n",
      "  rule learning: 3.9444\n",
      "  rule learning artificial: 5.0431\n",
      "  rulebased: 4.1268\n",
      "  rulebased machine: 4.1268\n",
      "  rulebased machine learning: 4.1268\n",
      "  rules: 7.3135\n",
      "  rules from: 5.0431\n",
      "  rules from data: 5.0431\n",
      "  rules over: 5.0431\n",
      "  rules over time: 5.0431\n",
      "  similar: 3.9444\n",
      "  similar models: 5.0431\n",
      "  similar models these: 5.0431\n",
      "  systems: 5.3834\n",
      "  systems and: 4.6376\n",
      "  systems and other: 5.0431\n",
      "  systems association: 4.6376\n",
      "  systems association rule: 4.6376\n",
      "  techniques: 3.3383\n",
      "  techniques includes: 5.0431\n",
      "  techniques includes learning: 5.0431\n",
      "  that: 1.6758\n",
      "  that automatically: 5.0431\n",
      "  that automatically discovers: 5.0431\n",
      "  these: 2.9030\n",
      "  these methods: 5.0431\n",
      "  these methods extract: 5.0431\n",
      "  time: 3.5390\n",
      "  useful: 3.9444\n",
      "  useful for: 5.0431\n",
      "  useful for decisionmaking: 5.0431\n",
      "\n",
      "Document 81:\n",
      "  a: 11.3298\n",
      "  a collection: 4.6376\n",
      "  a collection of: 4.6376\n",
      "  a corpus: 5.0431\n",
      "  a corpus of: 5.0431\n",
      "  a field: 4.6376\n",
      "  a field of: 4.6376\n",
      "  a high: 5.0431\n",
      "  a high quantity: 5.0431\n",
      "  a large: 4.6376\n",
      "  a large and: 5.0431\n",
      "  a machine: 6.8672\n",
      "  a machine learning: 7.0779\n",
      "  a potential: 5.0431\n",
      "  a potential result: 5.0431\n",
      "  a service: 5.0431\n",
      "  a service overfitting: 5.0431\n",
      "  accurate: 4.3499\n",
      "  accurate predictions: 4.6376\n",
      "  accurate predictions when: 5.0431\n",
      "  algorithmic: 3.9444\n",
      "  algorithmic bias: 4.6376\n",
      "  algorithmic bias is: 5.0431\n",
      "  and: 4.8576\n",
      "  and collect: 5.0431\n",
      "  and collect a: 5.0431\n",
      "  and data: 4.6376\n",
      "  and data collected: 5.0431\n",
      "  and notably: 5.0431\n",
      "  and notably becoming: 5.0431\n",
      "  and representative: 5.0431\n",
      "  and representative sample: 5.0431\n",
      "  as: 3.6888\n",
      "  as a: 2.9030\n",
      "  as a corpus: 5.0431\n",
      "  as varied: 5.0431\n",
      "  as varied as: 5.0431\n",
      "  be: 2.0726\n",
      "  be as: 5.0431\n",
      "  be as varied: 5.0431\n",
      "  becoming: 9.2752\n",
      "  becoming a: 4.6376\n",
      "  becoming a field: 5.0431\n",
      "  becoming integrated: 5.0431\n",
      "  becoming integrated within: 5.0431\n",
      "  being: 3.7903\n",
      "  being fully: 5.0431\n",
      "  being fully prepared: 5.0431\n",
      "  bias: 3.7903\n",
      "  bias is: 5.0431\n",
      "  bias is a: 5.0431\n",
      "  biased: 10.0861\n",
      "  biased models: 5.0431\n",
      "  biased models may: 5.0431\n",
      "  biased or: 5.0431\n",
      "  biased or nonevaluated: 5.0431\n",
      "  can: 4.3617\n",
      "  can be: 2.7405\n",
      "  can be as: 5.0431\n",
      "  can result: 4.6376\n",
      "  can result in: 4.6376\n",
      "  collect: 5.0431\n",
      "  collect a: 5.0431\n",
      "  collect a large: 5.0431\n",
      "  collected: 4.6376\n",
      "  collected from: 5.0431\n",
      "  collected from individual: 5.0431\n",
      "  collection: 4.1268\n",
      "  collection of: 4.1268\n",
      "  collection of images: 5.0431\n",
      "  corpus: 5.0431\n",
      "  corpus of: 5.0431\n",
      "  corpus of text: 5.0431\n",
      "  data: 13.0550\n",
      "  data and: 3.5390\n",
      "  data and data: 5.0431\n",
      "  data can: 4.3499\n",
      "  data can result: 5.0431\n",
      "  data collected: 5.0431\n",
      "  data collected from: 5.0431\n",
      "  data data: 4.3499\n",
      "  data data from: 5.0431\n",
      "  data from: 4.6376\n",
      "  data from the: 5.0431\n",
      "  data not: 5.0431\n",
      "  data not being: 5.0431\n",
      "  data to: 4.6376\n",
      "  data to perform: 5.0431\n",
      "  derived: 4.6376\n",
      "  derived from: 4.6376\n",
      "  derived from biased: 5.0431\n",
      "  detrimental: 5.0431\n",
      "  detrimental outcomes: 5.0431\n",
      "  detrimental outcomes thereby: 5.0431\n",
      "  engineering: 4.1268\n",
      "  engineering teams: 5.0431\n",
      "  engineers: 5.0431\n",
      "  engineers need: 5.0431\n",
      "  engineers need to: 5.0431\n",
      "  ethics: 4.6376\n",
      "  ethics is: 5.0431\n",
      "  ethics is becoming: 5.0431\n",
      "  field: 2.9636\n",
      "  field of: 3.5390\n",
      "  field of study: 4.3499\n",
      "  for: 3.4577\n",
      "  for training: 4.1268\n",
      "  for training machine: 5.0431\n",
      "  for when: 5.0431\n",
      "  for when training: 5.0431\n",
      "  from: 6.2179\n",
      "  from biased: 5.0431\n",
      "  from biased or: 5.0431\n",
      "  from individual: 5.0431\n",
      "  from individual users: 5.0431\n",
      "  from the: 3.3383\n",
      "  from the training: 4.6376\n",
      "  fully: 4.6376\n",
      "  fully prepared: 5.0431\n",
      "  fully prepared for: 5.0431\n",
      "  furthering: 5.0431\n",
      "  furthering the: 5.0431\n",
      "  furthering the negative: 5.0431\n",
      "  high: 4.3499\n",
      "  high quantity: 5.0431\n",
      "  high quantity of: 5.0431\n",
      "  images: 4.1268\n",
      "  images sensor: 5.0431\n",
      "  images sensor data: 5.0431\n",
      "  impacts: 4.6376\n",
      "  impacts on: 5.0431\n",
      "  impacts on society: 5.0431\n",
      "  in: 2.6835\n",
      "  in detrimental: 5.0431\n",
      "  in detrimental outcomes: 5.0431\n",
      "  in skewed: 5.0431\n",
      "  in skewed or: 5.0431\n",
      "  individual: 4.6376\n",
      "  individual users: 5.0431\n",
      "  individual users of: 5.0431\n",
      "  integrated: 5.0431\n",
      "  integrated within: 5.0431\n",
      "  integrated within machine: 5.0431\n",
      "  is: 4.5501\n",
      "  is a: 2.5173\n",
      "  is a potential: 5.0431\n",
      "  is becoming: 4.6376\n",
      "  is becoming a: 4.6376\n",
      "  is something: 5.0431\n",
      "  is something to: 5.0431\n",
      "  large: 3.9444\n",
      "  large and: 5.0431\n",
      "  large and representative: 5.0431\n",
      "  learning: 7.6911\n",
      "  learning engineering: 5.0431\n",
      "  learning engineering teams: 5.0431\n",
      "  learning engineers: 5.0431\n",
      "  learning engineers need: 5.0431\n",
      "  learning ethics: 5.0431\n",
      "  learning ethics is: 5.0431\n",
      "  learning model: 8.2535\n",
      "  learning model machine: 5.0431\n",
      "  learning model trained: 5.0431\n",
      "  learning models: 3.7903\n",
      "  learning models require: 5.0431\n",
      "  machine: 8.8411\n",
      "  machine learning: 9.3709\n",
      "  machine learning engineering: 5.0431\n",
      "  machine learning engineers: 5.0431\n",
      "  machine learning ethics: 5.0431\n",
      "  machine learning model: 8.6998\n",
      "  machine learning models: 3.7903\n",
      "  may: 3.2513\n",
      "  may result: 5.0431\n",
      "  may result in: 5.0431\n",
      "  model: 4.6700\n",
      "  model machine: 5.0431\n",
      "  model machine learning: 5.0431\n",
      "  model trained: 5.0431\n",
      "  model trained models: 5.0431\n",
      "  models: 7.6744\n",
      "  models derived: 5.0431\n",
      "  models derived from: 5.0431\n",
      "  models may: 5.0431\n",
      "  models may result: 5.0431\n",
      "  models require: 5.0431\n",
      "  models require a: 5.0431\n",
      "  need: 4.6376\n",
      "  need to: 4.6376\n",
      "  need to target: 5.0431\n",
      "  negative: 3.9444\n",
      "  negative impacts: 5.0431\n",
      "  negative impacts on: 5.0431\n",
      "  nonevaluated: 5.0431\n",
      "  nonevaluated data: 5.0431\n",
      "  nonevaluated data can: 5.0431\n",
      "  not: 2.6007\n",
      "  not being: 4.6376\n",
      "  not being fully: 5.0431\n",
      "  notably: 5.0431\n",
      "  notably becoming: 5.0431\n",
      "  notably becoming integrated: 5.0431\n",
      "  objectives: 4.6376\n",
      "  objectives algorithmic: 5.0431\n",
      "  objectives algorithmic bias: 5.0431\n",
      "  of: 8.5009\n",
      "  of a: 3.0281\n",
      "  of a service: 5.0431\n",
      "  of data: 7.3135\n",
      "  of data data: 5.0431\n",
      "  of data not: 5.0431\n",
      "  of images: 5.0431\n",
      "  of images sensor: 5.0431\n",
      "  of reliable: 5.0431\n",
      "  of reliable data: 5.0431\n",
      "  of study: 4.3499\n",
      "  of study and: 5.0431\n",
      "  of text: 5.0431\n",
      "  of text a: 5.0431\n",
      "  on: 2.0473\n",
      "  on society: 5.0431\n",
      "  on society or: 5.0431\n",
      "  or: 6.0679\n",
      "  or nonevaluated: 5.0431\n",
      "  or nonevaluated data: 5.0431\n",
      "  or objectives: 5.0431\n",
      "  or objectives algorithmic: 5.0431\n",
      "  or undesired: 5.0431\n",
      "  or undesired predictions: 5.0431\n",
      "  out: 3.7903\n",
      "  out for: 5.0431\n",
      "  out for when: 5.0431\n",
      "  outcomes: 4.3499\n",
      "  outcomes thereby: 5.0431\n",
      "  outcomes thereby furthering: 5.0431\n",
      "  overfitting: 3.7903\n",
      "  overfitting is: 5.0431\n",
      "  overfitting is something: 5.0431\n",
      "  perform: 3.2513\n",
      "  perform accurate: 5.0431\n",
      "  perform accurate predictions: 5.0431\n",
      "  potential: 4.1268\n",
      "  potential result: 5.0431\n",
      "  potential result of: 5.0431\n",
      "  predictions: 6.6766\n",
      "  predictions biased: 5.0431\n",
      "  predictions biased models: 5.0431\n",
      "  predictions when: 5.0431\n",
      "  predictions when training: 5.0431\n",
      "  prepared: 5.0431\n",
      "  prepared for: 5.0431\n",
      "  prepared for training: 5.0431\n",
      "  quantity: 5.0431\n",
      "  quantity of: 5.0431\n",
      "  quantity of reliable: 5.0431\n",
      "  reliable: 5.0431\n",
      "  reliable data: 5.0431\n",
      "  reliable data to: 5.0431\n",
      "  representative: 3.9444\n",
      "  representative sample: 5.0431\n",
      "  representative sample of: 5.0431\n",
      "  require: 4.1268\n",
      "  require a: 4.6376\n",
      "  require a high: 5.0431\n",
      "  result: 13.0497\n",
      "  result in: 8.6998\n",
      "  result in detrimental: 5.0431\n",
      "  result in skewed: 5.0431\n",
      "  result of: 5.0431\n",
      "  result of data: 5.0431\n",
      "  sample: 4.6376\n",
      "  sample of: 5.0431\n",
      "  sample of data: 5.0431\n",
      "  sensor: 5.0431\n",
      "  sensor data: 5.0431\n",
      "  sensor data and: 5.0431\n",
      "  service: 5.0431\n",
      "  service overfitting: 5.0431\n",
      "  service overfitting is: 5.0431\n",
      "  set: 2.6007\n",
      "  set can: 5.0431\n",
      "  set can be: 5.0431\n",
      "  skewed: 5.0431\n",
      "  skewed or: 5.0431\n",
      "  skewed or undesired: 5.0431\n",
      "  society: 4.6376\n",
      "  society or: 5.0431\n",
      "  society or objectives: 5.0431\n",
      "  something: 5.0431\n",
      "  something to: 5.0431\n",
      "  something to watch: 5.0431\n",
      "  study: 3.6568\n",
      "  study and: 5.0431\n",
      "  study and notably: 5.0431\n",
      "  target: 4.6376\n",
      "  target and: 5.0431\n",
      "  target and collect: 5.0431\n",
      "  teams: 4.6376\n",
      "  text: 4.6376\n",
      "  text a: 5.0431\n",
      "  text a collection: 5.0431\n",
      "  the: 2.3858\n",
      "  the negative: 5.0431\n",
      "  the negative impacts: 5.0431\n",
      "  the training: 3.3383\n",
      "  the training set: 5.0431\n",
      "  thereby: 4.1268\n",
      "  thereby furthering: 5.0431\n",
      "  thereby furthering the: 5.0431\n",
      "  to: 3.6760\n",
      "  to perform: 3.9444\n",
      "  to perform accurate: 5.0431\n",
      "  to target: 5.0431\n",
      "  to target and: 5.0431\n",
      "  to watch: 5.0431\n",
      "  to watch out: 5.0431\n",
      "  trained: 3.3383\n",
      "  trained models: 5.0431\n",
      "  trained models derived: 5.0431\n",
      "  training: 10.2326\n",
      "  training a: 8.2535\n",
      "  training a machine: 10.0861\n",
      "  training machine: 4.6376\n",
      "  training machine learning: 4.6376\n",
      "  training set: 4.1268\n",
      "  training set can: 5.0431\n",
      "  typically: 3.5390\n",
      "  typically machine: 5.0431\n",
      "  typically machine learning: 5.0431\n",
      "  undesired: 5.0431\n",
      "  undesired predictions: 5.0431\n",
      "  undesired predictions biased: 5.0431\n",
      "  users: 3.9444\n",
      "  users of: 4.6376\n",
      "  users of a: 5.0431\n",
      "  varied: 5.0431\n",
      "  varied as: 5.0431\n",
      "  varied as a: 5.0431\n",
      "  watch: 5.0431\n",
      "  watch out: 5.0431\n",
      "  watch out for: 5.0431\n",
      "  when: 6.6766\n",
      "  when training: 10.0861\n",
      "  when training a: 10.0861\n",
      "  within: 3.4336\n",
      "  within machine: 5.0431\n",
      "  within machine learning: 5.0431\n",
      "\n",
      "Document 82:\n",
      "  a: 1.2589\n",
      "  a centralised: 5.0431\n",
      "  a centralised server: 5.0431\n",
      "  adapted: 5.0431\n",
      "  adapted form: 5.0431\n",
      "  adapted form of: 5.0431\n",
      "  allowing: 5.0431\n",
      "  allowing for: 5.0431\n",
      "  allowing for users: 5.0431\n",
      "  also: 2.6452\n",
      "  also increases: 5.0431\n",
      "  also increases efficiency: 5.0431\n",
      "  an: 2.1527\n",
      "  an adapted: 5.0431\n",
      "  an adapted form: 5.0431\n",
      "  artificial: 2.7918\n",
      "  artificial intelligence: 3.5390\n",
      "  artificial intelligence to: 4.6376\n",
      "  back: 4.6376\n",
      "  back to: 4.6376\n",
      "  back to google: 5.0431\n",
      "  be: 2.0726\n",
      "  be maintained: 5.0431\n",
      "  be maintained by: 5.0431\n",
      "  by: 3.8151\n",
      "  by decentralising: 5.0431\n",
      "  by decentralising the: 5.0431\n",
      "  by not: 5.0431\n",
      "  by not needing: 5.0431\n",
      "  centralised: 5.0431\n",
      "  centralised server: 5.0431\n",
      "  centralised server this: 5.0431\n",
      "  data: 1.8650\n",
      "  data to: 4.6376\n",
      "  data to a: 5.0431\n",
      "  decentralises: 5.0431\n",
      "  decentralises the: 5.0431\n",
      "  decentralises the training: 5.0431\n",
      "  decentralising: 5.0431\n",
      "  decentralising the: 5.0431\n",
      "  decentralising the training: 5.0431\n",
      "  devices: 4.6376\n",
      "  devices for: 5.0431\n",
      "  devices for example: 5.0431\n",
      "  distributed: 5.0431\n",
      "  distributed artificial: 5.0431\n",
      "  distributed artificial intelligence: 5.0431\n",
      "  efficiency: 4.3499\n",
      "  efficiency by: 5.0431\n",
      "  efficiency by decentralising: 5.0431\n",
      "  example: 2.9636\n",
      "  example gboard: 5.0431\n",
      "  example gboard uses: 5.0431\n",
      "  federated: 10.0861\n",
      "  federated learning: 5.0431\n",
      "  federated learning is: 5.0431\n",
      "  federated machine: 5.0431\n",
      "  federated machine learning: 5.0431\n",
      "  for: 3.4577\n",
      "  for example: 3.2513\n",
      "  for example gboard: 5.0431\n",
      "  for users: 5.0431\n",
      "  for users privacy: 5.0431\n",
      "  form: 4.3499\n",
      "  form of: 5.0431\n",
      "  form of distributed: 5.0431\n",
      "  gboard: 5.0431\n",
      "  gboard uses: 5.0431\n",
      "  gboard uses federated: 5.0431\n",
      "  google: 4.3499\n",
      "  having: 4.3499\n",
      "  having to: 5.0431\n",
      "  having to send: 5.0431\n",
      "  increases: 4.6376\n",
      "  increases efficiency: 5.0431\n",
      "  increases efficiency by: 5.0431\n",
      "  individual: 4.6376\n",
      "  individual searches: 5.0431\n",
      "  individual searches back: 5.0431\n",
      "  intelligence: 3.1712\n",
      "  intelligence to: 4.6376\n",
      "  intelligence to training: 5.0431\n",
      "  is: 1.5167\n",
      "  is an: 3.6568\n",
      "  is an adapted: 5.0431\n",
      "  learning: 3.8456\n",
      "  learning is: 3.0281\n",
      "  learning is an: 4.3499\n",
      "  learning models: 3.7903\n",
      "  learning models that: 4.6376\n",
      "  learning to: 4.3499\n",
      "  learning to train: 5.0431\n",
      "  machine: 2.9470\n",
      "  machine learning: 3.1236\n",
      "  machine learning models: 3.7903\n",
      "  machine learning to: 4.6376\n",
      "  maintained: 5.0431\n",
      "  maintained by: 5.0431\n",
      "  maintained by not: 5.0431\n",
      "  many: 2.9030\n",
      "  many devices: 5.0431\n",
      "  many devices for: 5.0431\n",
      "  mobile: 5.0431\n",
      "  mobile phones: 5.0431\n",
      "  mobile phones without: 5.0431\n",
      "  models: 5.1163\n",
      "  models on: 5.0431\n",
      "  models on users: 5.0431\n",
      "  models that: 4.3499\n",
      "  models that decentralises: 5.0431\n",
      "  needing: 5.0431\n",
      "  needing to: 5.0431\n",
      "  needing to send: 5.0431\n",
      "  not: 2.6007\n",
      "  not needing: 5.0431\n",
      "  not needing to: 5.0431\n",
      "  of: 1.2144\n",
      "  of distributed: 5.0431\n",
      "  of distributed artificial: 5.0431\n",
      "  on: 2.0473\n",
      "  on users: 5.0431\n",
      "  on users mobile: 5.0431\n",
      "  phones: 5.0431\n",
      "  phones without: 5.0431\n",
      "  phones without having: 5.0431\n",
      "  prediction: 3.7903\n",
      "  prediction models: 5.0431\n",
      "  prediction models on: 5.0431\n",
      "  privacy: 4.1268\n",
      "  privacy to: 5.0431\n",
      "  privacy to be: 5.0431\n",
      "  process: 6.8672\n",
      "  process allowing: 5.0431\n",
      "  process allowing for: 5.0431\n",
      "  process to: 5.0431\n",
      "  process to many: 5.0431\n",
      "  query: 5.0431\n",
      "  query prediction: 5.0431\n",
      "  query prediction models: 5.0431\n",
      "  search: 4.3499\n",
      "  search query: 5.0431\n",
      "  search query prediction: 5.0431\n",
      "  searches: 5.0431\n",
      "  searches back: 5.0431\n",
      "  searches back to: 5.0431\n",
      "  send: 10.0861\n",
      "  send individual: 5.0431\n",
      "  send individual searches: 5.0431\n",
      "  send their: 5.0431\n",
      "  send their data: 5.0431\n",
      "  server: 5.0431\n",
      "  server this: 5.0431\n",
      "  server this also: 5.0431\n",
      "  that: 1.6758\n",
      "  that decentralises: 5.0431\n",
      "  that decentralises the: 5.0431\n",
      "  the: 2.3858\n",
      "  the training: 6.6766\n",
      "  the training process: 10.0861\n",
      "  their: 2.7918\n",
      "  their data: 5.0431\n",
      "  their data to: 5.0431\n",
      "  this: 2.6007\n",
      "  this also: 5.0431\n",
      "  this also increases: 5.0431\n",
      "  to: 9.8027\n",
      "  to a: 3.1712\n",
      "  to a centralised: 5.0431\n",
      "  to be: 3.4336\n",
      "  to be maintained: 5.0431\n",
      "  to google: 5.0431\n",
      "  to many: 5.0431\n",
      "  to many devices: 5.0431\n",
      "  to send: 10.0861\n",
      "  to send individual: 5.0431\n",
      "  to send their: 5.0431\n",
      "  to train: 4.3499\n",
      "  to train search: 5.0431\n",
      "  to training: 5.0431\n",
      "  to training machine: 5.0431\n",
      "  train: 4.3499\n",
      "  train search: 5.0431\n",
      "  train search query: 5.0431\n",
      "  training: 7.6744\n",
      "  training machine: 4.6376\n",
      "  training machine learning: 4.6376\n",
      "  training process: 10.0861\n",
      "  training process allowing: 5.0431\n",
      "  training process to: 5.0431\n",
      "  users: 7.8889\n",
      "  users mobile: 5.0431\n",
      "  users mobile phones: 5.0431\n",
      "  users privacy: 5.0431\n",
      "  users privacy to: 5.0431\n",
      "  uses: 4.1268\n",
      "  uses federated: 5.0431\n",
      "  uses federated machine: 5.0431\n",
      "  without: 3.3383\n",
      "  without having: 5.0431\n",
      "  without having to: 5.0431\n",
      "\n",
      "Document 83:\n",
      "  applications: 3.7903\n",
      "  applications for: 5.0431\n",
      "  applications for machine: 5.0431\n",
      "  are: 1.9750\n",
      "  are many: 4.6376\n",
      "  are many applications: 5.0431\n",
      "  for: 1.7289\n",
      "  for machine: 3.9444\n",
      "  for machine learning: 4.1268\n",
      "  including: 3.4336\n",
      "  learning: 1.2819\n",
      "  learning including: 5.0431\n",
      "  machine: 1.4735\n",
      "  machine learning: 1.5618\n",
      "  machine learning including: 5.0431\n",
      "  many: 2.9030\n",
      "  many applications: 5.0431\n",
      "  many applications for: 5.0431\n",
      "  there: 3.6568\n",
      "  there are: 4.1268\n",
      "  there are many: 4.6376\n",
      "\n",
      "Document 84:\n",
      "  a: 7.5532\n",
      "  a cure: 5.0431\n",
      "  a cure for: 5.0431\n",
      "  a joint: 5.0431\n",
      "  a joint team: 5.0431\n",
      "  a machine: 3.4336\n",
      "  a machine learning: 3.5390\n",
      "  a program: 4.6376\n",
      "  a program to: 5.0431\n",
      "  a recommendation: 5.0431\n",
      "  a recommendation and: 5.0431\n",
      "  a wide: 5.0431\n",
      "  a wide range: 5.0431\n",
      "  about: 3.6568\n",
      "  about the: 4.6376\n",
      "  about the firm: 5.0431\n",
      "  accordingly: 5.0431\n",
      "  accordingly in: 5.0431\n",
      "  accordingly in the: 5.0431\n",
      "  accuracy: 3.6568\n",
      "  accuracy of: 4.6376\n",
      "  accuracy of its: 4.6376\n",
      "  after: 3.7903\n",
      "  after the: 5.0431\n",
      "  after the prize: 5.0431\n",
      "  aid: 5.0431\n",
      "  aid researchers: 5.0431\n",
      "  aid researchers in: 5.0431\n",
      "  algorithm: 5.8060\n",
      "  algorithm by: 5.0431\n",
      "  algorithm by at: 5.0431\n",
      "  algorithm had: 5.0431\n",
      "  algorithm had been: 5.0431\n",
      "  algorithms: 2.3689\n",
      "  algorithms mlas: 5.0431\n",
      "  algorithms mlas can: 5.0431\n",
      "  also: 2.6452\n",
      "  also applied: 5.0431\n",
      "  also applied to: 5.0431\n",
      "  among: 3.9444\n",
      "  among artists: 5.0431\n",
      "  among artists in: 5.0431\n",
      "  an: 2.1527\n",
      "  an ensemble: 4.6376\n",
      "  an ensemble model: 5.0431\n",
      "  and: 9.7153\n",
      "  and aid: 5.0431\n",
      "  and aid researchers: 5.0431\n",
      "  and combining: 5.0431\n",
      "  and combining forecasts: 5.0431\n",
      "  and improve: 5.0431\n",
      "  and improve the: 5.0431\n",
      "  and pragmatic: 5.0431\n",
      "  and pragmatic theory: 5.0431\n",
      "  and that: 4.3499\n",
      "  and that it: 5.0431\n",
      "  and their: 3.9444\n",
      "  and their use: 5.0431\n",
      "  and thermal: 5.0431\n",
      "  and thermal behaviour: 5.0431\n",
      "  and they: 4.6376\n",
      "  and they changed: 5.0431\n",
      "  applied: 17.3996\n",
      "  applied correctly: 5.0431\n",
      "  applied correctly machine: 5.0431\n",
      "  applied in: 4.6376\n",
      "  applied in the: 5.0431\n",
      "  applied to: 9.2752\n",
      "  applied to optimise: 5.0431\n",
      "  applied to predict: 5.0431\n",
      "  art: 10.0861\n",
      "  art history: 5.0431\n",
      "  art history to: 5.0431\n",
      "  art paintings: 5.0431\n",
      "  art paintings and: 5.0431\n",
      "  artists: 5.0431\n",
      "  artists in: 5.0431\n",
      "  artists in springer: 5.0431\n",
      "  at: 3.9444\n",
      "  at least: 5.0431\n",
      "  at least a: 5.0431\n",
      "  att: 5.0431\n",
      "  att labsresearch: 5.0431\n",
      "  att labsresearch in: 5.0431\n",
      "  automated: 4.3499\n",
      "  automated machine: 5.0431\n",
      "  automated machine learning: 5.0431\n",
      "  awarded: 5.0431\n",
      "  awarded netflix: 5.0431\n",
      "  awarded netflix realised: 5.0431\n",
      "  based: 3.4336\n",
      "  based on: 3.4336\n",
      "  based on the: 4.3499\n",
      "  basic: 4.6376\n",
      "  basic linear: 5.0431\n",
      "  basic linear techniques: 5.0431\n",
      "  be: 2.0726\n",
      "  be lost: 5.0431\n",
      "  be lost in: 5.0431\n",
      "  been: 2.6917\n",
      "  been applied: 4.6376\n",
      "  been applied in: 4.6376\n",
      "  behaviour: 8.6998\n",
      "  behaviour based: 5.0431\n",
      "  behaviour based on: 5.0431\n",
      "  behaviour of: 5.0431\n",
      "  behaviour of travellers: 5.0431\n",
      "  best: 3.6568\n",
      "  best indicators: 5.0431\n",
      "  best indicators of: 5.0431\n",
      "  better: 4.1268\n",
      "  better predict: 5.0431\n",
      "  better predict user: 5.0431\n",
      "  big: 5.0431\n",
      "  big chaos: 5.0431\n",
      "  big chaos and: 5.0431\n",
      "  book: 4.3499\n",
      "  book created: 5.0431\n",
      "  book created using: 5.0431\n",
      "  built: 4.1268\n",
      "  built an: 5.0431\n",
      "  built an ensemble: 5.0431\n",
      "  by: 3.8151\n",
      "  by at: 5.0431\n",
      "  by at least: 5.0431\n",
      "  by employing: 5.0431\n",
      "  by employing effective: 5.0431\n",
      "  can: 4.3617\n",
      "  can generate: 5.0431\n",
      "  can generate results: 5.0431\n",
      "  can utilise: 5.0431\n",
      "  can utilise a: 5.0431\n",
      "  changed: 4.6376\n",
      "  changed their: 5.0431\n",
      "  changed their recommendation: 5.0431\n",
      "  chaos: 5.0431\n",
      "  chaos and: 5.0431\n",
      "  chaos and pragmatic: 5.0431\n",
      "  characteristics: 5.0431\n",
      "  characteristics to: 5.0431\n",
      "  characteristics to predict: 5.0431\n",
      "  cinematch: 5.0431\n",
      "  cinematch movie: 5.0431\n",
      "  cinematch movie recommendation: 5.0431\n",
      "  cofounder: 5.0431\n",
      "  cofounder of: 5.0431\n",
      "  cofounder of sun: 5.0431\n",
      "  collaboration: 5.0431\n",
      "  collaboration with: 5.0431\n",
      "  collaboration with the: 5.0431\n",
      "  combining: 5.0431\n",
      "  combining forecasts: 5.0431\n",
      "  combining forecasts mlas: 5.0431\n",
      "  company: 4.3499\n",
      "  company characteristics: 5.0431\n",
      "  company characteristics to: 5.0431\n",
      "  competition: 5.0431\n",
      "  competition to: 5.0431\n",
      "  competition to find: 5.0431\n",
      "  correctly: 4.3499\n",
      "  correctly machine: 5.0431\n",
      "  correctly machine learning: 5.0431\n",
      "  covid: 5.0431\n",
      "  covid machine: 5.0431\n",
      "  covid machine learning: 5.0431\n",
      "  created: 4.6376\n",
      "  created using: 5.0431\n",
      "  created using machine: 5.0431\n",
      "  crisis: 5.0431\n",
      "  crisis in: 5.0431\n",
      "  crisis in cofounder: 5.0431\n",
      "  cure: 5.0431\n",
      "  cure for: 5.0431\n",
      "  cure for covid: 5.0431\n",
      "  decades: 4.6376\n",
      "  decades to: 5.0431\n",
      "  decades to automated: 5.0431\n",
      "  developing: 5.0431\n",
      "  developing a: 5.0431\n",
      "  developing a cure: 5.0431\n",
      "  diagnoses: 5.0431\n",
      "  diagnoses and: 5.0431\n",
      "  diagnoses and aid: 5.0431\n",
      "  diagnostic: 5.0431\n",
      "  diagnostic software: 5.0431\n",
      "  diagnostic software in: 5.0431\n",
      "  doctors: 5.0431\n",
      "  doctors jobs: 5.0431\n",
      "  doctors jobs would: 5.0431\n",
      "  effective: 4.3499\n",
      "  effective feature: 5.0431\n",
      "  effective feature engineering: 5.0431\n",
      "  employing: 5.0431\n",
      "  employing effective: 5.0431\n",
      "  employing effective feature: 5.0431\n",
      "  engine: 5.0431\n",
      "  engine accordingly: 5.0431\n",
      "  engine accordingly in: 5.0431\n",
      "  engineering: 4.1268\n",
      "  engineering and: 4.6376\n",
      "  engineering and combining: 5.0431\n",
      "  ensemble: 4.3499\n",
      "  ensemble model: 5.0431\n",
      "  ensemble model to: 5.0431\n",
      "  everything: 5.0431\n",
      "  everything is: 5.0431\n",
      "  everything is a: 5.0431\n",
      "  existing: 5.0431\n",
      "  existing cinematch: 5.0431\n",
      "  existing cinematch movie: 5.0431\n",
      "  far: 5.0431\n",
      "  far surpass: 5.0431\n",
      "  far surpass those: 5.0431\n",
      "  feature: 3.4336\n",
      "  feature engineering: 4.6376\n",
      "  feature engineering and: 4.6376\n",
      "  field: 2.9636\n",
      "  field of: 3.5390\n",
      "  field of art: 5.0431\n",
      "  financial: 5.0431\n",
      "  financial crisis: 5.0431\n",
      "  financial crisis in: 5.0431\n",
      "  find: 4.6376\n",
      "  find a: 5.0431\n",
      "  find a program: 5.0431\n",
      "  fine: 5.0431\n",
      "  fine art: 5.0431\n",
      "  fine art paintings: 5.0431\n",
      "  firm: 4.6376\n",
      "  firm rebellion: 5.0431\n",
      "  firm rebellion research: 5.0431\n",
      "  first: 8.6998\n",
      "  first netflix: 5.0431\n",
      "  first netflix prize: 5.0431\n",
      "  first research: 5.0431\n",
      "  first research book: 5.0431\n",
      "  for: 3.4577\n",
      "  for covid: 5.0431\n",
      "  for covid machine: 5.0431\n",
      "  for million: 5.0431\n",
      "  for million shortly: 5.0431\n",
      "  forecasts: 5.0431\n",
      "  forecasts mlas: 5.0431\n",
      "  forecasts mlas can: 5.0431\n",
      "  from: 4.1453\n",
      "  from att: 5.0431\n",
      "  from att labsresearch: 5.0431\n",
      "  from basic: 5.0431\n",
      "  from basic linear: 5.0431\n",
      "  generate: 4.6376\n",
      "  generate results: 5.0431\n",
      "  generate results that: 5.0431\n",
      "  grand: 5.0431\n",
      "  grand prize: 5.0431\n",
      "  grand prize in: 5.0431\n",
      "  had: 3.6568\n",
      "  had been: 4.1268\n",
      "  had been applied: 5.0431\n",
      "  have: 2.4781\n",
      "  have revealed: 5.0431\n",
      "  have revealed previously: 5.0431\n",
      "  held: 5.0431\n",
      "  held the: 5.0431\n",
      "  held the first: 5.0431\n",
      "  help: 4.6376\n",
      "  help make: 5.0431\n",
      "  help make diagnoses: 5.0431\n",
      "  history: 4.3499\n",
      "  history to: 5.0431\n",
      "  history to study: 5.0431\n",
      "  improve: 4.1268\n",
      "  improve the: 4.6376\n",
      "  improve the accuracy: 5.0431\n",
      "  in: 14.7592\n",
      "  in cofounder: 5.0431\n",
      "  in cofounder of: 5.0431\n",
      "  in collaboration: 5.0431\n",
      "  in collaboration with: 5.0431\n",
      "  in developing: 5.0431\n",
      "  in developing a: 5.0431\n",
      "  in for: 5.0431\n",
      "  in for million: 5.0431\n",
      "  in it: 4.6376\n",
      "  in it was: 5.0431\n",
      "  in machine: 3.6568\n",
      "  in machine learning: 3.6568\n",
      "  in springer: 5.0431\n",
      "  in springer nature: 5.0431\n",
      "  in the: 9.7614\n",
      "  in the field: 4.1268\n",
      "  in the mediaservices: 5.0431\n",
      "  in the next: 5.0431\n",
      "  in the wall: 5.0431\n",
      "  indicators: 4.6376\n",
      "  indicators of: 5.0431\n",
      "  indicators of their: 5.0431\n",
      "  influences: 5.0431\n",
      "  influences among: 5.0431\n",
      "  influences among artists: 5.0431\n",
      "  interaction: 4.6376\n",
      "  interaction with: 5.0431\n",
      "  interaction with the: 5.0431\n",
      "  is: 1.5167\n",
      "  is a: 2.5173\n",
      "  is a recommendation: 5.0431\n",
      "  it: 4.5409\n",
      "  it may: 5.0431\n",
      "  it may have: 5.0431\n",
      "  it was: 4.6376\n",
      "  it was reported: 5.0431\n",
      "  its: 2.9636\n",
      "  its existing: 5.0431\n",
      "  its existing cinematch: 5.0431\n",
      "  jobs: 5.0431\n",
      "  jobs would: 5.0431\n",
      "  jobs would be: 5.0431\n",
      "  joint: 5.0431\n",
      "  joint team: 5.0431\n",
      "  joint team made: 5.0431\n",
      "  journal: 5.0431\n",
      "  journal wrote: 5.0431\n",
      "  journal wrote about: 5.0431\n",
      "  khosla: 5.0431\n",
      "  khosla predicted: 5.0431\n",
      "  khosla predicted that: 5.0431\n",
      "  labsresearch: 5.0431\n",
      "  labsresearch in: 5.0431\n",
      "  labsresearch in collaboration: 5.0431\n",
      "  learning: 10.2548\n",
      "  learning algorithm: 3.9444\n",
      "  learning algorithm had: 5.0431\n",
      "  learning algorithms: 2.9030\n",
      "  learning algorithms mlas: 5.0431\n",
      "  learning in: 3.6568\n",
      "  learning in machine: 5.0431\n",
      "  learning medical: 5.0431\n",
      "  learning medical diagnostic: 5.0431\n",
      "  learning technology: 10.0861\n",
      "  learning technology was: 10.0861\n",
      "  learning to: 4.3499\n",
      "  learning to predict: 5.0431\n",
      "  learning was: 4.6376\n",
      "  learning was recently: 5.0431\n",
      "  least: 4.3499\n",
      "  least a: 5.0431\n",
      "  least a joint: 5.0431\n",
      "  like: 3.3383\n",
      "  like ols: 5.0431\n",
      "  linear: 3.7903\n",
      "  linear techniques: 5.0431\n",
      "  linear techniques like: 5.0431\n",
      "  lost: 5.0431\n",
      "  lost in: 5.0431\n",
      "  lost in the: 5.0431\n",
      "  machine: 11.7881\n",
      "  machine learning: 12.4945\n",
      "  machine learning algorithm: 4.1268\n",
      "  machine learning algorithms: 3.4336\n",
      "  machine learning in: 4.1268\n",
      "  machine learning medical: 5.0431\n",
      "  machine learning technology: 10.0861\n",
      "  machine learning to: 4.6376\n",
      "  machine learning was: 4.6376\n",
      "  made: 4.6376\n",
      "  made up: 5.0431\n",
      "  made up of: 5.0431\n",
      "  make: 3.3383\n",
      "  make diagnoses: 5.0431\n",
      "  make diagnoses and: 5.0431\n",
      "  may: 3.2513\n",
      "  may have: 4.6376\n",
      "  may have revealed: 5.0431\n",
      "  mediaservices: 5.0431\n",
      "  mediaservices provider: 5.0431\n",
      "  mediaservices provider netflix: 5.0431\n",
      "  medical: 7.5806\n",
      "  medical diagnostic: 5.0431\n",
      "  medical diagnostic software: 5.0431\n",
      "  medical doctors: 5.0431\n",
      "  medical doctors jobs: 5.0431\n",
      "  microsystems: 5.0431\n",
      "  microsystems vinod: 5.0431\n",
      "  microsystems vinod khosla: 5.0431\n",
      "  million: 5.0431\n",
      "  million shortly: 5.0431\n",
      "  million shortly after: 5.0431\n",
      "  mlas: 10.0861\n",
      "  mlas can: 10.0861\n",
      "  mlas can generate: 5.0431\n",
      "  mlas can utilise: 5.0431\n",
      "  model: 2.3350\n",
      "  model to: 4.3499\n",
      "  model to win: 5.0431\n",
      "  movie: 5.0431\n",
      "  movie recommendation: 5.0431\n",
      "  movie recommendation algorithm: 5.0431\n",
      "  nature: 4.1268\n",
      "  nature published: 5.0431\n",
      "  nature published the: 5.0431\n",
      "  netflix: 15.1292\n",
      "  netflix held: 5.0431\n",
      "  netflix held the: 5.0431\n",
      "  netflix prize: 5.0431\n",
      "  netflix prize competition: 5.0431\n",
      "  netflix realised: 5.0431\n",
      "  netflix realised that: 5.0431\n",
      "  next: 5.0431\n",
      "  next two: 5.0431\n",
      "  next two decades: 5.0431\n",
      "  not: 2.6007\n",
      "  not the: 5.0431\n",
      "  not the best: 5.0431\n",
      "  obtained: 5.0431\n",
      "  obtained from: 5.0431\n",
      "  obtained from basic: 5.0431\n",
      "  of: 10.9297\n",
      "  of art: 5.0431\n",
      "  of art history: 5.0431\n",
      "  of company: 5.0431\n",
      "  of company characteristics: 5.0431\n",
      "  of its: 3.9444\n",
      "  of its existing: 5.0431\n",
      "  of machine: 3.0281\n",
      "  of machine learning: 3.0281\n",
      "  of medical: 4.6376\n",
      "  of medical doctors: 5.0431\n",
      "  of researchers: 5.0431\n",
      "  of researchers from: 5.0431\n",
      "  of sun: 5.0431\n",
      "  of sun microsystems: 5.0431\n",
      "  of their: 5.0431\n",
      "  of their viewing: 5.0431\n",
      "  of travellers: 5.0431\n",
      "  of travellers recently: 5.0431\n",
      "  ols: 5.0431\n",
      "  on: 2.0473\n",
      "  on the: 3.2513\n",
      "  on the users: 5.0431\n",
      "  optimise: 5.0431\n",
      "  optimise smartphones: 5.0431\n",
      "  optimise smartphones performance: 5.0431\n",
      "  overfitting: 3.7903\n",
      "  overfitting by: 4.6376\n",
      "  overfitting by employing: 5.0431\n",
      "  paintings: 5.0431\n",
      "  paintings and: 5.0431\n",
      "  paintings and that: 5.0431\n",
      "  patterns: 3.4336\n",
      "  patterns everything: 5.0431\n",
      "  patterns everything is: 5.0431\n",
      "  performance: 3.4336\n",
      "  performance and: 5.0431\n",
      "  performance and thermal: 5.0431\n",
      "  phone: 5.0431\n",
      "  phone when: 5.0431\n",
      "  phone when applied: 5.0431\n",
      "  pragmatic: 5.0431\n",
      "  pragmatic theory: 5.0431\n",
      "  pragmatic theory built: 5.0431\n",
      "  predict: 15.7778\n",
      "  predict stock: 5.0431\n",
      "  predict stock returns: 5.0431\n",
      "  predict the: 8.2535\n",
      "  predict the financial: 5.0431\n",
      "  predict the proenvironmental: 5.0431\n",
      "  predict user: 5.0431\n",
      "  predict user preferences: 5.0431\n",
      "  predicted: 5.0431\n",
      "  predicted that: 5.0431\n",
      "  predicted that of: 5.0431\n",
      "  preferences: 5.0431\n",
      "  preferences and: 5.0431\n",
      "  preferences and improve: 5.0431\n",
      "  previously: 4.3499\n",
      "  previously unrecognised: 5.0431\n",
      "  previously unrecognised influences: 5.0431\n",
      "  prize: 13.9128\n",
      "  prize competition: 5.0431\n",
      "  prize competition to: 5.0431\n",
      "  prize in: 5.0431\n",
      "  prize in for: 5.0431\n",
      "  prize was: 5.0431\n",
      "  prize was awarded: 5.0431\n",
      "  proenvironmental: 5.0431\n",
      "  proenvironmental behaviour: 5.0431\n",
      "  proenvironmental behaviour of: 5.0431\n",
      "  program: 3.7903\n",
      "  program to: 5.0431\n",
      "  program to better: 5.0431\n",
      "  provider: 5.0431\n",
      "  provider netflix: 5.0431\n",
      "  provider netflix held: 5.0431\n",
      "  published: 4.6376\n",
      "  published the: 4.6376\n",
      "  published the first: 5.0431\n",
      "  range: 4.3499\n",
      "  range of: 4.6376\n",
      "  range of company: 5.0431\n",
      "  ratings: 5.0431\n",
      "  ratings were: 5.0431\n",
      "  ratings were not: 5.0431\n",
      "  realised: 5.0431\n",
      "  realised that: 5.0431\n",
      "  realised that viewers: 5.0431\n",
      "  rebellion: 5.0431\n",
      "  rebellion research: 5.0431\n",
      "  rebellion research and: 5.0431\n",
      "  recently: 10.0861\n",
      "  recently applied: 5.0431\n",
      "  recently applied to: 5.0431\n",
      "  recently machine: 5.0431\n",
      "  recently machine learning: 5.0431\n",
      "  recommendation: 13.9128\n",
      "  recommendation algorithm: 5.0431\n",
      "  recommendation algorithm by: 5.0431\n",
      "  recommendation and: 5.0431\n",
      "  recommendation and they: 5.0431\n",
      "  recommendation engine: 5.0431\n",
      "  recommendation engine accordingly: 5.0431\n",
      "  reported: 4.6376\n",
      "  reported that: 5.0431\n",
      "  reported that a: 5.0431\n",
      "  research: 6.8672\n",
      "  research and: 5.0431\n",
      "  research and their: 5.0431\n",
      "  research book: 5.0431\n",
      "  research book created: 5.0431\n",
      "  researchers: 7.3135\n",
      "  researchers from: 4.6376\n",
      "  researchers from att: 5.0431\n",
      "  researchers in: 5.0431\n",
      "  researchers in developing: 5.0431\n",
      "  results: 4.3499\n",
      "  results that: 5.0431\n",
      "  results that far: 5.0431\n",
      "  returns: 5.0431\n",
      "  returns without: 5.0431\n",
      "  returns without overfitting: 5.0431\n",
      "  revealed: 5.0431\n",
      "  revealed previously: 5.0431\n",
      "  revealed previously unrecognised: 5.0431\n",
      "  shortly: 5.0431\n",
      "  shortly after: 5.0431\n",
      "  shortly after the: 5.0431\n",
      "  smartphones: 5.0431\n",
      "  smartphones performance: 5.0431\n",
      "  smartphones performance and: 5.0431\n",
      "  software: 3.9444\n",
      "  software in: 5.0431\n",
      "  software in it: 5.0431\n",
      "  springer: 5.0431\n",
      "  springer nature: 5.0431\n",
      "  springer nature published: 5.0431\n",
      "  stock: 4.6376\n",
      "  stock returns: 5.0431\n",
      "  stock returns without: 5.0431\n",
      "  street: 5.0431\n",
      "  street journal: 5.0431\n",
      "  street journal wrote: 5.0431\n",
      "  study: 3.6568\n",
      "  study fine: 5.0431\n",
      "  study fine art: 5.0431\n",
      "  sun: 5.0431\n",
      "  sun microsystems: 5.0431\n",
      "  sun microsystems vinod: 5.0431\n",
      "  surpass: 4.6376\n",
      "  surpass those: 5.0431\n",
      "  surpass those obtained: 5.0431\n",
      "  team: 5.0431\n",
      "  team made: 5.0431\n",
      "  team made up: 5.0431\n",
      "  teams: 4.6376\n",
      "  teams big: 5.0431\n",
      "  teams big chaos: 5.0431\n",
      "  techniques: 3.3383\n",
      "  techniques like: 4.6376\n",
      "  techniques like ols: 5.0431\n",
      "  technology: 10.0861\n",
      "  technology was: 10.0861\n",
      "  technology was also: 5.0431\n",
      "  technology was used: 5.0431\n",
      "  that: 8.3788\n",
      "  that a: 4.1268\n",
      "  that a machine: 5.0431\n",
      "  that far: 5.0431\n",
      "  that far surpass: 5.0431\n",
      "  that it: 5.0431\n",
      "  that it may: 5.0431\n",
      "  that of: 5.0431\n",
      "  that of medical: 5.0431\n",
      "  that viewers: 5.0431\n",
      "  that viewers ratings: 5.0431\n",
      "  the: 19.0865\n",
      "  the accuracy: 4.6376\n",
      "  the accuracy of: 4.6376\n",
      "  the best: 4.1268\n",
      "  the best indicators: 5.0431\n",
      "  the field: 3.4336\n",
      "  the field of: 3.7903\n",
      "  the financial: 5.0431\n",
      "  the financial crisis: 5.0431\n",
      "  the firm: 5.0431\n",
      "  the firm rebellion: 5.0431\n",
      "  the first: 9.2752\n",
      "  the first netflix: 5.0431\n",
      "  the first research: 5.0431\n",
      "  the grand: 5.0431\n",
      "  the grand prize: 5.0431\n",
      "  the mediaservices: 5.0431\n",
      "  the mediaservices provider: 5.0431\n",
      "  the next: 5.0431\n",
      "  the next two: 5.0431\n",
      "  the phone: 5.0431\n",
      "  the phone when: 5.0431\n",
      "  the prize: 5.0431\n",
      "  the prize was: 5.0431\n",
      "  the proenvironmental: 5.0431\n",
      "  the proenvironmental behaviour: 5.0431\n",
      "  the teams: 5.0431\n",
      "  the teams big: 5.0431\n",
      "  the users: 5.0431\n",
      "  the users interaction: 5.0431\n",
      "  the wall: 5.0431\n",
      "  the wall street: 5.0431\n",
      "  their: 8.3753\n",
      "  their recommendation: 5.0431\n",
      "  their recommendation engine: 5.0431\n",
      "  their use: 5.0431\n",
      "  their use of: 5.0431\n",
      "  their viewing: 5.0431\n",
      "  their viewing patterns: 5.0431\n",
      "  theory: 3.3383\n",
      "  theory built: 5.0431\n",
      "  theory built an: 5.0431\n",
      "  thermal: 5.0431\n",
      "  thermal behaviour: 5.0431\n",
      "  thermal behaviour based: 5.0431\n",
      "  they: 3.4336\n",
      "  they changed: 5.0431\n",
      "  they changed their: 5.0431\n",
      "  those: 4.3499\n",
      "  those obtained: 5.0431\n",
      "  those obtained from: 5.0431\n",
      "  to: 12.2534\n",
      "  to automated: 5.0431\n",
      "  to automated machine: 5.0431\n",
      "  to better: 4.6376\n",
      "  to better predict: 5.0431\n",
      "  to find: 5.0431\n",
      "  to find a: 5.0431\n",
      "  to help: 4.6376\n",
      "  to help make: 5.0431\n",
      "  to optimise: 5.0431\n",
      "  to optimise smartphones: 5.0431\n",
      "  to predict: 12.3803\n",
      "  to predict stock: 5.0431\n",
      "  to predict the: 8.6998\n",
      "  to study: 4.6376\n",
      "  to study fine: 5.0431\n",
      "  to win: 5.0431\n",
      "  to win the: 5.0431\n",
      "  travellers: 5.0431\n",
      "  travellers recently: 5.0431\n",
      "  travellers recently machine: 5.0431\n",
      "  two: 3.5390\n",
      "  two decades: 5.0431\n",
      "  two decades to: 5.0431\n",
      "  unrecognised: 5.0431\n",
      "  unrecognised influences: 5.0431\n",
      "  unrecognised influences among: 5.0431\n",
      "  up: 3.7903\n",
      "  up of: 4.6376\n",
      "  up of researchers: 5.0431\n",
      "  use: 3.3383\n",
      "  use of: 4.3499\n",
      "  use of machine: 4.6376\n",
      "  used: 2.3350\n",
      "  used to: 3.3383\n",
      "  used to help: 5.0431\n",
      "  user: 5.0431\n",
      "  user preferences: 5.0431\n",
      "  user preferences and: 5.0431\n",
      "  users: 3.9444\n",
      "  users interaction: 5.0431\n",
      "  users interaction with: 5.0431\n",
      "  using: 3.2513\n",
      "  using machine: 5.0431\n",
      "  using machine learning: 5.0431\n",
      "  utilise: 5.0431\n",
      "  utilise a: 5.0431\n",
      "  utilise a wide: 5.0431\n",
      "  viewers: 5.0431\n",
      "  viewers ratings: 5.0431\n",
      "  viewers ratings were: 5.0431\n",
      "  viewing: 5.0431\n",
      "  viewing patterns: 5.0431\n",
      "  viewing patterns everything: 5.0431\n",
      "  vinod: 5.0431\n",
      "  vinod khosla: 5.0431\n",
      "  vinod khosla predicted: 5.0431\n",
      "  wall: 5.0431\n",
      "  wall street: 5.0431\n",
      "  wall street journal: 5.0431\n",
      "  was: 16.6915\n",
      "  was also: 4.3499\n",
      "  was also applied: 5.0431\n",
      "  was awarded: 5.0431\n",
      "  was awarded netflix: 5.0431\n",
      "  was recently: 5.0431\n",
      "  was recently applied: 5.0431\n",
      "  was reported: 5.0431\n",
      "  was reported that: 5.0431\n",
      "  was used: 5.0431\n",
      "  was used to: 5.0431\n",
      "  were: 3.7903\n",
      "  were not: 4.6376\n",
      "  were not the: 5.0431\n",
      "  when: 3.3383\n",
      "  when applied: 5.0431\n",
      "  when applied correctly: 5.0431\n",
      "  wide: 5.0431\n",
      "  wide range: 5.0431\n",
      "  wide range of: 5.0431\n",
      "  win: 5.0431\n",
      "  win the: 5.0431\n",
      "  win the grand: 5.0431\n",
      "  with: 4.1453\n",
      "  with the: 7.0779\n",
      "  with the phone: 5.0431\n",
      "  with the teams: 5.0431\n",
      "  without: 3.3383\n",
      "  without overfitting: 5.0431\n",
      "  without overfitting by: 5.0431\n",
      "  would: 3.9444\n",
      "  would be: 5.0431\n",
      "  would be lost: 5.0431\n",
      "  wrote: 5.0431\n",
      "  wrote about: 5.0431\n",
      "  wrote about the: 5.0431\n",
      "\n",
      "Document 85:\n",
      "  advancements: 5.0431\n",
      "  advancements in: 5.0431\n",
      "  advancements in machine: 5.0431\n",
      "  algorithms: 2.3689\n",
      "  algorithms now: 5.0431\n",
      "  algorithms now enable: 5.0431\n",
      "  chemical: 5.0431\n",
      "  chemical reactions: 5.0431\n",
      "  chemical reactions thereby: 5.0431\n",
      "  chemistry: 5.0431\n",
      "  chemistry where: 5.0431\n",
      "  chemistry where novel: 5.0431\n",
      "  chemists: 5.0431\n",
      "  chemists to: 5.0431\n",
      "  chemists to tailor: 5.0431\n",
      "  conditions: 5.0431\n",
      "  conditions for: 5.0431\n",
      "  conditions for optimal: 5.0431\n",
      "  effects: 5.0431\n",
      "  effects on: 5.0431\n",
      "  effects on chemical: 5.0431\n",
      "  enable: 5.0431\n",
      "  enable the: 5.0431\n",
      "  enable the prediction: 5.0431\n",
      "  experimental: 4.6376\n",
      "  experimental conditions: 5.0431\n",
      "  experimental conditions for: 5.0431\n",
      "  extended: 4.3499\n",
      "  extended into: 5.0431\n",
      "  extended into the: 5.0431\n",
      "  field: 2.9636\n",
      "  field of: 3.5390\n",
      "  field of quantum: 5.0431\n",
      "  for: 3.4577\n",
      "  for chemists: 5.0431\n",
      "  for chemists to: 5.0431\n",
      "  for optimal: 4.6376\n",
      "  for optimal outcomes: 5.0431\n",
      "  have: 2.4781\n",
      "  have extended: 5.0431\n",
      "  have extended into: 5.0431\n",
      "  in: 1.3417\n",
      "  in machine: 3.6568\n",
      "  in machine learning: 3.6568\n",
      "  into: 2.9636\n",
      "  into the: 4.3499\n",
      "  into the field: 5.0431\n",
      "  learning: 1.2819\n",
      "  learning have: 4.6376\n",
      "  learning have extended: 5.0431\n",
      "  machine: 1.4735\n",
      "  machine learning: 1.5618\n",
      "  machine learning have: 5.0431\n",
      "  new: 3.2513\n",
      "  new tools: 5.0431\n",
      "  new tools for: 5.0431\n",
      "  novel: 5.0431\n",
      "  novel algorithms: 5.0431\n",
      "  novel algorithms now: 5.0431\n",
      "  now: 4.6376\n",
      "  now enable: 5.0431\n",
      "  now enable the: 5.0431\n",
      "  of: 2.4288\n",
      "  of quantum: 5.0431\n",
      "  of quantum chemistry: 5.0431\n",
      "  of solvent: 5.0431\n",
      "  of solvent effects: 5.0431\n",
      "  offering: 5.0431\n",
      "  offering new: 5.0431\n",
      "  offering new tools: 5.0431\n",
      "  on: 2.0473\n",
      "  on chemical: 5.0431\n",
      "  on chemical reactions: 5.0431\n",
      "  optimal: 4.3499\n",
      "  optimal outcomes: 5.0431\n",
      "  outcomes: 4.3499\n",
      "  prediction: 3.7903\n",
      "  prediction of: 5.0431\n",
      "  prediction of solvent: 5.0431\n",
      "  quantum: 5.0431\n",
      "  quantum chemistry: 5.0431\n",
      "  quantum chemistry where: 5.0431\n",
      "  reactions: 5.0431\n",
      "  reactions thereby: 5.0431\n",
      "  reactions thereby offering: 5.0431\n",
      "  recent: 4.6376\n",
      "  recent advancements: 5.0431\n",
      "  recent advancements in: 5.0431\n",
      "  solvent: 5.0431\n",
      "  solvent effects: 5.0431\n",
      "  solvent effects on: 5.0431\n",
      "  tailor: 5.0431\n",
      "  tailor experimental: 5.0431\n",
      "  tailor experimental conditions: 5.0431\n",
      "  the: 2.3858\n",
      "  the field: 3.4336\n",
      "  the field of: 3.7903\n",
      "  the prediction: 5.0431\n",
      "  the prediction of: 5.0431\n",
      "  thereby: 4.1268\n",
      "  thereby offering: 5.0431\n",
      "  thereby offering new: 5.0431\n",
      "  to: 1.2253\n",
      "  to tailor: 5.0431\n",
      "  to tailor experimental: 5.0431\n",
      "  tools: 4.1268\n",
      "  tools for: 4.6376\n",
      "  tools for chemists: 5.0431\n",
      "  where: 3.2513\n",
      "  where novel: 5.0431\n",
      "  where novel algorithms: 5.0431\n",
      "\n",
      "Document 86:\n",
      "  a: 1.2589\n",
      "  a useful: 5.0431\n",
      "  a useful tool: 5.0431\n",
      "  and: 4.8576\n",
      "  and hurricanes: 5.0431\n",
      "  and hurricanes other: 5.0431\n",
      "  and predict: 5.0431\n",
      "  and predict evacuation: 5.0431\n",
      "  and small: 5.0431\n",
      "  and small scale: 5.0431\n",
      "  and when: 5.0431\n",
      "  and when householders: 5.0431\n",
      "  applications: 3.7903\n",
      "  applications have: 5.0431\n",
      "  applications have been: 5.0431\n",
      "  becoming: 4.6376\n",
      "  becoming a: 4.6376\n",
      "  becoming a useful: 5.0431\n",
      "  been: 5.3834\n",
      "  been focusing: 5.0431\n",
      "  been focusing on: 5.0431\n",
      "  been tested: 5.0431\n",
      "  been tested to: 5.0431\n",
      "  building: 5.0431\n",
      "  building fires: 5.0431\n",
      "  decide: 5.0431\n",
      "  decide to: 5.0431\n",
      "  decide to evacuate: 5.0431\n",
      "  decision: 3.6568\n",
      "  decision making: 4.6376\n",
      "  decision making in: 4.6376\n",
      "  decisions: 3.6568\n",
      "  decisions in: 5.0431\n",
      "  decisions in building: 5.0431\n",
      "  different: 3.9444\n",
      "  different solutions: 5.0431\n",
      "  different solutions have: 5.0431\n",
      "  disasters: 5.0431\n",
      "  disasters different: 5.0431\n",
      "  disasters different solutions: 5.0431\n",
      "  during: 4.1268\n",
      "  during wildfires: 5.0431\n",
      "  during wildfires and: 5.0431\n",
      "  evacuate: 5.0431\n",
      "  evacuate during: 5.0431\n",
      "  evacuate during wildfires: 5.0431\n",
      "  evacuation: 10.0861\n",
      "  evacuation decision: 5.0431\n",
      "  evacuation decision making: 5.0431\n",
      "  evacuation decisions: 5.0431\n",
      "  evacuation decisions in: 5.0431\n",
      "  fires: 5.0431\n",
      "  focusing: 4.6376\n",
      "  focusing on: 4.6376\n",
      "  focusing on pre: 5.0431\n",
      "  have: 4.9562\n",
      "  have been: 7.0779\n",
      "  have been focusing: 5.0431\n",
      "  have been tested: 5.0431\n",
      "  householders: 5.0431\n",
      "  householders decide: 5.0431\n",
      "  householders decide to: 5.0431\n",
      "  hurricanes: 5.0431\n",
      "  hurricanes other: 5.0431\n",
      "  hurricanes other applications: 5.0431\n",
      "  if: 3.6568\n",
      "  if and: 5.0431\n",
      "  if and when: 5.0431\n",
      "  in: 2.6835\n",
      "  in building: 5.0431\n",
      "  in building fires: 5.0431\n",
      "  in large: 4.6376\n",
      "  in large scale: 5.0431\n",
      "  investigate: 5.0431\n",
      "  investigate and: 5.0431\n",
      "  investigate and predict: 5.0431\n",
      "  is: 1.5167\n",
      "  is becoming: 4.6376\n",
      "  is becoming a: 4.6376\n",
      "  large: 3.9444\n",
      "  large scale: 5.0431\n",
      "  large scale and: 5.0431\n",
      "  learning: 1.2819\n",
      "  learning is: 3.0281\n",
      "  learning is becoming: 5.0431\n",
      "  machine: 1.4735\n",
      "  machine learning: 1.5618\n",
      "  machine learning is: 3.6568\n",
      "  making: 4.1268\n",
      "  making in: 4.6376\n",
      "  making in large: 5.0431\n",
      "  on: 2.0473\n",
      "  on pre: 5.0431\n",
      "  on pre evacuation: 5.0431\n",
      "  other: 2.7918\n",
      "  other applications: 5.0431\n",
      "  other applications have: 5.0431\n",
      "  pre: 5.0431\n",
      "  pre evacuation: 5.0431\n",
      "  pre evacuation decisions: 5.0431\n",
      "  predict: 7.8889\n",
      "  predict evacuation: 5.0431\n",
      "  predict evacuation decision: 5.0431\n",
      "  predict if: 5.0431\n",
      "  predict if and: 5.0431\n",
      "  scale: 10.0861\n",
      "  scale and: 5.0431\n",
      "  scale and small: 5.0431\n",
      "  scale disasters: 5.0431\n",
      "  scale disasters different: 5.0431\n",
      "  small: 4.6376\n",
      "  small scale: 5.0431\n",
      "  small scale disasters: 5.0431\n",
      "  solutions: 4.6376\n",
      "  solutions have: 5.0431\n",
      "  solutions have been: 5.0431\n",
      "  tested: 4.6376\n",
      "  tested to: 5.0431\n",
      "  tested to predict: 5.0431\n",
      "  to: 3.6760\n",
      "  to evacuate: 5.0431\n",
      "  to evacuate during: 5.0431\n",
      "  to investigate: 5.0431\n",
      "  to investigate and: 5.0431\n",
      "  to predict: 4.1268\n",
      "  to predict if: 5.0431\n",
      "  tool: 4.1268\n",
      "  tool to: 4.6376\n",
      "  tool to investigate: 5.0431\n",
      "  useful: 3.9444\n",
      "  useful tool: 5.0431\n",
      "  useful tool to: 5.0431\n",
      "  when: 3.3383\n",
      "  when householders: 5.0431\n",
      "  when householders decide: 5.0431\n",
      "  wildfires: 5.0431\n",
      "  wildfires and: 5.0431\n",
      "  wildfires and hurricanes: 5.0431\n",
      "\n",
      "Document 87:\n",
      "  a: 5.0354\n",
      "  a move: 5.0431\n",
      "  a move toward: 5.0431\n",
      "  a promising: 5.0431\n",
      "  a promising tool: 5.0431\n",
      "  a replacement: 5.0431\n",
      "  a replacement for: 5.0431\n",
      "  a way: 4.6376\n",
      "  a way to: 5.0431\n",
      "  also: 2.6452\n",
      "  also emerging: 5.0431\n",
      "  also emerging as: 5.0431\n",
      "  and: 2.4288\n",
      "  and patterns: 5.0431\n",
      "  and site: 5.0431\n",
      "  and site characterization: 5.0431\n",
      "  as: 3.6888\n",
      "  as a: 2.9030\n",
      "  as a promising: 5.0431\n",
      "  as ground: 5.0431\n",
      "  as ground classification: 5.0431\n",
      "  but: 3.0281\n",
      "  but a: 5.0431\n",
      "  but a way: 5.0431\n",
      "  characterization: 5.0431\n",
      "  characterization recent: 5.0431\n",
      "  characterization recent research: 5.0431\n",
      "  classification: 2.9636\n",
      "  classification hazard: 5.0431\n",
      "  classification hazard prediction: 5.0431\n",
      "  data: 1.8650\n",
      "  data and: 3.5390\n",
      "  data and patterns: 5.0431\n",
      "  datacentric: 5.0431\n",
      "  datacentric methods: 5.0431\n",
      "  datacentric methods in: 5.0431\n",
      "  emerging: 4.6376\n",
      "  emerging as: 5.0431\n",
      "  emerging as a: 5.0431\n",
      "  emphasizes: 5.0431\n",
      "  emphasizes a: 5.0431\n",
      "  emphasizes a move: 5.0431\n",
      "  engineering: 8.2535\n",
      "  engineering judgment: 5.0431\n",
      "  engineering judgment but: 5.0431\n",
      "  engineering where: 5.0431\n",
      "  engineering where it: 5.0431\n",
      "  enhance: 5.0431\n",
      "  enhance it: 5.0431\n",
      "  enhance it using: 5.0431\n",
      "  field: 2.9636\n",
      "  field where: 5.0431\n",
      "  field where machine: 5.0431\n",
      "  for: 1.7289\n",
      "  for engineering: 5.0431\n",
      "  for engineering judgment: 5.0431\n",
      "  geotechnical: 5.0431\n",
      "  geotechnical engineering: 5.0431\n",
      "  geotechnical engineering where: 5.0431\n",
      "  ground: 5.0431\n",
      "  ground classification: 5.0431\n",
      "  ground classification hazard: 5.0431\n",
      "  hazard: 5.0431\n",
      "  hazard prediction: 5.0431\n",
      "  hazard prediction and: 5.0431\n",
      "  in: 2.6835\n",
      "  in geotechnical: 5.0431\n",
      "  in geotechnical engineering: 5.0431\n",
      "  in this: 4.3499\n",
      "  in this field: 5.0431\n",
      "  is: 4.5501\n",
      "  is also: 5.0431\n",
      "  is also emerging: 5.0431\n",
      "  is not: 4.6376\n",
      "  is not a: 5.0431\n",
      "  is used: 4.1268\n",
      "  is used to: 5.0431\n",
      "  it: 4.5409\n",
      "  it is: 3.5390\n",
      "  it is used: 5.0431\n",
      "  it using: 5.0431\n",
      "  it using sitespecific: 5.0431\n",
      "  judgment: 5.0431\n",
      "  judgment but: 5.0431\n",
      "  judgment but a: 5.0431\n",
      "  learning: 2.5637\n",
      "  learning is: 6.0563\n",
      "  learning is also: 5.0431\n",
      "  learning is not: 4.6376\n",
      "  machine: 2.9470\n",
      "  machine learning: 3.1236\n",
      "  machine learning is: 7.3135\n",
      "  methods: 2.7405\n",
      "  methods in: 4.6376\n",
      "  methods in this: 5.0431\n",
      "  move: 5.0431\n",
      "  move toward: 5.0431\n",
      "  move toward datacentric: 5.0431\n",
      "  not: 2.6007\n",
      "  not a: 4.6376\n",
      "  not a replacement: 5.0431\n",
      "  patterns: 3.4336\n",
      "  prediction: 3.7903\n",
      "  prediction and: 5.0431\n",
      "  prediction and site: 5.0431\n",
      "  promising: 5.0431\n",
      "  promising tool: 5.0431\n",
      "  promising tool in: 5.0431\n",
      "  recent: 4.6376\n",
      "  recent research: 5.0431\n",
      "  recent research emphasizes: 5.0431\n",
      "  replacement: 4.6376\n",
      "  replacement for: 5.0431\n",
      "  replacement for engineering: 5.0431\n",
      "  research: 3.4336\n",
      "  research emphasizes: 5.0431\n",
      "  research emphasizes a: 5.0431\n",
      "  site: 5.0431\n",
      "  site characterization: 5.0431\n",
      "  site characterization recent: 5.0431\n",
      "  sitespecific: 5.0431\n",
      "  sitespecific data: 5.0431\n",
      "  sitespecific data and: 5.0431\n",
      "  such: 2.4781\n",
      "  such as: 2.8458\n",
      "  such as ground: 5.0431\n",
      "  support: 5.0431\n",
      "  support tasks: 5.0431\n",
      "  support tasks such: 5.0431\n",
      "  tasks: 3.4336\n",
      "  tasks such: 4.1268\n",
      "  tasks such as: 4.1268\n",
      "  this: 2.6007\n",
      "  this field: 5.0431\n",
      "  this field where: 5.0431\n",
      "  to: 2.4507\n",
      "  to enhance: 5.0431\n",
      "  to enhance it: 5.0431\n",
      "  to support: 5.0431\n",
      "  to support tasks: 5.0431\n",
      "  tool: 4.1268\n",
      "  tool in: 5.0431\n",
      "  tool in geotechnical: 5.0431\n",
      "  toward: 4.3499\n",
      "  toward datacentric: 5.0431\n",
      "  toward datacentric methods: 5.0431\n",
      "  used: 2.3350\n",
      "  used to: 3.3383\n",
      "  used to support: 5.0431\n",
      "  using: 3.2513\n",
      "  using sitespecific: 5.0431\n",
      "  using sitespecific data: 5.0431\n",
      "  way: 3.9444\n",
      "  way to: 4.6376\n",
      "  way to enhance: 5.0431\n",
      "  where: 6.5026\n",
      "  where it: 4.6376\n",
      "  where it is: 5.0431\n",
      "  where machine: 5.0431\n",
      "  where machine learning: 5.0431\n",
      "\n",
      "Document 88:\n",
      "  access: 4.6376\n",
      "  access to: 5.0431\n",
      "  access to the: 5.0431\n",
      "  algorithms: 2.3689\n",
      "  algorithms wrong: 5.0431\n",
      "  algorithms wrong tools: 5.0431\n",
      "  although: 4.1268\n",
      "  although machine: 5.0431\n",
      "  although machine learning: 5.0431\n",
      "  and: 3.6432\n",
      "  and algorithms: 5.0431\n",
      "  and algorithms wrong: 5.0431\n",
      "  and evaluation: 5.0431\n",
      "  and evaluation problems: 5.0431\n",
      "  and people: 5.0431\n",
      "  and people lack: 5.0431\n",
      "  are: 1.9750\n",
      "  are numerous: 5.0431\n",
      "  are numerous lack: 5.0431\n",
      "  badly: 5.0431\n",
      "  badly chosen: 5.0431\n",
      "  badly chosen tasks: 5.0431\n",
      "  been: 2.6917\n",
      "  been transformative: 5.0431\n",
      "  been transformative in: 5.0431\n",
      "  bias: 3.7903\n",
      "  bias privacy: 5.0431\n",
      "  bias privacy problems: 5.0431\n",
      "  chosen: 4.6376\n",
      "  chosen tasks: 5.0431\n",
      "  chosen tasks and: 5.0431\n",
      "  data: 5.5950\n",
      "  data bias: 5.0431\n",
      "  data bias privacy: 5.0431\n",
      "  data data: 4.3499\n",
      "  data data bias: 5.0431\n",
      "  data lack: 5.0431\n",
      "  data lack of: 5.0431\n",
      "  deliver: 4.6376\n",
      "  deliver expected: 5.0431\n",
      "  deliver expected results: 5.0431\n",
      "  evaluation: 4.3499\n",
      "  evaluation problems: 5.0431\n",
      "  expected: 5.0431\n",
      "  expected results: 5.0431\n",
      "  expected results reasons: 5.0431\n",
      "  fail: 4.3499\n",
      "  fail to: 4.6376\n",
      "  fail to deliver: 5.0431\n",
      "  fields: 3.9444\n",
      "  fields machinelearning: 5.0431\n",
      "  fields machinelearning programs: 5.0431\n",
      "  for: 1.7289\n",
      "  for this: 5.0431\n",
      "  for this are: 5.0431\n",
      "  has: 2.8458\n",
      "  has been: 3.6568\n",
      "  has been transformative: 5.0431\n",
      "  in: 1.3417\n",
      "  in some: 5.0431\n",
      "  in some fields: 5.0431\n",
      "  lack: 13.0497\n",
      "  lack of: 13.9128\n",
      "  lack of access: 5.0431\n",
      "  lack of resources: 5.0431\n",
      "  lack of suitable: 5.0431\n",
      "  learning: 1.2819\n",
      "  learning has: 4.1268\n",
      "  learning has been: 4.3499\n",
      "  machine: 1.4735\n",
      "  machine learning: 1.5618\n",
      "  machine learning has: 4.3499\n",
      "  machinelearning: 4.6376\n",
      "  machinelearning programs: 5.0431\n",
      "  machinelearning programs often: 5.0431\n",
      "  numerous: 5.0431\n",
      "  numerous lack: 5.0431\n",
      "  numerous lack of: 5.0431\n",
      "  of: 3.6432\n",
      "  of access: 5.0431\n",
      "  of access to: 5.0431\n",
      "  of resources: 5.0431\n",
      "  of resources and: 5.0431\n",
      "  of suitable: 5.0431\n",
      "  of suitable data: 5.0431\n",
      "  often: 3.0971\n",
      "  often fail: 5.0431\n",
      "  often fail to: 5.0431\n",
      "  people: 4.3499\n",
      "  people lack: 5.0431\n",
      "  people lack of: 5.0431\n",
      "  privacy: 4.1268\n",
      "  privacy problems: 5.0431\n",
      "  privacy problems badly: 5.0431\n",
      "  problems: 6.3425\n",
      "  problems badly: 5.0431\n",
      "  problems badly chosen: 5.0431\n",
      "  programs: 4.3499\n",
      "  programs often: 5.0431\n",
      "  programs often fail: 5.0431\n",
      "  reasons: 5.0431\n",
      "  reasons for: 5.0431\n",
      "  reasons for this: 5.0431\n",
      "  resources: 4.6376\n",
      "  resources and: 5.0431\n",
      "  resources and evaluation: 5.0431\n",
      "  results: 4.3499\n",
      "  results reasons: 5.0431\n",
      "  results reasons for: 5.0431\n",
      "  some: 2.9636\n",
      "  some fields: 5.0431\n",
      "  some fields machinelearning: 5.0431\n",
      "  suitable: 4.6376\n",
      "  suitable data: 5.0431\n",
      "  suitable data lack: 5.0431\n",
      "  tasks: 3.4336\n",
      "  tasks and: 5.0431\n",
      "  tasks and algorithms: 5.0431\n",
      "  the: 1.1929\n",
      "  the data: 3.0971\n",
      "  the data data: 5.0431\n",
      "  this: 2.6007\n",
      "  this are: 5.0431\n",
      "  this are numerous: 5.0431\n",
      "  to: 2.4507\n",
      "  to deliver: 4.6376\n",
      "  to deliver expected: 5.0431\n",
      "  to the: 3.1712\n",
      "  to the data: 5.0431\n",
      "  tools: 4.1268\n",
      "  tools and: 5.0431\n",
      "  tools and people: 5.0431\n",
      "  transformative: 5.0431\n",
      "  transformative in: 5.0431\n",
      "  transformative in some: 5.0431\n",
      "  wrong: 4.6376\n",
      "  wrong tools: 5.0431\n",
      "  wrong tools and: 5.0431\n",
      "\n",
      "Document 89:\n",
      "  a: 3.7766\n",
      "  a full: 5.0431\n",
      "  a full and: 5.0431\n",
      "  a situation: 5.0431\n",
      "  a situation where: 5.0431\n",
      "  a substantial: 5.0431\n",
      "  a substantial impact: 5.0431\n",
      "  acceptable: 5.0431\n",
      "  acceptable unless: 5.0431\n",
      "  acceptable unless it: 5.0431\n",
      "  algorithm: 5.8060\n",
      "  algorithm cannot: 5.0431\n",
      "  algorithm cannot audit: 5.0431\n",
      "  algorithm or: 5.0431\n",
      "  algorithm or the: 5.0431\n",
      "  an: 6.4580\n",
      "  an individuals: 5.0431\n",
      "  an individuals life: 5.0431\n",
      "  an intelligence: 5.0431\n",
      "  an intelligence system: 5.0431\n",
      "  an output: 5.0431\n",
      "  an output is: 5.0431\n",
      "  and: 1.2144\n",
      "  and satisfactory: 5.0431\n",
      "  and satisfactory explanation: 5.0431\n",
      "  another: 4.1268\n",
      "  another yet: 5.0431\n",
      "  another yet significant: 5.0431\n",
      "  audit: 5.0431\n",
      "  audit the: 5.0431\n",
      "  audit the pattern: 5.0431\n",
      "  be: 2.0726\n",
      "  be considered: 4.6376\n",
      "  be considered acceptable: 5.0431\n",
      "  black: 8.2535\n",
      "  black box: 9.2752\n",
      "  black box refers: 5.0431\n",
      "  black box theory: 5.0431\n",
      "  box: 9.2752\n",
      "  box refers: 5.0431\n",
      "  box refers to: 5.0431\n",
      "  box theory: 5.0431\n",
      "  box theory poses: 5.0431\n",
      "  cannot: 3.7903\n",
      "  cannot audit: 5.0431\n",
      "  cannot audit the: 5.0431\n",
      "  challenge: 5.0431\n",
      "  challenge black: 5.0431\n",
      "  challenge black box: 5.0431\n",
      "  claimed: 5.0431\n",
      "  claimed that: 5.0431\n",
      "  claimed that such: 5.0431\n",
      "  coders: 5.0431\n",
      "  coders of: 5.0431\n",
      "  coders of the: 5.0431\n",
      "  committee: 5.0431\n",
      "  committee which: 5.0431\n",
      "  committee which claimed: 5.0431\n",
      "  considered: 3.7903\n",
      "  considered acceptable: 5.0431\n",
      "  considered acceptable unless: 5.0431\n",
      "  could: 4.3499\n",
      "  could have: 5.0431\n",
      "  could have a: 5.0431\n",
      "  data: 1.8650\n",
      "  data the: 5.0431\n",
      "  data the house: 5.0431\n",
      "  decisions: 3.6568\n",
      "  decisions it: 5.0431\n",
      "  decisions it makes: 5.0431\n",
      "  entirely: 5.0431\n",
      "  entirely opaque: 5.0431\n",
      "  entirely opaque meaning: 5.0431\n",
      "  even: 3.9444\n",
      "  even the: 5.0431\n",
      "  even the coders: 5.0431\n",
      "  explanation: 4.6376\n",
      "  explanation for: 5.0431\n",
      "  explanation for the: 5.0431\n",
      "  extracted: 5.0431\n",
      "  extracted out: 5.0431\n",
      "  extracted out of: 5.0431\n",
      "  for: 1.7289\n",
      "  for the: 4.1268\n",
      "  for the decisions: 5.0431\n",
      "  full: 5.0431\n",
      "  full and: 5.0431\n",
      "  full and satisfactory: 5.0431\n",
      "  have: 2.4781\n",
      "  have a: 4.3499\n",
      "  have a substantial: 5.0431\n",
      "  house: 5.0431\n",
      "  house of: 5.0431\n",
      "  house of lords: 5.0431\n",
      "  impact: 5.0431\n",
      "  impact on: 5.0431\n",
      "  impact on an: 5.0431\n",
      "  individuals: 5.0431\n",
      "  individuals life: 5.0431\n",
      "  individuals life would: 5.0431\n",
      "  intelligence: 3.1712\n",
      "  intelligence system: 5.0431\n",
      "  intelligence system that: 5.0431\n",
      "  is: 1.5167\n",
      "  is entirely: 5.0431\n",
      "  is entirely opaque: 5.0431\n",
      "  it: 4.5409\n",
      "  it makes: 5.0431\n",
      "  it provided: 5.0431\n",
      "  it provided a: 5.0431\n",
      "  life: 5.0431\n",
      "  life would: 5.0431\n",
      "  life would not: 5.0431\n",
      "  lords: 5.0431\n",
      "  lords select: 5.0431\n",
      "  lords select committee: 5.0431\n",
      "  machine: 1.4735\n",
      "  machine extracted: 5.0431\n",
      "  machine extracted out: 5.0431\n",
      "  makes: 4.3499\n",
      "  meaning: 4.3499\n",
      "  meaning that: 4.6376\n",
      "  meaning that even: 5.0431\n",
      "  not: 2.6007\n",
      "  not be: 4.3499\n",
      "  not be considered: 5.0431\n",
      "  of: 4.8576\n",
      "  of lords: 5.0431\n",
      "  of lords select: 5.0431\n",
      "  of producing: 5.0431\n",
      "  of producing an: 5.0431\n",
      "  of the: 4.6044\n",
      "  of the algorithm: 5.0431\n",
      "  of the data: 4.1268\n",
      "  on: 2.0473\n",
      "  on an: 5.0431\n",
      "  on an individuals: 5.0431\n",
      "  opaque: 5.0431\n",
      "  opaque meaning: 5.0431\n",
      "  opaque meaning that: 5.0431\n",
      "  or: 2.0226\n",
      "  or the: 4.6376\n",
      "  or the process: 5.0431\n",
      "  out: 3.7903\n",
      "  out of: 4.3499\n",
      "  out of the: 4.6376\n",
      "  output: 3.3383\n",
      "  output is: 4.6376\n",
      "  output is entirely: 5.0431\n",
      "  pattern: 4.1268\n",
      "  pattern that: 5.0431\n",
      "  pattern that the: 5.0431\n",
      "  poses: 5.0431\n",
      "  poses another: 5.0431\n",
      "  poses another yet: 5.0431\n",
      "  process: 3.4336\n",
      "  process of: 4.3499\n",
      "  process of producing: 5.0431\n",
      "  producing: 5.0431\n",
      "  producing an: 5.0431\n",
      "  producing an output: 5.0431\n",
      "  provided: 4.1268\n",
      "  provided a: 4.6376\n",
      "  provided a full: 5.0431\n",
      "  refers: 4.1268\n",
      "  refers to: 4.1268\n",
      "  refers to a: 4.6376\n",
      "  satisfactory: 5.0431\n",
      "  satisfactory explanation: 5.0431\n",
      "  satisfactory explanation for: 5.0431\n",
      "  select: 5.0431\n",
      "  select committee: 5.0431\n",
      "  select committee which: 5.0431\n",
      "  significant: 4.6376\n",
      "  significant challenge: 5.0431\n",
      "  significant challenge black: 5.0431\n",
      "  situation: 4.6376\n",
      "  situation where: 5.0431\n",
      "  situation where the: 5.0431\n",
      "  substantial: 5.0431\n",
      "  substantial impact: 5.0431\n",
      "  substantial impact on: 5.0431\n",
      "  such: 2.4781\n",
      "  such an: 5.0431\n",
      "  such an intelligence: 5.0431\n",
      "  system: 3.0281\n",
      "  system that: 4.6376\n",
      "  system that could: 5.0431\n",
      "  that: 6.7030\n",
      "  that could: 5.0431\n",
      "  that could have: 5.0431\n",
      "  that even: 5.0431\n",
      "  that even the: 5.0431\n",
      "  that such: 5.0431\n",
      "  that such an: 5.0431\n",
      "  that the: 3.9444\n",
      "  that the machine: 5.0431\n",
      "  the: 11.9290\n",
      "  the algorithm: 9.2752\n",
      "  the algorithm cannot: 5.0431\n",
      "  the algorithm or: 5.0431\n",
      "  the black: 4.6376\n",
      "  the black box: 4.6376\n",
      "  the coders: 5.0431\n",
      "  the coders of: 5.0431\n",
      "  the data: 3.0971\n",
      "  the data the: 5.0431\n",
      "  the decisions: 4.6376\n",
      "  the decisions it: 5.0431\n",
      "  the house: 5.0431\n",
      "  the house of: 5.0431\n",
      "  the machine: 4.1268\n",
      "  the machine extracted: 5.0431\n",
      "  the pattern: 5.0431\n",
      "  the pattern that: 5.0431\n",
      "  the process: 4.3499\n",
      "  the process of: 4.6376\n",
      "  theory: 3.3383\n",
      "  theory poses: 5.0431\n",
      "  theory poses another: 5.0431\n",
      "  to: 1.2253\n",
      "  to a: 3.1712\n",
      "  to a situation: 5.0431\n",
      "  unless: 4.6376\n",
      "  unless it: 5.0431\n",
      "  unless it provided: 5.0431\n",
      "  where: 3.2513\n",
      "  where the: 4.6376\n",
      "  where the algorithm: 5.0431\n",
      "  which: 2.6917\n",
      "  which claimed: 5.0431\n",
      "  which claimed that: 5.0431\n",
      "  would: 3.9444\n",
      "  would not: 5.0431\n",
      "  would not be: 5.0431\n",
      "  yet: 4.3499\n",
      "  yet significant: 5.0431\n",
      "  yet significant challenge: 5.0431\n",
      "\n",
      "Document 90:\n",
      "  a: 3.7766\n",
      "  a collision: 5.0431\n",
      "  a collision attempts: 5.0431\n",
      "  a pedestrian: 5.0431\n",
      "  a pedestrian who: 5.0431\n",
      "  a selfdriving: 5.0431\n",
      "  a selfdriving car: 5.0431\n",
      "  after: 7.5806\n",
      "  after a: 5.0431\n",
      "  after a collision: 5.0431\n",
      "  after years: 5.0431\n",
      "  after years of: 5.0431\n",
      "  against: 4.6376\n",
      "  against its: 5.0431\n",
      "  against its users: 5.0431\n",
      "  and: 2.4288\n",
      "  and billions: 5.0431\n",
      "  and billions of: 5.0431\n",
      "  and offensive: 5.0431\n",
      "  and offensive response: 5.0431\n",
      "  attempts: 4.6376\n",
      "  attempts to: 4.6376\n",
      "  attempts to use: 5.0431\n",
      "  been: 2.6917\n",
      "  been reported: 5.0431\n",
      "  been reported to: 5.0431\n",
      "  billions: 5.0431\n",
      "  billions of: 5.0431\n",
      "  billions of dollars: 5.0431\n",
      "  bing: 5.0431\n",
      "  bing chat: 5.0431\n",
      "  bing chat chatbot: 5.0431\n",
      "  car: 5.0431\n",
      "  car from: 5.0431\n",
      "  car from uber: 5.0431\n",
      "  chat: 5.0431\n",
      "  chat chatbot: 5.0431\n",
      "  chat chatbot has: 5.0431\n",
      "  chatbot: 4.6376\n",
      "  chatbot has: 5.0431\n",
      "  chatbot has been: 5.0431\n",
      "  collision: 5.0431\n",
      "  collision attempts: 5.0431\n",
      "  collision attempts to: 5.0431\n",
      "  deliver: 4.6376\n",
      "  deliver even: 5.0431\n",
      "  deliver even after: 5.0431\n",
      "  detect: 4.3499\n",
      "  detect a: 5.0431\n",
      "  detect a pedestrian: 5.0431\n",
      "  dollars: 5.0431\n",
      "  dollars invested: 5.0431\n",
      "  dollars invested microsofts: 5.0431\n",
      "  even: 3.9444\n",
      "  even after: 5.0431\n",
      "  even after years: 5.0431\n",
      "  failed: 10.0861\n",
      "  failed to: 10.0861\n",
      "  failed to deliver: 5.0431\n",
      "  failed to detect: 5.0431\n",
      "  from: 2.0726\n",
      "  from uber: 5.0431\n",
      "  from uber failed: 5.0431\n",
      "  has: 2.8458\n",
      "  has been: 3.6568\n",
      "  has been reported: 5.0431\n",
      "  healthcare: 4.6376\n",
      "  healthcare with: 5.0431\n",
      "  healthcare with the: 5.0431\n",
      "  hostile: 5.0431\n",
      "  hostile and: 5.0431\n",
      "  hostile and offensive: 5.0431\n",
      "  ibm: 4.6376\n",
      "  ibm watson: 5.0431\n",
      "  ibm watson system: 5.0431\n",
      "  in: 2.6835\n",
      "  in a: 3.0971\n",
      "  in a selfdriving: 5.0431\n",
      "  in healthcare: 5.0431\n",
      "  in healthcare with: 5.0431\n",
      "  invested: 5.0431\n",
      "  invested microsofts: 5.0431\n",
      "  invested microsofts bing: 5.0431\n",
      "  its: 2.9636\n",
      "  its users: 5.0431\n",
      "  killed: 5.0431\n",
      "  killed after: 5.0431\n",
      "  killed after a: 5.0431\n",
      "  learning: 1.2819\n",
      "  learning in: 3.6568\n",
      "  learning in healthcare: 5.0431\n",
      "  machine: 1.4735\n",
      "  machine learning: 1.5618\n",
      "  machine learning in: 4.1268\n",
      "  microsofts: 5.0431\n",
      "  microsofts bing: 5.0431\n",
      "  microsofts bing chat: 5.0431\n",
      "  of: 2.4288\n",
      "  of dollars: 5.0431\n",
      "  of dollars invested: 5.0431\n",
      "  of time: 4.6376\n",
      "  of time and: 5.0431\n",
      "  offensive: 5.0431\n",
      "  offensive response: 5.0431\n",
      "  offensive response against: 5.0431\n",
      "  pedestrian: 5.0431\n",
      "  pedestrian who: 5.0431\n",
      "  pedestrian who was: 5.0431\n",
      "  produce: 4.3499\n",
      "  produce hostile: 5.0431\n",
      "  produce hostile and: 5.0431\n",
      "  reported: 4.6376\n",
      "  reported to: 5.0431\n",
      "  reported to produce: 5.0431\n",
      "  response: 4.6376\n",
      "  response against: 5.0431\n",
      "  response against its: 5.0431\n",
      "  selfdriving: 5.0431\n",
      "  selfdriving car: 5.0431\n",
      "  selfdriving car from: 5.0431\n",
      "  system: 3.0281\n",
      "  system failed: 5.0431\n",
      "  system failed to: 5.0431\n",
      "  the: 1.1929\n",
      "  the ibm: 5.0431\n",
      "  the ibm watson: 5.0431\n",
      "  time: 3.5390\n",
      "  time and: 5.0431\n",
      "  time and billions: 5.0431\n",
      "  to: 4.9014\n",
      "  to deliver: 4.6376\n",
      "  to deliver even: 5.0431\n",
      "  to detect: 4.6376\n",
      "  to detect a: 5.0431\n",
      "  to produce: 4.6376\n",
      "  to produce hostile: 5.0431\n",
      "  to use: 4.6376\n",
      "  to use machine: 5.0431\n",
      "  uber: 5.0431\n",
      "  uber failed: 5.0431\n",
      "  uber failed to: 5.0431\n",
      "  use: 3.3383\n",
      "  use machine: 5.0431\n",
      "  use machine learning: 5.0431\n",
      "  users: 3.9444\n",
      "  was: 3.3383\n",
      "  was killed: 5.0431\n",
      "  was killed after: 5.0431\n",
      "  watson: 5.0431\n",
      "  watson system: 5.0431\n",
      "  watson system failed: 5.0431\n",
      "  who: 3.9444\n",
      "  who was: 5.0431\n",
      "  who was killed: 5.0431\n",
      "  with: 2.0726\n",
      "  with the: 3.5390\n",
      "  with the ibm: 5.0431\n",
      "  years: 5.0431\n",
      "  years of: 5.0431\n",
      "  years of time: 5.0431\n",
      "\n",
      "Document 91:\n",
      "  a: 2.5177\n",
      "  a strategy: 5.0431\n",
      "  a strategy to: 5.0431\n",
      "  a systematic: 5.0431\n",
      "  a systematic review: 5.0431\n",
      "  and: 1.2144\n",
      "  and increased: 5.0431\n",
      "  and increased reviewer: 5.0431\n",
      "  as: 1.8444\n",
      "  as a: 2.9030\n",
      "  as a strategy: 5.0431\n",
      "  been: 2.6917\n",
      "  been used: 3.9444\n",
      "  been used as: 4.6376\n",
      "  biomedical: 5.0431\n",
      "  biomedical literature: 5.0431\n",
      "  biomedical literature while: 5.0431\n",
      "  burden: 10.0861\n",
      "  burden related: 5.0431\n",
      "  burden related to: 5.0431\n",
      "  burden without: 5.0431\n",
      "  burden without limiting: 5.0431\n",
      "  developed: 3.7903\n",
      "  developed sufficiently: 5.0431\n",
      "  developed sufficiently to: 5.0431\n",
      "  evidence: 4.6376\n",
      "  evidence related: 5.0431\n",
      "  evidence related to: 5.0431\n",
      "  findings: 5.0431\n",
      "  findings research: 5.0431\n",
      "  findings research themselves: 5.0431\n",
      "  for: 1.7289\n",
      "  for the: 4.1268\n",
      "  for the findings: 5.0431\n",
      "  growth: 5.0431\n",
      "  growth of: 5.0431\n",
      "  growth of biomedical: 5.0431\n",
      "  has: 8.5375\n",
      "  has been: 3.6568\n",
      "  has been used: 4.6376\n",
      "  has improved: 5.0431\n",
      "  has improved with: 5.0431\n",
      "  has not: 4.3499\n",
      "  has not yet: 5.0431\n",
      "  improved: 5.0431\n",
      "  improved with: 5.0431\n",
      "  improved with training: 5.0431\n",
      "  increased: 4.6376\n",
      "  increased reviewer: 5.0431\n",
      "  increased reviewer burden: 5.0431\n",
      "  it: 4.5409\n",
      "  it has: 8.6998\n",
      "  it has improved: 5.0431\n",
      "  it has not: 5.0431\n",
      "  learning: 1.2819\n",
      "  learning has: 4.1268\n",
      "  learning has been: 4.3499\n",
      "  limiting: 5.0431\n",
      "  limiting the: 5.0431\n",
      "  limiting the necessary: 5.0431\n",
      "  literature: 5.0431\n",
      "  literature while: 5.0431\n",
      "  literature while it: 5.0431\n",
      "  machine: 1.4735\n",
      "  machine learning: 1.5618\n",
      "  machine learning has: 4.3499\n",
      "  necessary: 5.0431\n",
      "  necessary sensitivity: 5.0431\n",
      "  necessary sensitivity for: 5.0431\n",
      "  not: 2.6007\n",
      "  not yet: 5.0431\n",
      "  not yet developed: 5.0431\n",
      "  of: 1.2144\n",
      "  of biomedical: 5.0431\n",
      "  of biomedical literature: 5.0431\n",
      "  reduce: 4.1268\n",
      "  reduce the: 4.6376\n",
      "  reduce the workload: 5.0431\n",
      "  related: 7.3135\n",
      "  related to: 8.6998\n",
      "  related to a: 5.0431\n",
      "  related to the: 5.0431\n",
      "  research: 3.4336\n",
      "  research themselves: 5.0431\n",
      "  review: 5.0431\n",
      "  review and: 5.0431\n",
      "  review and increased: 5.0431\n",
      "  reviewer: 5.0431\n",
      "  reviewer burden: 5.0431\n",
      "  reviewer burden related: 5.0431\n",
      "  sensitivity: 4.6376\n",
      "  sensitivity for: 5.0431\n",
      "  sensitivity for the: 5.0431\n",
      "  sets: 4.1268\n",
      "  sets it: 5.0431\n",
      "  sets it has: 5.0431\n",
      "  strategy: 5.0431\n",
      "  strategy to: 5.0431\n",
      "  strategy to update: 5.0431\n",
      "  sufficiently: 4.6376\n",
      "  sufficiently to: 5.0431\n",
      "  sufficiently to reduce: 5.0431\n",
      "  systematic: 5.0431\n",
      "  systematic review: 5.0431\n",
      "  systematic review and: 5.0431\n",
      "  the: 5.9645\n",
      "  the evidence: 5.0431\n",
      "  the evidence related: 5.0431\n",
      "  the findings: 5.0431\n",
      "  the findings research: 5.0431\n",
      "  the growth: 5.0431\n",
      "  the growth of: 5.0431\n",
      "  the necessary: 5.0431\n",
      "  the necessary sensitivity: 5.0431\n",
      "  the workload: 5.0431\n",
      "  the workload burden: 5.0431\n",
      "  themselves: 5.0431\n",
      "  to: 4.9014\n",
      "  to a: 3.1712\n",
      "  to a systematic: 5.0431\n",
      "  to reduce: 4.1268\n",
      "  to reduce the: 4.6376\n",
      "  to the: 3.1712\n",
      "  to the growth: 5.0431\n",
      "  to update: 5.0431\n",
      "  to update the: 5.0431\n",
      "  training: 2.5581\n",
      "  training sets: 4.3499\n",
      "  training sets it: 5.0431\n",
      "  update: 5.0431\n",
      "  update the: 5.0431\n",
      "  update the evidence: 5.0431\n",
      "  used: 2.3350\n",
      "  used as: 4.1268\n",
      "  used as a: 4.6376\n",
      "  while: 3.4336\n",
      "  while it: 5.0431\n",
      "  while it has: 5.0431\n",
      "  with: 2.0726\n",
      "  with training: 5.0431\n",
      "  with training sets: 5.0431\n",
      "  without: 3.3383\n",
      "  without limiting: 5.0431\n",
      "  without limiting the: 5.0431\n",
      "  workload: 5.0431\n",
      "  workload burden: 5.0431\n",
      "  workload burden without: 5.0431\n",
      "  yet: 4.3499\n",
      "  yet developed: 5.0431\n",
      "  yet developed sufficiently: 5.0431\n",
      "\n",
      "Document 92:\n",
      "  a: 1.2589\n",
      "  a specific: 4.3499\n",
      "  a specific decision: 5.0431\n",
      "  ai: 17.1681\n",
      "  ai arrived: 5.0431\n",
      "  ai arrived at: 5.0431\n",
      "  ai in: 4.6376\n",
      "  ai in which: 5.0431\n",
      "  ai it: 5.0431\n",
      "  ai it contrasts: 5.0431\n",
      "  ai or: 5.0431\n",
      "  ai or explainable: 5.0431\n",
      "  ai xai: 5.0431\n",
      "  ai xai or: 5.0431\n",
      "  aipowered: 4.6376\n",
      "  aipowered systems: 5.0431\n",
      "  aipowered systems and: 5.0431\n",
      "  an: 4.3054\n",
      "  an ai: 5.0431\n",
      "  an ai arrived: 5.0431\n",
      "  an implementation: 5.0431\n",
      "  an implementation of: 5.0431\n",
      "  and: 1.2144\n",
      "  and dismantling: 5.0431\n",
      "  and dismantling their: 5.0431\n",
      "  arrived: 5.0431\n",
      "  arrived at: 5.0431\n",
      "  arrived at a: 5.0431\n",
      "  artificial: 2.7918\n",
      "  artificial intelligence: 3.5390\n",
      "  artificial intelligence ai: 4.6376\n",
      "  at: 3.9444\n",
      "  at a: 4.6376\n",
      "  at a specific: 5.0431\n",
      "  be: 2.0726\n",
      "  be an: 4.3499\n",
      "  be an implementation: 5.0431\n",
      "  black: 4.1268\n",
      "  black box: 4.6376\n",
      "  black box concept: 5.0431\n",
      "  box: 4.6376\n",
      "  box concept: 5.0431\n",
      "  box concept in: 5.0431\n",
      "  by: 3.8151\n",
      "  by refining: 5.0431\n",
      "  by refining the: 5.0431\n",
      "  by the: 3.2513\n",
      "  by the ai: 5.0431\n",
      "  can: 2.1809\n",
      "  can understand: 5.0431\n",
      "  can understand the: 5.0431\n",
      "  cannot: 3.7903\n",
      "  cannot explain: 5.0431\n",
      "  cannot explain why: 5.0431\n",
      "  concept: 4.3499\n",
      "  concept in: 5.0431\n",
      "  concept in machine: 5.0431\n",
      "  contrasts: 5.0431\n",
      "  contrasts with: 5.0431\n",
      "  contrasts with the: 5.0431\n",
      "  decision: 3.6568\n",
      "  decision by: 5.0431\n",
      "  decision by refining: 5.0431\n",
      "  decisions: 3.6568\n",
      "  decisions or: 5.0431\n",
      "  decisions or predictions: 5.0431\n",
      "  designers: 5.0431\n",
      "  designers cannot: 5.0431\n",
      "  designers cannot explain: 5.0431\n",
      "  dismantling: 5.0431\n",
      "  dismantling their: 5.0431\n",
      "  dismantling their misconceptions: 5.0431\n",
      "  effectively: 5.0431\n",
      "  effectively xai: 5.0431\n",
      "  effectively xai may: 5.0431\n",
      "  even: 3.9444\n",
      "  even its: 5.0431\n",
      "  even its designers: 5.0431\n",
      "  explain: 4.3499\n",
      "  explain why: 5.0431\n",
      "  explain why an: 5.0431\n",
      "  explainable: 10.0861\n",
      "  explainable ai: 5.0431\n",
      "  explainable ai xai: 5.0431\n",
      "  explainable machine: 5.0431\n",
      "  explainable machine learning: 5.0431\n",
      "  explanation: 4.6376\n",
      "  help: 4.6376\n",
      "  help users: 5.0431\n",
      "  help users perform: 5.0431\n",
      "  humans: 4.6376\n",
      "  humans can: 5.0431\n",
      "  humans can understand: 5.0431\n",
      "  implementation: 4.6376\n",
      "  implementation of: 5.0431\n",
      "  implementation of the: 5.0431\n",
      "  in: 2.6835\n",
      "  in machine: 3.6568\n",
      "  in machine learning: 3.6568\n",
      "  in which: 3.7903\n",
      "  in which humans: 5.0431\n",
      "  intelligence: 3.1712\n",
      "  intelligence ai: 4.6376\n",
      "  intelligence ai in: 4.6376\n",
      "  interpretable: 4.6376\n",
      "  interpretable ai: 5.0431\n",
      "  interpretable ai or: 5.0431\n",
      "  is: 1.5167\n",
      "  is artificial: 5.0431\n",
      "  is artificial intelligence: 5.0431\n",
      "  it: 2.2705\n",
      "  it contrasts: 5.0431\n",
      "  it contrasts with: 5.0431\n",
      "  its: 2.9636\n",
      "  its designers: 5.0431\n",
      "  its designers cannot: 5.0431\n",
      "  learning: 2.5637\n",
      "  learning where: 4.6376\n",
      "  learning where even: 5.0431\n",
      "  learning xml: 5.0431\n",
      "  learning xml is: 5.0431\n",
      "  machine: 2.9470\n",
      "  machine learning: 3.1236\n",
      "  machine learning where: 4.6376\n",
      "  machine learning xml: 5.0431\n",
      "  made: 4.6376\n",
      "  made by: 5.0431\n",
      "  made by the: 5.0431\n",
      "  may: 3.2513\n",
      "  may be: 4.1268\n",
      "  may be an: 4.6376\n",
      "  mental: 5.0431\n",
      "  mental models: 5.0431\n",
      "  mental models of: 5.0431\n",
      "  misconceptions: 5.0431\n",
      "  misconceptions xai: 5.0431\n",
      "  misconceptions xai promises: 5.0431\n",
      "  models: 2.5581\n",
      "  models of: 4.3499\n",
      "  models of users: 5.0431\n",
      "  more: 3.1712\n",
      "  more effectively: 5.0431\n",
      "  more effectively xai: 5.0431\n",
      "  of: 3.6432\n",
      "  of aipowered: 4.6376\n",
      "  of aipowered systems: 5.0431\n",
      "  of the: 2.3022\n",
      "  of the social: 5.0431\n",
      "  of users: 5.0431\n",
      "  of users of: 5.0431\n",
      "  or: 6.0679\n",
      "  or explainable: 5.0431\n",
      "  or explainable machine: 5.0431\n",
      "  or interpretable: 5.0431\n",
      "  or interpretable ai: 5.0431\n",
      "  or predictions: 4.3499\n",
      "  or predictions made: 5.0431\n",
      "  perform: 3.2513\n",
      "  perform more: 5.0431\n",
      "  perform more effectively: 5.0431\n",
      "  predictions: 3.3383\n",
      "  predictions made: 5.0431\n",
      "  predictions made by: 5.0431\n",
      "  promises: 5.0431\n",
      "  promises to: 5.0431\n",
      "  promises to help: 5.0431\n",
      "  refining: 5.0431\n",
      "  refining the: 5.0431\n",
      "  refining the mental: 5.0431\n",
      "  right: 5.0431\n",
      "  right to: 5.0431\n",
      "  right to explanation: 5.0431\n",
      "  social: 4.6376\n",
      "  social right: 5.0431\n",
      "  social right to: 5.0431\n",
      "  specific: 3.7903\n",
      "  specific decision: 5.0431\n",
      "  specific decision by: 5.0431\n",
      "  systems: 2.6917\n",
      "  systems and: 4.6376\n",
      "  systems and dismantling: 5.0431\n",
      "  the: 5.9645\n",
      "  the ai: 5.0431\n",
      "  the ai it: 5.0431\n",
      "  the black: 4.6376\n",
      "  the black box: 4.6376\n",
      "  the decisions: 4.6376\n",
      "  the decisions or: 5.0431\n",
      "  the mental: 5.0431\n",
      "  the mental models: 5.0431\n",
      "  the social: 5.0431\n",
      "  the social right: 5.0431\n",
      "  their: 2.7918\n",
      "  their misconceptions: 5.0431\n",
      "  their misconceptions xai: 5.0431\n",
      "  to: 2.4507\n",
      "  to explanation: 5.0431\n",
      "  to help: 4.6376\n",
      "  to help users: 5.0431\n",
      "  understand: 4.6376\n",
      "  understand the: 5.0431\n",
      "  understand the decisions: 5.0431\n",
      "  users: 7.8889\n",
      "  users of: 4.6376\n",
      "  users of aipowered: 5.0431\n",
      "  users perform: 5.0431\n",
      "  users perform more: 5.0431\n",
      "  where: 3.2513\n",
      "  where even: 5.0431\n",
      "  where even its: 5.0431\n",
      "  which: 2.6917\n",
      "  which humans: 5.0431\n",
      "  which humans can: 5.0431\n",
      "  why: 5.0431\n",
      "  why an: 5.0431\n",
      "  why an ai: 5.0431\n",
      "  with: 2.0726\n",
      "  with the: 3.5390\n",
      "  with the black: 5.0431\n",
      "  xai: 15.1292\n",
      "  xai may: 5.0431\n",
      "  xai may be: 5.0431\n",
      "  xai or: 5.0431\n",
      "  xai or interpretable: 5.0431\n",
      "  xai promises: 5.0431\n",
      "  xai promises to: 5.0431\n",
      "  xml: 5.0431\n",
      "  xml is: 5.0431\n",
      "  xml is artificial: 5.0431\n",
      "\n",
      "Document 93:\n",
      "  a: 2.5177\n",
      "  a bad: 5.0431\n",
      "  a bad overly: 5.0431\n",
      "  a theory: 4.6376\n",
      "  a theory in: 5.0431\n",
      "  accordance: 10.0861\n",
      "  accordance with: 10.0861\n",
      "  accordance with how: 10.0861\n",
      "  all: 3.5390\n",
      "  all the: 5.0431\n",
      "  all the past: 5.0431\n",
      "  as: 1.8444\n",
      "  as overfitting: 5.0431\n",
      "  as overfitting many: 5.0431\n",
      "  attempt: 4.3499\n",
      "  attempt to: 4.3499\n",
      "  attempt to reduce: 5.0431\n",
      "  bad: 5.0431\n",
      "  bad overly: 5.0431\n",
      "  bad overly complex: 5.0431\n",
      "  but: 3.0281\n",
      "  but penalising: 5.0431\n",
      "  but penalising the: 5.0431\n",
      "  by: 1.9076\n",
      "  by rewarding: 5.0431\n",
      "  by rewarding a: 5.0431\n",
      "  complex: 9.2752\n",
      "  complex the: 5.0431\n",
      "  complex the theory: 5.0431\n",
      "  complex theory: 5.0431\n",
      "  complex theory gerrymandered: 5.0431\n",
      "  data: 3.7300\n",
      "  data but: 4.6376\n",
      "  data but penalising: 5.0431\n",
      "  data is: 4.6376\n",
      "  data is known: 5.0431\n",
      "  fit: 4.1268\n",
      "  fit all: 5.0431\n",
      "  fit all the: 5.0431\n",
      "  fits: 5.0431\n",
      "  fits the: 5.0431\n",
      "  fits the data: 5.0431\n",
      "  gerrymandered: 5.0431\n",
      "  gerrymandered to: 5.0431\n",
      "  gerrymandered to fit: 5.0431\n",
      "  how: 7.0779\n",
      "  how complex: 5.0431\n",
      "  how complex the: 5.0431\n",
      "  how well: 5.0431\n",
      "  how well it: 5.0431\n",
      "  in: 2.6835\n",
      "  in accordance: 10.0861\n",
      "  in accordance with: 10.0861\n",
      "  is: 3.0334\n",
      "  is known: 4.6376\n",
      "  is known as: 4.6376\n",
      "  it: 2.2705\n",
      "  it fits: 5.0431\n",
      "  it fits the: 5.0431\n",
      "  known: 3.5390\n",
      "  known as: 3.7903\n",
      "  known as overfitting: 5.0431\n",
      "  many: 2.9030\n",
      "  many systems: 5.0431\n",
      "  many systems attempt: 5.0431\n",
      "  on: 2.0473\n",
      "  on a: 3.5390\n",
      "  on a bad: 5.0431\n",
      "  overfitting: 7.5806\n",
      "  overfitting by: 4.6376\n",
      "  overfitting by rewarding: 5.0431\n",
      "  overfitting many: 5.0431\n",
      "  overfitting many systems: 5.0431\n",
      "  overly: 5.0431\n",
      "  overly complex: 5.0431\n",
      "  overly complex theory: 5.0431\n",
      "  past: 5.0431\n",
      "  past training: 5.0431\n",
      "  past training data: 5.0431\n",
      "  penalising: 5.0431\n",
      "  penalising the: 5.0431\n",
      "  penalising the theory: 5.0431\n",
      "  reduce: 4.1268\n",
      "  reduce overfitting: 5.0431\n",
      "  reduce overfitting by: 5.0431\n",
      "  rewarding: 5.0431\n",
      "  rewarding a: 5.0431\n",
      "  rewarding a theory: 5.0431\n",
      "  settling: 5.0431\n",
      "  settling on: 5.0431\n",
      "  settling on a: 5.0431\n",
      "  systems: 2.6917\n",
      "  systems attempt: 5.0431\n",
      "  systems attempt to: 5.0431\n",
      "  the: 4.7716\n",
      "  the data: 3.0971\n",
      "  the data but: 5.0431\n",
      "  the past: 5.0431\n",
      "  the past training: 5.0431\n",
      "  the theory: 9.2752\n",
      "  the theory in: 5.0431\n",
      "  the theory is: 5.0431\n",
      "  theory: 13.3532\n",
      "  theory gerrymandered: 5.0431\n",
      "  theory gerrymandered to: 5.0431\n",
      "  theory in: 10.0861\n",
      "  theory in accordance: 10.0861\n",
      "  theory is: 4.6376\n",
      "  to: 2.4507\n",
      "  to fit: 4.6376\n",
      "  to fit all: 5.0431\n",
      "  to reduce: 4.1268\n",
      "  to reduce overfitting: 5.0431\n",
      "  training: 2.5581\n",
      "  training data: 3.7903\n",
      "  training data is: 4.6376\n",
      "  well: 3.9444\n",
      "  well it: 5.0431\n",
      "  well it fits: 5.0431\n",
      "  with: 4.1453\n",
      "  with how: 9.2752\n",
      "  with how complex: 5.0431\n",
      "  with how well: 5.0431\n",
      "\n",
      "Document 94:\n",
      "  a: 3.7766\n",
      "  a legitimate: 5.0431\n",
      "  a legitimate image: 5.0431\n",
      "  a realworld: 5.0431\n",
      "  a realworld example: 5.0431\n",
      "  a toy: 5.0431\n",
      "  a toy example: 5.0431\n",
      "  adversarial: 4.6376\n",
      "  adversarial images: 5.0431\n",
      "  adversarial images that: 5.0431\n",
      "  all: 3.5390\n",
      "  all brown: 5.0431\n",
      "  all brown patches: 5.0431\n",
      "  also: 2.6452\n",
      "  also disappoint: 5.0431\n",
      "  also disappoint by: 5.0431\n",
      "  an: 2.1527\n",
      "  an image: 4.6376\n",
      "  an image classifier: 5.0431\n",
      "  and: 2.4288\n",
      "  and black: 5.0431\n",
      "  and black cats: 5.0431\n",
      "  and they: 4.6376\n",
      "  and they learn: 5.0431\n",
      "  are: 3.9500\n",
      "  are likely: 4.6376\n",
      "  are likely to: 4.6376\n",
      "  are oblivious: 5.0431\n",
      "  are oblivious to: 5.0431\n",
      "  be: 2.0726\n",
      "  be horses: 5.0431\n",
      "  be horses a: 5.0431\n",
      "  between: 5.9272\n",
      "  between components: 5.0431\n",
      "  between components of: 5.0431\n",
      "  between pixels: 5.0431\n",
      "  between pixels that: 5.0431\n",
      "  black: 4.1268\n",
      "  black cats: 5.0431\n",
      "  black cats might: 5.0431\n",
      "  brown: 10.0861\n",
      "  brown horses: 5.0431\n",
      "  brown horses and: 5.0431\n",
      "  brown patches: 5.0431\n",
      "  brown patches are: 5.0431\n",
      "  but: 3.0281\n",
      "  but that: 5.0431\n",
      "  but that still: 5.0431\n",
      "  by: 1.9076\n",
      "  by learning: 5.0431\n",
      "  by learning the: 5.0431\n",
      "  can: 4.3617\n",
      "  can also: 4.6376\n",
      "  can also disappoint: 5.0431\n",
      "  can result: 4.6376\n",
      "  can result in: 4.6376\n",
      "  cats: 5.0431\n",
      "  cats might: 5.0431\n",
      "  cats might conclude: 5.0431\n",
      "  certain: 4.1268\n",
      "  certain types: 5.0431\n",
      "  certain types of: 5.0431\n",
      "  classifier: 3.7903\n",
      "  classifier trained: 5.0431\n",
      "  classifier trained only: 5.0431\n",
      "  classifiers: 5.0431\n",
      "  classifiers often: 5.0431\n",
      "  classifiers often do: 5.0431\n",
      "  components: 5.0431\n",
      "  components of: 5.0431\n",
      "  components of the: 5.0431\n",
      "  conclude: 5.0431\n",
      "  conclude that: 5.0431\n",
      "  conclude that all: 5.0431\n",
      "  correlate: 5.0431\n",
      "  correlate with: 5.0431\n",
      "  correlate with images: 5.0431\n",
      "  current: 4.3499\n",
      "  current image: 5.0431\n",
      "  current image classifiers: 5.0431\n",
      "  disappoint: 5.0431\n",
      "  disappoint by: 5.0431\n",
      "  disappoint by learning: 5.0431\n",
      "  do: 3.6568\n",
      "  do not: 4.3499\n",
      "  do not primarily: 5.0431\n",
      "  example: 5.9272\n",
      "  example is: 8.6998\n",
      "  example is that: 10.0861\n",
      "  from: 2.0726\n",
      "  from the: 3.3383\n",
      "  from the spatial: 5.0431\n",
      "  horses: 10.0861\n",
      "  horses a: 5.0431\n",
      "  horses a realworld: 5.0431\n",
      "  horses and: 5.0431\n",
      "  horses and black: 5.0431\n",
      "  humans: 9.2752\n",
      "  humans are: 5.0431\n",
      "  humans are oblivious: 5.0431\n",
      "  humans current: 5.0431\n",
      "  humans current image: 5.0431\n",
      "  image: 11.8333\n",
      "  image can: 5.0431\n",
      "  image can result: 5.0431\n",
      "  image classifier: 5.0431\n",
      "  image classifier trained: 5.0431\n",
      "  image classifiers: 5.0431\n",
      "  image classifiers often: 5.0431\n",
      "  images: 8.2535\n",
      "  images of: 5.0431\n",
      "  images of certain: 5.0431\n",
      "  images that: 5.0431\n",
      "  images that the: 5.0431\n",
      "  in: 1.3417\n",
      "  in adversarial: 5.0431\n",
      "  in adversarial images: 5.0431\n",
      "  is: 3.0334\n",
      "  is that: 9.2752\n",
      "  is that an: 5.0431\n",
      "  is that unlike: 5.0431\n",
      "  judgements: 5.0431\n",
      "  judgements from: 5.0431\n",
      "  judgements from the: 5.0431\n",
      "  learn: 3.3383\n",
      "  learn relationships: 5.0431\n",
      "  learn relationships between: 5.0431\n",
      "  learners: 4.6376\n",
      "  learners can: 5.0431\n",
      "  learners can also: 5.0431\n",
      "  learning: 1.2819\n",
      "  learning the: 4.3499\n",
      "  learning the wrong: 5.0431\n",
      "  legitimate: 5.0431\n",
      "  legitimate image: 5.0431\n",
      "  legitimate image can: 5.0431\n",
      "  lesson: 5.0431\n",
      "  lesson a: 5.0431\n",
      "  lesson a toy: 5.0431\n",
      "  likely: 4.3499\n",
      "  likely to: 4.3499\n",
      "  likely to be: 5.0431\n",
      "  make: 3.3383\n",
      "  make judgements: 5.0431\n",
      "  make judgements from: 5.0431\n",
      "  might: 4.6376\n",
      "  might conclude: 5.0431\n",
      "  might conclude that: 5.0431\n",
      "  misclassifies: 5.0431\n",
      "  modifying: 5.0431\n",
      "  modifying these: 5.0431\n",
      "  modifying these patterns: 5.0431\n",
      "  not: 2.6007\n",
      "  not primarily: 5.0431\n",
      "  not primarily make: 5.0431\n",
      "  objects: 4.3499\n",
      "  objects modifying: 5.0431\n",
      "  objects modifying these: 5.0431\n",
      "  oblivious: 5.0431\n",
      "  oblivious to: 5.0431\n",
      "  oblivious to but: 5.0431\n",
      "  of: 4.8576\n",
      "  of brown: 5.0431\n",
      "  of brown horses: 5.0431\n",
      "  of certain: 5.0431\n",
      "  of certain types: 5.0431\n",
      "  of real: 5.0431\n",
      "  of real objects: 5.0431\n",
      "  of the: 2.3022\n",
      "  of the picture: 5.0431\n",
      "  often: 3.0971\n",
      "  often do: 5.0431\n",
      "  often do not: 5.0431\n",
      "  on: 4.0946\n",
      "  on a: 3.5390\n",
      "  on a legitimate: 5.0431\n",
      "  on pictures: 5.0431\n",
      "  on pictures of: 5.0431\n",
      "  only: 3.6568\n",
      "  only on: 5.0431\n",
      "  only on pictures: 5.0431\n",
      "  patches: 5.0431\n",
      "  patches are: 5.0431\n",
      "  patches are likely: 5.0431\n",
      "  patterns: 3.4336\n",
      "  patterns on: 5.0431\n",
      "  patterns on a: 5.0431\n",
      "  picture: 5.0431\n",
      "  picture and: 5.0431\n",
      "  picture and they: 5.0431\n",
      "  pictures: 5.0431\n",
      "  pictures of: 5.0431\n",
      "  pictures of brown: 5.0431\n",
      "  pixels: 5.0431\n",
      "  pixels that: 5.0431\n",
      "  pixels that humans: 5.0431\n",
      "  primarily: 5.0431\n",
      "  primarily make: 5.0431\n",
      "  primarily make judgements: 5.0431\n",
      "  real: 4.3499\n",
      "  real objects: 5.0431\n",
      "  real objects modifying: 5.0431\n",
      "  realworld: 4.6376\n",
      "  realworld example: 5.0431\n",
      "  realworld example is: 5.0431\n",
      "  relationship: 4.6376\n",
      "  relationship between: 4.6376\n",
      "  relationship between components: 5.0431\n",
      "  relationships: 4.1268\n",
      "  relationships between: 4.1268\n",
      "  relationships between pixels: 5.0431\n",
      "  result: 4.3499\n",
      "  result in: 4.3499\n",
      "  result in adversarial: 5.0431\n",
      "  spatial: 5.0431\n",
      "  spatial relationship: 5.0431\n",
      "  spatial relationship between: 5.0431\n",
      "  still: 4.6376\n",
      "  still correlate: 5.0431\n",
      "  still correlate with: 5.0431\n",
      "  system: 3.0281\n",
      "  system misclassifies: 5.0431\n",
      "  that: 10.0545\n",
      "  that all: 5.0431\n",
      "  that all brown: 5.0431\n",
      "  that an: 4.3499\n",
      "  that an image: 5.0431\n",
      "  that humans: 5.0431\n",
      "  that humans are: 5.0431\n",
      "  that still: 5.0431\n",
      "  that still correlate: 5.0431\n",
      "  that the: 3.9444\n",
      "  that the system: 5.0431\n",
      "  that unlike: 5.0431\n",
      "  that unlike humans: 5.0431\n",
      "  the: 4.7716\n",
      "  the picture: 5.0431\n",
      "  the picture and: 5.0431\n",
      "  the spatial: 5.0431\n",
      "  the spatial relationship: 5.0431\n",
      "  the system: 4.3499\n",
      "  the system misclassifies: 5.0431\n",
      "  the wrong: 5.0431\n",
      "  the wrong lesson: 5.0431\n",
      "  these: 2.9030\n",
      "  these patterns: 4.6376\n",
      "  these patterns on: 5.0431\n",
      "  they: 3.4336\n",
      "  they learn: 5.0431\n",
      "  they learn relationships: 5.0431\n",
      "  to: 2.4507\n",
      "  to be: 3.4336\n",
      "  to be horses: 5.0431\n",
      "  to but: 5.0431\n",
      "  to but that: 5.0431\n",
      "  toy: 5.0431\n",
      "  toy example: 5.0431\n",
      "  toy example is: 5.0431\n",
      "  trained: 3.3383\n",
      "  trained only: 5.0431\n",
      "  trained only on: 5.0431\n",
      "  types: 4.3499\n",
      "  types of: 4.3499\n",
      "  types of real: 5.0431\n",
      "  unlike: 4.6376\n",
      "  unlike humans: 5.0431\n",
      "  unlike humans current: 5.0431\n",
      "  with: 2.0726\n",
      "  with images: 5.0431\n",
      "  with images of: 5.0431\n",
      "  wrong: 4.6376\n",
      "  wrong lesson: 5.0431\n",
      "  wrong lesson a: 5.0431\n",
      "\n",
      "Document 95:\n",
      "  a: 1.2589\n",
      "  a single: 4.6376\n",
      "  a single adversarially: 5.0431\n",
      "  adversarial: 9.2752\n",
      "  adversarial machine: 5.0431\n",
      "  adversarial machine learning: 5.0431\n",
      "  adversarial vulnerabilities: 5.0431\n",
      "  adversarial vulnerabilities can: 5.0431\n",
      "  adversarially: 5.0431\n",
      "  adversarially chosen: 5.0431\n",
      "  adversarially chosen pixel: 5.0431\n",
      "  also: 2.6452\n",
      "  also result: 5.0431\n",
      "  also result in: 5.0431\n",
      "  are: 1.9750\n",
      "  are often: 4.1268\n",
      "  are often vulnerable: 5.0431\n",
      "  by: 1.9076\n",
      "  by only: 5.0431\n",
      "  by only changing: 5.0431\n",
      "  can: 2.1809\n",
      "  can also: 4.6376\n",
      "  can also result: 5.0431\n",
      "  change: 4.6376\n",
      "  change the: 4.6376\n",
      "  change the output: 5.0431\n",
      "  changing: 4.6376\n",
      "  changing a: 5.0431\n",
      "  changing a single: 5.0431\n",
      "  chosen: 4.6376\n",
      "  chosen pixel: 5.0431\n",
      "  chosen pixel machine: 5.0431\n",
      "  evasion: 5.0431\n",
      "  evasion via: 5.0431\n",
      "  evasion via adversarial: 5.0431\n",
      "  for: 1.7289\n",
      "  for some: 5.0431\n",
      "  for some systems: 5.0431\n",
      "  from: 2.0726\n",
      "  from nonpattern: 5.0431\n",
      "  from nonpattern perturbations: 5.0431\n",
      "  in: 1.3417\n",
      "  in nonlinear: 5.0431\n",
      "  in nonlinear systems: 5.0431\n",
      "  is: 1.5167\n",
      "  is possible: 5.0431\n",
      "  is possible to: 5.0431\n",
      "  it: 2.2705\n",
      "  it is: 3.5390\n",
      "  it is possible: 5.0431\n",
      "  learning: 2.5637\n",
      "  learning models: 3.7903\n",
      "  learning models are: 5.0431\n",
      "  machine: 2.9470\n",
      "  machine learning: 3.1236\n",
      "  machine learning models: 3.7903\n",
      "  manipulation: 5.0431\n",
      "  manipulation or: 5.0431\n",
      "  manipulation or evasion: 5.0431\n",
      "  models: 2.5581\n",
      "  models are: 4.1268\n",
      "  models are often: 5.0431\n",
      "  nonlinear: 3.9444\n",
      "  nonlinear systems: 5.0431\n",
      "  nonlinear systems or: 5.0431\n",
      "  nonpattern: 5.0431\n",
      "  nonpattern perturbations: 5.0431\n",
      "  nonpattern perturbations for: 5.0431\n",
      "  often: 3.0971\n",
      "  often vulnerable: 5.0431\n",
      "  often vulnerable to: 5.0431\n",
      "  only: 3.6568\n",
      "  only changing: 5.0431\n",
      "  only changing a: 5.0431\n",
      "  or: 4.0453\n",
      "  or evasion: 5.0431\n",
      "  or evasion via: 5.0431\n",
      "  or from: 5.0431\n",
      "  or from nonpattern: 5.0431\n",
      "  output: 3.3383\n",
      "  output by: 5.0431\n",
      "  output by only: 5.0431\n",
      "  perturbations: 5.0431\n",
      "  perturbations for: 5.0431\n",
      "  perturbations for some: 5.0431\n",
      "  pixel: 5.0431\n",
      "  pixel machine: 5.0431\n",
      "  pixel machine learning: 5.0431\n",
      "  possible: 4.6376\n",
      "  possible to: 5.0431\n",
      "  possible to change: 5.0431\n",
      "  result: 4.3499\n",
      "  result in: 4.3499\n",
      "  result in nonlinear: 5.0431\n",
      "  single: 4.1268\n",
      "  single adversarially: 5.0431\n",
      "  single adversarially chosen: 5.0431\n",
      "  some: 2.9636\n",
      "  some systems: 5.0431\n",
      "  some systems it: 5.0431\n",
      "  systems: 5.3834\n",
      "  systems it: 5.0431\n",
      "  systems it is: 5.0431\n",
      "  systems or: 5.0431\n",
      "  systems or from: 5.0431\n",
      "  the: 1.1929\n",
      "  the output: 3.9444\n",
      "  the output by: 5.0431\n",
      "  to: 2.4507\n",
      "  to change: 5.0431\n",
      "  to change the: 5.0431\n",
      "  to manipulation: 5.0431\n",
      "  to manipulation or: 5.0431\n",
      "  via: 4.3499\n",
      "  via adversarial: 5.0431\n",
      "  via adversarial machine: 5.0431\n",
      "  vulnerabilities: 5.0431\n",
      "  vulnerabilities can: 5.0431\n",
      "  vulnerabilities can also: 5.0431\n",
      "  vulnerable: 5.0431\n",
      "  vulnerable to: 5.0431\n",
      "  vulnerable to manipulation: 5.0431\n",
      "\n",
      "Document 96:\n",
      "  a: 1.2589\n",
      "  a type: 4.6376\n",
      "  a type of: 4.6376\n",
      "  access: 4.6376\n",
      "  and: 1.2144\n",
      "  and wellvisible: 5.0431\n",
      "  and wellvisible not: 5.0431\n",
      "  any: 3.6568\n",
      "  any input: 5.0431\n",
      "  any input including: 5.0431\n",
      "  are: 1.9750\n",
      "  are often: 4.1268\n",
      "  are often developed: 5.0431\n",
      "  backdoors: 5.0431\n",
      "  backdoors can: 5.0431\n",
      "  backdoors can be: 5.0431\n",
      "  be: 2.0726\n",
      "  be placed: 5.0431\n",
      "  be placed undetectably: 5.0431\n",
      "  by: 1.9076\n",
      "  by third: 5.0431\n",
      "  by third parties: 5.0431\n",
      "  can: 4.3617\n",
      "  can be: 2.7405\n",
      "  can be placed: 5.0431\n",
      "  can change: 5.0431\n",
      "  can change the: 5.0431\n",
      "  cases: 4.6376\n",
      "  cases for: 5.0431\n",
      "  cases for which: 5.0431\n",
      "  categories: 4.1268\n",
      "  categories spam: 5.0431\n",
      "  categories spam and: 5.0431\n",
      "  change: 4.6376\n",
      "  change the: 4.6376\n",
      "  change the classification: 5.0431\n",
      "  classification: 2.9636\n",
      "  classification of: 4.6376\n",
      "  classification of any: 5.0431\n",
      "  classifying: 4.6376\n",
      "  classifying eg: 5.0431\n",
      "  classifying eg for: 5.0431\n",
      "  datasoftware: 5.0431\n",
      "  datasoftware transparency: 5.0431\n",
      "  datasoftware transparency is: 5.0431\n",
      "  demonstrated: 5.0431\n",
      "  demonstrated how: 5.0431\n",
      "  demonstrated how backdoors: 5.0431\n",
      "  developed: 3.7903\n",
      "  developed or: 5.0431\n",
      "  developed or trained: 5.0431\n",
      "  eg: 3.9444\n",
      "  eg for: 5.0431\n",
      "  eg for categories: 5.0431\n",
      "  for: 3.4577\n",
      "  for categories: 5.0431\n",
      "  for categories spam: 5.0431\n",
      "  for which: 5.0431\n",
      "  for which a: 5.0431\n",
      "  have: 2.4781\n",
      "  have demonstrated: 5.0431\n",
      "  have demonstrated how: 5.0431\n",
      "  how: 3.5390\n",
      "  how backdoors: 5.0431\n",
      "  how backdoors can: 5.0431\n",
      "  in: 1.3417\n",
      "  in cases: 5.0431\n",
      "  in cases for: 5.0431\n",
      "  including: 6.8672\n",
      "  including in: 5.0431\n",
      "  including in cases: 5.0431\n",
      "  including whitebox: 5.0431\n",
      "  including whitebox access: 5.0431\n",
      "  input: 3.0281\n",
      "  input including: 5.0431\n",
      "  input including in: 5.0431\n",
      "  into: 2.9636\n",
      "  into classifying: 5.0431\n",
      "  into classifying eg: 5.0431\n",
      "  is: 1.5167\n",
      "  is provided: 5.0431\n",
      "  is provided possibly: 5.0431\n",
      "  learning: 1.2819\n",
      "  learning models: 3.7903\n",
      "  learning models that: 4.6376\n",
      "  machine: 1.4735\n",
      "  machine learning: 1.5618\n",
      "  machine learning models: 3.7903\n",
      "  models: 2.5581\n",
      "  models that: 4.3499\n",
      "  models that are: 5.0431\n",
      "  not: 2.6007\n",
      "  not spam: 5.0431\n",
      "  not spam of: 5.0431\n",
      "  of: 3.6432\n",
      "  of any: 5.0431\n",
      "  of any input: 5.0431\n",
      "  of datasoftware: 5.0431\n",
      "  of datasoftware transparency: 5.0431\n",
      "  of posts: 5.0431\n",
      "  of posts machine: 5.0431\n",
      "  often: 3.0971\n",
      "  often developed: 5.0431\n",
      "  often developed or: 5.0431\n",
      "  or: 2.0226\n",
      "  or trained: 5.0431\n",
      "  or trained by: 5.0431\n",
      "  parties: 10.0861\n",
      "  parties can: 5.0431\n",
      "  parties can change: 5.0431\n",
      "  parties parties: 5.0431\n",
      "  parties parties can: 5.0431\n",
      "  placed: 5.0431\n",
      "  placed undetectably: 5.0431\n",
      "  placed undetectably into: 5.0431\n",
      "  possibly: 4.6376\n",
      "  possibly including: 5.0431\n",
      "  possibly including whitebox: 5.0431\n",
      "  posts: 5.0431\n",
      "  posts machine: 5.0431\n",
      "  posts machine learning: 5.0431\n",
      "  provided: 4.1268\n",
      "  provided possibly: 5.0431\n",
      "  provided possibly including: 5.0431\n",
      "  researchers: 3.6568\n",
      "  researchers have: 4.6376\n",
      "  researchers have demonstrated: 5.0431\n",
      "  spam: 10.0861\n",
      "  spam and: 5.0431\n",
      "  spam and wellvisible: 5.0431\n",
      "  spam of: 5.0431\n",
      "  spam of posts: 5.0431\n",
      "  that: 1.6758\n",
      "  that are: 3.7903\n",
      "  that are often: 5.0431\n",
      "  the: 1.1929\n",
      "  the classification: 5.0431\n",
      "  the classification of: 5.0431\n",
      "  third: 5.0431\n",
      "  third parties: 5.0431\n",
      "  third parties parties: 5.0431\n",
      "  trained: 3.3383\n",
      "  trained by: 4.6376\n",
      "  trained by third: 5.0431\n",
      "  transparency: 5.0431\n",
      "  transparency is: 5.0431\n",
      "  transparency is provided: 5.0431\n",
      "  type: 4.1268\n",
      "  type of: 4.1268\n",
      "  type of datasoftware: 5.0431\n",
      "  undetectably: 5.0431\n",
      "  undetectably into: 5.0431\n",
      "  undetectably into classifying: 5.0431\n",
      "  wellvisible: 5.0431\n",
      "  wellvisible not: 5.0431\n",
      "  wellvisible not spam: 5.0431\n",
      "  which: 2.6917\n",
      "  which a: 4.6376\n",
      "  which a type: 5.0431\n",
      "  whitebox: 5.0431\n",
      "  whitebox access: 5.0431\n",
      "\n",
      "Document 97:\n",
      "  a: 1.2589\n",
      "  a training: 4.3499\n",
      "  a training and: 5.0431\n",
      "  accuracy: 7.3135\n",
      "  accuracy estimation: 5.0431\n",
      "  accuracy estimation techniques: 5.0431\n",
      "  addition: 3.7903\n",
      "  addition to: 3.9444\n",
      "  addition to the: 5.0431\n",
      "  and: 7.2865\n",
      "  and crossvalidation: 5.0431\n",
      "  and crossvalidation methods: 5.0431\n",
      "  and evaluates: 5.0431\n",
      "  and evaluates the: 5.0431\n",
      "  and test: 10.0861\n",
      "  and test set: 10.0861\n",
      "  and the: 3.3383\n",
      "  and the remaining: 5.0431\n",
      "  and then: 4.3499\n",
      "  and then k: 5.0431\n",
      "  are: 1.9750\n",
      "  are performed: 5.0431\n",
      "  are performed each: 5.0431\n",
      "  assess: 5.0431\n",
      "  assess model: 5.0431\n",
      "  assess model accuracy: 5.0431\n",
      "  be: 4.1453\n",
      "  be used: 3.4336\n",
      "  be used to: 3.9444\n",
      "  be validated: 5.0431\n",
      "  be validated by: 5.0431\n",
      "  bootstrap: 5.0431\n",
      "  bootstrap which: 5.0431\n",
      "  bootstrap which samples: 5.0431\n",
      "  by: 1.9076\n",
      "  by accuracy: 5.0431\n",
      "  by accuracy estimation: 5.0431\n",
      "  can: 4.3617\n",
      "  can be: 5.4809\n",
      "  can be used: 3.6568\n",
      "  can be validated: 5.0431\n",
      "  classification: 2.9636\n",
      "  classification of: 4.6376\n",
      "  classification of machine: 5.0431\n",
      "  comparison: 5.0431\n",
      "  comparison the: 5.0431\n",
      "  comparison the kfoldcrossvalidation: 5.0431\n",
      "  considering: 4.6376\n",
      "  considering subset: 5.0431\n",
      "  considering subset for: 5.0431\n",
      "  conventionally: 5.0431\n",
      "  conventionally training: 5.0431\n",
      "  conventionally training set: 5.0431\n",
      "  crossvalidation: 5.0431\n",
      "  crossvalidation methods: 5.0431\n",
      "  crossvalidation methods bootstrap: 5.0431\n",
      "  data: 3.7300\n",
      "  data in: 5.0431\n",
      "  data in a: 5.0431\n",
      "  data into: 5.0431\n",
      "  data into k: 5.0431\n",
      "  dataset: 4.3499\n",
      "  dataset can: 4.6376\n",
      "  dataset can be: 4.6376\n",
      "  designation: 5.0431\n",
      "  designation and: 5.0431\n",
      "  designation and evaluates: 5.0431\n",
      "  each: 3.0971\n",
      "  each respectively: 5.0431\n",
      "  each respectively considering: 5.0431\n",
      "  estimation: 4.6376\n",
      "  estimation techniques: 5.0431\n",
      "  estimation techniques like: 5.0431\n",
      "  evaluates: 5.0431\n",
      "  evaluates the: 5.0431\n",
      "  evaluates the performance: 5.0431\n",
      "  evaluation: 4.3499\n",
      "  evaluation and: 5.0431\n",
      "  evaluation and the: 5.0431\n",
      "  experiments: 5.0431\n",
      "  experiments are: 5.0431\n",
      "  experiments are performed: 5.0431\n",
      "  for: 3.4577\n",
      "  for evaluation: 5.0431\n",
      "  for evaluation and: 5.0431\n",
      "  for training: 4.1268\n",
      "  for training the: 5.0431\n",
      "  from: 2.0726\n",
      "  from the: 3.3383\n",
      "  from the dataset: 5.0431\n",
      "  holdout: 10.0861\n",
      "  holdout and: 5.0431\n",
      "  holdout and crossvalidation: 5.0431\n",
      "  holdout method: 5.0431\n",
      "  holdout method which: 5.0431\n",
      "  in: 4.0252\n",
      "  in a: 3.0971\n",
      "  in a training: 5.0431\n",
      "  in addition: 3.7903\n",
      "  in addition to: 3.9444\n",
      "  in comparison: 5.0431\n",
      "  in comparison the: 5.0431\n",
      "  instances: 4.3499\n",
      "  instances with: 5.0431\n",
      "  instances with replacement: 5.0431\n",
      "  into: 2.9636\n",
      "  into k: 5.0431\n",
      "  into k subsets: 5.0431\n",
      "  k: 13.9128\n",
      "  k experiments: 5.0431\n",
      "  k experiments are: 5.0431\n",
      "  k subsets: 10.0861\n",
      "  k subsets and: 5.0431\n",
      "  k subsets for: 5.0431\n",
      "  kfoldcrossvalidation: 5.0431\n",
      "  kfoldcrossvalidation method: 5.0431\n",
      "  kfoldcrossvalidation method randomly: 5.0431\n",
      "  learning: 1.2819\n",
      "  learning models: 3.7903\n",
      "  learning models can: 5.0431\n",
      "  like: 3.3383\n",
      "  like the: 4.3499\n",
      "  like the holdout: 5.0431\n",
      "  machine: 1.4735\n",
      "  machine learning: 1.5618\n",
      "  machine learning models: 3.7903\n",
      "  method: 7.3135\n",
      "  method randomly: 5.0431\n",
      "  method randomly partitions: 5.0431\n",
      "  method which: 5.0431\n",
      "  method which splits: 5.0431\n",
      "  methods: 2.7405\n",
      "  methods bootstrap: 5.0431\n",
      "  methods bootstrap which: 5.0431\n",
      "  model: 7.0050\n",
      "  model accuracy: 5.0431\n",
      "  model in: 5.0431\n",
      "  model in addition: 5.0431\n",
      "  model on: 5.0431\n",
      "  model on the: 5.0431\n",
      "  models: 2.5581\n",
      "  models can: 5.0431\n",
      "  models can be: 5.0431\n",
      "  n: 5.0431\n",
      "  n instances: 5.0431\n",
      "  n instances with: 5.0431\n",
      "  of: 2.4288\n",
      "  of machine: 3.0281\n",
      "  of machine learning: 3.0281\n",
      "  of the: 2.3022\n",
      "  of the training: 4.3499\n",
      "  on: 2.0473\n",
      "  on the: 3.2513\n",
      "  on the test: 5.0431\n",
      "  partitions: 5.0431\n",
      "  partitions the: 5.0431\n",
      "  partitions the data: 5.0431\n",
      "  performance: 3.4336\n",
      "  performance of: 4.3499\n",
      "  performance of the: 5.0431\n",
      "  performed: 5.0431\n",
      "  performed each: 5.0431\n",
      "  performed each respectively: 5.0431\n",
      "  randomly: 5.0431\n",
      "  randomly partitions: 5.0431\n",
      "  randomly partitions the: 5.0431\n",
      "  remaining: 5.0431\n",
      "  remaining k: 5.0431\n",
      "  remaining k subsets: 5.0431\n",
      "  replacement: 4.6376\n",
      "  replacement from: 5.0431\n",
      "  replacement from the: 5.0431\n",
      "  respectively: 4.6376\n",
      "  respectively considering: 5.0431\n",
      "  respectively considering subset: 5.0431\n",
      "  samples: 4.6376\n",
      "  samples n: 5.0431\n",
      "  samples n instances: 5.0431\n",
      "  set: 10.4028\n",
      "  set and: 4.6376\n",
      "  set and test: 5.0431\n",
      "  set conventionally: 5.0431\n",
      "  set conventionally training: 5.0431\n",
      "  set designation: 5.0431\n",
      "  set designation and: 5.0431\n",
      "  set in: 4.6376\n",
      "  set in comparison: 5.0431\n",
      "  splits: 5.0431\n",
      "  splits the: 5.0431\n",
      "  splits the data: 5.0431\n",
      "  subset: 5.0431\n",
      "  subset for: 5.0431\n",
      "  subset for evaluation: 5.0431\n",
      "  subsets: 9.2752\n",
      "  subsets and: 5.0431\n",
      "  subsets and then: 5.0431\n",
      "  subsets for: 5.0431\n",
      "  subsets for training: 5.0431\n",
      "  techniques: 3.3383\n",
      "  techniques like: 4.6376\n",
      "  techniques like the: 5.0431\n",
      "  test: 13.9128\n",
      "  test set: 15.1292\n",
      "  test set conventionally: 5.0431\n",
      "  test set designation: 5.0431\n",
      "  test set in: 5.0431\n",
      "  the: 13.1219\n",
      "  the data: 6.1943\n",
      "  the data in: 5.0431\n",
      "  the data into: 5.0431\n",
      "  the dataset: 5.0431\n",
      "  the dataset can: 5.0431\n",
      "  the holdout: 10.0861\n",
      "  the holdout and: 5.0431\n",
      "  the holdout method: 5.0431\n",
      "  the kfoldcrossvalidation: 5.0431\n",
      "  the kfoldcrossvalidation method: 5.0431\n",
      "  the model: 3.9444\n",
      "  the model in: 5.0431\n",
      "  the performance: 4.3499\n",
      "  the performance of: 4.3499\n",
      "  the remaining: 5.0431\n",
      "  the remaining k: 5.0431\n",
      "  the test: 5.0431\n",
      "  the test set: 5.0431\n",
      "  the training: 3.3383\n",
      "  the training model: 5.0431\n",
      "  then: 3.9444\n",
      "  then k: 5.0431\n",
      "  then k experiments: 5.0431\n",
      "  to: 2.4507\n",
      "  to assess: 5.0431\n",
      "  to assess model: 5.0431\n",
      "  to the: 3.1712\n",
      "  to the holdout: 5.0431\n",
      "  training: 10.2326\n",
      "  training and: 4.6376\n",
      "  training and test: 5.0431\n",
      "  training model: 5.0431\n",
      "  training model on: 5.0431\n",
      "  training set: 4.1268\n",
      "  training set and: 5.0431\n",
      "  training the: 5.0431\n",
      "  training the model: 5.0431\n",
      "  used: 2.3350\n",
      "  used to: 3.3383\n",
      "  used to assess: 5.0431\n",
      "  validated: 5.0431\n",
      "  validated by: 5.0431\n",
      "  validated by accuracy: 5.0431\n",
      "  which: 5.3834\n",
      "  which samples: 5.0431\n",
      "  which samples n: 5.0431\n",
      "  which splits: 5.0431\n",
      "  which splits the: 5.0431\n",
      "  with: 2.0726\n",
      "  with replacement: 5.0431\n",
      "  with replacement from: 5.0431\n",
      "\n",
      "Document 98:\n",
      "  a: 1.2589\n",
      "  a better: 5.0431\n",
      "  a better performing: 5.0431\n",
      "  accompanying: 5.0431\n",
      "  accompanying area: 5.0431\n",
      "  accompanying area under: 5.0431\n",
      "  accuracy: 3.6568\n",
      "  accuracy investigators: 5.0431\n",
      "  accuracy investigators frequently: 5.0431\n",
      "  addition: 3.7903\n",
      "  addition to: 3.9444\n",
      "  addition to overall: 5.0431\n",
      "  additional: 4.3499\n",
      "  additional tools: 5.0431\n",
      "  additional tools for: 5.0431\n",
      "  along: 4.3499\n",
      "  along with: 4.6376\n",
      "  along with the: 5.0431\n",
      "  and: 3.6432\n",
      "  and denominators: 5.0431\n",
      "  and denominators receiver: 5.0431\n",
      "  and specificity: 5.0431\n",
      "  and specificity meaning: 5.0431\n",
      "  and true: 5.0431\n",
      "  and true negative: 5.0431\n",
      "  are: 1.9750\n",
      "  are ratios: 5.0431\n",
      "  are ratios that: 5.0431\n",
      "  area: 3.9444\n",
      "  area under: 5.0431\n",
      "  area under the: 5.0431\n",
      "  as: 3.6888\n",
      "  as the: 4.3499\n",
      "  as the false: 5.0431\n",
      "  as well: 4.1268\n",
      "  as well as: 4.6376\n",
      "  assessment: 5.0431\n",
      "  assessment higher: 5.0431\n",
      "  assessment higher auc: 5.0431\n",
      "  associated: 3.7903\n",
      "  associated with: 4.3499\n",
      "  associated with a: 5.0431\n",
      "  auc: 10.0861\n",
      "  auc is: 5.0431\n",
      "  auc is associated: 5.0431\n",
      "  auc offer: 5.0431\n",
      "  auc offer additional: 5.0431\n",
      "  better: 4.1268\n",
      "  better performing: 5.0431\n",
      "  better performing model: 5.0431\n",
      "  characteristic: 4.6376\n",
      "  characteristic roc: 5.0431\n",
      "  characteristic roc along: 5.0431\n",
      "  classification: 2.9636\n",
      "  classification model: 5.0431\n",
      "  classification model assessment: 5.0431\n",
      "  curve: 5.0431\n",
      "  curve auc: 5.0431\n",
      "  curve auc offer: 5.0431\n",
      "  denominators: 5.0431\n",
      "  denominators receiver: 5.0431\n",
      "  denominators receiver operating: 5.0431\n",
      "  fail: 4.3499\n",
      "  fail to: 4.6376\n",
      "  fail to reveal: 5.0431\n",
      "  false: 10.0861\n",
      "  false negative: 5.0431\n",
      "  false negative rate: 5.0431\n",
      "  false positive: 5.0431\n",
      "  false positive rate: 5.0431\n",
      "  fnr: 5.0431\n",
      "  fnr however: 5.0431\n",
      "  fnr however these: 5.0431\n",
      "  for: 1.7289\n",
      "  for classification: 4.6376\n",
      "  for classification model: 5.0431\n",
      "  fpr: 5.0431\n",
      "  fpr as: 5.0431\n",
      "  fpr as well: 5.0431\n",
      "  frequently: 5.0431\n",
      "  frequently report: 5.0431\n",
      "  frequently report sensitivity: 5.0431\n",
      "  higher: 4.6376\n",
      "  higher auc: 5.0431\n",
      "  higher auc is: 5.0431\n",
      "  however: 3.7903\n",
      "  however these: 4.6376\n",
      "  however these rates: 5.0431\n",
      "  in: 1.3417\n",
      "  in addition: 3.7903\n",
      "  in addition to: 3.9444\n",
      "  investigators: 10.0861\n",
      "  investigators frequently: 5.0431\n",
      "  investigators frequently report: 5.0431\n",
      "  investigators sometimes: 5.0431\n",
      "  investigators sometimes report: 5.0431\n",
      "  is: 1.5167\n",
      "  is associated: 4.6376\n",
      "  is associated with: 4.6376\n",
      "  meaning: 4.3499\n",
      "  meaning true: 5.0431\n",
      "  meaning true positive: 5.0431\n",
      "  model: 4.6700\n",
      "  model assessment: 5.0431\n",
      "  model assessment higher: 5.0431\n",
      "  negative: 7.8889\n",
      "  negative rate: 10.0861\n",
      "  negative rate fnr: 5.0431\n",
      "  negative rate tnr: 5.0431\n",
      "  numerators: 5.0431\n",
      "  numerators and: 5.0431\n",
      "  numerators and denominators: 5.0431\n",
      "  offer: 5.0431\n",
      "  offer additional: 5.0431\n",
      "  offer additional tools: 5.0431\n",
      "  operating: 5.0431\n",
      "  operating characteristic: 5.0431\n",
      "  operating characteristic roc: 5.0431\n",
      "  overall: 4.6376\n",
      "  overall accuracy: 5.0431\n",
      "  overall accuracy investigators: 5.0431\n",
      "  performing: 3.9444\n",
      "  performing model: 5.0431\n",
      "  positive: 8.2535\n",
      "  positive rate: 10.0861\n",
      "  positive rate fpr: 5.0431\n",
      "  positive rate tpr: 5.0431\n",
      "  rate: 20.1722\n",
      "  rate fnr: 5.0431\n",
      "  rate fnr however: 5.0431\n",
      "  rate fpr: 5.0431\n",
      "  rate fpr as: 5.0431\n",
      "  rate tnr: 5.0431\n",
      "  rate tnr respectively: 5.0431\n",
      "  rate tpr: 5.0431\n",
      "  rate tpr and: 5.0431\n",
      "  rates: 4.6376\n",
      "  rates are: 5.0431\n",
      "  rates are ratios: 5.0431\n",
      "  ratios: 5.0431\n",
      "  ratios that: 5.0431\n",
      "  ratios that fail: 5.0431\n",
      "  receiver: 5.0431\n",
      "  receiver operating: 5.0431\n",
      "  receiver operating characteristic: 5.0431\n",
      "  report: 9.2752\n",
      "  report sensitivity: 5.0431\n",
      "  report sensitivity and: 5.0431\n",
      "  report the: 5.0431\n",
      "  report the false: 5.0431\n",
      "  respectively: 4.6376\n",
      "  respectively similarly: 5.0431\n",
      "  respectively similarly investigators: 5.0431\n",
      "  reveal: 5.0431\n",
      "  reveal their: 5.0431\n",
      "  reveal their numerators: 5.0431\n",
      "  roc: 10.0861\n",
      "  roc along: 5.0431\n",
      "  roc along with: 5.0431\n",
      "  roc curve: 5.0431\n",
      "  roc curve auc: 5.0431\n",
      "  sensitivity: 4.6376\n",
      "  sensitivity and: 5.0431\n",
      "  sensitivity and specificity: 5.0431\n",
      "  similarly: 5.0431\n",
      "  similarly investigators: 5.0431\n",
      "  similarly investigators sometimes: 5.0431\n",
      "  sometimes: 4.3499\n",
      "  sometimes report: 5.0431\n",
      "  sometimes report the: 5.0431\n",
      "  specificity: 4.6376\n",
      "  specificity meaning: 5.0431\n",
      "  specificity meaning true: 5.0431\n",
      "  that: 1.6758\n",
      "  that fail: 5.0431\n",
      "  that fail to: 5.0431\n",
      "  the: 4.7716\n",
      "  the accompanying: 5.0431\n",
      "  the accompanying area: 5.0431\n",
      "  the false: 10.0861\n",
      "  the false negative: 5.0431\n",
      "  the false positive: 5.0431\n",
      "  the roc: 5.0431\n",
      "  the roc curve: 5.0431\n",
      "  their: 2.7918\n",
      "  their numerators: 5.0431\n",
      "  their numerators and: 5.0431\n",
      "  these: 2.9030\n",
      "  these rates: 5.0431\n",
      "  these rates are: 5.0431\n",
      "  tnr: 5.0431\n",
      "  tnr respectively: 5.0431\n",
      "  tnr respectively similarly: 5.0431\n",
      "  to: 2.4507\n",
      "  to overall: 5.0431\n",
      "  to overall accuracy: 5.0431\n",
      "  to reveal: 5.0431\n",
      "  to reveal their: 5.0431\n",
      "  tools: 4.1268\n",
      "  tools for: 4.6376\n",
      "  tools for classification: 5.0431\n",
      "  tpr: 5.0431\n",
      "  tpr and: 5.0431\n",
      "  tpr and true: 5.0431\n",
      "  true: 9.2752\n",
      "  true negative: 5.0431\n",
      "  true negative rate: 5.0431\n",
      "  true positive: 5.0431\n",
      "  true positive rate: 5.0431\n",
      "  under: 3.4336\n",
      "  under the: 4.3499\n",
      "  under the roc: 5.0431\n",
      "  well: 3.9444\n",
      "  well as: 4.6376\n",
      "  well as the: 5.0431\n",
      "  with: 4.1453\n",
      "  with a: 3.6568\n",
      "  with a better: 5.0431\n",
      "  with the: 3.5390\n",
      "  with the accompanying: 5.0431\n",
      "\n",
      "Document 99:\n",
      "\n",
      "Document 100:\n",
      "  a: 2.5177\n",
      "  a broad: 5.0431\n",
      "  a broad range: 5.0431\n",
      "  a moral: 5.0431\n",
      "  a moral status: 5.0431\n",
      "  accountability: 5.0431\n",
      "  accountability privacy: 5.0431\n",
      "  accountability privacy and: 5.0431\n",
      "  ai: 13.7345\n",
      "  ai safety: 5.0431\n",
      "  ai safety and: 5.0431\n",
      "  ai systems: 5.0431\n",
      "  ai systems if: 5.0431\n",
      "  ai that: 5.0431\n",
      "  ai that are: 5.0431\n",
      "  ai welfare: 5.0431\n",
      "  ai welfare and: 5.0431\n",
      "  aienabled: 5.0431\n",
      "  aienabled misinformation: 5.0431\n",
      "  aienabled misinformation how: 5.0431\n",
      "  algorithmic: 3.9444\n",
      "  algorithmic biases: 5.0431\n",
      "  algorithmic biases fairness: 5.0431\n",
      "  alignment: 5.0431\n",
      "  alignment technological: 5.0431\n",
      "  alignment technological unemployment: 5.0431\n",
      "  also: 2.6452\n",
      "  also covers: 5.0431\n",
      "  also covers various: 5.0431\n",
      "  and: 4.8576\n",
      "  and alignment: 5.0431\n",
      "  and alignment technological: 5.0431\n",
      "  and existential: 5.0431\n",
      "  and existential risks: 5.0431\n",
      "  and regulation: 5.0431\n",
      "  and regulation it: 5.0431\n",
      "  and rights: 5.0431\n",
      "  and rights artificial: 5.0431\n",
      "  are: 1.9750\n",
      "  are considered: 5.0431\n",
      "  are considered to: 5.0431\n",
      "  arms: 5.0431\n",
      "  arms race: 5.0431\n",
      "  arms race dynamics: 5.0431\n",
      "  artificial: 5.5835\n",
      "  artificial intelligence: 3.5390\n",
      "  artificial intelligence covers: 5.0431\n",
      "  artificial superintelligence: 5.0431\n",
      "  artificial superintelligence and: 5.0431\n",
      "  as: 1.8444\n",
      "  as machine: 5.0431\n",
      "  as machine ethics: 5.0431\n",
      "  automated: 4.3499\n",
      "  automated decisionmaking: 5.0431\n",
      "  automated decisionmaking accountability: 5.0431\n",
      "  autonomous: 4.6376\n",
      "  autonomous weapon: 5.0431\n",
      "  autonomous weapon systems: 5.0431\n",
      "  behave: 5.0431\n",
      "  behave ethically: 5.0431\n",
      "  behave ethically lethal: 5.0431\n",
      "  biases: 3.7903\n",
      "  biases fairness: 5.0431\n",
      "  biases fairness automated: 5.0431\n",
      "  broad: 4.3499\n",
      "  broad range: 5.0431\n",
      "  broad range of: 5.0431\n",
      "  certain: 4.1268\n",
      "  certain ai: 5.0431\n",
      "  certain ai systems: 5.0431\n",
      "  challenges: 4.6376\n",
      "  challenges such: 5.0431\n",
      "  challenges such as: 5.0431\n",
      "  considered: 3.7903\n",
      "  considered to: 5.0431\n",
      "  considered to have: 5.0431\n",
      "  covers: 10.0861\n",
      "  covers a: 5.0431\n",
      "  covers a broad: 5.0431\n",
      "  covers various: 5.0431\n",
      "  covers various emerging: 5.0431\n",
      "  decisionmaking: 4.3499\n",
      "  decisionmaking accountability: 5.0431\n",
      "  decisionmaking accountability privacy: 5.0431\n",
      "  dynamics: 5.0431\n",
      "  dynamics ai: 5.0431\n",
      "  dynamics ai safety: 5.0431\n",
      "  emerging: 4.6376\n",
      "  emerging or: 5.0431\n",
      "  emerging or potential: 5.0431\n",
      "  ethical: 4.6376\n",
      "  ethical stakes: 5.0431\n",
      "  ethical stakes this: 5.0431\n",
      "  ethically: 5.0431\n",
      "  ethically lethal: 5.0431\n",
      "  ethically lethal autonomous: 5.0431\n",
      "  ethics: 9.2752\n",
      "  ethics how: 5.0431\n",
      "  ethics how to: 5.0431\n",
      "  ethics of: 5.0431\n",
      "  ethics of artificial: 5.0431\n",
      "  existential: 5.0431\n",
      "  existential risks: 5.0431\n",
      "  fairness: 4.6376\n",
      "  fairness automated: 5.0431\n",
      "  fairness automated decisionmaking: 5.0431\n",
      "  future: 4.1268\n",
      "  future challenges: 5.0431\n",
      "  future challenges such: 5.0431\n",
      "  have: 4.9562\n",
      "  have a: 4.3499\n",
      "  have a moral: 5.0431\n",
      "  have particular: 5.0431\n",
      "  have particular ethical: 5.0431\n",
      "  how: 7.0779\n",
      "  how to: 10.0861\n",
      "  how to make: 5.0431\n",
      "  how to treat: 5.0431\n",
      "  if: 3.6568\n",
      "  if they: 5.0431\n",
      "  if they have: 5.0431\n",
      "  includes: 4.1268\n",
      "  includes algorithmic: 5.0431\n",
      "  includes algorithmic biases: 5.0431\n",
      "  intelligence: 3.1712\n",
      "  intelligence covers: 5.0431\n",
      "  intelligence covers a: 5.0431\n",
      "  it: 2.2705\n",
      "  it also: 5.0431\n",
      "  it also covers: 5.0431\n",
      "  lethal: 5.0431\n",
      "  lethal autonomous: 5.0431\n",
      "  lethal autonomous weapon: 5.0431\n",
      "  machine: 1.4735\n",
      "  machine ethics: 5.0431\n",
      "  machine ethics how: 5.0431\n",
      "  machines: 3.6568\n",
      "  machines that: 5.0431\n",
      "  machines that behave: 5.0431\n",
      "  make: 3.3383\n",
      "  make machines: 5.0431\n",
      "  make machines that: 5.0431\n",
      "  misinformation: 5.0431\n",
      "  misinformation how: 5.0431\n",
      "  misinformation how to: 5.0431\n",
      "  moral: 5.0431\n",
      "  moral status: 5.0431\n",
      "  moral status ai: 5.0431\n",
      "  of: 2.4288\n",
      "  of artificial: 5.0431\n",
      "  of artificial intelligence: 5.0431\n",
      "  of topics: 5.0431\n",
      "  of topics within: 5.0431\n",
      "  or: 2.0226\n",
      "  or potential: 5.0431\n",
      "  or potential future: 5.0431\n",
      "  particular: 4.3499\n",
      "  particular ethical: 5.0431\n",
      "  particular ethical stakes: 5.0431\n",
      "  potential: 4.1268\n",
      "  potential future: 5.0431\n",
      "  potential future challenges: 5.0431\n",
      "  privacy: 4.1268\n",
      "  privacy and: 5.0431\n",
      "  privacy and regulation: 5.0431\n",
      "  race: 5.0431\n",
      "  race dynamics: 5.0431\n",
      "  race dynamics ai: 5.0431\n",
      "  range: 4.3499\n",
      "  range of: 4.6376\n",
      "  range of topics: 5.0431\n",
      "  regulation: 5.0431\n",
      "  regulation it: 5.0431\n",
      "  regulation it also: 5.0431\n",
      "  rights: 5.0431\n",
      "  rights artificial: 5.0431\n",
      "  rights artificial superintelligence: 5.0431\n",
      "  risks: 5.0431\n",
      "  safety: 5.0431\n",
      "  safety and: 5.0431\n",
      "  safety and alignment: 5.0431\n",
      "  stakes: 4.6376\n",
      "  stakes this: 5.0431\n",
      "  stakes this includes: 5.0431\n",
      "  status: 5.0431\n",
      "  status ai: 5.0431\n",
      "  status ai welfare: 5.0431\n",
      "  such: 2.4781\n",
      "  such as: 2.8458\n",
      "  such as machine: 5.0431\n",
      "  superintelligence: 5.0431\n",
      "  superintelligence and: 5.0431\n",
      "  superintelligence and existential: 5.0431\n",
      "  systems: 5.3834\n",
      "  systems arms: 5.0431\n",
      "  systems arms race: 5.0431\n",
      "  systems if: 5.0431\n",
      "  systems if they: 5.0431\n",
      "  technological: 5.0431\n",
      "  technological unemployment: 5.0431\n",
      "  technological unemployment aienabled: 5.0431\n",
      "  that: 3.3515\n",
      "  that are: 3.7903\n",
      "  that are considered: 5.0431\n",
      "  that behave: 5.0431\n",
      "  that behave ethically: 5.0431\n",
      "  the: 1.1929\n",
      "  the ethics: 5.0431\n",
      "  the ethics of: 5.0431\n",
      "  they: 3.4336\n",
      "  they have: 5.0431\n",
      "  they have a: 5.0431\n",
      "  this: 2.6007\n",
      "  this includes: 5.0431\n",
      "  this includes algorithmic: 5.0431\n",
      "  to: 3.6760\n",
      "  to have: 4.3499\n",
      "  to have particular: 5.0431\n",
      "  to make: 3.9444\n",
      "  to make machines: 5.0431\n",
      "  to treat: 5.0431\n",
      "  to treat certain: 5.0431\n",
      "  topics: 5.0431\n",
      "  topics within: 5.0431\n",
      "  topics within ai: 5.0431\n",
      "  treat: 5.0431\n",
      "  treat certain: 5.0431\n",
      "  treat certain ai: 5.0431\n",
      "  unemployment: 5.0431\n",
      "  unemployment aienabled: 5.0431\n",
      "  unemployment aienabled misinformation: 5.0431\n",
      "  various: 3.4336\n",
      "  various emerging: 5.0431\n",
      "  various emerging or: 5.0431\n",
      "  weapon: 5.0431\n",
      "  weapon systems: 5.0431\n",
      "  weapon systems arms: 5.0431\n",
      "  welfare: 5.0431\n",
      "  welfare and: 5.0431\n",
      "  welfare and rights: 5.0431\n",
      "  within: 3.4336\n",
      "  within ai: 4.6376\n",
      "  within ai that: 5.0431\n",
      "\n",
      "Document 101:\n",
      "  a: 1.2589\n",
      "  a machine: 3.4336\n",
      "  a machine learning: 3.5390\n",
      "  able: 4.6376\n",
      "  able to: 4.6376\n",
      "  able to predict: 5.0431\n",
      "  already: 4.6376\n",
      "  already present: 5.0431\n",
      "  already present in: 5.0431\n",
      "  and: 1.2144\n",
      "  and unconscious: 5.0431\n",
      "  and unconscious biases: 5.0431\n",
      "  approaches: 3.5390\n",
      "  approaches can: 5.0431\n",
      "  approaches can suffer: 5.0431\n",
      "  are: 1.9750\n",
      "  are not: 5.0431\n",
      "  are not represented: 5.0431\n",
      "  be: 2.0726\n",
      "  be able: 4.6376\n",
      "  be able to: 4.6376\n",
      "  biases: 7.5806\n",
      "  biases a: 5.0431\n",
      "  biases a machine: 5.0431\n",
      "  biases already: 5.0431\n",
      "  biases already present: 5.0431\n",
      "  can: 2.1809\n",
      "  can suffer: 5.0431\n",
      "  can suffer from: 5.0431\n",
      "  constitutional: 5.0431\n",
      "  constitutional and: 5.0431\n",
      "  constitutional and unconscious: 5.0431\n",
      "  current: 4.3499\n",
      "  current customers: 5.0431\n",
      "  current customers may: 5.0431\n",
      "  customer: 4.6376\n",
      "  customer groups: 5.0431\n",
      "  customer groups that: 5.0431\n",
      "  customers: 5.0431\n",
      "  customers may: 5.0431\n",
      "  customers may not: 5.0431\n",
      "  data: 5.5950\n",
      "  data biases: 5.0431\n",
      "  data biases a: 5.0431\n",
      "  data machine: 5.0431\n",
      "  data machine learning: 5.0431\n",
      "  data when: 4.6376\n",
      "  data when trained: 5.0431\n",
      "  different: 7.8889\n",
      "  different data: 5.0431\n",
      "  different data biases: 5.0431\n",
      "  different machine: 5.0431\n",
      "  different machine learning: 5.0431\n",
      "  from: 2.0726\n",
      "  from different: 4.6376\n",
      "  from different data: 5.0431\n",
      "  groups: 4.6376\n",
      "  groups that: 5.0431\n",
      "  groups that are: 5.0431\n",
      "  humanmade: 5.0431\n",
      "  humanmade data: 5.0431\n",
      "  humanmade data machine: 5.0431\n",
      "  in: 2.6835\n",
      "  in society: 5.0431\n",
      "  in the: 2.4404\n",
      "  in the training: 5.0431\n",
      "  is: 1.5167\n",
      "  is likely: 5.0431\n",
      "  is likely to: 5.0431\n",
      "  learning: 3.8456\n",
      "  learning approaches: 3.9444\n",
      "  learning approaches can: 5.0431\n",
      "  learning is: 3.0281\n",
      "  learning is likely: 5.0431\n",
      "  learning system: 4.1268\n",
      "  learning system trained: 5.0431\n",
      "  likely: 4.3499\n",
      "  likely to: 4.3499\n",
      "  likely to pick: 5.0431\n",
      "  machine: 4.4206\n",
      "  machine learning: 4.6854\n",
      "  machine learning approaches: 3.9444\n",
      "  machine learning is: 3.6568\n",
      "  machine learning system: 4.3499\n",
      "  may: 3.2513\n",
      "  may not: 5.0431\n",
      "  may not be: 5.0431\n",
      "  needs: 5.0431\n",
      "  needs of: 5.0431\n",
      "  needs of new: 5.0431\n",
      "  new: 3.2513\n",
      "  new customer: 5.0431\n",
      "  new customer groups: 5.0431\n",
      "  not: 5.2014\n",
      "  not be: 4.3499\n",
      "  not be able: 5.0431\n",
      "  not represented: 5.0431\n",
      "  not represented in: 5.0431\n",
      "  of: 1.2144\n",
      "  of new: 4.6376\n",
      "  of new customer: 5.0431\n",
      "  on: 4.0946\n",
      "  on current: 5.0431\n",
      "  on current customers: 5.0431\n",
      "  on humanmade: 5.0431\n",
      "  on humanmade data: 5.0431\n",
      "  pick: 5.0431\n",
      "  pick up: 5.0431\n",
      "  pick up the: 5.0431\n",
      "  predict: 3.9444\n",
      "  predict the: 4.1268\n",
      "  predict the needs: 5.0431\n",
      "  present: 5.0431\n",
      "  present in: 5.0431\n",
      "  present in society: 5.0431\n",
      "  represented: 3.6568\n",
      "  represented in: 4.6376\n",
      "  represented in the: 4.6376\n",
      "  society: 4.6376\n",
      "  specifically: 4.6376\n",
      "  specifically on: 5.0431\n",
      "  specifically on current: 5.0431\n",
      "  suffer: 5.0431\n",
      "  suffer from: 5.0431\n",
      "  suffer from different: 5.0431\n",
      "  system: 3.0281\n",
      "  system trained: 5.0431\n",
      "  system trained specifically: 5.0431\n",
      "  that: 1.6758\n",
      "  that are: 3.7903\n",
      "  that are not: 5.0431\n",
      "  the: 3.5787\n",
      "  the constitutional: 5.0431\n",
      "  the constitutional and: 5.0431\n",
      "  the needs: 5.0431\n",
      "  the needs of: 5.0431\n",
      "  the training: 3.3383\n",
      "  the training data: 4.3499\n",
      "  to: 2.4507\n",
      "  to pick: 5.0431\n",
      "  to pick up: 5.0431\n",
      "  to predict: 4.1268\n",
      "  to predict the: 4.3499\n",
      "  trained: 6.6766\n",
      "  trained on: 3.9444\n",
      "  trained on humanmade: 5.0431\n",
      "  trained specifically: 5.0431\n",
      "  trained specifically on: 5.0431\n",
      "  training: 2.5581\n",
      "  training data: 3.7903\n",
      "  training data when: 5.0431\n",
      "  unconscious: 5.0431\n",
      "  unconscious biases: 5.0431\n",
      "  unconscious biases already: 5.0431\n",
      "  up: 3.7903\n",
      "  up the: 5.0431\n",
      "  up the constitutional: 5.0431\n",
      "  when: 3.3383\n",
      "  when trained: 5.0431\n",
      "  when trained on: 5.0431\n",
      "\n",
      "Document 102:\n",
      "  a: 3.7766\n",
      "  a computer: 4.3499\n",
      "  a computer program: 4.6376\n",
      "  a firm: 5.0431\n",
      "  a firm with: 5.0431\n",
      "  a machine: 3.4336\n",
      "  a machine learning: 3.5390\n",
      "  admissions: 5.0431\n",
      "  admissions staff: 5.0431\n",
      "  admissions staff and: 5.0431\n",
      "  after: 3.7903\n",
      "  after being: 5.0431\n",
      "  after being trained: 5.0431\n",
      "  algorithm: 2.9030\n",
      "  algorithm that: 4.3499\n",
      "  algorithm that resulted: 5.0431\n",
      "  algorithmic: 3.9444\n",
      "  algorithmic bias: 4.6376\n",
      "  algorithmic bias thus: 5.0431\n",
      "  and: 2.4288\n",
      "  and minority: 5.0431\n",
      "  and minority communities: 5.0431\n",
      "  and that: 4.3499\n",
      "  and that this: 5.0431\n",
      "  another: 4.1268\n",
      "  another example: 5.0431\n",
      "  another example includes: 5.0431\n",
      "  applicants: 10.0861\n",
      "  applicants another: 5.0431\n",
      "  applicants another example: 5.0431\n",
      "  applicants by: 5.0431\n",
      "  applicants by similarity: 5.0431\n",
      "  are: 1.9750\n",
      "  are trained: 4.6376\n",
      "  are trained on: 5.0431\n",
      "  be: 2.0726\n",
      "  be women: 5.0431\n",
      "  be women or: 5.0431\n",
      "  been: 2.6917\n",
      "  been using: 5.0431\n",
      "  been using a: 5.0431\n",
      "  being: 3.7903\n",
      "  being trained: 4.6376\n",
      "  being trained with: 5.0431\n",
      "  bias: 7.5806\n",
      "  bias by: 5.0431\n",
      "  bias by scoring: 5.0431\n",
      "  bias thus: 5.0431\n",
      "  bias thus digitising: 5.0431\n",
      "  biases: 7.5806\n",
      "  biases may: 5.0431\n",
      "  biases may exhibit: 5.0431\n",
      "  biases upon: 5.0431\n",
      "  biases upon use: 5.0431\n",
      "  by: 3.8151\n",
      "  by scoring: 5.0431\n",
      "  by scoring job: 5.0431\n",
      "  by similarity: 5.0431\n",
      "  by similarity to: 5.0431\n",
      "  candidates: 5.0431\n",
      "  candidates who: 5.0431\n",
      "  candidates who were: 5.0431\n",
      "  collected: 4.6376\n",
      "  collected with: 5.0431\n",
      "  collected with biases: 5.0431\n",
      "  commission: 5.0431\n",
      "  commission for: 5.0431\n",
      "  commission for racial: 5.0431\n",
      "  communities: 4.6376\n",
      "  communities after: 5.0431\n",
      "  communities after being: 5.0431\n",
      "  company: 4.3499\n",
      "  company geoliticas: 5.0431\n",
      "  company geoliticas predictive: 5.0431\n",
      "  computer: 3.2513\n",
      "  computer program: 4.6376\n",
      "  computer program trained: 5.0431\n",
      "  crime: 5.0431\n",
      "  crime data: 5.0431\n",
      "  cultural: 5.0431\n",
      "  cultural prejudices: 5.0431\n",
      "  cultural prejudices for: 5.0431\n",
      "  data: 5.5950\n",
      "  data from: 4.6376\n",
      "  data from a: 5.0431\n",
      "  data of: 4.3499\n",
      "  data of previous: 5.0431\n",
      "  datasets: 4.3499\n",
      "  datasets collected: 5.0431\n",
      "  datasets collected with: 5.0431\n",
      "  denied: 5.0431\n",
      "  denied nearly: 5.0431\n",
      "  denied nearly candidates: 5.0431\n",
      "  digitising: 5.0431\n",
      "  digitising cultural: 5.0431\n",
      "  digitising cultural prejudices: 5.0431\n",
      "  disproportionately: 5.0431\n",
      "  disproportionately high: 5.0431\n",
      "  disproportionately high levels: 5.0431\n",
      "  duplicating: 5.0431\n",
      "  duplicating the: 5.0431\n",
      "  duplicating the bias: 5.0431\n",
      "  either: 3.9444\n",
      "  either be: 5.0431\n",
      "  either be women: 5.0431\n",
      "  equality: 5.0431\n",
      "  equality found: 5.0431\n",
      "  equality found that: 5.0431\n",
      "  example: 5.9272\n",
      "  example in: 4.1268\n",
      "  example in the: 5.0431\n",
      "  example includes: 5.0431\n",
      "  example includes predictive: 5.0431\n",
      "  exhibit: 5.0431\n",
      "  exhibit these: 5.0431\n",
      "  exhibit these biases: 5.0431\n",
      "  firm: 4.6376\n",
      "  firm with: 5.0431\n",
      "  firm with racist: 5.0431\n",
      "  for: 3.4577\n",
      "  for example: 3.2513\n",
      "  for example in: 4.1268\n",
      "  for racial: 5.0431\n",
      "  for racial equality: 5.0431\n",
      "  found: 7.5806\n",
      "  found that: 4.6376\n",
      "  found that st: 5.0431\n",
      "  found to: 4.6376\n",
      "  found to either: 5.0431\n",
      "  from: 4.1453\n",
      "  from a: 3.7903\n",
      "  from a firm: 5.0431\n",
      "  from data: 3.9444\n",
      "  from data of: 5.0431\n",
      "  geoliticas: 5.0431\n",
      "  geoliticas predictive: 5.0431\n",
      "  geoliticas predictive algorithm: 5.0431\n",
      "  georges: 5.0431\n",
      "  georges medical: 5.0431\n",
      "  georges medical school: 5.0431\n",
      "  had: 7.3135\n",
      "  had been: 4.1268\n",
      "  had been using: 5.0431\n",
      "  had denied: 5.0431\n",
      "  had denied nearly: 5.0431\n",
      "  have: 2.4781\n",
      "  have noneuropean: 5.0431\n",
      "  have noneuropean sounding: 5.0431\n",
      "  high: 4.3499\n",
      "  high levels: 5.0431\n",
      "  high levels of: 5.0431\n",
      "  hiring: 10.0861\n",
      "  hiring data: 5.0431\n",
      "  hiring data from: 5.0431\n",
      "  hiring policies: 5.0431\n",
      "  hiring policies may: 5.0431\n",
      "  historical: 4.6376\n",
      "  historical crime: 5.0431\n",
      "  historical crime data: 5.0431\n",
      "  in: 4.0252\n",
      "  in disproportionately: 5.0431\n",
      "  in disproportionately high: 5.0431\n",
      "  in lowincome: 5.0431\n",
      "  in lowincome and: 5.0431\n",
      "  in the: 2.4404\n",
      "  in the uks: 5.0431\n",
      "  includes: 4.1268\n",
      "  includes predictive: 5.0431\n",
      "  includes predictive policing: 5.0431\n",
      "  job: 10.0861\n",
      "  job applicants: 5.0431\n",
      "  job applicants by: 5.0431\n",
      "  job hiring: 5.0431\n",
      "  job hiring data: 5.0431\n",
      "  lead: 4.3499\n",
      "  lead to: 4.3499\n",
      "  lead to a: 4.6376\n",
      "  learning: 1.2819\n",
      "  learning system: 4.1268\n",
      "  learning system duplicating: 5.0431\n",
      "  levels: 4.3499\n",
      "  levels of: 4.3499\n",
      "  levels of overpolicing: 5.0431\n",
      "  lowincome: 5.0431\n",
      "  lowincome and: 5.0431\n",
      "  lowincome and minority: 5.0431\n",
      "  machine: 1.4735\n",
      "  machine learning: 1.5618\n",
      "  machine learning system: 4.3499\n",
      "  may: 6.5026\n",
      "  may exhibit: 5.0431\n",
      "  may exhibit these: 5.0431\n",
      "  may lead: 5.0431\n",
      "  may lead to: 5.0431\n",
      "  medical: 3.7903\n",
      "  medical school: 5.0431\n",
      "  medical school had: 5.0431\n",
      "  minority: 4.6376\n",
      "  minority communities: 5.0431\n",
      "  minority communities after: 5.0431\n",
      "  names: 5.0431\n",
      "  names using: 5.0431\n",
      "  names using job: 5.0431\n",
      "  nearly: 5.0431\n",
      "  nearly candidates: 5.0431\n",
      "  nearly candidates who: 5.0431\n",
      "  noneuropean: 5.0431\n",
      "  noneuropean sounding: 5.0431\n",
      "  noneuropean sounding names: 5.0431\n",
      "  of: 2.4288\n",
      "  of overpolicing: 5.0431\n",
      "  of overpolicing in: 5.0431\n",
      "  of previous: 5.0431\n",
      "  of previous admissions: 5.0431\n",
      "  on: 2.0473\n",
      "  on datasets: 5.0431\n",
      "  on datasets collected: 5.0431\n",
      "  or: 2.0226\n",
      "  or have: 5.0431\n",
      "  or have noneuropean: 5.0431\n",
      "  overpolicing: 5.0431\n",
      "  overpolicing in: 5.0431\n",
      "  overpolicing in lowincome: 5.0431\n",
      "  policies: 5.0431\n",
      "  policies may: 5.0431\n",
      "  policies may lead: 5.0431\n",
      "  policing: 5.0431\n",
      "  policing company: 5.0431\n",
      "  policing company geoliticas: 5.0431\n",
      "  predictive: 8.2535\n",
      "  predictive algorithm: 5.0431\n",
      "  predictive algorithm that: 5.0431\n",
      "  predictive policing: 5.0431\n",
      "  predictive policing company: 5.0431\n",
      "  prejudices: 5.0431\n",
      "  prejudices for: 5.0431\n",
      "  prejudices for example: 5.0431\n",
      "  previous: 8.2535\n",
      "  previous admissions: 5.0431\n",
      "  previous admissions staff: 5.0431\n",
      "  previous successful: 5.0431\n",
      "  previous successful applicants: 5.0431\n",
      "  program: 7.5806\n",
      "  program had: 5.0431\n",
      "  program had denied: 5.0431\n",
      "  program trained: 5.0431\n",
      "  program trained from: 5.0431\n",
      "  racial: 5.0431\n",
      "  racial equality: 5.0431\n",
      "  racial equality found: 5.0431\n",
      "  racist: 4.6376\n",
      "  racist hiring: 5.0431\n",
      "  racist hiring policies: 5.0431\n",
      "  resulted: 5.0431\n",
      "  resulted in: 5.0431\n",
      "  resulted in disproportionately: 5.0431\n",
      "  school: 5.0431\n",
      "  school had: 5.0431\n",
      "  school had been: 5.0431\n",
      "  scoring: 5.0431\n",
      "  scoring job: 5.0431\n",
      "  scoring job applicants: 5.0431\n",
      "  similarity: 4.1268\n",
      "  similarity to: 5.0431\n",
      "  similarity to previous: 5.0431\n",
      "  sounding: 5.0431\n",
      "  sounding names: 5.0431\n",
      "  sounding names using: 5.0431\n",
      "  st: 5.0431\n",
      "  st georges: 5.0431\n",
      "  st georges medical: 5.0431\n",
      "  staff: 5.0431\n",
      "  staff and: 5.0431\n",
      "  staff and that: 5.0431\n",
      "  successful: 4.6376\n",
      "  successful applicants: 5.0431\n",
      "  successful applicants another: 5.0431\n",
      "  system: 3.0281\n",
      "  system duplicating: 5.0431\n",
      "  system duplicating the: 5.0431\n",
      "  systems: 2.6917\n",
      "  systems that: 5.0431\n",
      "  systems that are: 5.0431\n",
      "  that: 6.7030\n",
      "  that are: 3.7903\n",
      "  that are trained: 5.0431\n",
      "  that resulted: 5.0431\n",
      "  that resulted in: 5.0431\n",
      "  that st: 5.0431\n",
      "  that st georges: 5.0431\n",
      "  that this: 5.0431\n",
      "  that this program: 5.0431\n",
      "  the: 2.3858\n",
      "  the bias: 5.0431\n",
      "  the bias by: 5.0431\n",
      "  the uks: 5.0431\n",
      "  the uks commission: 5.0431\n",
      "  these: 2.9030\n",
      "  these biases: 4.3499\n",
      "  these biases upon: 5.0431\n",
      "  this: 2.6007\n",
      "  this program: 5.0431\n",
      "  this program had: 5.0431\n",
      "  thus: 4.3499\n",
      "  thus digitising: 5.0431\n",
      "  thus digitising cultural: 5.0431\n",
      "  to: 3.6760\n",
      "  to a: 3.1712\n",
      "  to a machine: 5.0431\n",
      "  to either: 5.0431\n",
      "  to either be: 5.0431\n",
      "  to previous: 5.0431\n",
      "  to previous successful: 5.0431\n",
      "  trained: 10.0149\n",
      "  trained from: 5.0431\n",
      "  trained from data: 5.0431\n",
      "  trained on: 3.9444\n",
      "  trained on datasets: 5.0431\n",
      "  trained with: 5.0431\n",
      "  trained with historical: 5.0431\n",
      "  uks: 5.0431\n",
      "  uks commission: 5.0431\n",
      "  uks commission for: 5.0431\n",
      "  upon: 5.0431\n",
      "  upon use: 5.0431\n",
      "  upon use algorithmic: 5.0431\n",
      "  use: 3.3383\n",
      "  use algorithmic: 5.0431\n",
      "  use algorithmic bias: 5.0431\n",
      "  using: 6.5026\n",
      "  using a: 4.6376\n",
      "  using a computer: 5.0431\n",
      "  using job: 5.0431\n",
      "  using job hiring: 5.0431\n",
      "  were: 3.7903\n",
      "  were found: 5.0431\n",
      "  were found to: 5.0431\n",
      "  who: 3.9444\n",
      "  who were: 5.0431\n",
      "  who were found: 5.0431\n",
      "  with: 6.2179\n",
      "  with biases: 5.0431\n",
      "  with biases may: 5.0431\n",
      "  with historical: 5.0431\n",
      "  with historical crime: 5.0431\n",
      "  with racist: 5.0431\n",
      "  with racist hiring: 5.0431\n",
      "  women: 5.0431\n",
      "  women or: 5.0431\n",
      "  women or have: 5.0431\n",
      "\n",
      "Document 103:\n",
      "  a: 3.7766\n",
      "  a critical: 5.0431\n",
      "  a critical part: 5.0431\n",
      "  a lack: 5.0431\n",
      "  a lack of: 5.0431\n",
      "  a system: 4.3499\n",
      "  a system is: 5.0431\n",
      "  according: 3.9444\n",
      "  according to: 3.9444\n",
      "  according to research: 5.0431\n",
      "  african: 5.0431\n",
      "  african american: 5.0431\n",
      "  african american which: 5.0431\n",
      "  ai: 13.7345\n",
      "  ai among: 5.0431\n",
      "  ai among several: 5.0431\n",
      "  ai for: 5.0431\n",
      "  ai for machine: 5.0431\n",
      "  ai phd: 5.0431\n",
      "  ai phd graduates: 5.0431\n",
      "  algorithmic: 3.9444\n",
      "  algorithmic rules: 5.0431\n",
      "  algorithmic rules used: 5.0431\n",
      "  all: 3.5390\n",
      "  all faculty: 5.0431\n",
      "  all faculty members: 5.0431\n",
      "  american: 5.0431\n",
      "  american which: 5.0431\n",
      "  american which further: 5.0431\n",
      "  among: 7.8889\n",
      "  among several: 5.0431\n",
      "  among several universities: 5.0431\n",
      "  among the: 5.0431\n",
      "  among the group: 5.0431\n",
      "  and: 3.6432\n",
      "  and as: 5.0431\n",
      "  and as african: 5.0431\n",
      "  and documentation: 5.0431\n",
      "  and documentation of: 5.0431\n",
      "  and representation: 4.6376\n",
      "  and representation of: 5.0431\n",
      "  around: 4.6376\n",
      "  around the: 4.6376\n",
      "  around the world: 5.0431\n",
      "  as: 7.3775\n",
      "  as african: 5.0431\n",
      "  as african american: 5.0431\n",
      "  as asian: 5.0431\n",
      "  as asian as: 5.0431\n",
      "  as hispanic: 5.0431\n",
      "  as hispanic and: 5.0431\n",
      "  as white: 4.6376\n",
      "  as white as: 5.0431\n",
      "  asian: 5.0431\n",
      "  asian as: 5.0431\n",
      "  asian as hispanic: 5.0431\n",
      "  association: 3.9444\n",
      "  association cra: 5.0431\n",
      "  association cra in: 5.0431\n",
      "  biases: 3.7903\n",
      "  biases in: 4.6376\n",
      "  biases in fact: 5.0431\n",
      "  blame: 5.0431\n",
      "  blame lack: 5.0431\n",
      "  blame lack of: 5.0431\n",
      "  by: 3.8151\n",
      "  by a: 4.1268\n",
      "  by a system: 5.0431\n",
      "  by the: 3.2513\n",
      "  by the computing: 5.0431\n",
      "  carried: 4.6376\n",
      "  carried out: 4.6376\n",
      "  carried out by: 4.6376\n",
      "  collection: 4.1268\n",
      "  collection of: 4.1268\n",
      "  collection of data: 5.0431\n",
      "  computing: 3.9444\n",
      "  computing research: 5.0431\n",
      "  computing research association: 5.0431\n",
      "  considered: 3.7903\n",
      "  considered a: 5.0431\n",
      "  considered a critical: 5.0431\n",
      "  cra: 5.0431\n",
      "  cra in: 5.0431\n",
      "  cra in female: 5.0431\n",
      "  critical: 5.0431\n",
      "  critical part: 5.0431\n",
      "  critical part of: 5.0431\n",
      "  data: 1.8650\n",
      "  data and: 3.5390\n",
      "  data and documentation: 5.0431\n",
      "  demonstrates: 5.0431\n",
      "  demonstrates a: 5.0431\n",
      "  demonstrates a lack: 5.0431\n",
      "  diversity: 5.0431\n",
      "  diversity in: 5.0431\n",
      "  diversity in the: 5.0431\n",
      "  documentation: 5.0431\n",
      "  documentation of: 5.0431\n",
      "  documentation of algorithmic: 5.0431\n",
      "  fact: 4.6376\n",
      "  fact according: 5.0431\n",
      "  fact according to: 5.0431\n",
      "  faculty: 10.0861\n",
      "  faculty members: 5.0431\n",
      "  faculty members who: 5.0431\n",
      "  faculty merely: 5.0431\n",
      "  faculty merely make: 5.0431\n",
      "  female: 5.0431\n",
      "  female faculty: 5.0431\n",
      "  female faculty merely: 5.0431\n",
      "  field: 5.9272\n",
      "  field of: 7.0779\n",
      "  field of ai: 9.2752\n",
      "  focus: 4.6376\n",
      "  focus on: 5.0431\n",
      "  focus on ai: 5.0431\n",
      "  for: 1.7289\n",
      "  for machine: 3.9444\n",
      "  for machine learnings: 5.0431\n",
      "  further: 4.6376\n",
      "  further demonstrates: 5.0431\n",
      "  further demonstrates a: 5.0431\n",
      "  furthermore: 5.0431\n",
      "  furthermore among: 5.0431\n",
      "  furthermore among the: 5.0431\n",
      "  graduates: 5.0431\n",
      "  graduates identified: 5.0431\n",
      "  graduates identified as: 5.0431\n",
      "  group: 5.0431\n",
      "  group of: 5.0431\n",
      "  group of new: 5.0431\n",
      "  hispanic: 5.0431\n",
      "  hispanic and: 5.0431\n",
      "  hispanic and as: 5.0431\n",
      "  identified: 5.0431\n",
      "  identified as: 5.0431\n",
      "  identified as white: 5.0431\n",
      "  in: 5.3670\n",
      "  in fact: 5.0431\n",
      "  in fact according: 5.0431\n",
      "  in female: 5.0431\n",
      "  in female faculty: 5.0431\n",
      "  in the: 4.8807\n",
      "  in the field: 8.2535\n",
      "  is: 1.5167\n",
      "  is considered: 4.6376\n",
      "  is considered a: 5.0431\n",
      "  lack: 8.6998\n",
      "  lack of: 9.2752\n",
      "  lack of diversity: 5.0431\n",
      "  lack of participation: 5.0431\n",
      "  learning: 1.2819\n",
      "  learning some: 5.0431\n",
      "  learning some researchers: 5.0431\n",
      "  learnings: 5.0431\n",
      "  learnings vulnerability: 5.0431\n",
      "  learnings vulnerability to: 5.0431\n",
      "  machine: 2.9470\n",
      "  machine learning: 1.5618\n",
      "  machine learning some: 5.0431\n",
      "  machine learnings: 5.0431\n",
      "  machine learnings vulnerability: 5.0431\n",
      "  make: 3.3383\n",
      "  make up: 5.0431\n",
      "  make up of: 5.0431\n",
      "  members: 4.3499\n",
      "  members who: 5.0431\n",
      "  members who focus: 5.0431\n",
      "  merely: 5.0431\n",
      "  merely make: 5.0431\n",
      "  merely make up: 5.0431\n",
      "  minority: 4.6376\n",
      "  minority population: 5.0431\n",
      "  minority population in: 5.0431\n",
      "  new: 3.2513\n",
      "  new us: 5.0431\n",
      "  new us resident: 5.0431\n",
      "  of: 12.1441\n",
      "  of ai: 8.2535\n",
      "  of ai for: 5.0431\n",
      "  of algorithmic: 5.0431\n",
      "  of algorithmic rules: 5.0431\n",
      "  of all: 5.0431\n",
      "  of all faculty: 5.0431\n",
      "  of data: 3.6568\n",
      "  of data and: 5.0431\n",
      "  of diversity: 5.0431\n",
      "  of diversity in: 5.0431\n",
      "  of machine: 3.0281\n",
      "  of machine learning: 3.0281\n",
      "  of minority: 5.0431\n",
      "  of minority population: 5.0431\n",
      "  of new: 4.6376\n",
      "  of new us: 5.0431\n",
      "  of participation: 5.0431\n",
      "  of participation and: 5.0431\n",
      "  on: 2.0473\n",
      "  on ai: 5.0431\n",
      "  on ai among: 5.0431\n",
      "  out: 3.7903\n",
      "  out by: 4.6376\n",
      "  out by the: 5.0431\n",
      "  part: 4.6376\n",
      "  part of: 4.6376\n",
      "  part of machine: 5.0431\n",
      "  participation: 5.0431\n",
      "  participation and: 5.0431\n",
      "  participation and representation: 5.0431\n",
      "  phd: 5.0431\n",
      "  phd graduates: 5.0431\n",
      "  phd graduates identified: 5.0431\n",
      "  population: 4.6376\n",
      "  population in: 5.0431\n",
      "  population in the: 5.0431\n",
      "  representation: 3.9444\n",
      "  representation of: 5.0431\n",
      "  representation of minority: 5.0431\n",
      "  research: 6.8672\n",
      "  research association: 5.0431\n",
      "  research association cra: 5.0431\n",
      "  research carried: 5.0431\n",
      "  research carried out: 5.0431\n",
      "  researchers: 3.6568\n",
      "  researchers blame: 5.0431\n",
      "  researchers blame lack: 5.0431\n",
      "  resident: 5.0431\n",
      "  resident ai: 5.0431\n",
      "  resident ai phd: 5.0431\n",
      "  responsible: 5.0431\n",
      "  responsible collection: 5.0431\n",
      "  responsible collection of: 5.0431\n",
      "  rules: 3.6568\n",
      "  rules used: 5.0431\n",
      "  rules used by: 5.0431\n",
      "  several: 3.9444\n",
      "  several universities: 5.0431\n",
      "  several universities around: 5.0431\n",
      "  some: 2.9636\n",
      "  some researchers: 4.6376\n",
      "  some researchers blame: 5.0431\n",
      "  system: 3.0281\n",
      "  system is: 4.6376\n",
      "  system is considered: 5.0431\n",
      "  the: 5.9645\n",
      "  the computing: 5.0431\n",
      "  the computing research: 5.0431\n",
      "  the field: 6.8672\n",
      "  the field of: 7.5806\n",
      "  the group: 5.0431\n",
      "  the group of: 5.0431\n",
      "  the world: 5.0431\n",
      "  the world furthermore: 5.0431\n",
      "  to: 2.4507\n",
      "  to biases: 5.0431\n",
      "  to biases in: 5.0431\n",
      "  to research: 5.0431\n",
      "  to research carried: 5.0431\n",
      "  universities: 5.0431\n",
      "  universities around: 5.0431\n",
      "  universities around the: 5.0431\n",
      "  up: 3.7903\n",
      "  up of: 4.6376\n",
      "  up of all: 5.0431\n",
      "  us: 5.0431\n",
      "  us resident: 5.0431\n",
      "  us resident ai: 5.0431\n",
      "  used: 2.3350\n",
      "  used by: 4.3499\n",
      "  used by a: 5.0431\n",
      "  vulnerability: 5.0431\n",
      "  vulnerability to: 5.0431\n",
      "  vulnerability to biases: 5.0431\n",
      "  which: 2.6917\n",
      "  which further: 5.0431\n",
      "  which further demonstrates: 5.0431\n",
      "  while: 3.4336\n",
      "  while responsible: 5.0431\n",
      "  while responsible collection: 5.0431\n",
      "  white: 4.6376\n",
      "  white as: 5.0431\n",
      "  white as asian: 5.0431\n",
      "  who: 3.9444\n",
      "  who focus: 5.0431\n",
      "  who focus on: 5.0431\n",
      "  world: 5.0431\n",
      "  world furthermore: 5.0431\n",
      "  world furthermore among: 5.0431\n",
      "\n",
      "Document 104:\n",
      "  a: 1.2589\n",
      "  a chatbot: 5.0431\n",
      "  a chatbot that: 5.0431\n",
      "  also: 2.6452\n",
      "  also learn: 5.0431\n",
      "  also learn these: 5.0431\n",
      "  and: 2.4288\n",
      "  and it: 4.3499\n",
      "  and it quickly: 5.0431\n",
      "  and sexist: 5.0431\n",
      "  and sexist language: 5.0431\n",
      "  because: 4.3499\n",
      "  because human: 5.0431\n",
      "  because human languages: 5.0431\n",
      "  been: 2.6917\n",
      "  been shown: 5.0431\n",
      "  been shown to: 5.0431\n",
      "  biases: 11.3709\n",
      "  biases because: 5.0431\n",
      "  biases because human: 5.0431\n",
      "  biases in: 4.6376\n",
      "  biases in microsoft: 5.0431\n",
      "  biases machines: 5.0431\n",
      "  biases machines trained: 5.0431\n",
      "  chatbot: 4.6376\n",
      "  chatbot that: 5.0431\n",
      "  chatbot that learned: 5.0431\n",
      "  contain: 9.2752\n",
      "  contain biases: 5.0431\n",
      "  contain biases machines: 5.0431\n",
      "  contain humanlike: 5.0431\n",
      "  contain humanlike biases: 5.0431\n",
      "  corpora: 5.0431\n",
      "  corpora will: 5.0431\n",
      "  corpora will necessarily: 5.0431\n",
      "  data: 1.8650\n",
      "  data have: 5.0431\n",
      "  data have been: 5.0431\n",
      "  from: 4.1453\n",
      "  from data: 3.9444\n",
      "  from data have: 5.0431\n",
      "  from twitter: 5.0431\n",
      "  from twitter and: 5.0431\n",
      "  have: 2.4781\n",
      "  have been: 3.5390\n",
      "  have been shown: 5.0431\n",
      "  human: 3.6568\n",
      "  human languages: 5.0431\n",
      "  human languages contain: 5.0431\n",
      "  humanlike: 5.0431\n",
      "  humanlike biases: 5.0431\n",
      "  humanlike biases because: 5.0431\n",
      "  in: 1.3417\n",
      "  in microsoft: 4.6376\n",
      "  in microsoft tested: 5.0431\n",
      "  it: 2.2705\n",
      "  it quickly: 5.0431\n",
      "  it quickly picked: 5.0431\n",
      "  language: 11.8333\n",
      "  language corpora: 5.0431\n",
      "  language corpora will: 5.0431\n",
      "  language models: 4.6376\n",
      "  language models learned: 5.0431\n",
      "  languages: 5.0431\n",
      "  languages contain: 5.0431\n",
      "  languages contain biases: 5.0431\n",
      "  learn: 3.3383\n",
      "  learn these: 5.0431\n",
      "  learn these biases: 5.0431\n",
      "  learned: 7.5806\n",
      "  learned from: 9.2752\n",
      "  learned from data: 5.0431\n",
      "  learned from twitter: 5.0431\n",
      "  machines: 3.6568\n",
      "  machines trained: 5.0431\n",
      "  machines trained on: 5.0431\n",
      "  microsoft: 4.6376\n",
      "  microsoft tested: 5.0431\n",
      "  microsoft tested tay: 5.0431\n",
      "  models: 2.5581\n",
      "  models learned: 5.0431\n",
      "  models learned from: 5.0431\n",
      "  necessarily: 4.6376\n",
      "  necessarily also: 5.0431\n",
      "  necessarily also learn: 5.0431\n",
      "  on: 2.0473\n",
      "  on language: 5.0431\n",
      "  on language corpora: 5.0431\n",
      "  picked: 5.0431\n",
      "  picked up: 5.0431\n",
      "  picked up racist: 5.0431\n",
      "  quickly: 5.0431\n",
      "  quickly picked: 5.0431\n",
      "  quickly picked up: 5.0431\n",
      "  racist: 4.6376\n",
      "  racist and: 5.0431\n",
      "  racist and sexist: 5.0431\n",
      "  sexist: 5.0431\n",
      "  sexist language: 5.0431\n",
      "  shown: 5.0431\n",
      "  shown to: 5.0431\n",
      "  shown to contain: 5.0431\n",
      "  tay: 5.0431\n",
      "  tay a: 5.0431\n",
      "  tay a chatbot: 5.0431\n",
      "  tested: 4.6376\n",
      "  tested tay: 5.0431\n",
      "  tested tay a: 5.0431\n",
      "  that: 1.6758\n",
      "  that learned: 5.0431\n",
      "  that learned from: 5.0431\n",
      "  these: 2.9030\n",
      "  these biases: 4.3499\n",
      "  these biases in: 5.0431\n",
      "  to: 1.2253\n",
      "  to contain: 5.0431\n",
      "  to contain humanlike: 5.0431\n",
      "  trained: 3.3383\n",
      "  trained on: 3.9444\n",
      "  trained on language: 5.0431\n",
      "  twitter: 5.0431\n",
      "  twitter and: 5.0431\n",
      "  twitter and it: 5.0431\n",
      "  up: 3.7903\n",
      "  up racist: 5.0431\n",
      "  up racist and: 5.0431\n",
      "  will: 3.7903\n",
      "  will necessarily: 5.0431\n",
      "  will necessarily also: 5.0431\n",
      "\n",
      "Document 105:\n",
      "  a: 2.5177\n",
      "  a couple: 5.0431\n",
      "  a couple of: 5.0431\n",
      "  a machine: 3.4336\n",
      "  a machine learning: 3.5390\n",
      "  algorithms: 2.3689\n",
      "  algorithms insight: 5.0431\n",
      "  algorithms insight into: 5.0431\n",
      "  among: 3.9444\n",
      "  among prisoners: 5.0431\n",
      "  among prisoners falsely: 5.0431\n",
      "  an: 4.3054\n",
      "  an experiment: 5.0431\n",
      "  an experiment carried: 5.0431\n",
      "  an investigative: 5.0431\n",
      "  an investigative journalism: 5.0431\n",
      "  and: 1.2144\n",
      "  and in: 5.0431\n",
      "  and in it: 5.0431\n",
      "  as: 5.5331\n",
      "  as gorillas: 5.0431\n",
      "  as gorillas which: 5.0431\n",
      "  as often: 5.0431\n",
      "  as often as: 5.0431\n",
      "  as white: 4.6376\n",
      "  as white defendants: 5.0431\n",
      "  been: 2.6917\n",
      "  been found: 5.0431\n",
      "  been found in: 5.0431\n",
      "  black: 8.2535\n",
      "  black defendants: 5.0431\n",
      "  black defendants high: 5.0431\n",
      "  black people: 5.0431\n",
      "  black people as: 5.0431\n",
      "  by: 1.9076\n",
      "  by propublica: 5.0431\n",
      "  by propublica an: 5.0431\n",
      "  cannot: 3.7903\n",
      "  cannot recognise: 5.0431\n",
      "  cannot recognise gorillas: 5.0431\n",
      "  carried: 4.6376\n",
      "  carried out: 4.6376\n",
      "  carried out by: 4.6376\n",
      "  caused: 4.6376\n",
      "  caused controversy: 5.0431\n",
      "  caused controversy the: 5.0431\n",
      "  controversy: 5.0431\n",
      "  controversy the: 5.0431\n",
      "  controversy the gorilla: 5.0431\n",
      "  couple: 5.0431\n",
      "  couple of: 5.0431\n",
      "  couple of black: 5.0431\n",
      "  defendants: 10.0861\n",
      "  defendants high: 5.0431\n",
      "  defendants high risk: 5.0431\n",
      "  defendants in: 5.0431\n",
      "  defendants in google: 5.0431\n",
      "  experiment: 5.0431\n",
      "  experiment carried: 5.0431\n",
      "  experiment carried out: 5.0431\n",
      "  falsely: 5.0431\n",
      "  falsely flagged: 5.0431\n",
      "  falsely flagged black: 5.0431\n",
      "  flagged: 5.0431\n",
      "  flagged black: 5.0431\n",
      "  flagged black defendants: 5.0431\n",
      "  found: 3.7903\n",
      "  found in: 4.6376\n",
      "  found in many: 5.0431\n",
      "  google: 4.3499\n",
      "  google photos: 5.0431\n",
      "  google photos once: 5.0431\n",
      "  gorilla: 5.0431\n",
      "  gorilla label: 5.0431\n",
      "  gorilla label was: 5.0431\n",
      "  gorillas: 10.0861\n",
      "  gorillas similar: 5.0431\n",
      "  gorillas similar issues: 5.0431\n",
      "  gorillas which: 5.0431\n",
      "  gorillas which caused: 5.0431\n",
      "  have: 2.4781\n",
      "  have been: 3.5390\n",
      "  have been found: 5.0431\n",
      "  high: 4.3499\n",
      "  high risk: 5.0431\n",
      "  high risk twice: 5.0431\n",
      "  in: 5.3670\n",
      "  in an: 3.9444\n",
      "  in an experiment: 5.0431\n",
      "  in google: 4.6376\n",
      "  in google photos: 5.0431\n",
      "  in it: 4.6376\n",
      "  in it still: 5.0431\n",
      "  in many: 4.3499\n",
      "  in many other: 4.6376\n",
      "  insight: 5.0431\n",
      "  insight into: 5.0431\n",
      "  insight into the: 5.0431\n",
      "  into: 2.9636\n",
      "  into the: 4.3499\n",
      "  into the recidivism: 5.0431\n",
      "  investigative: 5.0431\n",
      "  investigative journalism: 5.0431\n",
      "  investigative journalism organisation: 5.0431\n",
      "  issues: 4.6376\n",
      "  issues with: 5.0431\n",
      "  issues with recognising: 5.0431\n",
      "  it: 2.2705\n",
      "  it still: 5.0431\n",
      "  it still cannot: 5.0431\n",
      "  journalism: 5.0431\n",
      "  journalism organisation: 5.0431\n",
      "  journalism organisation a: 5.0431\n",
      "  label: 4.6376\n",
      "  label was: 5.0431\n",
      "  label was subsequently: 5.0431\n",
      "  learning: 1.2819\n",
      "  learning algorithms: 2.9030\n",
      "  learning algorithms insight: 5.0431\n",
      "  machine: 1.4735\n",
      "  machine learning: 1.5618\n",
      "  machine learning algorithms: 3.4336\n",
      "  many: 2.9030\n",
      "  many other: 4.3499\n",
      "  many other systems: 5.0431\n",
      "  nonwhite: 5.0431\n",
      "  nonwhite people: 5.0431\n",
      "  nonwhite people have: 5.0431\n",
      "  of: 1.2144\n",
      "  of black: 5.0431\n",
      "  of black people: 5.0431\n",
      "  often: 3.0971\n",
      "  often as: 4.6376\n",
      "  often as white: 5.0431\n",
      "  once: 4.3499\n",
      "  once tagged: 5.0431\n",
      "  once tagged a: 5.0431\n",
      "  organisation: 5.0431\n",
      "  organisation a: 5.0431\n",
      "  organisation a machine: 5.0431\n",
      "  other: 2.7918\n",
      "  other systems: 5.0431\n",
      "  out: 3.7903\n",
      "  out by: 4.6376\n",
      "  out by propublica: 5.0431\n",
      "  people: 8.6998\n",
      "  people as: 5.0431\n",
      "  people as gorillas: 5.0431\n",
      "  people have: 5.0431\n",
      "  people have been: 5.0431\n",
      "  photos: 5.0431\n",
      "  photos once: 5.0431\n",
      "  photos once tagged: 5.0431\n",
      "  prisoners: 5.0431\n",
      "  prisoners falsely: 5.0431\n",
      "  prisoners falsely flagged: 5.0431\n",
      "  propublica: 5.0431\n",
      "  propublica an: 5.0431\n",
      "  propublica an investigative: 5.0431\n",
      "  rates: 4.6376\n",
      "  rates among: 5.0431\n",
      "  rates among prisoners: 5.0431\n",
      "  recidivism: 5.0431\n",
      "  recidivism rates: 5.0431\n",
      "  recidivism rates among: 5.0431\n",
      "  recognise: 4.6376\n",
      "  recognise gorillas: 5.0431\n",
      "  recognise gorillas similar: 5.0431\n",
      "  recognising: 5.0431\n",
      "  recognising nonwhite: 5.0431\n",
      "  recognising nonwhite people: 5.0431\n",
      "  removed: 5.0431\n",
      "  removed and: 5.0431\n",
      "  removed and in: 5.0431\n",
      "  risk: 4.6376\n",
      "  risk twice: 5.0431\n",
      "  risk twice as: 5.0431\n",
      "  similar: 3.9444\n",
      "  similar issues: 5.0431\n",
      "  similar issues with: 5.0431\n",
      "  still: 4.6376\n",
      "  still cannot: 5.0431\n",
      "  still cannot recognise: 5.0431\n",
      "  subsequently: 5.0431\n",
      "  subsequently removed: 5.0431\n",
      "  subsequently removed and: 5.0431\n",
      "  systems: 2.6917\n",
      "  tagged: 5.0431\n",
      "  tagged a: 5.0431\n",
      "  tagged a couple: 5.0431\n",
      "  the: 2.3858\n",
      "  the gorilla: 5.0431\n",
      "  the gorilla label: 5.0431\n",
      "  the recidivism: 5.0431\n",
      "  the recidivism rates: 5.0431\n",
      "  twice: 5.0431\n",
      "  twice as: 5.0431\n",
      "  twice as often: 5.0431\n",
      "  was: 3.3383\n",
      "  was subsequently: 5.0431\n",
      "  was subsequently removed: 5.0431\n",
      "  which: 2.6917\n",
      "  which caused: 5.0431\n",
      "  which caused controversy: 5.0431\n",
      "  white: 4.6376\n",
      "  white defendants: 5.0431\n",
      "  white defendants in: 5.0431\n",
      "  with: 2.0726\n",
      "  with recognising: 5.0431\n",
      "  with recognising nonwhite: 5.0431\n",
      "\n",
      "Document 106:\n",
      "  a: 2.5177\n",
      "  a powerful: 5.0431\n",
      "  a powerful tool: 5.0431\n",
      "  a profound: 5.0431\n",
      "  a profound responsibility: 5.0431\n",
      "  about: 3.6568\n",
      "  about ai: 5.0431\n",
      "  about ai its: 5.0431\n",
      "  adopted: 4.6376\n",
      "  adopted in: 5.0431\n",
      "  adopted in other: 5.0431\n",
      "  ai: 3.4336\n",
      "  ai its: 5.0431\n",
      "  ai its inspired: 5.0431\n",
      "  and: 2.4288\n",
      "  and propelling: 5.0431\n",
      "  and propelling its: 5.0431\n",
      "  and that: 4.3499\n",
      "  and that is: 5.0431\n",
      "  andmost: 5.0431\n",
      "  andmost importantlyit: 5.0431\n",
      "  andmost importantlyit impacts: 5.0431\n",
      "  are: 1.9750\n",
      "  are only: 5.0431\n",
      "  are only just: 5.0431\n",
      "  artificial: 5.5835\n",
      "  artificial about: 5.0431\n",
      "  artificial about ai: 5.0431\n",
      "  artificial intelligence: 3.5390\n",
      "  artificial intelligence scientists: 5.0431\n",
      "  be: 2.0726\n",
      "  be adopted: 5.0431\n",
      "  be adopted in: 5.0431\n",
      "  because: 4.3499\n",
      "  because of: 5.0431\n",
      "  because of such: 5.0431\n",
      "  beginning: 5.0431\n",
      "  beginning to: 5.0431\n",
      "  beginning to understand: 5.0431\n",
      "  bias: 3.7903\n",
      "  bias in: 5.0431\n",
      "  bias in machine: 5.0431\n",
      "  by: 5.7227\n",
      "  by artificial: 5.0431\n",
      "  by artificial intelligence: 5.0431\n",
      "  by people: 10.0861\n",
      "  by people andmost: 5.0431\n",
      "  by people its: 5.0431\n",
      "  challenges: 4.6376\n",
      "  challenges the: 5.0431\n",
      "  challenges the effective: 5.0431\n",
      "  concern: 5.0431\n",
      "  concern for: 5.0431\n",
      "  concern for fairness: 5.0431\n",
      "  created: 4.6376\n",
      "  created by: 5.0431\n",
      "  created by people: 5.0431\n",
      "  domains: 5.0431\n",
      "  domains concern: 5.0431\n",
      "  domains concern for: 5.0431\n",
      "  effective: 4.3499\n",
      "  effective use: 5.0431\n",
      "  effective use of: 5.0431\n",
      "  expressed: 5.0431\n",
      "  expressed by: 5.0431\n",
      "  expressed by artificial: 5.0431\n",
      "  fairness: 4.6376\n",
      "  fairness in: 5.0431\n",
      "  fairness in machine: 5.0431\n",
      "  feifei: 5.0431\n",
      "  feifei li: 5.0431\n",
      "  feifei li who: 5.0431\n",
      "  for: 3.4577\n",
      "  for fairness: 5.0431\n",
      "  for fairness in: 5.0431\n",
      "  for human: 5.0431\n",
      "  for human good: 5.0431\n",
      "  good: 4.6376\n",
      "  good is: 5.0431\n",
      "  good is increasingly: 5.0431\n",
      "  human: 3.6568\n",
      "  human good: 5.0431\n",
      "  human good is: 5.0431\n",
      "  impacts: 4.6376\n",
      "  impacts people: 5.0431\n",
      "  impacts people it: 5.0431\n",
      "  importantlyit: 5.0431\n",
      "  importantlyit impacts: 5.0431\n",
      "  importantlyit impacts people: 5.0431\n",
      "  in: 4.0252\n",
      "  in machine: 7.3135\n",
      "  in machine learning: 7.3135\n",
      "  in other: 4.6376\n",
      "  in other domains: 5.0431\n",
      "  including: 3.4336\n",
      "  including feifei: 5.0431\n",
      "  including feifei li: 5.0431\n",
      "  increasingly: 5.0431\n",
      "  increasingly expressed: 5.0431\n",
      "  increasingly expressed by: 5.0431\n",
      "  inspired: 4.3499\n",
      "  inspired by: 4.3499\n",
      "  inspired by people: 5.0431\n",
      "  intelligence: 3.1712\n",
      "  intelligence scientists: 5.0431\n",
      "  intelligence scientists including: 5.0431\n",
      "  is: 6.0668\n",
      "  is a: 5.0346\n",
      "  is a powerful: 5.0431\n",
      "  is a profound: 5.0431\n",
      "  is increasingly: 5.0431\n",
      "  is increasingly expressed: 5.0431\n",
      "  is reducing: 5.0431\n",
      "  is reducing bias: 5.0431\n",
      "  it: 2.2705\n",
      "  it is: 3.5390\n",
      "  it is a: 4.3499\n",
      "  its: 8.8908\n",
      "  its created: 5.0431\n",
      "  its created by: 5.0431\n",
      "  its inspired: 5.0431\n",
      "  its inspired by: 5.0431\n",
      "  its use: 5.0431\n",
      "  its use for: 5.0431\n",
      "  just: 4.6376\n",
      "  just beginning: 5.0431\n",
      "  just beginning to: 5.0431\n",
      "  learning: 3.8456\n",
      "  learning and: 3.6568\n",
      "  learning and propelling: 5.0431\n",
      "  learning may: 5.0431\n",
      "  learning may take: 5.0431\n",
      "  learning that: 4.3499\n",
      "  learning that is: 5.0431\n",
      "  li: 5.0431\n",
      "  li who: 5.0431\n",
      "  li who said: 5.0431\n",
      "  longer: 5.0431\n",
      "  longer to: 5.0431\n",
      "  longer to be: 5.0431\n",
      "  machine: 4.4206\n",
      "  machine learning: 4.6854\n",
      "  machine learning and: 4.1268\n",
      "  machine learning may: 5.0431\n",
      "  machine learning that: 4.3499\n",
      "  may: 3.2513\n",
      "  may take: 5.0431\n",
      "  may take longer: 5.0431\n",
      "  nothing: 5.0431\n",
      "  nothing artificial: 5.0431\n",
      "  nothing artificial about: 5.0431\n",
      "  of: 2.4288\n",
      "  of machine: 3.0281\n",
      "  of machine learning: 3.0281\n",
      "  of such: 4.6376\n",
      "  of such challenges: 5.0431\n",
      "  only: 3.6568\n",
      "  only just: 5.0431\n",
      "  only just beginning: 5.0431\n",
      "  other: 2.7918\n",
      "  other domains: 5.0431\n",
      "  other domains concern: 5.0431\n",
      "  people: 13.0497\n",
      "  people andmost: 5.0431\n",
      "  people andmost importantlyit: 5.0431\n",
      "  people it: 5.0431\n",
      "  people it is: 5.0431\n",
      "  people its: 5.0431\n",
      "  people its created: 5.0431\n",
      "  powerful: 5.0431\n",
      "  powerful tool: 5.0431\n",
      "  powerful tool we: 5.0431\n",
      "  profound: 5.0431\n",
      "  profound responsibility: 5.0431\n",
      "  propelling: 5.0431\n",
      "  propelling its: 5.0431\n",
      "  propelling its use: 5.0431\n",
      "  reducing: 4.3499\n",
      "  reducing bias: 5.0431\n",
      "  reducing bias in: 5.0431\n",
      "  responsibility: 5.0431\n",
      "  said: 4.3499\n",
      "  said that: 5.0431\n",
      "  said that theres: 5.0431\n",
      "  scientists: 5.0431\n",
      "  scientists including: 5.0431\n",
      "  scientists including feifei: 5.0431\n",
      "  such: 2.4781\n",
      "  such challenges: 5.0431\n",
      "  such challenges the: 5.0431\n",
      "  take: 4.1268\n",
      "  take longer: 5.0431\n",
      "  take longer to: 5.0431\n",
      "  that: 5.0273\n",
      "  that is: 8.6998\n",
      "  that is a: 5.0431\n",
      "  that is reducing: 5.0431\n",
      "  that theres: 5.0431\n",
      "  that theres nothing: 5.0431\n",
      "  the: 1.1929\n",
      "  the effective: 5.0431\n",
      "  the effective use: 5.0431\n",
      "  theres: 5.0431\n",
      "  theres nothing: 5.0431\n",
      "  theres nothing artificial: 5.0431\n",
      "  to: 2.4507\n",
      "  to be: 3.4336\n",
      "  to be adopted: 5.0431\n",
      "  to understand: 5.0431\n",
      "  to understand and: 5.0431\n",
      "  tool: 4.1268\n",
      "  tool we: 5.0431\n",
      "  tool we are: 5.0431\n",
      "  understand: 4.6376\n",
      "  understand and: 5.0431\n",
      "  understand and that: 5.0431\n",
      "  use: 6.6766\n",
      "  use for: 5.0431\n",
      "  use for human: 5.0431\n",
      "  use of: 4.3499\n",
      "  use of machine: 4.6376\n",
      "  we: 4.3499\n",
      "  we are: 5.0431\n",
      "  we are only: 5.0431\n",
      "  who: 3.9444\n",
      "  who said: 5.0431\n",
      "  who said that: 5.0431\n",
      "\n",
      "Document 107:\n",
      "  a: 1.2589\n",
      "  a longstanding: 5.0431\n",
      "  a longstanding ethical: 5.0431\n",
      "  additional: 4.3499\n",
      "  additional tool: 5.0431\n",
      "  additional tool to: 5.0431\n",
      "  algorithms: 4.7378\n",
      "  algorithms could: 5.0431\n",
      "  algorithms could be: 5.0431\n",
      "  algorithms proprietary: 5.0431\n",
      "  algorithms proprietary owners: 5.0431\n",
      "  also: 2.6452\n",
      "  also increasing: 5.0431\n",
      "  also increasing profits: 5.0431\n",
      "  among: 3.9444\n",
      "  among health: 5.0431\n",
      "  among health care: 5.0431\n",
      "  an: 2.1527\n",
      "  an additional: 5.0431\n",
      "  an additional tool: 5.0431\n",
      "  and: 1.2144\n",
      "  and plan: 5.0431\n",
      "  and plan recovery: 5.0431\n",
      "  are: 1.9750\n",
      "  are concerns: 5.0431\n",
      "  are concerns among: 5.0431\n",
      "  as: 1.8444\n",
      "  as incomegenerating: 5.0431\n",
      "  as incomegenerating machines: 5.0431\n",
      "  be: 6.2179\n",
      "  be designed: 10.0861\n",
      "  be designed in: 5.0431\n",
      "  be designed to: 5.0431\n",
      "  be mitigated: 5.0431\n",
      "  biases: 3.7903\n",
      "  biases to: 5.0431\n",
      "  biases to be: 5.0431\n",
      "  but: 9.0844\n",
      "  but also: 4.6376\n",
      "  but also increasing: 5.0431\n",
      "  but as: 5.0431\n",
      "  but as incomegenerating: 5.0431\n",
      "  but this: 5.0431\n",
      "  but this requires: 5.0431\n",
      "  care: 15.1292\n",
      "  care but: 5.0431\n",
      "  care but also: 5.0431\n",
      "  care professionals: 5.0431\n",
      "  care professionals that: 5.0431\n",
      "  care to: 5.0431\n",
      "  care to provide: 5.0431\n",
      "  concerns: 5.0431\n",
      "  concerns among: 5.0431\n",
      "  concerns among health: 5.0431\n",
      "  could: 4.3499\n",
      "  could be: 5.0431\n",
      "  could be designed: 5.0431\n",
      "  designed: 9.2752\n",
      "  designed in: 5.0431\n",
      "  designed in the: 5.0431\n",
      "  designed to: 4.6376\n",
      "  designed to provide: 5.0431\n",
      "  diagnose: 5.0431\n",
      "  diagnose medicate: 5.0431\n",
      "  diagnose medicate and: 5.0431\n",
      "  dilemma: 5.0431\n",
      "  dilemma of: 5.0431\n",
      "  dilemma of improving: 5.0431\n",
      "  especially: 4.1268\n",
      "  especially true: 5.0431\n",
      "  especially true in: 5.0431\n",
      "  ethical: 4.6376\n",
      "  ethical dilemma: 5.0431\n",
      "  ethical dilemma of: 5.0431\n",
      "  example: 2.9636\n",
      "  example the: 4.6376\n",
      "  example the algorithms: 5.0431\n",
      "  for: 5.1866\n",
      "  for example: 3.2513\n",
      "  for example the: 4.6376\n",
      "  for machine: 3.9444\n",
      "  for machine learning: 4.1268\n",
      "  for patients: 5.0431\n",
      "  for patients but: 5.0431\n",
      "  health: 15.1292\n",
      "  health care: 15.1292\n",
      "  health care but: 5.0431\n",
      "  health care professionals: 5.0431\n",
      "  health care to: 5.0431\n",
      "  hold: 5.0431\n",
      "  hold stakes: 5.0431\n",
      "  hold stakes there: 5.0431\n",
      "  improving: 5.0431\n",
      "  improving health: 5.0431\n",
      "  improving health care: 5.0431\n",
      "  in: 5.3670\n",
      "  in health: 5.0431\n",
      "  in health care: 5.0431\n",
      "  in the: 4.8807\n",
      "  in the publics: 5.0431\n",
      "  in the united: 5.0431\n",
      "  in which: 3.7903\n",
      "  in which the: 4.6376\n",
      "  incomegenerating: 5.0431\n",
      "  incomegenerating machines: 5.0431\n",
      "  incomegenerating machines this: 5.0431\n",
      "  increasing: 4.6376\n",
      "  increasing profits: 5.0431\n",
      "  increasing profits for: 5.0431\n",
      "  interest: 4.6376\n",
      "  interest but: 5.0431\n",
      "  interest but as: 5.0431\n",
      "  is: 4.5501\n",
      "  is a: 2.5173\n",
      "  is a longstanding: 5.0431\n",
      "  is especially: 5.0431\n",
      "  is especially true: 5.0431\n",
      "  is potential: 5.0431\n",
      "  is potential for: 5.0431\n",
      "  learning: 1.2819\n",
      "  learning in: 3.6568\n",
      "  learning in health: 5.0431\n",
      "  longstanding: 5.0431\n",
      "  longstanding ethical: 5.0431\n",
      "  longstanding ethical dilemma: 5.0431\n",
      "  machine: 1.4735\n",
      "  machine learning: 1.5618\n",
      "  machine learning in: 4.1268\n",
      "  machines: 3.6568\n",
      "  machines this: 5.0431\n",
      "  machines this is: 5.0431\n",
      "  medicate: 5.0431\n",
      "  medicate and: 5.0431\n",
      "  medicate and plan: 5.0431\n",
      "  medication: 5.0431\n",
      "  medication in: 5.0431\n",
      "  medication in which: 5.0431\n",
      "  might: 4.6376\n",
      "  might not: 5.0431\n",
      "  might not be: 5.0431\n",
      "  mitigated: 5.0431\n",
      "  not: 2.6007\n",
      "  not be: 4.3499\n",
      "  not be designed: 5.0431\n",
      "  of: 1.2144\n",
      "  of improving: 5.0431\n",
      "  of improving health: 5.0431\n",
      "  or: 2.0226\n",
      "  or medication: 5.0431\n",
      "  or medication in: 5.0431\n",
      "  owners: 5.0431\n",
      "  owners hold: 5.0431\n",
      "  owners hold stakes: 5.0431\n",
      "  paths: 5.0431\n",
      "  paths for: 5.0431\n",
      "  paths for patients: 5.0431\n",
      "  patients: 10.0861\n",
      "  patients but: 5.0431\n",
      "  patients but this: 5.0431\n",
      "  patients with: 5.0431\n",
      "  patients with unnecessary: 5.0431\n",
      "  plan: 5.0431\n",
      "  plan recovery: 5.0431\n",
      "  plan recovery paths: 5.0431\n",
      "  potential: 4.1268\n",
      "  potential for: 5.0431\n",
      "  potential for machine: 5.0431\n",
      "  professionals: 10.0861\n",
      "  professionals an: 5.0431\n",
      "  professionals an additional: 5.0431\n",
      "  professionals that: 5.0431\n",
      "  professionals that these: 5.0431\n",
      "  profits: 5.0431\n",
      "  profits for: 5.0431\n",
      "  profits for example: 5.0431\n",
      "  proprietary: 5.0431\n",
      "  proprietary owners: 5.0431\n",
      "  proprietary owners hold: 5.0431\n",
      "  provide: 10.0861\n",
      "  provide patients: 5.0431\n",
      "  provide patients with: 5.0431\n",
      "  provide professionals: 5.0431\n",
      "  provide professionals an: 5.0431\n",
      "  publics: 5.0431\n",
      "  publics interest: 5.0431\n",
      "  publics interest but: 5.0431\n",
      "  recovery: 5.0431\n",
      "  recovery paths: 5.0431\n",
      "  recovery paths for: 5.0431\n",
      "  requires: 5.0431\n",
      "  requires these: 5.0431\n",
      "  requires these biases: 5.0431\n",
      "  stakes: 4.6376\n",
      "  stakes there: 5.0431\n",
      "  stakes there is: 5.0431\n",
      "  states: 5.0431\n",
      "  states where: 5.0431\n",
      "  states where there: 5.0431\n",
      "  systems: 2.6917\n",
      "  systems might: 5.0431\n",
      "  systems might not: 5.0431\n",
      "  tests: 5.0431\n",
      "  tests or: 5.0431\n",
      "  tests or medication: 5.0431\n",
      "  that: 1.6758\n",
      "  that these: 5.0431\n",
      "  that these systems: 5.0431\n",
      "  the: 4.7716\n",
      "  the algorithms: 9.2752\n",
      "  the algorithms could: 5.0431\n",
      "  the algorithms proprietary: 5.0431\n",
      "  the publics: 5.0431\n",
      "  the publics interest: 5.0431\n",
      "  the united: 5.0431\n",
      "  the united states: 5.0431\n",
      "  there: 10.9703\n",
      "  there are: 4.1268\n",
      "  there are concerns: 5.0431\n",
      "  there is: 8.6998\n",
      "  there is a: 4.6376\n",
      "  there is potential: 5.0431\n",
      "  these: 5.8060\n",
      "  these biases: 4.3499\n",
      "  these biases to: 5.0431\n",
      "  these systems: 4.6376\n",
      "  these systems might: 5.0431\n",
      "  this: 5.2014\n",
      "  this is: 4.3499\n",
      "  this is especially: 5.0431\n",
      "  this requires: 5.0431\n",
      "  this requires these: 5.0431\n",
      "  to: 4.9014\n",
      "  to be: 3.4336\n",
      "  to be mitigated: 5.0431\n",
      "  to diagnose: 5.0431\n",
      "  to diagnose medicate: 5.0431\n",
      "  to provide: 10.0861\n",
      "  to provide patients: 5.0431\n",
      "  to provide professionals: 5.0431\n",
      "  tool: 4.1268\n",
      "  tool to: 4.6376\n",
      "  tool to diagnose: 5.0431\n",
      "  true: 4.6376\n",
      "  true in: 5.0431\n",
      "  true in the: 5.0431\n",
      "  united: 5.0431\n",
      "  united states: 5.0431\n",
      "  united states where: 5.0431\n",
      "  unnecessary: 5.0431\n",
      "  unnecessary tests: 5.0431\n",
      "  unnecessary tests or: 5.0431\n",
      "  where: 3.2513\n",
      "  where there: 5.0431\n",
      "  where there is: 5.0431\n",
      "  which: 2.6917\n",
      "  which the: 4.6376\n",
      "  which the algorithms: 5.0431\n",
      "  with: 2.0726\n",
      "  with unnecessary: 5.0431\n",
      "  with unnecessary tests: 5.0431\n",
      "\n",
      "Document 108:\n",
      "  a: 3.7766\n",
      "  a doublingtime: 5.0431\n",
      "  a doublingtime trendline: 5.0431\n",
      "  a fold: 5.0431\n",
      "  a fold increase: 5.0431\n",
      "  a particular: 5.0431\n",
      "  a particular narrow: 5.0431\n",
      "  advances: 4.6376\n",
      "  advances in: 4.6376\n",
      "  advances in both: 5.0431\n",
      "  ai: 3.4336\n",
      "  ai openai: 5.0431\n",
      "  ai openai estimated: 5.0431\n",
      "  aispecific: 5.0431\n",
      "  aispecific enhancements: 5.0431\n",
      "  aispecific enhancements had: 5.0431\n",
      "  alexnet: 5.0431\n",
      "  alexnet to: 5.0431\n",
      "  alexnet to alphazero: 5.0431\n",
      "  algorithms: 2.3689\n",
      "  algorithms and: 4.6376\n",
      "  algorithms and computer: 5.0431\n",
      "  alphazero: 5.0431\n",
      "  alphazero and: 5.0431\n",
      "  alphazero and found: 5.0431\n",
      "  amount: 4.6376\n",
      "  amount of: 4.6376\n",
      "  amount of compute: 5.0431\n",
      "  and: 2.4288\n",
      "  and computer: 4.6376\n",
      "  and computer hardware: 5.0431\n",
      "  and found: 5.0431\n",
      "  and found a: 5.0431\n",
      "  as: 1.8444\n",
      "  as the: 4.3499\n",
      "  as the dominant: 5.0431\n",
      "  both: 3.7903\n",
      "  both machine: 5.0431\n",
      "  both machine learning: 5.0431\n",
      "  by: 1.9076\n",
      "  by graphics: 5.0431\n",
      "  by graphics processing: 5.0431\n",
      "  cloud: 4.3499\n",
      "  cloud ai: 4.6376\n",
      "  cloud ai openai: 5.0431\n",
      "  commercial: 5.0431\n",
      "  commercial cloud: 5.0431\n",
      "  commercial cloud ai: 5.0431\n",
      "  compute: 8.6998\n",
      "  compute required: 5.0431\n",
      "  compute required with: 5.0431\n",
      "  compute used: 5.0431\n",
      "  compute used in: 5.0431\n",
      "  computer: 3.2513\n",
      "  computer hardware: 5.0431\n",
      "  computer hardware have: 5.0431\n",
      "  contain: 4.6376\n",
      "  contain many: 5.0431\n",
      "  contain many layers: 5.0431\n",
      "  cpus: 5.0431\n",
      "  cpus as: 5.0431\n",
      "  cpus as the: 5.0431\n",
      "  deep: 7.3135\n",
      "  deep learning: 3.7903\n",
      "  deep learning projects: 5.0431\n",
      "  deep neural: 4.6376\n",
      "  deep neural networks: 4.6376\n",
      "  displaced: 5.0431\n",
      "  displaced cpus: 5.0431\n",
      "  displaced cpus as: 5.0431\n",
      "  dominant: 5.0431\n",
      "  dominant method: 5.0431\n",
      "  dominant method of: 5.0431\n",
      "  doublingtime: 5.0431\n",
      "  doublingtime trendline: 5.0431\n",
      "  doublingtime trendline of: 5.0431\n",
      "  efficient: 4.3499\n",
      "  efficient methods: 5.0431\n",
      "  efficient methods for: 5.0431\n",
      "  enhancements: 5.0431\n",
      "  enhancements had: 5.0431\n",
      "  enhancements had displaced: 5.0431\n",
      "  estimated: 4.6376\n",
      "  estimated the: 5.0431\n",
      "  estimated the hardware: 5.0431\n",
      "  fold: 5.0431\n",
      "  fold increase: 5.0431\n",
      "  fold increase in: 5.0431\n",
      "  for: 1.7289\n",
      "  for training: 4.1268\n",
      "  for training deep: 5.0431\n",
      "  found: 3.7903\n",
      "  found a: 5.0431\n",
      "  found a fold: 5.0431\n",
      "  from: 2.0726\n",
      "  from alexnet: 5.0431\n",
      "  from alexnet to: 5.0431\n",
      "  gpus: 4.6376\n",
      "  gpus often: 5.0431\n",
      "  gpus often with: 5.0431\n",
      "  graphics: 5.0431\n",
      "  graphics processing: 5.0431\n",
      "  graphics processing units: 5.0431\n",
      "  had: 3.6568\n",
      "  had displaced: 5.0431\n",
      "  had displaced cpus: 5.0431\n",
      "  hardware: 7.8889\n",
      "  hardware compute: 5.0431\n",
      "  hardware compute used: 5.0431\n",
      "  hardware have: 5.0431\n",
      "  hardware have led: 5.0431\n",
      "  have: 2.4781\n",
      "  have led: 5.0431\n",
      "  have led to: 5.0431\n",
      "  hidden: 4.6376\n",
      "  hidden units: 5.0431\n",
      "  hidden units by: 5.0431\n",
      "  in: 4.0252\n",
      "  in both: 5.0431\n",
      "  in both machine: 5.0431\n",
      "  in the: 4.8807\n",
      "  in the amount: 5.0431\n",
      "  in the largest: 5.0431\n",
      "  increase: 5.0431\n",
      "  increase in: 5.0431\n",
      "  increase in the: 5.0431\n",
      "  largescale: 4.1268\n",
      "  largescale commercial: 5.0431\n",
      "  largescale commercial cloud: 5.0431\n",
      "  largest: 5.0431\n",
      "  largest deep: 5.0431\n",
      "  largest deep learning: 5.0431\n",
      "  layers: 4.3499\n",
      "  layers of: 5.0431\n",
      "  layers of nonlinear: 5.0431\n",
      "  learning: 3.8456\n",
      "  learning algorithms: 2.9030\n",
      "  learning algorithms and: 4.6376\n",
      "  learning projects: 5.0431\n",
      "  learning projects from: 5.0431\n",
      "  learning that: 4.3499\n",
      "  learning that contain: 5.0431\n",
      "  led: 5.0431\n",
      "  led to: 5.0431\n",
      "  led to more: 5.0431\n",
      "  machine: 2.9470\n",
      "  machine learning: 3.1236\n",
      "  machine learning algorithms: 3.4336\n",
      "  machine learning that: 4.3499\n",
      "  many: 2.9030\n",
      "  many layers: 5.0431\n",
      "  many layers of: 5.0431\n",
      "  method: 3.6568\n",
      "  method of: 5.0431\n",
      "  method of training: 5.0431\n",
      "  methods: 2.7405\n",
      "  methods for: 5.0431\n",
      "  methods for training: 5.0431\n",
      "  months: 5.0431\n",
      "  more: 3.1712\n",
      "  more efficient: 5.0431\n",
      "  more efficient methods: 5.0431\n",
      "  narrow: 5.0431\n",
      "  narrow subdomain: 5.0431\n",
      "  narrow subdomain of: 5.0431\n",
      "  networks: 3.0971\n",
      "  networks a: 4.6376\n",
      "  networks a particular: 5.0431\n",
      "  neural: 3.0281\n",
      "  neural networks: 3.2513\n",
      "  neural networks a: 4.6376\n",
      "  nonlinear: 3.9444\n",
      "  nonlinear hidden: 5.0431\n",
      "  nonlinear hidden units: 5.0431\n",
      "  of: 6.0720\n",
      "  of compute: 5.0431\n",
      "  of compute required: 5.0431\n",
      "  of machine: 3.0281\n",
      "  of machine learning: 3.0281\n",
      "  of months: 5.0431\n",
      "  of nonlinear: 5.0431\n",
      "  of nonlinear hidden: 5.0431\n",
      "  of training: 4.1268\n",
      "  of training largescale: 5.0431\n",
      "  often: 3.0971\n",
      "  often with: 5.0431\n",
      "  often with aispecific: 5.0431\n",
      "  openai: 5.0431\n",
      "  openai estimated: 5.0431\n",
      "  openai estimated the: 5.0431\n",
      "  particular: 4.3499\n",
      "  particular narrow: 5.0431\n",
      "  particular narrow subdomain: 5.0431\n",
      "  processing: 3.6568\n",
      "  processing units: 4.6376\n",
      "  processing units gpus: 5.0431\n",
      "  projects: 5.0431\n",
      "  projects from: 5.0431\n",
      "  projects from alexnet: 5.0431\n",
      "  required: 4.6376\n",
      "  required with: 5.0431\n",
      "  required with a: 5.0431\n",
      "  s: 3.9444\n",
      "  s advances: 5.0431\n",
      "  s advances in: 5.0431\n",
      "  since: 4.3499\n",
      "  since the: 5.0431\n",
      "  since the s: 5.0431\n",
      "  subdomain: 5.0431\n",
      "  subdomain of: 5.0431\n",
      "  subdomain of machine: 5.0431\n",
      "  that: 1.6758\n",
      "  that contain: 5.0431\n",
      "  that contain many: 5.0431\n",
      "  the: 5.9645\n",
      "  the amount: 5.0431\n",
      "  the amount of: 5.0431\n",
      "  the dominant: 5.0431\n",
      "  the dominant method: 5.0431\n",
      "  the hardware: 5.0431\n",
      "  the hardware compute: 5.0431\n",
      "  the largest: 5.0431\n",
      "  the largest deep: 5.0431\n",
      "  the s: 3.9444\n",
      "  the s advances: 5.0431\n",
      "  to: 2.4507\n",
      "  to alphazero: 5.0431\n",
      "  to alphazero and: 5.0431\n",
      "  to more: 5.0431\n",
      "  to more efficient: 5.0431\n",
      "  training: 5.1163\n",
      "  training deep: 5.0431\n",
      "  training deep neural: 5.0431\n",
      "  training largescale: 5.0431\n",
      "  training largescale commercial: 5.0431\n",
      "  trendline: 4.6376\n",
      "  trendline of: 5.0431\n",
      "  trendline of months: 5.0431\n",
      "  units: 8.6998\n",
      "  units by: 5.0431\n",
      "  units by graphics: 5.0431\n",
      "  units gpus: 5.0431\n",
      "  units gpus often: 5.0431\n",
      "  used: 2.3350\n",
      "  used in: 3.4336\n",
      "  used in the: 4.6376\n",
      "  with: 4.1453\n",
      "  with a: 3.6568\n",
      "  with a doublingtime: 5.0431\n",
      "  with aispecific: 5.0431\n",
      "  with aispecific enhancements: 5.0431\n",
      "\n",
      "Document 109:\n",
      "  a: 1.2589\n",
      "  a key: 5.0431\n",
      "  a key component: 5.0431\n",
      "  accelerate: 5.0431\n",
      "  accelerate computations: 5.0431\n",
      "  accelerate computations while: 5.0431\n",
      "  accelerators: 5.0431\n",
      "  accelerators developed: 5.0431\n",
      "  accelerators developed by: 5.0431\n",
      "  ai: 6.8672\n",
      "  ai infrastructure: 5.0431\n",
      "  ai infrastructure especially: 5.0431\n",
      "  ai services: 5.0431\n",
      "  ai services and: 5.0431\n",
      "  alphafold: 5.0431\n",
      "  alphafold and: 5.0431\n",
      "  alphafold and large: 5.0431\n",
      "  and: 6.0720\n",
      "  and fpgas: 5.0431\n",
      "  and fpgas tpus: 5.0431\n",
      "  and highbandwidth: 5.0431\n",
      "  and highbandwidth memory: 5.0431\n",
      "  and inference: 5.0431\n",
      "  and inference they: 5.0431\n",
      "  and large: 5.0431\n",
      "  and large language: 5.0431\n",
      "  and largescale: 5.0431\n",
      "  and largescale machine: 5.0431\n",
      "  are: 5.9250\n",
      "  are optimised: 5.0431\n",
      "  are optimised for: 5.0431\n",
      "  are specialised: 5.0431\n",
      "  are specialised hardware: 5.0431\n",
      "  are widely: 5.0431\n",
      "  are widely used: 5.0431\n",
      "  as: 1.8444\n",
      "  as training: 4.6376\n",
      "  as training and: 5.0431\n",
      "  become: 5.0431\n",
      "  become a: 5.0431\n",
      "  become a key: 5.0431\n",
      "  by: 1.9076\n",
      "  by google: 5.0431\n",
      "  by google specifically: 5.0431\n",
      "  cloud: 4.3499\n",
      "  cloud ai: 4.6376\n",
      "  cloud ai services: 5.0431\n",
      "  cloudbased: 5.0431\n",
      "  cloudbased environments: 5.0431\n",
      "  component: 3.9444\n",
      "  component of: 5.0431\n",
      "  component of ai: 5.0431\n",
      "  computations: 10.0861\n",
      "  computations making: 5.0431\n",
      "  computations making them: 5.0431\n",
      "  computations while: 5.0431\n",
      "  computations while maintaining: 5.0431\n",
      "  deep: 3.6568\n",
      "  deep learning: 3.7903\n",
      "  deep learning tasks: 5.0431\n",
      "  deepmind: 5.0431\n",
      "  deepmind alphafold: 5.0431\n",
      "  deepmind alphafold and: 5.0431\n",
      "  developed: 3.7903\n",
      "  developed by: 4.6376\n",
      "  developed by google: 5.0431\n",
      "  efficiency: 4.3499\n",
      "  efficiency since: 5.0431\n",
      "  efficiency since their: 5.0431\n",
      "  efficient: 4.3499\n",
      "  efficient for: 5.0431\n",
      "  efficient for deep: 5.0431\n",
      "  energy: 5.0431\n",
      "  energy efficiency: 5.0431\n",
      "  energy efficiency since: 5.0431\n",
      "  environments: 4.6376\n",
      "  especially: 4.1268\n",
      "  especially in: 4.6376\n",
      "  especially in cloudbased: 5.0431\n",
      "  for: 5.1866\n",
      "  for deep: 4.6376\n",
      "  for deep learning: 4.6376\n",
      "  for machine: 3.9444\n",
      "  for machine learning: 4.1268\n",
      "  for tensor: 5.0431\n",
      "  for tensor computations: 5.0431\n",
      "  fpgas: 5.0431\n",
      "  fpgas tpus: 5.0431\n",
      "  fpgas tpus are: 5.0431\n",
      "  generalpurpose: 5.0431\n",
      "  generalpurpose gpus: 5.0431\n",
      "  generalpurpose gpus and: 5.0431\n",
      "  google: 8.6998\n",
      "  google cloud: 5.0431\n",
      "  google cloud ai: 5.0431\n",
      "  google specifically: 5.0431\n",
      "  google specifically for: 5.0431\n",
      "  googles: 5.0431\n",
      "  googles deepmind: 5.0431\n",
      "  googles deepmind alphafold: 5.0431\n",
      "  gpus: 4.6376\n",
      "  gpus and: 5.0431\n",
      "  gpus and fpgas: 5.0431\n",
      "  hardware: 3.9444\n",
      "  hardware accelerators: 5.0431\n",
      "  hardware accelerators developed: 5.0431\n",
      "  have: 2.4781\n",
      "  have become: 5.0431\n",
      "  have become a: 5.0431\n",
      "  highbandwidth: 5.0431\n",
      "  highbandwidth memory: 5.0431\n",
      "  highbandwidth memory to: 5.0431\n",
      "  in: 4.0252\n",
      "  in cloudbased: 5.0431\n",
      "  in cloudbased environments: 5.0431\n",
      "  in google: 4.6376\n",
      "  in google cloud: 5.0431\n",
      "  in tpus: 5.0431\n",
      "  in tpus have: 5.0431\n",
      "  inference: 4.3499\n",
      "  inference they: 5.0431\n",
      "  inference they are: 5.0431\n",
      "  infrastructure: 5.0431\n",
      "  infrastructure especially: 5.0431\n",
      "  infrastructure especially in: 5.0431\n",
      "  introduction: 5.0431\n",
      "  introduction in: 5.0431\n",
      "  introduction in tpus: 5.0431\n",
      "  key: 3.9444\n",
      "  key component: 5.0431\n",
      "  key component of: 5.0431\n",
      "  language: 3.9444\n",
      "  language models: 4.6376\n",
      "  language models tpus: 5.0431\n",
      "  large: 3.9444\n",
      "  large language: 5.0431\n",
      "  large language models: 5.0431\n",
      "  largescale: 4.1268\n",
      "  largescale machine: 5.0431\n",
      "  largescale machine learning: 5.0431\n",
      "  learning: 3.8456\n",
      "  learning models: 3.7903\n",
      "  learning models like: 5.0431\n",
      "  learning tasks: 4.6376\n",
      "  learning tasks such: 4.6376\n",
      "  learning workloads: 5.0431\n",
      "  learning workloads unlike: 5.0431\n",
      "  leverage: 4.6376\n",
      "  leverage matrix: 5.0431\n",
      "  leverage matrix multiplication: 5.0431\n",
      "  like: 3.3383\n",
      "  like googles: 5.0431\n",
      "  like googles deepmind: 5.0431\n",
      "  machine: 2.9470\n",
      "  machine learning: 3.1236\n",
      "  machine learning models: 3.7903\n",
      "  machine learning workloads: 5.0431\n",
      "  maintaining: 5.0431\n",
      "  maintaining energy: 5.0431\n",
      "  maintaining energy efficiency: 5.0431\n",
      "  making: 4.1268\n",
      "  making them: 5.0431\n",
      "  making them particularly: 5.0431\n",
      "  matrix: 3.9444\n",
      "  matrix multiplication: 5.0431\n",
      "  matrix multiplication units: 5.0431\n",
      "  memory: 4.3499\n",
      "  memory to: 5.0431\n",
      "  memory to accelerate: 5.0431\n",
      "  models: 5.1163\n",
      "  models like: 5.0431\n",
      "  models like googles: 5.0431\n",
      "  models tpus: 5.0431\n",
      "  models tpus leverage: 5.0431\n",
      "  multiplication: 5.0431\n",
      "  multiplication units: 5.0431\n",
      "  multiplication units and: 5.0431\n",
      "  of: 1.2144\n",
      "  of ai: 4.1268\n",
      "  of ai infrastructure: 5.0431\n",
      "  optimised: 5.0431\n",
      "  optimised for: 5.0431\n",
      "  optimised for tensor: 5.0431\n",
      "  particularly: 4.1268\n",
      "  particularly efficient: 5.0431\n",
      "  particularly efficient for: 5.0431\n",
      "  processing: 3.6568\n",
      "  processing units: 4.6376\n",
      "  processing units tpus: 5.0431\n",
      "  services: 5.0431\n",
      "  services and: 5.0431\n",
      "  services and largescale: 5.0431\n",
      "  since: 4.3499\n",
      "  since their: 5.0431\n",
      "  since their introduction: 5.0431\n",
      "  specialised: 4.6376\n",
      "  specialised hardware: 4.6376\n",
      "  specialised hardware accelerators: 5.0431\n",
      "  specifically: 4.6376\n",
      "  specifically for: 5.0431\n",
      "  specifically for machine: 5.0431\n",
      "  such: 2.4781\n",
      "  such as: 2.8458\n",
      "  such as training: 5.0431\n",
      "  tasks: 3.4336\n",
      "  tasks such: 4.1268\n",
      "  tasks such as: 4.1268\n",
      "  tensor: 9.2752\n",
      "  tensor computations: 5.0431\n",
      "  tensor computations making: 5.0431\n",
      "  tensor processing: 5.0431\n",
      "  tensor processing units: 5.0431\n",
      "  their: 2.7918\n",
      "  their introduction: 5.0431\n",
      "  their introduction in: 5.0431\n",
      "  them: 4.3499\n",
      "  them particularly: 5.0431\n",
      "  them particularly efficient: 5.0431\n",
      "  they: 3.4336\n",
      "  they are: 4.6376\n",
      "  they are widely: 5.0431\n",
      "  to: 1.2253\n",
      "  to accelerate: 5.0431\n",
      "  to accelerate computations: 5.0431\n",
      "  tpus: 20.1722\n",
      "  tpus are: 10.0861\n",
      "  tpus are optimised: 5.0431\n",
      "  tpus are specialised: 5.0431\n",
      "  tpus have: 5.0431\n",
      "  tpus have become: 5.0431\n",
      "  tpus leverage: 5.0431\n",
      "  tpus leverage matrix: 5.0431\n",
      "  training: 2.5581\n",
      "  training and: 4.6376\n",
      "  training and inference: 5.0431\n",
      "  units: 8.6998\n",
      "  units and: 5.0431\n",
      "  units and highbandwidth: 5.0431\n",
      "  units tpus: 5.0431\n",
      "  units tpus are: 5.0431\n",
      "  unlike: 4.6376\n",
      "  unlike generalpurpose: 5.0431\n",
      "  unlike generalpurpose gpus: 5.0431\n",
      "  used: 2.3350\n",
      "  used in: 3.4336\n",
      "  used in google: 5.0431\n",
      "  while: 3.4336\n",
      "  while maintaining: 5.0431\n",
      "  while maintaining energy: 5.0431\n",
      "  widely: 4.6376\n",
      "  widely used: 5.0431\n",
      "  widely used in: 5.0431\n",
      "  workloads: 5.0431\n",
      "  workloads unlike: 5.0431\n",
      "  workloads unlike generalpurpose: 5.0431\n",
      "\n",
      "Document 110:\n",
      "  a: 1.2589\n",
      "  a class: 4.6376\n",
      "  a class of: 4.6376\n",
      "  and: 1.2144\n",
      "  and functionality: 5.0431\n",
      "  and functionality of: 5.0431\n",
      "  architectures: 5.0431\n",
      "  be: 2.0726\n",
      "  be implemented: 5.0431\n",
      "  be implemented through: 5.0431\n",
      "  biological: 4.3499\n",
      "  biological neural: 4.6376\n",
      "  biological neural networks: 4.6376\n",
      "  class: 3.5390\n",
      "  class of: 3.9444\n",
      "  class of computing: 5.0431\n",
      "  computing: 7.8889\n",
      "  computing refers: 5.0431\n",
      "  computing refers to: 5.0431\n",
      "  computing systems: 4.6376\n",
      "  computing systems designed: 5.0431\n",
      "  conventional: 4.6376\n",
      "  conventional hardware: 5.0431\n",
      "  conventional hardware or: 5.0431\n",
      "  designed: 4.6376\n",
      "  designed to: 4.6376\n",
      "  designed to emulate: 5.0431\n",
      "  emulate: 4.6376\n",
      "  emulate the: 4.6376\n",
      "  emulate the structure: 5.0431\n",
      "  functionality: 5.0431\n",
      "  functionality of: 5.0431\n",
      "  functionality of biological: 5.0431\n",
      "  hardware: 7.8889\n",
      "  hardware architectures: 5.0431\n",
      "  hardware or: 5.0431\n",
      "  hardware or through: 5.0431\n",
      "  implemented: 4.6376\n",
      "  implemented through: 5.0431\n",
      "  implemented through softwarebased: 5.0431\n",
      "  may: 3.2513\n",
      "  may be: 4.1268\n",
      "  may be implemented: 5.0431\n",
      "  networks: 3.0971\n",
      "  networks these: 4.6376\n",
      "  networks these systems: 5.0431\n",
      "  neural: 3.0281\n",
      "  neural networks: 3.2513\n",
      "  neural networks these: 4.6376\n",
      "  neuromorphic: 4.6376\n",
      "  neuromorphic computing: 5.0431\n",
      "  neuromorphic computing refers: 5.0431\n",
      "  of: 2.4288\n",
      "  of biological: 5.0431\n",
      "  of biological neural: 5.0431\n",
      "  of computing: 5.0431\n",
      "  of computing systems: 5.0431\n",
      "  on: 2.0473\n",
      "  on conventional: 5.0431\n",
      "  on conventional hardware: 5.0431\n",
      "  or: 2.0226\n",
      "  or through: 5.0431\n",
      "  or through specialised: 5.0431\n",
      "  refers: 4.1268\n",
      "  refers to: 4.1268\n",
      "  refers to a: 4.6376\n",
      "  simulations: 5.0431\n",
      "  simulations on: 5.0431\n",
      "  simulations on conventional: 5.0431\n",
      "  softwarebased: 4.6376\n",
      "  softwarebased simulations: 5.0431\n",
      "  softwarebased simulations on: 5.0431\n",
      "  specialised: 4.6376\n",
      "  specialised hardware: 4.6376\n",
      "  specialised hardware architectures: 5.0431\n",
      "  structure: 4.3499\n",
      "  structure and: 5.0431\n",
      "  structure and functionality: 5.0431\n",
      "  systems: 5.3834\n",
      "  systems designed: 5.0431\n",
      "  systems designed to: 5.0431\n",
      "  systems may: 5.0431\n",
      "  systems may be: 5.0431\n",
      "  the: 1.1929\n",
      "  the structure: 4.6376\n",
      "  the structure and: 5.0431\n",
      "  these: 2.9030\n",
      "  these systems: 4.6376\n",
      "  these systems may: 5.0431\n",
      "  through: 8.2535\n",
      "  through softwarebased: 5.0431\n",
      "  through softwarebased simulations: 5.0431\n",
      "  through specialised: 5.0431\n",
      "  through specialised hardware: 5.0431\n",
      "  to: 2.4507\n",
      "  to a: 3.1712\n",
      "  to a class: 5.0431\n",
      "  to emulate: 4.6376\n",
      "  to emulate the: 4.6376\n",
      "\n",
      "Document 111:\n",
      "  a: 2.5177\n",
      "  a physical: 5.0431\n",
      "  a physical neural: 5.0431\n",
      "  a specific: 4.3499\n",
      "  a specific type: 5.0431\n",
      "  adjustable: 10.0861\n",
      "  adjustable materials: 5.0431\n",
      "  adjustable materials such: 5.0431\n",
      "  adjustable resistance: 5.0431\n",
      "  adjustable resistance to: 5.0431\n",
      "  artificial: 2.7918\n",
      "  artificial neural: 3.7903\n",
      "  artificial neural networks: 4.1268\n",
      "  as: 3.6888\n",
      "  as memristors: 5.0431\n",
      "  as memristors to: 5.0431\n",
      "  as opposed: 5.0431\n",
      "  as opposed to: 5.0431\n",
      "  broadly: 5.0431\n",
      "  broadly refers: 5.0431\n",
      "  broadly refers to: 5.0431\n",
      "  computation: 4.3499\n",
      "  computation as: 5.0431\n",
      "  computation as opposed: 5.0431\n",
      "  electrically: 5.0431\n",
      "  electrically adjustable: 5.0431\n",
      "  electrically adjustable materials: 5.0431\n",
      "  emulate: 4.6376\n",
      "  emulate the: 4.6376\n",
      "  emulate the function: 5.0431\n",
      "  for: 1.7289\n",
      "  for computation: 5.0431\n",
      "  for computation as: 5.0431\n",
      "  function: 3.4336\n",
      "  function of: 4.3499\n",
      "  function of neural: 5.0431\n",
      "  hardware: 7.8889\n",
      "  hardware for: 5.0431\n",
      "  hardware for computation: 5.0431\n",
      "  hardware that: 5.0431\n",
      "  hardware that relies: 5.0431\n",
      "  highlights: 5.0431\n",
      "  highlights the: 5.0431\n",
      "  highlights the use: 5.0431\n",
      "  implementations: 4.6376\n",
      "  implementations it: 5.0431\n",
      "  implementations it broadly: 5.0431\n",
      "  is: 1.5167\n",
      "  is a: 2.5173\n",
      "  is a specific: 5.0431\n",
      "  it: 2.2705\n",
      "  it broadly: 5.0431\n",
      "  it broadly refers: 5.0431\n",
      "  materials: 10.0861\n",
      "  materials such: 5.0431\n",
      "  materials such as: 5.0431\n",
      "  materials with: 5.0431\n",
      "  materials with adjustable: 5.0431\n",
      "  memristors: 5.0431\n",
      "  memristors to: 5.0431\n",
      "  memristors to emulate: 5.0431\n",
      "  network: 7.0779\n",
      "  network highlights: 5.0431\n",
      "  network highlights the: 5.0431\n",
      "  network is: 5.0431\n",
      "  network is a: 5.0431\n",
      "  networks: 3.0971\n",
      "  networks that: 4.3499\n",
      "  networks that use: 5.0431\n",
      "  neural: 15.1407\n",
      "  neural network: 8.2535\n",
      "  neural network highlights: 5.0431\n",
      "  neural network is: 5.0431\n",
      "  neural networks: 3.2513\n",
      "  neural networks that: 4.6376\n",
      "  neural synapses: 10.0861\n",
      "  neural synapses the: 5.0431\n",
      "  neuromorphic: 4.6376\n",
      "  neuromorphic hardware: 5.0431\n",
      "  neuromorphic hardware that: 5.0431\n",
      "  of: 3.6432\n",
      "  of neural: 4.6376\n",
      "  of neural synapses: 5.0431\n",
      "  of neuromorphic: 5.0431\n",
      "  of neuromorphic hardware: 5.0431\n",
      "  of physical: 5.0431\n",
      "  of physical hardware: 5.0431\n",
      "  on: 2.0473\n",
      "  on electrically: 5.0431\n",
      "  on electrically adjustable: 5.0431\n",
      "  opposed: 5.0431\n",
      "  opposed to: 5.0431\n",
      "  opposed to softwarebased: 5.0431\n",
      "  physical: 15.1292\n",
      "  physical hardware: 5.0431\n",
      "  physical hardware for: 5.0431\n",
      "  physical neural: 10.0861\n",
      "  physical neural network: 10.0861\n",
      "  refers: 4.1268\n",
      "  refers to: 4.1268\n",
      "  refers to artificial: 5.0431\n",
      "  relies: 4.6376\n",
      "  relies on: 4.6376\n",
      "  relies on electrically: 5.0431\n",
      "  replicate: 5.0431\n",
      "  replicate neural: 5.0431\n",
      "  replicate neural synapses: 5.0431\n",
      "  resistance: 5.0431\n",
      "  resistance to: 5.0431\n",
      "  resistance to replicate: 5.0431\n",
      "  softwarebased: 4.6376\n",
      "  softwarebased implementations: 5.0431\n",
      "  softwarebased implementations it: 5.0431\n",
      "  specific: 3.7903\n",
      "  specific type: 5.0431\n",
      "  specific type of: 5.0431\n",
      "  such: 2.4781\n",
      "  such as: 2.8458\n",
      "  such as memristors: 5.0431\n",
      "  synapses: 9.2752\n",
      "  synapses the: 5.0431\n",
      "  synapses the term: 5.0431\n",
      "  term: 3.7903\n",
      "  term physical: 5.0431\n",
      "  term physical neural: 5.0431\n",
      "  that: 3.3515\n",
      "  that relies: 5.0431\n",
      "  that relies on: 5.0431\n",
      "  that use: 5.0431\n",
      "  that use materials: 5.0431\n",
      "  the: 3.5787\n",
      "  the function: 4.6376\n",
      "  the function of: 5.0431\n",
      "  the term: 3.9444\n",
      "  the term physical: 5.0431\n",
      "  the use: 5.0431\n",
      "  the use of: 5.0431\n",
      "  to: 4.9014\n",
      "  to artificial: 5.0431\n",
      "  to artificial neural: 5.0431\n",
      "  to emulate: 4.6376\n",
      "  to emulate the: 4.6376\n",
      "  to replicate: 5.0431\n",
      "  to replicate neural: 5.0431\n",
      "  to softwarebased: 5.0431\n",
      "  to softwarebased implementations: 5.0431\n",
      "  type: 4.1268\n",
      "  type of: 4.1268\n",
      "  type of neuromorphic: 5.0431\n",
      "  use: 6.6766\n",
      "  use materials: 5.0431\n",
      "  use materials with: 5.0431\n",
      "  use of: 4.3499\n",
      "  use of physical: 5.0431\n",
      "  with: 2.0726\n",
      "  with adjustable: 5.0431\n",
      "  with adjustable resistance: 5.0431\n",
      "\n",
      "Document 112:\n",
      "  a: 1.2589\n",
      "  a subfield: 5.0431\n",
      "  a subfield of: 5.0431\n",
      "  acceleration: 5.0431\n",
      "  acceleration approximate: 5.0431\n",
      "  acceleration approximate computing: 5.0431\n",
      "  achieved: 5.0431\n",
      "  achieved through: 5.0431\n",
      "  achieved through various: 5.0431\n",
      "  and: 7.2865\n",
      "  and business: 5.0431\n",
      "  and business secrets: 5.0431\n",
      "  and microcontrollers: 5.0431\n",
      "  and microcontrollers running: 5.0431\n",
      "  and model: 5.0431\n",
      "  and model optimisation: 5.0431\n",
      "  and parameter: 5.0431\n",
      "  and parameter sharing: 5.0431\n",
      "  and store: 5.0431\n",
      "  and store data: 5.0431\n",
      "  and theft: 5.0431\n",
      "  and theft of: 5.0431\n",
      "  approximate: 5.0431\n",
      "  approximate computing: 5.0431\n",
      "  approximate computing and: 5.0431\n",
      "  architecture: 5.0431\n",
      "  architecture search: 5.0431\n",
      "  architecture search and: 5.0431\n",
      "  are: 1.9750\n",
      "  are deployed: 5.0431\n",
      "  are deployed on: 5.0431\n",
      "  as: 3.6888\n",
      "  as hardware: 5.0431\n",
      "  as hardware acceleration: 5.0431\n",
      "  as wearable: 5.0431\n",
      "  as wearable computers: 5.0431\n",
      "  be: 2.0726\n",
      "  be achieved: 5.0431\n",
      "  be achieved through: 5.0431\n",
      "  breaches: 5.0431\n",
      "  breaches privacy: 5.0431\n",
      "  breaches privacy leaks: 5.0431\n",
      "  business: 4.6376\n",
      "  business secrets: 5.0431\n",
      "  business secrets embedded: 5.0431\n",
      "  can: 2.1809\n",
      "  can be: 2.7405\n",
      "  can be achieved: 5.0431\n",
      "  cloud: 4.3499\n",
      "  cloud servers: 5.0431\n",
      "  cloud servers for: 5.0431\n",
      "  common: 3.9444\n",
      "  common optimisation: 5.0431\n",
      "  common optimisation techniques: 5.0431\n",
      "  computers: 4.3499\n",
      "  computers edge: 5.0431\n",
      "  computers edge devices: 5.0431\n",
      "  computing: 7.8889\n",
      "  computing and: 5.0431\n",
      "  computing and model: 5.0431\n",
      "  computing resources: 5.0431\n",
      "  computing resources such: 5.0431\n",
      "  data: 5.5950\n",
      "  data and: 3.5390\n",
      "  data and business: 5.0431\n",
      "  data breaches: 5.0431\n",
      "  data breaches privacy: 5.0431\n",
      "  data on: 5.0431\n",
      "  data on cloud: 5.0431\n",
      "  deployed: 5.0431\n",
      "  deployed on: 5.0431\n",
      "  deployed on embedded: 5.0431\n",
      "  devices: 9.2752\n",
      "  devices and: 5.0431\n",
      "  devices and microcontrollers: 5.0431\n",
      "  devices eliminates: 5.0431\n",
      "  devices eliminates the: 5.0431\n",
      "  directly: 4.1268\n",
      "  directly on: 5.0431\n",
      "  directly on these: 5.0431\n",
      "  distillation: 5.0431\n",
      "  distillation lowrank: 5.0431\n",
      "  distillation lowrank factorisation: 5.0431\n",
      "  edge: 5.0431\n",
      "  edge devices: 5.0431\n",
      "  edge devices and: 5.0431\n",
      "  eliminates: 5.0431\n",
      "  eliminates the: 5.0431\n",
      "  eliminates the need: 5.0431\n",
      "  embedded: 15.1292\n",
      "  embedded machine: 10.0861\n",
      "  embedded machine learning: 10.0861\n",
      "  embedded systems: 5.0431\n",
      "  embedded systems with: 5.0431\n",
      "  factorisation: 4.6376\n",
      "  factorisation network: 5.0431\n",
      "  factorisation network architecture: 5.0431\n",
      "  for: 1.7289\n",
      "  for further: 5.0431\n",
      "  for further processing: 5.0431\n",
      "  further: 4.6376\n",
      "  further processing: 5.0431\n",
      "  further processing thereby: 5.0431\n",
      "  hardware: 3.9444\n",
      "  hardware acceleration: 5.0431\n",
      "  hardware acceleration approximate: 5.0431\n",
      "  include: 3.4336\n",
      "  include pruning: 5.0431\n",
      "  include pruning quantisation: 5.0431\n",
      "  intellectual: 5.0431\n",
      "  intellectual property: 5.0431\n",
      "  intellectual property personal: 5.0431\n",
      "  is: 1.5167\n",
      "  is a: 2.5173\n",
      "  is a subfield: 5.0431\n",
      "  knowledge: 3.7903\n",
      "  knowledge distillation: 5.0431\n",
      "  knowledge distillation lowrank: 5.0431\n",
      "  leaks: 5.0431\n",
      "  leaks and: 5.0431\n",
      "  leaks and theft: 5.0431\n",
      "  learning: 3.8456\n",
      "  learning can: 4.6376\n",
      "  learning can be: 4.6376\n",
      "  learning is: 3.0281\n",
      "  learning is a: 4.1268\n",
      "  learning where: 4.6376\n",
      "  learning where models: 5.0431\n",
      "  limited: 4.3499\n",
      "  limited computing: 5.0431\n",
      "  limited computing resources: 5.0431\n",
      "  lowrank: 5.0431\n",
      "  lowrank factorisation: 5.0431\n",
      "  lowrank factorisation network: 5.0431\n",
      "  machine: 4.4206\n",
      "  machine learning: 4.6854\n",
      "  machine learning can: 5.0431\n",
      "  machine learning is: 3.6568\n",
      "  machine learning where: 4.6376\n",
      "  microcontrollers: 5.0431\n",
      "  microcontrollers running: 5.0431\n",
      "  microcontrollers running models: 5.0431\n",
      "  model: 2.3350\n",
      "  model optimisation: 5.0431\n",
      "  model optimisation common: 5.0431\n",
      "  models: 5.1163\n",
      "  models are: 4.1268\n",
      "  models are deployed: 5.0431\n",
      "  models directly: 5.0431\n",
      "  models directly on: 5.0431\n",
      "  need: 4.6376\n",
      "  need to: 4.6376\n",
      "  need to transfer: 5.0431\n",
      "  network: 3.5390\n",
      "  network architecture: 5.0431\n",
      "  network architecture search: 5.0431\n",
      "  of: 3.6432\n",
      "  of data: 3.6568\n",
      "  of data breaches: 5.0431\n",
      "  of intellectual: 5.0431\n",
      "  of intellectual property: 5.0431\n",
      "  of machine: 3.0281\n",
      "  of machine learning: 3.0281\n",
      "  on: 6.1420\n",
      "  on cloud: 5.0431\n",
      "  on cloud servers: 5.0431\n",
      "  on embedded: 5.0431\n",
      "  on embedded systems: 5.0431\n",
      "  on these: 4.6376\n",
      "  on these devices: 5.0431\n",
      "  optimisation: 7.5806\n",
      "  optimisation common: 5.0431\n",
      "  optimisation common optimisation: 5.0431\n",
      "  optimisation techniques: 5.0431\n",
      "  optimisation techniques include: 5.0431\n",
      "  parameter: 5.0431\n",
      "  parameter sharing: 5.0431\n",
      "  personal: 5.0431\n",
      "  personal data: 5.0431\n",
      "  personal data and: 5.0431\n",
      "  privacy: 4.1268\n",
      "  privacy leaks: 5.0431\n",
      "  privacy leaks and: 5.0431\n",
      "  processing: 3.6568\n",
      "  processing thereby: 5.0431\n",
      "  processing thereby reducing: 5.0431\n",
      "  property: 4.6376\n",
      "  property personal: 5.0431\n",
      "  property personal data: 5.0431\n",
      "  pruning: 5.0431\n",
      "  pruning quantisation: 5.0431\n",
      "  pruning quantisation knowledge: 5.0431\n",
      "  quantisation: 5.0431\n",
      "  quantisation knowledge: 5.0431\n",
      "  quantisation knowledge distillation: 5.0431\n",
      "  reducing: 4.3499\n",
      "  reducing the: 4.6376\n",
      "  reducing the risk: 5.0431\n",
      "  resources: 4.6376\n",
      "  resources such: 5.0431\n",
      "  resources such as: 5.0431\n",
      "  risk: 4.6376\n",
      "  risk of: 5.0431\n",
      "  risk of data: 5.0431\n",
      "  running: 5.0431\n",
      "  running models: 5.0431\n",
      "  running models directly: 5.0431\n",
      "  search: 4.3499\n",
      "  search and: 5.0431\n",
      "  search and parameter: 5.0431\n",
      "  secrets: 5.0431\n",
      "  secrets embedded: 5.0431\n",
      "  secrets embedded machine: 5.0431\n",
      "  servers: 5.0431\n",
      "  servers for: 5.0431\n",
      "  servers for further: 5.0431\n",
      "  sharing: 5.0431\n",
      "  store: 4.3499\n",
      "  store data: 5.0431\n",
      "  store data on: 5.0431\n",
      "  subfield: 5.0431\n",
      "  subfield of: 5.0431\n",
      "  subfield of machine: 5.0431\n",
      "  such: 4.9562\n",
      "  such as: 5.6917\n",
      "  such as hardware: 5.0431\n",
      "  such as wearable: 5.0431\n",
      "  systems: 2.6917\n",
      "  systems with: 5.0431\n",
      "  systems with limited: 5.0431\n",
      "  techniques: 6.6766\n",
      "  techniques include: 5.0431\n",
      "  techniques include pruning: 5.0431\n",
      "  techniques such: 5.0431\n",
      "  techniques such as: 5.0431\n",
      "  the: 2.3858\n",
      "  the need: 5.0431\n",
      "  the need to: 5.0431\n",
      "  the risk: 5.0431\n",
      "  the risk of: 5.0431\n",
      "  theft: 5.0431\n",
      "  theft of: 5.0431\n",
      "  theft of intellectual: 5.0431\n",
      "  thereby: 4.1268\n",
      "  thereby reducing: 5.0431\n",
      "  thereby reducing the: 5.0431\n",
      "  these: 2.9030\n",
      "  these devices: 5.0431\n",
      "  these devices eliminates: 5.0431\n",
      "  through: 4.1268\n",
      "  through various: 5.0431\n",
      "  through various techniques: 5.0431\n",
      "  to: 1.2253\n",
      "  to transfer: 5.0431\n",
      "  to transfer and: 5.0431\n",
      "  transfer: 5.0431\n",
      "  transfer and: 5.0431\n",
      "  transfer and store: 5.0431\n",
      "  various: 3.4336\n",
      "  various techniques: 5.0431\n",
      "  various techniques such: 5.0431\n",
      "  wearable: 5.0431\n",
      "  wearable computers: 5.0431\n",
      "  wearable computers edge: 5.0431\n",
      "  where: 3.2513\n",
      "  where models: 5.0431\n",
      "  where models are: 5.0431\n",
      "  with: 2.0726\n",
      "  with limited: 5.0431\n",
      "  with limited computing: 5.0431\n",
      "\n",
      "Document 113:\n",
      "  a: 1.2589\n",
      "  a variety: 4.6376\n",
      "  a variety of: 4.6376\n",
      "  algorithms: 2.3689\n",
      "  algorithms include: 4.6376\n",
      "  algorithms include the: 5.0431\n",
      "  containing: 5.0431\n",
      "  containing a: 5.0431\n",
      "  containing a variety: 5.0431\n",
      "  following: 4.6376\n",
      "  include: 3.4336\n",
      "  include the: 5.0431\n",
      "  include the following: 5.0431\n",
      "  learning: 1.2819\n",
      "  learning algorithms: 2.9030\n",
      "  learning algorithms include: 5.0431\n",
      "  machine: 1.4735\n",
      "  machine learning: 1.5618\n",
      "  machine learning algorithms: 3.4336\n",
      "  of: 1.2144\n",
      "  of machine: 3.0281\n",
      "  of machine learning: 3.0281\n",
      "  software: 3.9444\n",
      "  software suites: 5.0431\n",
      "  software suites containing: 5.0431\n",
      "  suites: 5.0431\n",
      "  suites containing: 5.0431\n",
      "  suites containing a: 5.0431\n",
      "  the: 1.1929\n",
      "  the following: 4.6376\n",
      "  variety: 4.3499\n",
      "  variety of: 4.3499\n",
      "  variety of machine: 5.0431\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTF-IDF: \")\n",
    "for i, tfidf in enumerate(doc_tfidf):\n",
    "    print(f\"\\nDocument {i+1}:\")\n",
    "    for term, score in sorted(tfidf.items()):\n",
    "        print(f\"  {term}: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n5HrNnX4hf6W"
   },
   "source": [
    "# Sklearn Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6nX33dfqhcv9",
    "outputId": "340c00be-dfb6-44f3-cd66-4ef11adf9758"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Fayez\n",
      "[nltk_data]     Siddiqui\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "def generate_ngrams(text, n):\n",
    "    tokens = text.split() \n",
    "    return list(ngrams(tokens, n))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "XE-wzQeUh6jR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document: \n",
      "\n",
      "\n",
      "Unigrams: []\n",
      "\n",
      "Bigrams: []\n",
      "\n",
      "Trigrams: []\n",
      "\n",
      "Document: Machine learning ML is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalise to unseen data and thus perform tasks without explicit instructions Within a subdiscipline in machine learning advances in the field of deep learning have allowed neural networks a class of statistical algorithms to surpass many previous machine learning approaches in performance\n",
      "\n",
      "\n",
      "Unigrams: [('Machine',), ('learning',), ('ML',), ('is',), ('a',), ('field',), ('of',), ('study',), ('in',), ('artificial',), ('intelligence',), ('concerned',), ('with',), ('the',), ('development',), ('and',), ('study',), ('of',), ('statistical',), ('algorithms',), ('that',), ('can',), ('learn',), ('from',), ('data',), ('and',), ('generalise',), ('to',), ('unseen',), ('data',), ('and',), ('thus',), ('perform',), ('tasks',), ('without',), ('explicit',), ('instructions',), ('Within',), ('a',), ('subdiscipline',), ('in',), ('machine',), ('learning',), ('advances',), ('in',), ('the',), ('field',), ('of',), ('deep',), ('learning',), ('have',), ('allowed',), ('neural',), ('networks',), ('a',), ('class',), ('of',), ('statistical',), ('algorithms',), ('to',), ('surpass',), ('many',), ('previous',), ('machine',), ('learning',), ('approaches',), ('in',), ('performance',)]\n",
      "\n",
      "Bigrams: [('Machine', 'learning'), ('learning', 'ML'), ('ML', 'is'), ('is', 'a'), ('a', 'field'), ('field', 'of'), ('of', 'study'), ('study', 'in'), ('in', 'artificial'), ('artificial', 'intelligence'), ('intelligence', 'concerned'), ('concerned', 'with'), ('with', 'the'), ('the', 'development'), ('development', 'and'), ('and', 'study'), ('study', 'of'), ('of', 'statistical'), ('statistical', 'algorithms'), ('algorithms', 'that'), ('that', 'can'), ('can', 'learn'), ('learn', 'from'), ('from', 'data'), ('data', 'and'), ('and', 'generalise'), ('generalise', 'to'), ('to', 'unseen'), ('unseen', 'data'), ('data', 'and'), ('and', 'thus'), ('thus', 'perform'), ('perform', 'tasks'), ('tasks', 'without'), ('without', 'explicit'), ('explicit', 'instructions'), ('instructions', 'Within'), ('Within', 'a'), ('a', 'subdiscipline'), ('subdiscipline', 'in'), ('in', 'machine'), ('machine', 'learning'), ('learning', 'advances'), ('advances', 'in'), ('in', 'the'), ('the', 'field'), ('field', 'of'), ('of', 'deep'), ('deep', 'learning'), ('learning', 'have'), ('have', 'allowed'), ('allowed', 'neural'), ('neural', 'networks'), ('networks', 'a'), ('a', 'class'), ('class', 'of'), ('of', 'statistical'), ('statistical', 'algorithms'), ('algorithms', 'to'), ('to', 'surpass'), ('surpass', 'many'), ('many', 'previous'), ('previous', 'machine'), ('machine', 'learning'), ('learning', 'approaches'), ('approaches', 'in'), ('in', 'performance')]\n",
      "\n",
      "Trigrams: [('Machine', 'learning', 'ML'), ('learning', 'ML', 'is'), ('ML', 'is', 'a'), ('is', 'a', 'field'), ('a', 'field', 'of'), ('field', 'of', 'study'), ('of', 'study', 'in'), ('study', 'in', 'artificial'), ('in', 'artificial', 'intelligence'), ('artificial', 'intelligence', 'concerned'), ('intelligence', 'concerned', 'with'), ('concerned', 'with', 'the'), ('with', 'the', 'development'), ('the', 'development', 'and'), ('development', 'and', 'study'), ('and', 'study', 'of'), ('study', 'of', 'statistical'), ('of', 'statistical', 'algorithms'), ('statistical', 'algorithms', 'that'), ('algorithms', 'that', 'can'), ('that', 'can', 'learn'), ('can', 'learn', 'from'), ('learn', 'from', 'data'), ('from', 'data', 'and'), ('data', 'and', 'generalise'), ('and', 'generalise', 'to'), ('generalise', 'to', 'unseen'), ('to', 'unseen', 'data'), ('unseen', 'data', 'and'), ('data', 'and', 'thus'), ('and', 'thus', 'perform'), ('thus', 'perform', 'tasks'), ('perform', 'tasks', 'without'), ('tasks', 'without', 'explicit'), ('without', 'explicit', 'instructions'), ('explicit', 'instructions', 'Within'), ('instructions', 'Within', 'a'), ('Within', 'a', 'subdiscipline'), ('a', 'subdiscipline', 'in'), ('subdiscipline', 'in', 'machine'), ('in', 'machine', 'learning'), ('machine', 'learning', 'advances'), ('learning', 'advances', 'in'), ('advances', 'in', 'the'), ('in', 'the', 'field'), ('the', 'field', 'of'), ('field', 'of', 'deep'), ('of', 'deep', 'learning'), ('deep', 'learning', 'have'), ('learning', 'have', 'allowed'), ('have', 'allowed', 'neural'), ('allowed', 'neural', 'networks'), ('neural', 'networks', 'a'), ('networks', 'a', 'class'), ('a', 'class', 'of'), ('class', 'of', 'statistical'), ('of', 'statistical', 'algorithms'), ('statistical', 'algorithms', 'to'), ('algorithms', 'to', 'surpass'), ('to', 'surpass', 'many'), ('surpass', 'many', 'previous'), ('many', 'previous', 'machine'), ('previous', 'machine', 'learning'), ('machine', 'learning', 'approaches'), ('learning', 'approaches', 'in'), ('approaches', 'in', 'performance')]\n",
      "\n",
      "Document: ML finds application in many fields including natural language processing computer vision speech recognition email filtering agriculture and medicine The application of ML to business problems is known as predictive analytics\n",
      "\n",
      "\n",
      "Unigrams: [('ML',), ('finds',), ('application',), ('in',), ('many',), ('fields',), ('including',), ('natural',), ('language',), ('processing',), ('computer',), ('vision',), ('speech',), ('recognition',), ('email',), ('filtering',), ('agriculture',), ('and',), ('medicine',), ('The',), ('application',), ('of',), ('ML',), ('to',), ('business',), ('problems',), ('is',), ('known',), ('as',), ('predictive',), ('analytics',)]\n",
      "\n",
      "Bigrams: [('ML', 'finds'), ('finds', 'application'), ('application', 'in'), ('in', 'many'), ('many', 'fields'), ('fields', 'including'), ('including', 'natural'), ('natural', 'language'), ('language', 'processing'), ('processing', 'computer'), ('computer', 'vision'), ('vision', 'speech'), ('speech', 'recognition'), ('recognition', 'email'), ('email', 'filtering'), ('filtering', 'agriculture'), ('agriculture', 'and'), ('and', 'medicine'), ('medicine', 'The'), ('The', 'application'), ('application', 'of'), ('of', 'ML'), ('ML', 'to'), ('to', 'business'), ('business', 'problems'), ('problems', 'is'), ('is', 'known'), ('known', 'as'), ('as', 'predictive'), ('predictive', 'analytics')]\n",
      "\n",
      "Trigrams: [('ML', 'finds', 'application'), ('finds', 'application', 'in'), ('application', 'in', 'many'), ('in', 'many', 'fields'), ('many', 'fields', 'including'), ('fields', 'including', 'natural'), ('including', 'natural', 'language'), ('natural', 'language', 'processing'), ('language', 'processing', 'computer'), ('processing', 'computer', 'vision'), ('computer', 'vision', 'speech'), ('vision', 'speech', 'recognition'), ('speech', 'recognition', 'email'), ('recognition', 'email', 'filtering'), ('email', 'filtering', 'agriculture'), ('filtering', 'agriculture', 'and'), ('agriculture', 'and', 'medicine'), ('and', 'medicine', 'The'), ('medicine', 'The', 'application'), ('The', 'application', 'of'), ('application', 'of', 'ML'), ('of', 'ML', 'to'), ('ML', 'to', 'business'), ('to', 'business', 'problems'), ('business', 'problems', 'is'), ('problems', 'is', 'known'), ('is', 'known', 'as'), ('known', 'as', 'predictive'), ('as', 'predictive', 'analytics')]\n",
      "\n",
      "Document: Statistics and mathematical optimisation mathematical programming methods comprise the foundations of machine learning Data mining is a related field of study focusing on exploratory data analysis EDA via unsupervised learning\n",
      "\n",
      "\n",
      "Unigrams: [('Statistics',), ('and',), ('mathematical',), ('optimisation',), ('mathematical',), ('programming',), ('methods',), ('comprise',), ('the',), ('foundations',), ('of',), ('machine',), ('learning',), ('Data',), ('mining',), ('is',), ('a',), ('related',), ('field',), ('of',), ('study',), ('focusing',), ('on',), ('exploratory',), ('data',), ('analysis',), ('EDA',), ('via',), ('unsupervised',), ('learning',)]\n",
      "\n",
      "Bigrams: [('Statistics', 'and'), ('and', 'mathematical'), ('mathematical', 'optimisation'), ('optimisation', 'mathematical'), ('mathematical', 'programming'), ('programming', 'methods'), ('methods', 'comprise'), ('comprise', 'the'), ('the', 'foundations'), ('foundations', 'of'), ('of', 'machine'), ('machine', 'learning'), ('learning', 'Data'), ('Data', 'mining'), ('mining', 'is'), ('is', 'a'), ('a', 'related'), ('related', 'field'), ('field', 'of'), ('of', 'study'), ('study', 'focusing'), ('focusing', 'on'), ('on', 'exploratory'), ('exploratory', 'data'), ('data', 'analysis'), ('analysis', 'EDA'), ('EDA', 'via'), ('via', 'unsupervised'), ('unsupervised', 'learning')]\n",
      "\n",
      "Trigrams: [('Statistics', 'and', 'mathematical'), ('and', 'mathematical', 'optimisation'), ('mathematical', 'optimisation', 'mathematical'), ('optimisation', 'mathematical', 'programming'), ('mathematical', 'programming', 'methods'), ('programming', 'methods', 'comprise'), ('methods', 'comprise', 'the'), ('comprise', 'the', 'foundations'), ('the', 'foundations', 'of'), ('foundations', 'of', 'machine'), ('of', 'machine', 'learning'), ('machine', 'learning', 'Data'), ('learning', 'Data', 'mining'), ('Data', 'mining', 'is'), ('mining', 'is', 'a'), ('is', 'a', 'related'), ('a', 'related', 'field'), ('related', 'field', 'of'), ('field', 'of', 'study'), ('of', 'study', 'focusing'), ('study', 'focusing', 'on'), ('focusing', 'on', 'exploratory'), ('on', 'exploratory', 'data'), ('exploratory', 'data', 'analysis'), ('data', 'analysis', 'EDA'), ('analysis', 'EDA', 'via'), ('EDA', 'via', 'unsupervised'), ('via', 'unsupervised', 'learning')]\n",
      "\n",
      "Document: From a theoretical viewpoint probably approximately correct learning provides a framework for describing machine learning\n",
      "\n",
      "\n",
      "Unigrams: [('From',), ('a',), ('theoretical',), ('viewpoint',), ('probably',), ('approximately',), ('correct',), ('learning',), ('provides',), ('a',), ('framework',), ('for',), ('describing',), ('machine',), ('learning',)]\n",
      "\n",
      "Bigrams: [('From', 'a'), ('a', 'theoretical'), ('theoretical', 'viewpoint'), ('viewpoint', 'probably'), ('probably', 'approximately'), ('approximately', 'correct'), ('correct', 'learning'), ('learning', 'provides'), ('provides', 'a'), ('a', 'framework'), ('framework', 'for'), ('for', 'describing'), ('describing', 'machine'), ('machine', 'learning')]\n",
      "\n",
      "Trigrams: [('From', 'a', 'theoretical'), ('a', 'theoretical', 'viewpoint'), ('theoretical', 'viewpoint', 'probably'), ('viewpoint', 'probably', 'approximately'), ('probably', 'approximately', 'correct'), ('approximately', 'correct', 'learning'), ('correct', 'learning', 'provides'), ('learning', 'provides', 'a'), ('provides', 'a', 'framework'), ('a', 'framework', 'for'), ('framework', 'for', 'describing'), ('for', 'describing', 'machine'), ('describing', 'machine', 'learning')]\n",
      "\n",
      "Document: The term machine learning was coined in  by Arthur Samuel an IBM employee and pioneer in the field of computer gaming and artificial intelligence The synonym selfteaching computers was also used in this time period\n",
      "\n",
      "\n",
      "Unigrams: [('The',), ('term',), ('machine',), ('learning',), ('was',), ('coined',), ('in',), ('by',), ('Arthur',), ('Samuel',), ('an',), ('IBM',), ('employee',), ('and',), ('pioneer',), ('in',), ('the',), ('field',), ('of',), ('computer',), ('gaming',), ('and',), ('artificial',), ('intelligence',), ('The',), ('synonym',), ('selfteaching',), ('computers',), ('was',), ('also',), ('used',), ('in',), ('this',), ('time',), ('period',)]\n",
      "\n",
      "Bigrams: [('The', 'term'), ('term', 'machine'), ('machine', 'learning'), ('learning', 'was'), ('was', 'coined'), ('coined', 'in'), ('in', 'by'), ('by', 'Arthur'), ('Arthur', 'Samuel'), ('Samuel', 'an'), ('an', 'IBM'), ('IBM', 'employee'), ('employee', 'and'), ('and', 'pioneer'), ('pioneer', 'in'), ('in', 'the'), ('the', 'field'), ('field', 'of'), ('of', 'computer'), ('computer', 'gaming'), ('gaming', 'and'), ('and', 'artificial'), ('artificial', 'intelligence'), ('intelligence', 'The'), ('The', 'synonym'), ('synonym', 'selfteaching'), ('selfteaching', 'computers'), ('computers', 'was'), ('was', 'also'), ('also', 'used'), ('used', 'in'), ('in', 'this'), ('this', 'time'), ('time', 'period')]\n",
      "\n",
      "Trigrams: [('The', 'term', 'machine'), ('term', 'machine', 'learning'), ('machine', 'learning', 'was'), ('learning', 'was', 'coined'), ('was', 'coined', 'in'), ('coined', 'in', 'by'), ('in', 'by', 'Arthur'), ('by', 'Arthur', 'Samuel'), ('Arthur', 'Samuel', 'an'), ('Samuel', 'an', 'IBM'), ('an', 'IBM', 'employee'), ('IBM', 'employee', 'and'), ('employee', 'and', 'pioneer'), ('and', 'pioneer', 'in'), ('pioneer', 'in', 'the'), ('in', 'the', 'field'), ('the', 'field', 'of'), ('field', 'of', 'computer'), ('of', 'computer', 'gaming'), ('computer', 'gaming', 'and'), ('gaming', 'and', 'artificial'), ('and', 'artificial', 'intelligence'), ('artificial', 'intelligence', 'The'), ('intelligence', 'The', 'synonym'), ('The', 'synonym', 'selfteaching'), ('synonym', 'selfteaching', 'computers'), ('selfteaching', 'computers', 'was'), ('computers', 'was', 'also'), ('was', 'also', 'used'), ('also', 'used', 'in'), ('used', 'in', 'this'), ('in', 'this', 'time'), ('this', 'time', 'period')]\n",
      "\n",
      "Document: Although the earliest machine learning model was introduced in the s when Arthur Samuel invented a program that calculated the winning chance in checkers for each side the history of machine learning roots back to decades of human desire and effort to study human cognitive processes In  Canadian psychologist Donald Hebb published the book The Organization of Behavior in which he introduced a theoretical neural structure formed by certain interactions among nerve cells Hebbs model of neurons interacting with one another set a groundwork for how AIs and machine learning algorithms work under nodes or artificial neurons used by computers to communicate data Other researchers who have studied human cognitive systems contributed to the modern machine learning technologies as well including logician Walter Pitts and Warren McCulloch who proposed the early mathematical models of neural networks to come up with algorithms that mirror human thought processes\n",
      "\n",
      "\n",
      "Unigrams: [('Although',), ('the',), ('earliest',), ('machine',), ('learning',), ('model',), ('was',), ('introduced',), ('in',), ('the',), ('s',), ('when',), ('Arthur',), ('Samuel',), ('invented',), ('a',), ('program',), ('that',), ('calculated',), ('the',), ('winning',), ('chance',), ('in',), ('checkers',), ('for',), ('each',), ('side',), ('the',), ('history',), ('of',), ('machine',), ('learning',), ('roots',), ('back',), ('to',), ('decades',), ('of',), ('human',), ('desire',), ('and',), ('effort',), ('to',), ('study',), ('human',), ('cognitive',), ('processes',), ('In',), ('Canadian',), ('psychologist',), ('Donald',), ('Hebb',), ('published',), ('the',), ('book',), ('The',), ('Organization',), ('of',), ('Behavior',), ('in',), ('which',), ('he',), ('introduced',), ('a',), ('theoretical',), ('neural',), ('structure',), ('formed',), ('by',), ('certain',), ('interactions',), ('among',), ('nerve',), ('cells',), ('Hebbs',), ('model',), ('of',), ('neurons',), ('interacting',), ('with',), ('one',), ('another',), ('set',), ('a',), ('groundwork',), ('for',), ('how',), ('AIs',), ('and',), ('machine',), ('learning',), ('algorithms',), ('work',), ('under',), ('nodes',), ('or',), ('artificial',), ('neurons',), ('used',), ('by',), ('computers',), ('to',), ('communicate',), ('data',), ('Other',), ('researchers',), ('who',), ('have',), ('studied',), ('human',), ('cognitive',), ('systems',), ('contributed',), ('to',), ('the',), ('modern',), ('machine',), ('learning',), ('technologies',), ('as',), ('well',), ('including',), ('logician',), ('Walter',), ('Pitts',), ('and',), ('Warren',), ('McCulloch',), ('who',), ('proposed',), ('the',), ('early',), ('mathematical',), ('models',), ('of',), ('neural',), ('networks',), ('to',), ('come',), ('up',), ('with',), ('algorithms',), ('that',), ('mirror',), ('human',), ('thought',), ('processes',)]\n",
      "\n",
      "Bigrams: [('Although', 'the'), ('the', 'earliest'), ('earliest', 'machine'), ('machine', 'learning'), ('learning', 'model'), ('model', 'was'), ('was', 'introduced'), ('introduced', 'in'), ('in', 'the'), ('the', 's'), ('s', 'when'), ('when', 'Arthur'), ('Arthur', 'Samuel'), ('Samuel', 'invented'), ('invented', 'a'), ('a', 'program'), ('program', 'that'), ('that', 'calculated'), ('calculated', 'the'), ('the', 'winning'), ('winning', 'chance'), ('chance', 'in'), ('in', 'checkers'), ('checkers', 'for'), ('for', 'each'), ('each', 'side'), ('side', 'the'), ('the', 'history'), ('history', 'of'), ('of', 'machine'), ('machine', 'learning'), ('learning', 'roots'), ('roots', 'back'), ('back', 'to'), ('to', 'decades'), ('decades', 'of'), ('of', 'human'), ('human', 'desire'), ('desire', 'and'), ('and', 'effort'), ('effort', 'to'), ('to', 'study'), ('study', 'human'), ('human', 'cognitive'), ('cognitive', 'processes'), ('processes', 'In'), ('In', 'Canadian'), ('Canadian', 'psychologist'), ('psychologist', 'Donald'), ('Donald', 'Hebb'), ('Hebb', 'published'), ('published', 'the'), ('the', 'book'), ('book', 'The'), ('The', 'Organization'), ('Organization', 'of'), ('of', 'Behavior'), ('Behavior', 'in'), ('in', 'which'), ('which', 'he'), ('he', 'introduced'), ('introduced', 'a'), ('a', 'theoretical'), ('theoretical', 'neural'), ('neural', 'structure'), ('structure', 'formed'), ('formed', 'by'), ('by', 'certain'), ('certain', 'interactions'), ('interactions', 'among'), ('among', 'nerve'), ('nerve', 'cells'), ('cells', 'Hebbs'), ('Hebbs', 'model'), ('model', 'of'), ('of', 'neurons'), ('neurons', 'interacting'), ('interacting', 'with'), ('with', 'one'), ('one', 'another'), ('another', 'set'), ('set', 'a'), ('a', 'groundwork'), ('groundwork', 'for'), ('for', 'how'), ('how', 'AIs'), ('AIs', 'and'), ('and', 'machine'), ('machine', 'learning'), ('learning', 'algorithms'), ('algorithms', 'work'), ('work', 'under'), ('under', 'nodes'), ('nodes', 'or'), ('or', 'artificial'), ('artificial', 'neurons'), ('neurons', 'used'), ('used', 'by'), ('by', 'computers'), ('computers', 'to'), ('to', 'communicate'), ('communicate', 'data'), ('data', 'Other'), ('Other', 'researchers'), ('researchers', 'who'), ('who', 'have'), ('have', 'studied'), ('studied', 'human'), ('human', 'cognitive'), ('cognitive', 'systems'), ('systems', 'contributed'), ('contributed', 'to'), ('to', 'the'), ('the', 'modern'), ('modern', 'machine'), ('machine', 'learning'), ('learning', 'technologies'), ('technologies', 'as'), ('as', 'well'), ('well', 'including'), ('including', 'logician'), ('logician', 'Walter'), ('Walter', 'Pitts'), ('Pitts', 'and'), ('and', 'Warren'), ('Warren', 'McCulloch'), ('McCulloch', 'who'), ('who', 'proposed'), ('proposed', 'the'), ('the', 'early'), ('early', 'mathematical'), ('mathematical', 'models'), ('models', 'of'), ('of', 'neural'), ('neural', 'networks'), ('networks', 'to'), ('to', 'come'), ('come', 'up'), ('up', 'with'), ('with', 'algorithms'), ('algorithms', 'that'), ('that', 'mirror'), ('mirror', 'human'), ('human', 'thought'), ('thought', 'processes')]\n",
      "\n",
      "Trigrams: [('Although', 'the', 'earliest'), ('the', 'earliest', 'machine'), ('earliest', 'machine', 'learning'), ('machine', 'learning', 'model'), ('learning', 'model', 'was'), ('model', 'was', 'introduced'), ('was', 'introduced', 'in'), ('introduced', 'in', 'the'), ('in', 'the', 's'), ('the', 's', 'when'), ('s', 'when', 'Arthur'), ('when', 'Arthur', 'Samuel'), ('Arthur', 'Samuel', 'invented'), ('Samuel', 'invented', 'a'), ('invented', 'a', 'program'), ('a', 'program', 'that'), ('program', 'that', 'calculated'), ('that', 'calculated', 'the'), ('calculated', 'the', 'winning'), ('the', 'winning', 'chance'), ('winning', 'chance', 'in'), ('chance', 'in', 'checkers'), ('in', 'checkers', 'for'), ('checkers', 'for', 'each'), ('for', 'each', 'side'), ('each', 'side', 'the'), ('side', 'the', 'history'), ('the', 'history', 'of'), ('history', 'of', 'machine'), ('of', 'machine', 'learning'), ('machine', 'learning', 'roots'), ('learning', 'roots', 'back'), ('roots', 'back', 'to'), ('back', 'to', 'decades'), ('to', 'decades', 'of'), ('decades', 'of', 'human'), ('of', 'human', 'desire'), ('human', 'desire', 'and'), ('desire', 'and', 'effort'), ('and', 'effort', 'to'), ('effort', 'to', 'study'), ('to', 'study', 'human'), ('study', 'human', 'cognitive'), ('human', 'cognitive', 'processes'), ('cognitive', 'processes', 'In'), ('processes', 'In', 'Canadian'), ('In', 'Canadian', 'psychologist'), ('Canadian', 'psychologist', 'Donald'), ('psychologist', 'Donald', 'Hebb'), ('Donald', 'Hebb', 'published'), ('Hebb', 'published', 'the'), ('published', 'the', 'book'), ('the', 'book', 'The'), ('book', 'The', 'Organization'), ('The', 'Organization', 'of'), ('Organization', 'of', 'Behavior'), ('of', 'Behavior', 'in'), ('Behavior', 'in', 'which'), ('in', 'which', 'he'), ('which', 'he', 'introduced'), ('he', 'introduced', 'a'), ('introduced', 'a', 'theoretical'), ('a', 'theoretical', 'neural'), ('theoretical', 'neural', 'structure'), ('neural', 'structure', 'formed'), ('structure', 'formed', 'by'), ('formed', 'by', 'certain'), ('by', 'certain', 'interactions'), ('certain', 'interactions', 'among'), ('interactions', 'among', 'nerve'), ('among', 'nerve', 'cells'), ('nerve', 'cells', 'Hebbs'), ('cells', 'Hebbs', 'model'), ('Hebbs', 'model', 'of'), ('model', 'of', 'neurons'), ('of', 'neurons', 'interacting'), ('neurons', 'interacting', 'with'), ('interacting', 'with', 'one'), ('with', 'one', 'another'), ('one', 'another', 'set'), ('another', 'set', 'a'), ('set', 'a', 'groundwork'), ('a', 'groundwork', 'for'), ('groundwork', 'for', 'how'), ('for', 'how', 'AIs'), ('how', 'AIs', 'and'), ('AIs', 'and', 'machine'), ('and', 'machine', 'learning'), ('machine', 'learning', 'algorithms'), ('learning', 'algorithms', 'work'), ('algorithms', 'work', 'under'), ('work', 'under', 'nodes'), ('under', 'nodes', 'or'), ('nodes', 'or', 'artificial'), ('or', 'artificial', 'neurons'), ('artificial', 'neurons', 'used'), ('neurons', 'used', 'by'), ('used', 'by', 'computers'), ('by', 'computers', 'to'), ('computers', 'to', 'communicate'), ('to', 'communicate', 'data'), ('communicate', 'data', 'Other'), ('data', 'Other', 'researchers'), ('Other', 'researchers', 'who'), ('researchers', 'who', 'have'), ('who', 'have', 'studied'), ('have', 'studied', 'human'), ('studied', 'human', 'cognitive'), ('human', 'cognitive', 'systems'), ('cognitive', 'systems', 'contributed'), ('systems', 'contributed', 'to'), ('contributed', 'to', 'the'), ('to', 'the', 'modern'), ('the', 'modern', 'machine'), ('modern', 'machine', 'learning'), ('machine', 'learning', 'technologies'), ('learning', 'technologies', 'as'), ('technologies', 'as', 'well'), ('as', 'well', 'including'), ('well', 'including', 'logician'), ('including', 'logician', 'Walter'), ('logician', 'Walter', 'Pitts'), ('Walter', 'Pitts', 'and'), ('Pitts', 'and', 'Warren'), ('and', 'Warren', 'McCulloch'), ('Warren', 'McCulloch', 'who'), ('McCulloch', 'who', 'proposed'), ('who', 'proposed', 'the'), ('proposed', 'the', 'early'), ('the', 'early', 'mathematical'), ('early', 'mathematical', 'models'), ('mathematical', 'models', 'of'), ('models', 'of', 'neural'), ('of', 'neural', 'networks'), ('neural', 'networks', 'to'), ('networks', 'to', 'come'), ('to', 'come', 'up'), ('come', 'up', 'with'), ('up', 'with', 'algorithms'), ('with', 'algorithms', 'that'), ('algorithms', 'that', 'mirror'), ('that', 'mirror', 'human'), ('mirror', 'human', 'thought'), ('human', 'thought', 'processes')]\n",
      "\n",
      "Document: By the early s an experimental learning machine with punched tape memory called Cybertron had been developed by Raytheon Company to analyse sonar signals electrocardiograms and speech patterns using rudimentary reinforcement learning It was repetitively trained by a human operatorteacher to recognise patterns and equipped with a goof button to cause it to reevaluate incorrect decisions A representative book on research into machine learning during the s was Nilssons book on Learning Machines dealing mostly with machine learning for pattern classification Interest related to pattern recognition continued into the s as described by Duda and Hart in  In  a report was given on using teaching strategies so that an artificial neural network learns to recognise  characters  letters  digits and  special symbols from a computer terminal\n",
      "\n",
      "\n",
      "Unigrams: [('By',), ('the',), ('early',), ('s',), ('an',), ('experimental',), ('learning',), ('machine',), ('with',), ('punched',), ('tape',), ('memory',), ('called',), ('Cybertron',), ('had',), ('been',), ('developed',), ('by',), ('Raytheon',), ('Company',), ('to',), ('analyse',), ('sonar',), ('signals',), ('electrocardiograms',), ('and',), ('speech',), ('patterns',), ('using',), ('rudimentary',), ('reinforcement',), ('learning',), ('It',), ('was',), ('repetitively',), ('trained',), ('by',), ('a',), ('human',), ('operatorteacher',), ('to',), ('recognise',), ('patterns',), ('and',), ('equipped',), ('with',), ('a',), ('goof',), ('button',), ('to',), ('cause',), ('it',), ('to',), ('reevaluate',), ('incorrect',), ('decisions',), ('A',), ('representative',), ('book',), ('on',), ('research',), ('into',), ('machine',), ('learning',), ('during',), ('the',), ('s',), ('was',), ('Nilssons',), ('book',), ('on',), ('Learning',), ('Machines',), ('dealing',), ('mostly',), ('with',), ('machine',), ('learning',), ('for',), ('pattern',), ('classification',), ('Interest',), ('related',), ('to',), ('pattern',), ('recognition',), ('continued',), ('into',), ('the',), ('s',), ('as',), ('described',), ('by',), ('Duda',), ('and',), ('Hart',), ('in',), ('In',), ('a',), ('report',), ('was',), ('given',), ('on',), ('using',), ('teaching',), ('strategies',), ('so',), ('that',), ('an',), ('artificial',), ('neural',), ('network',), ('learns',), ('to',), ('recognise',), ('characters',), ('letters',), ('digits',), ('and',), ('special',), ('symbols',), ('from',), ('a',), ('computer',), ('terminal',)]\n",
      "\n",
      "Bigrams: [('By', 'the'), ('the', 'early'), ('early', 's'), ('s', 'an'), ('an', 'experimental'), ('experimental', 'learning'), ('learning', 'machine'), ('machine', 'with'), ('with', 'punched'), ('punched', 'tape'), ('tape', 'memory'), ('memory', 'called'), ('called', 'Cybertron'), ('Cybertron', 'had'), ('had', 'been'), ('been', 'developed'), ('developed', 'by'), ('by', 'Raytheon'), ('Raytheon', 'Company'), ('Company', 'to'), ('to', 'analyse'), ('analyse', 'sonar'), ('sonar', 'signals'), ('signals', 'electrocardiograms'), ('electrocardiograms', 'and'), ('and', 'speech'), ('speech', 'patterns'), ('patterns', 'using'), ('using', 'rudimentary'), ('rudimentary', 'reinforcement'), ('reinforcement', 'learning'), ('learning', 'It'), ('It', 'was'), ('was', 'repetitively'), ('repetitively', 'trained'), ('trained', 'by'), ('by', 'a'), ('a', 'human'), ('human', 'operatorteacher'), ('operatorteacher', 'to'), ('to', 'recognise'), ('recognise', 'patterns'), ('patterns', 'and'), ('and', 'equipped'), ('equipped', 'with'), ('with', 'a'), ('a', 'goof'), ('goof', 'button'), ('button', 'to'), ('to', 'cause'), ('cause', 'it'), ('it', 'to'), ('to', 'reevaluate'), ('reevaluate', 'incorrect'), ('incorrect', 'decisions'), ('decisions', 'A'), ('A', 'representative'), ('representative', 'book'), ('book', 'on'), ('on', 'research'), ('research', 'into'), ('into', 'machine'), ('machine', 'learning'), ('learning', 'during'), ('during', 'the'), ('the', 's'), ('s', 'was'), ('was', 'Nilssons'), ('Nilssons', 'book'), ('book', 'on'), ('on', 'Learning'), ('Learning', 'Machines'), ('Machines', 'dealing'), ('dealing', 'mostly'), ('mostly', 'with'), ('with', 'machine'), ('machine', 'learning'), ('learning', 'for'), ('for', 'pattern'), ('pattern', 'classification'), ('classification', 'Interest'), ('Interest', 'related'), ('related', 'to'), ('to', 'pattern'), ('pattern', 'recognition'), ('recognition', 'continued'), ('continued', 'into'), ('into', 'the'), ('the', 's'), ('s', 'as'), ('as', 'described'), ('described', 'by'), ('by', 'Duda'), ('Duda', 'and'), ('and', 'Hart'), ('Hart', 'in'), ('in', 'In'), ('In', 'a'), ('a', 'report'), ('report', 'was'), ('was', 'given'), ('given', 'on'), ('on', 'using'), ('using', 'teaching'), ('teaching', 'strategies'), ('strategies', 'so'), ('so', 'that'), ('that', 'an'), ('an', 'artificial'), ('artificial', 'neural'), ('neural', 'network'), ('network', 'learns'), ('learns', 'to'), ('to', 'recognise'), ('recognise', 'characters'), ('characters', 'letters'), ('letters', 'digits'), ('digits', 'and'), ('and', 'special'), ('special', 'symbols'), ('symbols', 'from'), ('from', 'a'), ('a', 'computer'), ('computer', 'terminal')]\n",
      "\n",
      "Trigrams: [('By', 'the', 'early'), ('the', 'early', 's'), ('early', 's', 'an'), ('s', 'an', 'experimental'), ('an', 'experimental', 'learning'), ('experimental', 'learning', 'machine'), ('learning', 'machine', 'with'), ('machine', 'with', 'punched'), ('with', 'punched', 'tape'), ('punched', 'tape', 'memory'), ('tape', 'memory', 'called'), ('memory', 'called', 'Cybertron'), ('called', 'Cybertron', 'had'), ('Cybertron', 'had', 'been'), ('had', 'been', 'developed'), ('been', 'developed', 'by'), ('developed', 'by', 'Raytheon'), ('by', 'Raytheon', 'Company'), ('Raytheon', 'Company', 'to'), ('Company', 'to', 'analyse'), ('to', 'analyse', 'sonar'), ('analyse', 'sonar', 'signals'), ('sonar', 'signals', 'electrocardiograms'), ('signals', 'electrocardiograms', 'and'), ('electrocardiograms', 'and', 'speech'), ('and', 'speech', 'patterns'), ('speech', 'patterns', 'using'), ('patterns', 'using', 'rudimentary'), ('using', 'rudimentary', 'reinforcement'), ('rudimentary', 'reinforcement', 'learning'), ('reinforcement', 'learning', 'It'), ('learning', 'It', 'was'), ('It', 'was', 'repetitively'), ('was', 'repetitively', 'trained'), ('repetitively', 'trained', 'by'), ('trained', 'by', 'a'), ('by', 'a', 'human'), ('a', 'human', 'operatorteacher'), ('human', 'operatorteacher', 'to'), ('operatorteacher', 'to', 'recognise'), ('to', 'recognise', 'patterns'), ('recognise', 'patterns', 'and'), ('patterns', 'and', 'equipped'), ('and', 'equipped', 'with'), ('equipped', 'with', 'a'), ('with', 'a', 'goof'), ('a', 'goof', 'button'), ('goof', 'button', 'to'), ('button', 'to', 'cause'), ('to', 'cause', 'it'), ('cause', 'it', 'to'), ('it', 'to', 'reevaluate'), ('to', 'reevaluate', 'incorrect'), ('reevaluate', 'incorrect', 'decisions'), ('incorrect', 'decisions', 'A'), ('decisions', 'A', 'representative'), ('A', 'representative', 'book'), ('representative', 'book', 'on'), ('book', 'on', 'research'), ('on', 'research', 'into'), ('research', 'into', 'machine'), ('into', 'machine', 'learning'), ('machine', 'learning', 'during'), ('learning', 'during', 'the'), ('during', 'the', 's'), ('the', 's', 'was'), ('s', 'was', 'Nilssons'), ('was', 'Nilssons', 'book'), ('Nilssons', 'book', 'on'), ('book', 'on', 'Learning'), ('on', 'Learning', 'Machines'), ('Learning', 'Machines', 'dealing'), ('Machines', 'dealing', 'mostly'), ('dealing', 'mostly', 'with'), ('mostly', 'with', 'machine'), ('with', 'machine', 'learning'), ('machine', 'learning', 'for'), ('learning', 'for', 'pattern'), ('for', 'pattern', 'classification'), ('pattern', 'classification', 'Interest'), ('classification', 'Interest', 'related'), ('Interest', 'related', 'to'), ('related', 'to', 'pattern'), ('to', 'pattern', 'recognition'), ('pattern', 'recognition', 'continued'), ('recognition', 'continued', 'into'), ('continued', 'into', 'the'), ('into', 'the', 's'), ('the', 's', 'as'), ('s', 'as', 'described'), ('as', 'described', 'by'), ('described', 'by', 'Duda'), ('by', 'Duda', 'and'), ('Duda', 'and', 'Hart'), ('and', 'Hart', 'in'), ('Hart', 'in', 'In'), ('in', 'In', 'a'), ('In', 'a', 'report'), ('a', 'report', 'was'), ('report', 'was', 'given'), ('was', 'given', 'on'), ('given', 'on', 'using'), ('on', 'using', 'teaching'), ('using', 'teaching', 'strategies'), ('teaching', 'strategies', 'so'), ('strategies', 'so', 'that'), ('so', 'that', 'an'), ('that', 'an', 'artificial'), ('an', 'artificial', 'neural'), ('artificial', 'neural', 'network'), ('neural', 'network', 'learns'), ('network', 'learns', 'to'), ('learns', 'to', 'recognise'), ('to', 'recognise', 'characters'), ('recognise', 'characters', 'letters'), ('characters', 'letters', 'digits'), ('letters', 'digits', 'and'), ('digits', 'and', 'special'), ('and', 'special', 'symbols'), ('special', 'symbols', 'from'), ('symbols', 'from', 'a'), ('from', 'a', 'computer'), ('a', 'computer', 'terminal')]\n",
      "\n",
      "Document: Tom M Mitchell provided a widely quoted more formal definition of the algorithms studied in the machine learning field A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T as measured by P  improves with experience E This definition of the tasks in which machine learning is concerned offers a fundamentally operational definition rather than defining the field in cognitive terms This follows Alan Turings proposal in his paper Computing Machinery and Intelligence in which the question Can machines think is replaced with the question Can machines do what we as thinking entities can do\n",
      "\n",
      "\n",
      "Unigrams: [('Tom',), ('M',), ('Mitchell',), ('provided',), ('a',), ('widely',), ('quoted',), ('more',), ('formal',), ('definition',), ('of',), ('the',), ('algorithms',), ('studied',), ('in',), ('the',), ('machine',), ('learning',), ('field',), ('A',), ('computer',), ('program',), ('is',), ('said',), ('to',), ('learn',), ('from',), ('experience',), ('E',), ('with',), ('respect',), ('to',), ('some',), ('class',), ('of',), ('tasks',), ('T',), ('and',), ('performance',), ('measure',), ('P',), ('if',), ('its',), ('performance',), ('at',), ('tasks',), ('in',), ('T',), ('as',), ('measured',), ('by',), ('P',), ('improves',), ('with',), ('experience',), ('E',), ('This',), ('definition',), ('of',), ('the',), ('tasks',), ('in',), ('which',), ('machine',), ('learning',), ('is',), ('concerned',), ('offers',), ('a',), ('fundamentally',), ('operational',), ('definition',), ('rather',), ('than',), ('defining',), ('the',), ('field',), ('in',), ('cognitive',), ('terms',), ('This',), ('follows',), ('Alan',), ('Turings',), ('proposal',), ('in',), ('his',), ('paper',), ('Computing',), ('Machinery',), ('and',), ('Intelligence',), ('in',), ('which',), ('the',), ('question',), ('Can',), ('machines',), ('think',), ('is',), ('replaced',), ('with',), ('the',), ('question',), ('Can',), ('machines',), ('do',), ('what',), ('we',), ('as',), ('thinking',), ('entities',), ('can',), ('do',)]\n",
      "\n",
      "Bigrams: [('Tom', 'M'), ('M', 'Mitchell'), ('Mitchell', 'provided'), ('provided', 'a'), ('a', 'widely'), ('widely', 'quoted'), ('quoted', 'more'), ('more', 'formal'), ('formal', 'definition'), ('definition', 'of'), ('of', 'the'), ('the', 'algorithms'), ('algorithms', 'studied'), ('studied', 'in'), ('in', 'the'), ('the', 'machine'), ('machine', 'learning'), ('learning', 'field'), ('field', 'A'), ('A', 'computer'), ('computer', 'program'), ('program', 'is'), ('is', 'said'), ('said', 'to'), ('to', 'learn'), ('learn', 'from'), ('from', 'experience'), ('experience', 'E'), ('E', 'with'), ('with', 'respect'), ('respect', 'to'), ('to', 'some'), ('some', 'class'), ('class', 'of'), ('of', 'tasks'), ('tasks', 'T'), ('T', 'and'), ('and', 'performance'), ('performance', 'measure'), ('measure', 'P'), ('P', 'if'), ('if', 'its'), ('its', 'performance'), ('performance', 'at'), ('at', 'tasks'), ('tasks', 'in'), ('in', 'T'), ('T', 'as'), ('as', 'measured'), ('measured', 'by'), ('by', 'P'), ('P', 'improves'), ('improves', 'with'), ('with', 'experience'), ('experience', 'E'), ('E', 'This'), ('This', 'definition'), ('definition', 'of'), ('of', 'the'), ('the', 'tasks'), ('tasks', 'in'), ('in', 'which'), ('which', 'machine'), ('machine', 'learning'), ('learning', 'is'), ('is', 'concerned'), ('concerned', 'offers'), ('offers', 'a'), ('a', 'fundamentally'), ('fundamentally', 'operational'), ('operational', 'definition'), ('definition', 'rather'), ('rather', 'than'), ('than', 'defining'), ('defining', 'the'), ('the', 'field'), ('field', 'in'), ('in', 'cognitive'), ('cognitive', 'terms'), ('terms', 'This'), ('This', 'follows'), ('follows', 'Alan'), ('Alan', 'Turings'), ('Turings', 'proposal'), ('proposal', 'in'), ('in', 'his'), ('his', 'paper'), ('paper', 'Computing'), ('Computing', 'Machinery'), ('Machinery', 'and'), ('and', 'Intelligence'), ('Intelligence', 'in'), ('in', 'which'), ('which', 'the'), ('the', 'question'), ('question', 'Can'), ('Can', 'machines'), ('machines', 'think'), ('think', 'is'), ('is', 'replaced'), ('replaced', 'with'), ('with', 'the'), ('the', 'question'), ('question', 'Can'), ('Can', 'machines'), ('machines', 'do'), ('do', 'what'), ('what', 'we'), ('we', 'as'), ('as', 'thinking'), ('thinking', 'entities'), ('entities', 'can'), ('can', 'do')]\n",
      "\n",
      "Trigrams: [('Tom', 'M', 'Mitchell'), ('M', 'Mitchell', 'provided'), ('Mitchell', 'provided', 'a'), ('provided', 'a', 'widely'), ('a', 'widely', 'quoted'), ('widely', 'quoted', 'more'), ('quoted', 'more', 'formal'), ('more', 'formal', 'definition'), ('formal', 'definition', 'of'), ('definition', 'of', 'the'), ('of', 'the', 'algorithms'), ('the', 'algorithms', 'studied'), ('algorithms', 'studied', 'in'), ('studied', 'in', 'the'), ('in', 'the', 'machine'), ('the', 'machine', 'learning'), ('machine', 'learning', 'field'), ('learning', 'field', 'A'), ('field', 'A', 'computer'), ('A', 'computer', 'program'), ('computer', 'program', 'is'), ('program', 'is', 'said'), ('is', 'said', 'to'), ('said', 'to', 'learn'), ('to', 'learn', 'from'), ('learn', 'from', 'experience'), ('from', 'experience', 'E'), ('experience', 'E', 'with'), ('E', 'with', 'respect'), ('with', 'respect', 'to'), ('respect', 'to', 'some'), ('to', 'some', 'class'), ('some', 'class', 'of'), ('class', 'of', 'tasks'), ('of', 'tasks', 'T'), ('tasks', 'T', 'and'), ('T', 'and', 'performance'), ('and', 'performance', 'measure'), ('performance', 'measure', 'P'), ('measure', 'P', 'if'), ('P', 'if', 'its'), ('if', 'its', 'performance'), ('its', 'performance', 'at'), ('performance', 'at', 'tasks'), ('at', 'tasks', 'in'), ('tasks', 'in', 'T'), ('in', 'T', 'as'), ('T', 'as', 'measured'), ('as', 'measured', 'by'), ('measured', 'by', 'P'), ('by', 'P', 'improves'), ('P', 'improves', 'with'), ('improves', 'with', 'experience'), ('with', 'experience', 'E'), ('experience', 'E', 'This'), ('E', 'This', 'definition'), ('This', 'definition', 'of'), ('definition', 'of', 'the'), ('of', 'the', 'tasks'), ('the', 'tasks', 'in'), ('tasks', 'in', 'which'), ('in', 'which', 'machine'), ('which', 'machine', 'learning'), ('machine', 'learning', 'is'), ('learning', 'is', 'concerned'), ('is', 'concerned', 'offers'), ('concerned', 'offers', 'a'), ('offers', 'a', 'fundamentally'), ('a', 'fundamentally', 'operational'), ('fundamentally', 'operational', 'definition'), ('operational', 'definition', 'rather'), ('definition', 'rather', 'than'), ('rather', 'than', 'defining'), ('than', 'defining', 'the'), ('defining', 'the', 'field'), ('the', 'field', 'in'), ('field', 'in', 'cognitive'), ('in', 'cognitive', 'terms'), ('cognitive', 'terms', 'This'), ('terms', 'This', 'follows'), ('This', 'follows', 'Alan'), ('follows', 'Alan', 'Turings'), ('Alan', 'Turings', 'proposal'), ('Turings', 'proposal', 'in'), ('proposal', 'in', 'his'), ('in', 'his', 'paper'), ('his', 'paper', 'Computing'), ('paper', 'Computing', 'Machinery'), ('Computing', 'Machinery', 'and'), ('Machinery', 'and', 'Intelligence'), ('and', 'Intelligence', 'in'), ('Intelligence', 'in', 'which'), ('in', 'which', 'the'), ('which', 'the', 'question'), ('the', 'question', 'Can'), ('question', 'Can', 'machines'), ('Can', 'machines', 'think'), ('machines', 'think', 'is'), ('think', 'is', 'replaced'), ('is', 'replaced', 'with'), ('replaced', 'with', 'the'), ('with', 'the', 'question'), ('the', 'question', 'Can'), ('question', 'Can', 'machines'), ('Can', 'machines', 'do'), ('machines', 'do', 'what'), ('do', 'what', 'we'), ('what', 'we', 'as'), ('we', 'as', 'thinking'), ('as', 'thinking', 'entities'), ('thinking', 'entities', 'can'), ('entities', 'can', 'do')]\n",
      "\n",
      "Document: Modernday machine learning has two objectives  One is to classify data based on models which have been developed the other purpose is to make predictions for future outcomes based on these models A hypothetical algorithm specific to classifying data may use computer vision of moles coupled with supervised learning in order to train it to classify the cancerous moles A machine learning algorithm for stock trading may inform the trader of future potential predictions\n",
      "\n",
      "\n",
      "Unigrams: [('Modernday',), ('machine',), ('learning',), ('has',), ('two',), ('objectives',), ('One',), ('is',), ('to',), ('classify',), ('data',), ('based',), ('on',), ('models',), ('which',), ('have',), ('been',), ('developed',), ('the',), ('other',), ('purpose',), ('is',), ('to',), ('make',), ('predictions',), ('for',), ('future',), ('outcomes',), ('based',), ('on',), ('these',), ('models',), ('A',), ('hypothetical',), ('algorithm',), ('specific',), ('to',), ('classifying',), ('data',), ('may',), ('use',), ('computer',), ('vision',), ('of',), ('moles',), ('coupled',), ('with',), ('supervised',), ('learning',), ('in',), ('order',), ('to',), ('train',), ('it',), ('to',), ('classify',), ('the',), ('cancerous',), ('moles',), ('A',), ('machine',), ('learning',), ('algorithm',), ('for',), ('stock',), ('trading',), ('may',), ('inform',), ('the',), ('trader',), ('of',), ('future',), ('potential',), ('predictions',)]\n",
      "\n",
      "Bigrams: [('Modernday', 'machine'), ('machine', 'learning'), ('learning', 'has'), ('has', 'two'), ('two', 'objectives'), ('objectives', 'One'), ('One', 'is'), ('is', 'to'), ('to', 'classify'), ('classify', 'data'), ('data', 'based'), ('based', 'on'), ('on', 'models'), ('models', 'which'), ('which', 'have'), ('have', 'been'), ('been', 'developed'), ('developed', 'the'), ('the', 'other'), ('other', 'purpose'), ('purpose', 'is'), ('is', 'to'), ('to', 'make'), ('make', 'predictions'), ('predictions', 'for'), ('for', 'future'), ('future', 'outcomes'), ('outcomes', 'based'), ('based', 'on'), ('on', 'these'), ('these', 'models'), ('models', 'A'), ('A', 'hypothetical'), ('hypothetical', 'algorithm'), ('algorithm', 'specific'), ('specific', 'to'), ('to', 'classifying'), ('classifying', 'data'), ('data', 'may'), ('may', 'use'), ('use', 'computer'), ('computer', 'vision'), ('vision', 'of'), ('of', 'moles'), ('moles', 'coupled'), ('coupled', 'with'), ('with', 'supervised'), ('supervised', 'learning'), ('learning', 'in'), ('in', 'order'), ('order', 'to'), ('to', 'train'), ('train', 'it'), ('it', 'to'), ('to', 'classify'), ('classify', 'the'), ('the', 'cancerous'), ('cancerous', 'moles'), ('moles', 'A'), ('A', 'machine'), ('machine', 'learning'), ('learning', 'algorithm'), ('algorithm', 'for'), ('for', 'stock'), ('stock', 'trading'), ('trading', 'may'), ('may', 'inform'), ('inform', 'the'), ('the', 'trader'), ('trader', 'of'), ('of', 'future'), ('future', 'potential'), ('potential', 'predictions')]\n",
      "\n",
      "Trigrams: [('Modernday', 'machine', 'learning'), ('machine', 'learning', 'has'), ('learning', 'has', 'two'), ('has', 'two', 'objectives'), ('two', 'objectives', 'One'), ('objectives', 'One', 'is'), ('One', 'is', 'to'), ('is', 'to', 'classify'), ('to', 'classify', 'data'), ('classify', 'data', 'based'), ('data', 'based', 'on'), ('based', 'on', 'models'), ('on', 'models', 'which'), ('models', 'which', 'have'), ('which', 'have', 'been'), ('have', 'been', 'developed'), ('been', 'developed', 'the'), ('developed', 'the', 'other'), ('the', 'other', 'purpose'), ('other', 'purpose', 'is'), ('purpose', 'is', 'to'), ('is', 'to', 'make'), ('to', 'make', 'predictions'), ('make', 'predictions', 'for'), ('predictions', 'for', 'future'), ('for', 'future', 'outcomes'), ('future', 'outcomes', 'based'), ('outcomes', 'based', 'on'), ('based', 'on', 'these'), ('on', 'these', 'models'), ('these', 'models', 'A'), ('models', 'A', 'hypothetical'), ('A', 'hypothetical', 'algorithm'), ('hypothetical', 'algorithm', 'specific'), ('algorithm', 'specific', 'to'), ('specific', 'to', 'classifying'), ('to', 'classifying', 'data'), ('classifying', 'data', 'may'), ('data', 'may', 'use'), ('may', 'use', 'computer'), ('use', 'computer', 'vision'), ('computer', 'vision', 'of'), ('vision', 'of', 'moles'), ('of', 'moles', 'coupled'), ('moles', 'coupled', 'with'), ('coupled', 'with', 'supervised'), ('with', 'supervised', 'learning'), ('supervised', 'learning', 'in'), ('learning', 'in', 'order'), ('in', 'order', 'to'), ('order', 'to', 'train'), ('to', 'train', 'it'), ('train', 'it', 'to'), ('it', 'to', 'classify'), ('to', 'classify', 'the'), ('classify', 'the', 'cancerous'), ('the', 'cancerous', 'moles'), ('cancerous', 'moles', 'A'), ('moles', 'A', 'machine'), ('A', 'machine', 'learning'), ('machine', 'learning', 'algorithm'), ('learning', 'algorithm', 'for'), ('algorithm', 'for', 'stock'), ('for', 'stock', 'trading'), ('stock', 'trading', 'may'), ('trading', 'may', 'inform'), ('may', 'inform', 'the'), ('inform', 'the', 'trader'), ('the', 'trader', 'of'), ('trader', 'of', 'future'), ('of', 'future', 'potential'), ('future', 'potential', 'predictions')]\n",
      "\n",
      "Document: As a scientific endeavour machine learning grew out of the quest for artificial intelligence AI In the early days of AI as an academic discipline some researchers were interested in having machines learn from data They attempted to approach the problem with various symbolic methods as well as what were then termed neural networks these were mostly perceptrons and other models that were later found to be reinventions of the generalised linear models of statistics Probabilistic reasoning was also employed especially in automated medical diagnosis\n",
      "\n",
      "\n",
      "Unigrams: [('As',), ('a',), ('scientific',), ('endeavour',), ('machine',), ('learning',), ('grew',), ('out',), ('of',), ('the',), ('quest',), ('for',), ('artificial',), ('intelligence',), ('AI',), ('In',), ('the',), ('early',), ('days',), ('of',), ('AI',), ('as',), ('an',), ('academic',), ('discipline',), ('some',), ('researchers',), ('were',), ('interested',), ('in',), ('having',), ('machines',), ('learn',), ('from',), ('data',), ('They',), ('attempted',), ('to',), ('approach',), ('the',), ('problem',), ('with',), ('various',), ('symbolic',), ('methods',), ('as',), ('well',), ('as',), ('what',), ('were',), ('then',), ('termed',), ('neural',), ('networks',), ('these',), ('were',), ('mostly',), ('perceptrons',), ('and',), ('other',), ('models',), ('that',), ('were',), ('later',), ('found',), ('to',), ('be',), ('reinventions',), ('of',), ('the',), ('generalised',), ('linear',), ('models',), ('of',), ('statistics',), ('Probabilistic',), ('reasoning',), ('was',), ('also',), ('employed',), ('especially',), ('in',), ('automated',), ('medical',), ('diagnosis',)]\n",
      "\n",
      "Bigrams: [('As', 'a'), ('a', 'scientific'), ('scientific', 'endeavour'), ('endeavour', 'machine'), ('machine', 'learning'), ('learning', 'grew'), ('grew', 'out'), ('out', 'of'), ('of', 'the'), ('the', 'quest'), ('quest', 'for'), ('for', 'artificial'), ('artificial', 'intelligence'), ('intelligence', 'AI'), ('AI', 'In'), ('In', 'the'), ('the', 'early'), ('early', 'days'), ('days', 'of'), ('of', 'AI'), ('AI', 'as'), ('as', 'an'), ('an', 'academic'), ('academic', 'discipline'), ('discipline', 'some'), ('some', 'researchers'), ('researchers', 'were'), ('were', 'interested'), ('interested', 'in'), ('in', 'having'), ('having', 'machines'), ('machines', 'learn'), ('learn', 'from'), ('from', 'data'), ('data', 'They'), ('They', 'attempted'), ('attempted', 'to'), ('to', 'approach'), ('approach', 'the'), ('the', 'problem'), ('problem', 'with'), ('with', 'various'), ('various', 'symbolic'), ('symbolic', 'methods'), ('methods', 'as'), ('as', 'well'), ('well', 'as'), ('as', 'what'), ('what', 'were'), ('were', 'then'), ('then', 'termed'), ('termed', 'neural'), ('neural', 'networks'), ('networks', 'these'), ('these', 'were'), ('were', 'mostly'), ('mostly', 'perceptrons'), ('perceptrons', 'and'), ('and', 'other'), ('other', 'models'), ('models', 'that'), ('that', 'were'), ('were', 'later'), ('later', 'found'), ('found', 'to'), ('to', 'be'), ('be', 'reinventions'), ('reinventions', 'of'), ('of', 'the'), ('the', 'generalised'), ('generalised', 'linear'), ('linear', 'models'), ('models', 'of'), ('of', 'statistics'), ('statistics', 'Probabilistic'), ('Probabilistic', 'reasoning'), ('reasoning', 'was'), ('was', 'also'), ('also', 'employed'), ('employed', 'especially'), ('especially', 'in'), ('in', 'automated'), ('automated', 'medical'), ('medical', 'diagnosis')]\n",
      "\n",
      "Trigrams: [('As', 'a', 'scientific'), ('a', 'scientific', 'endeavour'), ('scientific', 'endeavour', 'machine'), ('endeavour', 'machine', 'learning'), ('machine', 'learning', 'grew'), ('learning', 'grew', 'out'), ('grew', 'out', 'of'), ('out', 'of', 'the'), ('of', 'the', 'quest'), ('the', 'quest', 'for'), ('quest', 'for', 'artificial'), ('for', 'artificial', 'intelligence'), ('artificial', 'intelligence', 'AI'), ('intelligence', 'AI', 'In'), ('AI', 'In', 'the'), ('In', 'the', 'early'), ('the', 'early', 'days'), ('early', 'days', 'of'), ('days', 'of', 'AI'), ('of', 'AI', 'as'), ('AI', 'as', 'an'), ('as', 'an', 'academic'), ('an', 'academic', 'discipline'), ('academic', 'discipline', 'some'), ('discipline', 'some', 'researchers'), ('some', 'researchers', 'were'), ('researchers', 'were', 'interested'), ('were', 'interested', 'in'), ('interested', 'in', 'having'), ('in', 'having', 'machines'), ('having', 'machines', 'learn'), ('machines', 'learn', 'from'), ('learn', 'from', 'data'), ('from', 'data', 'They'), ('data', 'They', 'attempted'), ('They', 'attempted', 'to'), ('attempted', 'to', 'approach'), ('to', 'approach', 'the'), ('approach', 'the', 'problem'), ('the', 'problem', 'with'), ('problem', 'with', 'various'), ('with', 'various', 'symbolic'), ('various', 'symbolic', 'methods'), ('symbolic', 'methods', 'as'), ('methods', 'as', 'well'), ('as', 'well', 'as'), ('well', 'as', 'what'), ('as', 'what', 'were'), ('what', 'were', 'then'), ('were', 'then', 'termed'), ('then', 'termed', 'neural'), ('termed', 'neural', 'networks'), ('neural', 'networks', 'these'), ('networks', 'these', 'were'), ('these', 'were', 'mostly'), ('were', 'mostly', 'perceptrons'), ('mostly', 'perceptrons', 'and'), ('perceptrons', 'and', 'other'), ('and', 'other', 'models'), ('other', 'models', 'that'), ('models', 'that', 'were'), ('that', 'were', 'later'), ('were', 'later', 'found'), ('later', 'found', 'to'), ('found', 'to', 'be'), ('to', 'be', 'reinventions'), ('be', 'reinventions', 'of'), ('reinventions', 'of', 'the'), ('of', 'the', 'generalised'), ('the', 'generalised', 'linear'), ('generalised', 'linear', 'models'), ('linear', 'models', 'of'), ('models', 'of', 'statistics'), ('of', 'statistics', 'Probabilistic'), ('statistics', 'Probabilistic', 'reasoning'), ('Probabilistic', 'reasoning', 'was'), ('reasoning', 'was', 'also'), ('was', 'also', 'employed'), ('also', 'employed', 'especially'), ('employed', 'especially', 'in'), ('especially', 'in', 'automated'), ('in', 'automated', 'medical'), ('automated', 'medical', 'diagnosis')]\n",
      "\n",
      "Document: However an increasing emphasis on the logical knowledgebased approach caused a rift between AI and machine learning Probabilistic systems were plagued by theoretical and practical problems of data acquisition and representation By  expert systems had come to dominate AI and statistics was out of favour Work on symbolicknowledgebased learning did continue within AI leading to inductive logic programmingILP but the more statistical line of research was now outside the field of AI proper in pattern recognition and information retrieval Neural networks research had been abandoned by AI and computer science around the same time This line too was continued outside the AICS field as connectionism by researchers from other disciplines including John Hopfield David Rumelhart and Geoffrey Hinton Their main success came in the mids with the reinvention of backpropagation\n",
      "\n",
      "\n",
      "Unigrams: [('However',), ('an',), ('increasing',), ('emphasis',), ('on',), ('the',), ('logical',), ('knowledgebased',), ('approach',), ('caused',), ('a',), ('rift',), ('between',), ('AI',), ('and',), ('machine',), ('learning',), ('Probabilistic',), ('systems',), ('were',), ('plagued',), ('by',), ('theoretical',), ('and',), ('practical',), ('problems',), ('of',), ('data',), ('acquisition',), ('and',), ('representation',), ('By',), ('expert',), ('systems',), ('had',), ('come',), ('to',), ('dominate',), ('AI',), ('and',), ('statistics',), ('was',), ('out',), ('of',), ('favour',), ('Work',), ('on',), ('symbolicknowledgebased',), ('learning',), ('did',), ('continue',), ('within',), ('AI',), ('leading',), ('to',), ('inductive',), ('logic',), ('programmingILP',), ('but',), ('the',), ('more',), ('statistical',), ('line',), ('of',), ('research',), ('was',), ('now',), ('outside',), ('the',), ('field',), ('of',), ('AI',), ('proper',), ('in',), ('pattern',), ('recognition',), ('and',), ('information',), ('retrieval',), ('Neural',), ('networks',), ('research',), ('had',), ('been',), ('abandoned',), ('by',), ('AI',), ('and',), ('computer',), ('science',), ('around',), ('the',), ('same',), ('time',), ('This',), ('line',), ('too',), ('was',), ('continued',), ('outside',), ('the',), ('AICS',), ('field',), ('as',), ('connectionism',), ('by',), ('researchers',), ('from',), ('other',), ('disciplines',), ('including',), ('John',), ('Hopfield',), ('David',), ('Rumelhart',), ('and',), ('Geoffrey',), ('Hinton',), ('Their',), ('main',), ('success',), ('came',), ('in',), ('the',), ('mids',), ('with',), ('the',), ('reinvention',), ('of',), ('backpropagation',)]\n",
      "\n",
      "Bigrams: [('However', 'an'), ('an', 'increasing'), ('increasing', 'emphasis'), ('emphasis', 'on'), ('on', 'the'), ('the', 'logical'), ('logical', 'knowledgebased'), ('knowledgebased', 'approach'), ('approach', 'caused'), ('caused', 'a'), ('a', 'rift'), ('rift', 'between'), ('between', 'AI'), ('AI', 'and'), ('and', 'machine'), ('machine', 'learning'), ('learning', 'Probabilistic'), ('Probabilistic', 'systems'), ('systems', 'were'), ('were', 'plagued'), ('plagued', 'by'), ('by', 'theoretical'), ('theoretical', 'and'), ('and', 'practical'), ('practical', 'problems'), ('problems', 'of'), ('of', 'data'), ('data', 'acquisition'), ('acquisition', 'and'), ('and', 'representation'), ('representation', 'By'), ('By', 'expert'), ('expert', 'systems'), ('systems', 'had'), ('had', 'come'), ('come', 'to'), ('to', 'dominate'), ('dominate', 'AI'), ('AI', 'and'), ('and', 'statistics'), ('statistics', 'was'), ('was', 'out'), ('out', 'of'), ('of', 'favour'), ('favour', 'Work'), ('Work', 'on'), ('on', 'symbolicknowledgebased'), ('symbolicknowledgebased', 'learning'), ('learning', 'did'), ('did', 'continue'), ('continue', 'within'), ('within', 'AI'), ('AI', 'leading'), ('leading', 'to'), ('to', 'inductive'), ('inductive', 'logic'), ('logic', 'programmingILP'), ('programmingILP', 'but'), ('but', 'the'), ('the', 'more'), ('more', 'statistical'), ('statistical', 'line'), ('line', 'of'), ('of', 'research'), ('research', 'was'), ('was', 'now'), ('now', 'outside'), ('outside', 'the'), ('the', 'field'), ('field', 'of'), ('of', 'AI'), ('AI', 'proper'), ('proper', 'in'), ('in', 'pattern'), ('pattern', 'recognition'), ('recognition', 'and'), ('and', 'information'), ('information', 'retrieval'), ('retrieval', 'Neural'), ('Neural', 'networks'), ('networks', 'research'), ('research', 'had'), ('had', 'been'), ('been', 'abandoned'), ('abandoned', 'by'), ('by', 'AI'), ('AI', 'and'), ('and', 'computer'), ('computer', 'science'), ('science', 'around'), ('around', 'the'), ('the', 'same'), ('same', 'time'), ('time', 'This'), ('This', 'line'), ('line', 'too'), ('too', 'was'), ('was', 'continued'), ('continued', 'outside'), ('outside', 'the'), ('the', 'AICS'), ('AICS', 'field'), ('field', 'as'), ('as', 'connectionism'), ('connectionism', 'by'), ('by', 'researchers'), ('researchers', 'from'), ('from', 'other'), ('other', 'disciplines'), ('disciplines', 'including'), ('including', 'John'), ('John', 'Hopfield'), ('Hopfield', 'David'), ('David', 'Rumelhart'), ('Rumelhart', 'and'), ('and', 'Geoffrey'), ('Geoffrey', 'Hinton'), ('Hinton', 'Their'), ('Their', 'main'), ('main', 'success'), ('success', 'came'), ('came', 'in'), ('in', 'the'), ('the', 'mids'), ('mids', 'with'), ('with', 'the'), ('the', 'reinvention'), ('reinvention', 'of'), ('of', 'backpropagation')]\n",
      "\n",
      "Trigrams: [('However', 'an', 'increasing'), ('an', 'increasing', 'emphasis'), ('increasing', 'emphasis', 'on'), ('emphasis', 'on', 'the'), ('on', 'the', 'logical'), ('the', 'logical', 'knowledgebased'), ('logical', 'knowledgebased', 'approach'), ('knowledgebased', 'approach', 'caused'), ('approach', 'caused', 'a'), ('caused', 'a', 'rift'), ('a', 'rift', 'between'), ('rift', 'between', 'AI'), ('between', 'AI', 'and'), ('AI', 'and', 'machine'), ('and', 'machine', 'learning'), ('machine', 'learning', 'Probabilistic'), ('learning', 'Probabilistic', 'systems'), ('Probabilistic', 'systems', 'were'), ('systems', 'were', 'plagued'), ('were', 'plagued', 'by'), ('plagued', 'by', 'theoretical'), ('by', 'theoretical', 'and'), ('theoretical', 'and', 'practical'), ('and', 'practical', 'problems'), ('practical', 'problems', 'of'), ('problems', 'of', 'data'), ('of', 'data', 'acquisition'), ('data', 'acquisition', 'and'), ('acquisition', 'and', 'representation'), ('and', 'representation', 'By'), ('representation', 'By', 'expert'), ('By', 'expert', 'systems'), ('expert', 'systems', 'had'), ('systems', 'had', 'come'), ('had', 'come', 'to'), ('come', 'to', 'dominate'), ('to', 'dominate', 'AI'), ('dominate', 'AI', 'and'), ('AI', 'and', 'statistics'), ('and', 'statistics', 'was'), ('statistics', 'was', 'out'), ('was', 'out', 'of'), ('out', 'of', 'favour'), ('of', 'favour', 'Work'), ('favour', 'Work', 'on'), ('Work', 'on', 'symbolicknowledgebased'), ('on', 'symbolicknowledgebased', 'learning'), ('symbolicknowledgebased', 'learning', 'did'), ('learning', 'did', 'continue'), ('did', 'continue', 'within'), ('continue', 'within', 'AI'), ('within', 'AI', 'leading'), ('AI', 'leading', 'to'), ('leading', 'to', 'inductive'), ('to', 'inductive', 'logic'), ('inductive', 'logic', 'programmingILP'), ('logic', 'programmingILP', 'but'), ('programmingILP', 'but', 'the'), ('but', 'the', 'more'), ('the', 'more', 'statistical'), ('more', 'statistical', 'line'), ('statistical', 'line', 'of'), ('line', 'of', 'research'), ('of', 'research', 'was'), ('research', 'was', 'now'), ('was', 'now', 'outside'), ('now', 'outside', 'the'), ('outside', 'the', 'field'), ('the', 'field', 'of'), ('field', 'of', 'AI'), ('of', 'AI', 'proper'), ('AI', 'proper', 'in'), ('proper', 'in', 'pattern'), ('in', 'pattern', 'recognition'), ('pattern', 'recognition', 'and'), ('recognition', 'and', 'information'), ('and', 'information', 'retrieval'), ('information', 'retrieval', 'Neural'), ('retrieval', 'Neural', 'networks'), ('Neural', 'networks', 'research'), ('networks', 'research', 'had'), ('research', 'had', 'been'), ('had', 'been', 'abandoned'), ('been', 'abandoned', 'by'), ('abandoned', 'by', 'AI'), ('by', 'AI', 'and'), ('AI', 'and', 'computer'), ('and', 'computer', 'science'), ('computer', 'science', 'around'), ('science', 'around', 'the'), ('around', 'the', 'same'), ('the', 'same', 'time'), ('same', 'time', 'This'), ('time', 'This', 'line'), ('This', 'line', 'too'), ('line', 'too', 'was'), ('too', 'was', 'continued'), ('was', 'continued', 'outside'), ('continued', 'outside', 'the'), ('outside', 'the', 'AICS'), ('the', 'AICS', 'field'), ('AICS', 'field', 'as'), ('field', 'as', 'connectionism'), ('as', 'connectionism', 'by'), ('connectionism', 'by', 'researchers'), ('by', 'researchers', 'from'), ('researchers', 'from', 'other'), ('from', 'other', 'disciplines'), ('other', 'disciplines', 'including'), ('disciplines', 'including', 'John'), ('including', 'John', 'Hopfield'), ('John', 'Hopfield', 'David'), ('Hopfield', 'David', 'Rumelhart'), ('David', 'Rumelhart', 'and'), ('Rumelhart', 'and', 'Geoffrey'), ('and', 'Geoffrey', 'Hinton'), ('Geoffrey', 'Hinton', 'Their'), ('Hinton', 'Their', 'main'), ('Their', 'main', 'success'), ('main', 'success', 'came'), ('success', 'came', 'in'), ('came', 'in', 'the'), ('in', 'the', 'mids'), ('the', 'mids', 'with'), ('mids', 'with', 'the'), ('with', 'the', 'reinvention'), ('the', 'reinvention', 'of'), ('reinvention', 'of', 'backpropagation')]\n",
      "\n",
      "Document: Machine learning ML reorganised and recognised as its own field started to flourish in the s The field changed its goal from achieving artificial intelligence to tackling solvable problems of a practical nature It shifted focus away from the symbolic approaches it had inherited from AI and toward methods and models borrowed from statistics fuzzy logic and probability theory\n",
      "\n",
      "\n",
      "Unigrams: [('Machine',), ('learning',), ('ML',), ('reorganised',), ('and',), ('recognised',), ('as',), ('its',), ('own',), ('field',), ('started',), ('to',), ('flourish',), ('in',), ('the',), ('s',), ('The',), ('field',), ('changed',), ('its',), ('goal',), ('from',), ('achieving',), ('artificial',), ('intelligence',), ('to',), ('tackling',), ('solvable',), ('problems',), ('of',), ('a',), ('practical',), ('nature',), ('It',), ('shifted',), ('focus',), ('away',), ('from',), ('the',), ('symbolic',), ('approaches',), ('it',), ('had',), ('inherited',), ('from',), ('AI',), ('and',), ('toward',), ('methods',), ('and',), ('models',), ('borrowed',), ('from',), ('statistics',), ('fuzzy',), ('logic',), ('and',), ('probability',), ('theory',)]\n",
      "\n",
      "Bigrams: [('Machine', 'learning'), ('learning', 'ML'), ('ML', 'reorganised'), ('reorganised', 'and'), ('and', 'recognised'), ('recognised', 'as'), ('as', 'its'), ('its', 'own'), ('own', 'field'), ('field', 'started'), ('started', 'to'), ('to', 'flourish'), ('flourish', 'in'), ('in', 'the'), ('the', 's'), ('s', 'The'), ('The', 'field'), ('field', 'changed'), ('changed', 'its'), ('its', 'goal'), ('goal', 'from'), ('from', 'achieving'), ('achieving', 'artificial'), ('artificial', 'intelligence'), ('intelligence', 'to'), ('to', 'tackling'), ('tackling', 'solvable'), ('solvable', 'problems'), ('problems', 'of'), ('of', 'a'), ('a', 'practical'), ('practical', 'nature'), ('nature', 'It'), ('It', 'shifted'), ('shifted', 'focus'), ('focus', 'away'), ('away', 'from'), ('from', 'the'), ('the', 'symbolic'), ('symbolic', 'approaches'), ('approaches', 'it'), ('it', 'had'), ('had', 'inherited'), ('inherited', 'from'), ('from', 'AI'), ('AI', 'and'), ('and', 'toward'), ('toward', 'methods'), ('methods', 'and'), ('and', 'models'), ('models', 'borrowed'), ('borrowed', 'from'), ('from', 'statistics'), ('statistics', 'fuzzy'), ('fuzzy', 'logic'), ('logic', 'and'), ('and', 'probability'), ('probability', 'theory')]\n",
      "\n",
      "Trigrams: [('Machine', 'learning', 'ML'), ('learning', 'ML', 'reorganised'), ('ML', 'reorganised', 'and'), ('reorganised', 'and', 'recognised'), ('and', 'recognised', 'as'), ('recognised', 'as', 'its'), ('as', 'its', 'own'), ('its', 'own', 'field'), ('own', 'field', 'started'), ('field', 'started', 'to'), ('started', 'to', 'flourish'), ('to', 'flourish', 'in'), ('flourish', 'in', 'the'), ('in', 'the', 's'), ('the', 's', 'The'), ('s', 'The', 'field'), ('The', 'field', 'changed'), ('field', 'changed', 'its'), ('changed', 'its', 'goal'), ('its', 'goal', 'from'), ('goal', 'from', 'achieving'), ('from', 'achieving', 'artificial'), ('achieving', 'artificial', 'intelligence'), ('artificial', 'intelligence', 'to'), ('intelligence', 'to', 'tackling'), ('to', 'tackling', 'solvable'), ('tackling', 'solvable', 'problems'), ('solvable', 'problems', 'of'), ('problems', 'of', 'a'), ('of', 'a', 'practical'), ('a', 'practical', 'nature'), ('practical', 'nature', 'It'), ('nature', 'It', 'shifted'), ('It', 'shifted', 'focus'), ('shifted', 'focus', 'away'), ('focus', 'away', 'from'), ('away', 'from', 'the'), ('from', 'the', 'symbolic'), ('the', 'symbolic', 'approaches'), ('symbolic', 'approaches', 'it'), ('approaches', 'it', 'had'), ('it', 'had', 'inherited'), ('had', 'inherited', 'from'), ('inherited', 'from', 'AI'), ('from', 'AI', 'and'), ('AI', 'and', 'toward'), ('and', 'toward', 'methods'), ('toward', 'methods', 'and'), ('methods', 'and', 'models'), ('and', 'models', 'borrowed'), ('models', 'borrowed', 'from'), ('borrowed', 'from', 'statistics'), ('from', 'statistics', 'fuzzy'), ('statistics', 'fuzzy', 'logic'), ('fuzzy', 'logic', 'and'), ('logic', 'and', 'probability'), ('and', 'probability', 'theory')]\n",
      "\n",
      "Document: There is a close connection between machine learning and compression A system that predicts the posterior probabilities of a sequence given its entire history can be used for optimal data compression by using arithmetic coding on the output distribution Conversely an optimal compressor can be used for prediction by finding the symbol that compresses best given the previous history This equivalence has been used as a justification for using data compression as a benchmark for general intelligence\n",
      "\n",
      "\n",
      "Unigrams: [('There',), ('is',), ('a',), ('close',), ('connection',), ('between',), ('machine',), ('learning',), ('and',), ('compression',), ('A',), ('system',), ('that',), ('predicts',), ('the',), ('posterior',), ('probabilities',), ('of',), ('a',), ('sequence',), ('given',), ('its',), ('entire',), ('history',), ('can',), ('be',), ('used',), ('for',), ('optimal',), ('data',), ('compression',), ('by',), ('using',), ('arithmetic',), ('coding',), ('on',), ('the',), ('output',), ('distribution',), ('Conversely',), ('an',), ('optimal',), ('compressor',), ('can',), ('be',), ('used',), ('for',), ('prediction',), ('by',), ('finding',), ('the',), ('symbol',), ('that',), ('compresses',), ('best',), ('given',), ('the',), ('previous',), ('history',), ('This',), ('equivalence',), ('has',), ('been',), ('used',), ('as',), ('a',), ('justification',), ('for',), ('using',), ('data',), ('compression',), ('as',), ('a',), ('benchmark',), ('for',), ('general',), ('intelligence',)]\n",
      "\n",
      "Bigrams: [('There', 'is'), ('is', 'a'), ('a', 'close'), ('close', 'connection'), ('connection', 'between'), ('between', 'machine'), ('machine', 'learning'), ('learning', 'and'), ('and', 'compression'), ('compression', 'A'), ('A', 'system'), ('system', 'that'), ('that', 'predicts'), ('predicts', 'the'), ('the', 'posterior'), ('posterior', 'probabilities'), ('probabilities', 'of'), ('of', 'a'), ('a', 'sequence'), ('sequence', 'given'), ('given', 'its'), ('its', 'entire'), ('entire', 'history'), ('history', 'can'), ('can', 'be'), ('be', 'used'), ('used', 'for'), ('for', 'optimal'), ('optimal', 'data'), ('data', 'compression'), ('compression', 'by'), ('by', 'using'), ('using', 'arithmetic'), ('arithmetic', 'coding'), ('coding', 'on'), ('on', 'the'), ('the', 'output'), ('output', 'distribution'), ('distribution', 'Conversely'), ('Conversely', 'an'), ('an', 'optimal'), ('optimal', 'compressor'), ('compressor', 'can'), ('can', 'be'), ('be', 'used'), ('used', 'for'), ('for', 'prediction'), ('prediction', 'by'), ('by', 'finding'), ('finding', 'the'), ('the', 'symbol'), ('symbol', 'that'), ('that', 'compresses'), ('compresses', 'best'), ('best', 'given'), ('given', 'the'), ('the', 'previous'), ('previous', 'history'), ('history', 'This'), ('This', 'equivalence'), ('equivalence', 'has'), ('has', 'been'), ('been', 'used'), ('used', 'as'), ('as', 'a'), ('a', 'justification'), ('justification', 'for'), ('for', 'using'), ('using', 'data'), ('data', 'compression'), ('compression', 'as'), ('as', 'a'), ('a', 'benchmark'), ('benchmark', 'for'), ('for', 'general'), ('general', 'intelligence')]\n",
      "\n",
      "Trigrams: [('There', 'is', 'a'), ('is', 'a', 'close'), ('a', 'close', 'connection'), ('close', 'connection', 'between'), ('connection', 'between', 'machine'), ('between', 'machine', 'learning'), ('machine', 'learning', 'and'), ('learning', 'and', 'compression'), ('and', 'compression', 'A'), ('compression', 'A', 'system'), ('A', 'system', 'that'), ('system', 'that', 'predicts'), ('that', 'predicts', 'the'), ('predicts', 'the', 'posterior'), ('the', 'posterior', 'probabilities'), ('posterior', 'probabilities', 'of'), ('probabilities', 'of', 'a'), ('of', 'a', 'sequence'), ('a', 'sequence', 'given'), ('sequence', 'given', 'its'), ('given', 'its', 'entire'), ('its', 'entire', 'history'), ('entire', 'history', 'can'), ('history', 'can', 'be'), ('can', 'be', 'used'), ('be', 'used', 'for'), ('used', 'for', 'optimal'), ('for', 'optimal', 'data'), ('optimal', 'data', 'compression'), ('data', 'compression', 'by'), ('compression', 'by', 'using'), ('by', 'using', 'arithmetic'), ('using', 'arithmetic', 'coding'), ('arithmetic', 'coding', 'on'), ('coding', 'on', 'the'), ('on', 'the', 'output'), ('the', 'output', 'distribution'), ('output', 'distribution', 'Conversely'), ('distribution', 'Conversely', 'an'), ('Conversely', 'an', 'optimal'), ('an', 'optimal', 'compressor'), ('optimal', 'compressor', 'can'), ('compressor', 'can', 'be'), ('can', 'be', 'used'), ('be', 'used', 'for'), ('used', 'for', 'prediction'), ('for', 'prediction', 'by'), ('prediction', 'by', 'finding'), ('by', 'finding', 'the'), ('finding', 'the', 'symbol'), ('the', 'symbol', 'that'), ('symbol', 'that', 'compresses'), ('that', 'compresses', 'best'), ('compresses', 'best', 'given'), ('best', 'given', 'the'), ('given', 'the', 'previous'), ('the', 'previous', 'history'), ('previous', 'history', 'This'), ('history', 'This', 'equivalence'), ('This', 'equivalence', 'has'), ('equivalence', 'has', 'been'), ('has', 'been', 'used'), ('been', 'used', 'as'), ('used', 'as', 'a'), ('as', 'a', 'justification'), ('a', 'justification', 'for'), ('justification', 'for', 'using'), ('for', 'using', 'data'), ('using', 'data', 'compression'), ('data', 'compression', 'as'), ('compression', 'as', 'a'), ('as', 'a', 'benchmark'), ('a', 'benchmark', 'for'), ('benchmark', 'for', 'general'), ('for', 'general', 'intelligence')]\n",
      "\n",
      "Document: An alternative view can show compression algorithms implicitly map strings into implicit feature space vectors and compressionbased similarity measures compute similarity within these feature spaces For each compressor C we define an associated vector space â„µ such that C maps an input string x corresponding to the vector norm x An exhaustive examination of the feature spaces underlying all compression algorithms is precluded by space instead feature vectors chooses to examine three representative lossless compression methods LZW LZ and PPM\n",
      "\n",
      "\n",
      "Unigrams: [('An',), ('alternative',), ('view',), ('can',), ('show',), ('compression',), ('algorithms',), ('implicitly',), ('map',), ('strings',), ('into',), ('implicit',), ('feature',), ('space',), ('vectors',), ('and',), ('compressionbased',), ('similarity',), ('measures',), ('compute',), ('similarity',), ('within',), ('these',), ('feature',), ('spaces',), ('For',), ('each',), ('compressor',), ('C',), ('we',), ('define',), ('an',), ('associated',), ('vector',), ('space',), ('â„µ',), ('such',), ('that',), ('C',), ('maps',), ('an',), ('input',), ('string',), ('x',), ('corresponding',), ('to',), ('the',), ('vector',), ('norm',), ('x',), ('An',), ('exhaustive',), ('examination',), ('of',), ('the',), ('feature',), ('spaces',), ('underlying',), ('all',), ('compression',), ('algorithms',), ('is',), ('precluded',), ('by',), ('space',), ('instead',), ('feature',), ('vectors',), ('chooses',), ('to',), ('examine',), ('three',), ('representative',), ('lossless',), ('compression',), ('methods',), ('LZW',), ('LZ',), ('and',), ('PPM',)]\n",
      "\n",
      "Bigrams: [('An', 'alternative'), ('alternative', 'view'), ('view', 'can'), ('can', 'show'), ('show', 'compression'), ('compression', 'algorithms'), ('algorithms', 'implicitly'), ('implicitly', 'map'), ('map', 'strings'), ('strings', 'into'), ('into', 'implicit'), ('implicit', 'feature'), ('feature', 'space'), ('space', 'vectors'), ('vectors', 'and'), ('and', 'compressionbased'), ('compressionbased', 'similarity'), ('similarity', 'measures'), ('measures', 'compute'), ('compute', 'similarity'), ('similarity', 'within'), ('within', 'these'), ('these', 'feature'), ('feature', 'spaces'), ('spaces', 'For'), ('For', 'each'), ('each', 'compressor'), ('compressor', 'C'), ('C', 'we'), ('we', 'define'), ('define', 'an'), ('an', 'associated'), ('associated', 'vector'), ('vector', 'space'), ('space', 'â„µ'), ('â„µ', 'such'), ('such', 'that'), ('that', 'C'), ('C', 'maps'), ('maps', 'an'), ('an', 'input'), ('input', 'string'), ('string', 'x'), ('x', 'corresponding'), ('corresponding', 'to'), ('to', 'the'), ('the', 'vector'), ('vector', 'norm'), ('norm', 'x'), ('x', 'An'), ('An', 'exhaustive'), ('exhaustive', 'examination'), ('examination', 'of'), ('of', 'the'), ('the', 'feature'), ('feature', 'spaces'), ('spaces', 'underlying'), ('underlying', 'all'), ('all', 'compression'), ('compression', 'algorithms'), ('algorithms', 'is'), ('is', 'precluded'), ('precluded', 'by'), ('by', 'space'), ('space', 'instead'), ('instead', 'feature'), ('feature', 'vectors'), ('vectors', 'chooses'), ('chooses', 'to'), ('to', 'examine'), ('examine', 'three'), ('three', 'representative'), ('representative', 'lossless'), ('lossless', 'compression'), ('compression', 'methods'), ('methods', 'LZW'), ('LZW', 'LZ'), ('LZ', 'and'), ('and', 'PPM')]\n",
      "\n",
      "Trigrams: [('An', 'alternative', 'view'), ('alternative', 'view', 'can'), ('view', 'can', 'show'), ('can', 'show', 'compression'), ('show', 'compression', 'algorithms'), ('compression', 'algorithms', 'implicitly'), ('algorithms', 'implicitly', 'map'), ('implicitly', 'map', 'strings'), ('map', 'strings', 'into'), ('strings', 'into', 'implicit'), ('into', 'implicit', 'feature'), ('implicit', 'feature', 'space'), ('feature', 'space', 'vectors'), ('space', 'vectors', 'and'), ('vectors', 'and', 'compressionbased'), ('and', 'compressionbased', 'similarity'), ('compressionbased', 'similarity', 'measures'), ('similarity', 'measures', 'compute'), ('measures', 'compute', 'similarity'), ('compute', 'similarity', 'within'), ('similarity', 'within', 'these'), ('within', 'these', 'feature'), ('these', 'feature', 'spaces'), ('feature', 'spaces', 'For'), ('spaces', 'For', 'each'), ('For', 'each', 'compressor'), ('each', 'compressor', 'C'), ('compressor', 'C', 'we'), ('C', 'we', 'define'), ('we', 'define', 'an'), ('define', 'an', 'associated'), ('an', 'associated', 'vector'), ('associated', 'vector', 'space'), ('vector', 'space', 'â„µ'), ('space', 'â„µ', 'such'), ('â„µ', 'such', 'that'), ('such', 'that', 'C'), ('that', 'C', 'maps'), ('C', 'maps', 'an'), ('maps', 'an', 'input'), ('an', 'input', 'string'), ('input', 'string', 'x'), ('string', 'x', 'corresponding'), ('x', 'corresponding', 'to'), ('corresponding', 'to', 'the'), ('to', 'the', 'vector'), ('the', 'vector', 'norm'), ('vector', 'norm', 'x'), ('norm', 'x', 'An'), ('x', 'An', 'exhaustive'), ('An', 'exhaustive', 'examination'), ('exhaustive', 'examination', 'of'), ('examination', 'of', 'the'), ('of', 'the', 'feature'), ('the', 'feature', 'spaces'), ('feature', 'spaces', 'underlying'), ('spaces', 'underlying', 'all'), ('underlying', 'all', 'compression'), ('all', 'compression', 'algorithms'), ('compression', 'algorithms', 'is'), ('algorithms', 'is', 'precluded'), ('is', 'precluded', 'by'), ('precluded', 'by', 'space'), ('by', 'space', 'instead'), ('space', 'instead', 'feature'), ('instead', 'feature', 'vectors'), ('feature', 'vectors', 'chooses'), ('vectors', 'chooses', 'to'), ('chooses', 'to', 'examine'), ('to', 'examine', 'three'), ('examine', 'three', 'representative'), ('three', 'representative', 'lossless'), ('representative', 'lossless', 'compression'), ('lossless', 'compression', 'methods'), ('compression', 'methods', 'LZW'), ('methods', 'LZW', 'LZ'), ('LZW', 'LZ', 'and'), ('LZ', 'and', 'PPM')]\n",
      "\n",
      "Document: According to AIXI theory a connection more directly explained in Hutter Prize the best possible compression of x is the smallest possible software that generates x For example in that model a zip files compressed size includes both the zip file and the unzipping software since you can not unzip it without both but there may be an even smaller combined form\n",
      "\n",
      "\n",
      "Unigrams: [('According',), ('to',), ('AIXI',), ('theory',), ('a',), ('connection',), ('more',), ('directly',), ('explained',), ('in',), ('Hutter',), ('Prize',), ('the',), ('best',), ('possible',), ('compression',), ('of',), ('x',), ('is',), ('the',), ('smallest',), ('possible',), ('software',), ('that',), ('generates',), ('x',), ('For',), ('example',), ('in',), ('that',), ('model',), ('a',), ('zip',), ('files',), ('compressed',), ('size',), ('includes',), ('both',), ('the',), ('zip',), ('file',), ('and',), ('the',), ('unzipping',), ('software',), ('since',), ('you',), ('can',), ('not',), ('unzip',), ('it',), ('without',), ('both',), ('but',), ('there',), ('may',), ('be',), ('an',), ('even',), ('smaller',), ('combined',), ('form',)]\n",
      "\n",
      "Bigrams: [('According', 'to'), ('to', 'AIXI'), ('AIXI', 'theory'), ('theory', 'a'), ('a', 'connection'), ('connection', 'more'), ('more', 'directly'), ('directly', 'explained'), ('explained', 'in'), ('in', 'Hutter'), ('Hutter', 'Prize'), ('Prize', 'the'), ('the', 'best'), ('best', 'possible'), ('possible', 'compression'), ('compression', 'of'), ('of', 'x'), ('x', 'is'), ('is', 'the'), ('the', 'smallest'), ('smallest', 'possible'), ('possible', 'software'), ('software', 'that'), ('that', 'generates'), ('generates', 'x'), ('x', 'For'), ('For', 'example'), ('example', 'in'), ('in', 'that'), ('that', 'model'), ('model', 'a'), ('a', 'zip'), ('zip', 'files'), ('files', 'compressed'), ('compressed', 'size'), ('size', 'includes'), ('includes', 'both'), ('both', 'the'), ('the', 'zip'), ('zip', 'file'), ('file', 'and'), ('and', 'the'), ('the', 'unzipping'), ('unzipping', 'software'), ('software', 'since'), ('since', 'you'), ('you', 'can'), ('can', 'not'), ('not', 'unzip'), ('unzip', 'it'), ('it', 'without'), ('without', 'both'), ('both', 'but'), ('but', 'there'), ('there', 'may'), ('may', 'be'), ('be', 'an'), ('an', 'even'), ('even', 'smaller'), ('smaller', 'combined'), ('combined', 'form')]\n",
      "\n",
      "Trigrams: [('According', 'to', 'AIXI'), ('to', 'AIXI', 'theory'), ('AIXI', 'theory', 'a'), ('theory', 'a', 'connection'), ('a', 'connection', 'more'), ('connection', 'more', 'directly'), ('more', 'directly', 'explained'), ('directly', 'explained', 'in'), ('explained', 'in', 'Hutter'), ('in', 'Hutter', 'Prize'), ('Hutter', 'Prize', 'the'), ('Prize', 'the', 'best'), ('the', 'best', 'possible'), ('best', 'possible', 'compression'), ('possible', 'compression', 'of'), ('compression', 'of', 'x'), ('of', 'x', 'is'), ('x', 'is', 'the'), ('is', 'the', 'smallest'), ('the', 'smallest', 'possible'), ('smallest', 'possible', 'software'), ('possible', 'software', 'that'), ('software', 'that', 'generates'), ('that', 'generates', 'x'), ('generates', 'x', 'For'), ('x', 'For', 'example'), ('For', 'example', 'in'), ('example', 'in', 'that'), ('in', 'that', 'model'), ('that', 'model', 'a'), ('model', 'a', 'zip'), ('a', 'zip', 'files'), ('zip', 'files', 'compressed'), ('files', 'compressed', 'size'), ('compressed', 'size', 'includes'), ('size', 'includes', 'both'), ('includes', 'both', 'the'), ('both', 'the', 'zip'), ('the', 'zip', 'file'), ('zip', 'file', 'and'), ('file', 'and', 'the'), ('and', 'the', 'unzipping'), ('the', 'unzipping', 'software'), ('unzipping', 'software', 'since'), ('software', 'since', 'you'), ('since', 'you', 'can'), ('you', 'can', 'not'), ('can', 'not', 'unzip'), ('not', 'unzip', 'it'), ('unzip', 'it', 'without'), ('it', 'without', 'both'), ('without', 'both', 'but'), ('both', 'but', 'there'), ('but', 'there', 'may'), ('there', 'may', 'be'), ('may', 'be', 'an'), ('be', 'an', 'even'), ('an', 'even', 'smaller'), ('even', 'smaller', 'combined'), ('smaller', 'combined', 'form')]\n",
      "\n",
      "Document: Examples of AIpowered audiovideo compression software include NVIDIA Maxine AIVC Examples of software that can perform AIpowered image compression include OpenCV TensorFlow MATLABs Image Processing Toolbox IPT and HighFidelity Generative Image Compression\n",
      "\n",
      "\n",
      "Unigrams: [('Examples',), ('of',), ('AIpowered',), ('audiovideo',), ('compression',), ('software',), ('include',), ('NVIDIA',), ('Maxine',), ('AIVC',), ('Examples',), ('of',), ('software',), ('that',), ('can',), ('perform',), ('AIpowered',), ('image',), ('compression',), ('include',), ('OpenCV',), ('TensorFlow',), ('MATLABs',), ('Image',), ('Processing',), ('Toolbox',), ('IPT',), ('and',), ('HighFidelity',), ('Generative',), ('Image',), ('Compression',)]\n",
      "\n",
      "Bigrams: [('Examples', 'of'), ('of', 'AIpowered'), ('AIpowered', 'audiovideo'), ('audiovideo', 'compression'), ('compression', 'software'), ('software', 'include'), ('include', 'NVIDIA'), ('NVIDIA', 'Maxine'), ('Maxine', 'AIVC'), ('AIVC', 'Examples'), ('Examples', 'of'), ('of', 'software'), ('software', 'that'), ('that', 'can'), ('can', 'perform'), ('perform', 'AIpowered'), ('AIpowered', 'image'), ('image', 'compression'), ('compression', 'include'), ('include', 'OpenCV'), ('OpenCV', 'TensorFlow'), ('TensorFlow', 'MATLABs'), ('MATLABs', 'Image'), ('Image', 'Processing'), ('Processing', 'Toolbox'), ('Toolbox', 'IPT'), ('IPT', 'and'), ('and', 'HighFidelity'), ('HighFidelity', 'Generative'), ('Generative', 'Image'), ('Image', 'Compression')]\n",
      "\n",
      "Trigrams: [('Examples', 'of', 'AIpowered'), ('of', 'AIpowered', 'audiovideo'), ('AIpowered', 'audiovideo', 'compression'), ('audiovideo', 'compression', 'software'), ('compression', 'software', 'include'), ('software', 'include', 'NVIDIA'), ('include', 'NVIDIA', 'Maxine'), ('NVIDIA', 'Maxine', 'AIVC'), ('Maxine', 'AIVC', 'Examples'), ('AIVC', 'Examples', 'of'), ('Examples', 'of', 'software'), ('of', 'software', 'that'), ('software', 'that', 'can'), ('that', 'can', 'perform'), ('can', 'perform', 'AIpowered'), ('perform', 'AIpowered', 'image'), ('AIpowered', 'image', 'compression'), ('image', 'compression', 'include'), ('compression', 'include', 'OpenCV'), ('include', 'OpenCV', 'TensorFlow'), ('OpenCV', 'TensorFlow', 'MATLABs'), ('TensorFlow', 'MATLABs', 'Image'), ('MATLABs', 'Image', 'Processing'), ('Image', 'Processing', 'Toolbox'), ('Processing', 'Toolbox', 'IPT'), ('Toolbox', 'IPT', 'and'), ('IPT', 'and', 'HighFidelity'), ('and', 'HighFidelity', 'Generative'), ('HighFidelity', 'Generative', 'Image'), ('Generative', 'Image', 'Compression')]\n",
      "\n",
      "Document: In unsupervised machine learning kmeans clustering can be utilized to compress data by grouping similar data points into clusters This technique simplifies handling extensive datasets that lack predefined labels and finds widespread use in fields such as image compression\n",
      "\n",
      "\n",
      "Unigrams: [('In',), ('unsupervised',), ('machine',), ('learning',), ('kmeans',), ('clustering',), ('can',), ('be',), ('utilized',), ('to',), ('compress',), ('data',), ('by',), ('grouping',), ('similar',), ('data',), ('points',), ('into',), ('clusters',), ('This',), ('technique',), ('simplifies',), ('handling',), ('extensive',), ('datasets',), ('that',), ('lack',), ('predefined',), ('labels',), ('and',), ('finds',), ('widespread',), ('use',), ('in',), ('fields',), ('such',), ('as',), ('image',), ('compression',)]\n",
      "\n",
      "Bigrams: [('In', 'unsupervised'), ('unsupervised', 'machine'), ('machine', 'learning'), ('learning', 'kmeans'), ('kmeans', 'clustering'), ('clustering', 'can'), ('can', 'be'), ('be', 'utilized'), ('utilized', 'to'), ('to', 'compress'), ('compress', 'data'), ('data', 'by'), ('by', 'grouping'), ('grouping', 'similar'), ('similar', 'data'), ('data', 'points'), ('points', 'into'), ('into', 'clusters'), ('clusters', 'This'), ('This', 'technique'), ('technique', 'simplifies'), ('simplifies', 'handling'), ('handling', 'extensive'), ('extensive', 'datasets'), ('datasets', 'that'), ('that', 'lack'), ('lack', 'predefined'), ('predefined', 'labels'), ('labels', 'and'), ('and', 'finds'), ('finds', 'widespread'), ('widespread', 'use'), ('use', 'in'), ('in', 'fields'), ('fields', 'such'), ('such', 'as'), ('as', 'image'), ('image', 'compression')]\n",
      "\n",
      "Trigrams: [('In', 'unsupervised', 'machine'), ('unsupervised', 'machine', 'learning'), ('machine', 'learning', 'kmeans'), ('learning', 'kmeans', 'clustering'), ('kmeans', 'clustering', 'can'), ('clustering', 'can', 'be'), ('can', 'be', 'utilized'), ('be', 'utilized', 'to'), ('utilized', 'to', 'compress'), ('to', 'compress', 'data'), ('compress', 'data', 'by'), ('data', 'by', 'grouping'), ('by', 'grouping', 'similar'), ('grouping', 'similar', 'data'), ('similar', 'data', 'points'), ('data', 'points', 'into'), ('points', 'into', 'clusters'), ('into', 'clusters', 'This'), ('clusters', 'This', 'technique'), ('This', 'technique', 'simplifies'), ('technique', 'simplifies', 'handling'), ('simplifies', 'handling', 'extensive'), ('handling', 'extensive', 'datasets'), ('extensive', 'datasets', 'that'), ('datasets', 'that', 'lack'), ('that', 'lack', 'predefined'), ('lack', 'predefined', 'labels'), ('predefined', 'labels', 'and'), ('labels', 'and', 'finds'), ('and', 'finds', 'widespread'), ('finds', 'widespread', 'use'), ('widespread', 'use', 'in'), ('use', 'in', 'fields'), ('in', 'fields', 'such'), ('fields', 'such', 'as'), ('such', 'as', 'image'), ('as', 'image', 'compression')]\n",
      "\n",
      "Document: Data compression aims to reduce the size of data files enhancing storage efficiency and speeding up data transmission Kmeans clustering an unsupervised machine learning algorithm is employed to partition a dataset into a specified number of clusters k each represented by the centroid of its points This process condenses extensive datasets into a more compact set of representative points Particularly beneficial in image and signal processing kmeans clustering aids in data reduction by replacing groups of data points with their centroids thereby preserving the core information of the original data while significantly decreasing the required storage space\n",
      "\n",
      "\n",
      "Unigrams: [('Data',), ('compression',), ('aims',), ('to',), ('reduce',), ('the',), ('size',), ('of',), ('data',), ('files',), ('enhancing',), ('storage',), ('efficiency',), ('and',), ('speeding',), ('up',), ('data',), ('transmission',), ('Kmeans',), ('clustering',), ('an',), ('unsupervised',), ('machine',), ('learning',), ('algorithm',), ('is',), ('employed',), ('to',), ('partition',), ('a',), ('dataset',), ('into',), ('a',), ('specified',), ('number',), ('of',), ('clusters',), ('k',), ('each',), ('represented',), ('by',), ('the',), ('centroid',), ('of',), ('its',), ('points',), ('This',), ('process',), ('condenses',), ('extensive',), ('datasets',), ('into',), ('a',), ('more',), ('compact',), ('set',), ('of',), ('representative',), ('points',), ('Particularly',), ('beneficial',), ('in',), ('image',), ('and',), ('signal',), ('processing',), ('kmeans',), ('clustering',), ('aids',), ('in',), ('data',), ('reduction',), ('by',), ('replacing',), ('groups',), ('of',), ('data',), ('points',), ('with',), ('their',), ('centroids',), ('thereby',), ('preserving',), ('the',), ('core',), ('information',), ('of',), ('the',), ('original',), ('data',), ('while',), ('significantly',), ('decreasing',), ('the',), ('required',), ('storage',), ('space',)]\n",
      "\n",
      "Bigrams: [('Data', 'compression'), ('compression', 'aims'), ('aims', 'to'), ('to', 'reduce'), ('reduce', 'the'), ('the', 'size'), ('size', 'of'), ('of', 'data'), ('data', 'files'), ('files', 'enhancing'), ('enhancing', 'storage'), ('storage', 'efficiency'), ('efficiency', 'and'), ('and', 'speeding'), ('speeding', 'up'), ('up', 'data'), ('data', 'transmission'), ('transmission', 'Kmeans'), ('Kmeans', 'clustering'), ('clustering', 'an'), ('an', 'unsupervised'), ('unsupervised', 'machine'), ('machine', 'learning'), ('learning', 'algorithm'), ('algorithm', 'is'), ('is', 'employed'), ('employed', 'to'), ('to', 'partition'), ('partition', 'a'), ('a', 'dataset'), ('dataset', 'into'), ('into', 'a'), ('a', 'specified'), ('specified', 'number'), ('number', 'of'), ('of', 'clusters'), ('clusters', 'k'), ('k', 'each'), ('each', 'represented'), ('represented', 'by'), ('by', 'the'), ('the', 'centroid'), ('centroid', 'of'), ('of', 'its'), ('its', 'points'), ('points', 'This'), ('This', 'process'), ('process', 'condenses'), ('condenses', 'extensive'), ('extensive', 'datasets'), ('datasets', 'into'), ('into', 'a'), ('a', 'more'), ('more', 'compact'), ('compact', 'set'), ('set', 'of'), ('of', 'representative'), ('representative', 'points'), ('points', 'Particularly'), ('Particularly', 'beneficial'), ('beneficial', 'in'), ('in', 'image'), ('image', 'and'), ('and', 'signal'), ('signal', 'processing'), ('processing', 'kmeans'), ('kmeans', 'clustering'), ('clustering', 'aids'), ('aids', 'in'), ('in', 'data'), ('data', 'reduction'), ('reduction', 'by'), ('by', 'replacing'), ('replacing', 'groups'), ('groups', 'of'), ('of', 'data'), ('data', 'points'), ('points', 'with'), ('with', 'their'), ('their', 'centroids'), ('centroids', 'thereby'), ('thereby', 'preserving'), ('preserving', 'the'), ('the', 'core'), ('core', 'information'), ('information', 'of'), ('of', 'the'), ('the', 'original'), ('original', 'data'), ('data', 'while'), ('while', 'significantly'), ('significantly', 'decreasing'), ('decreasing', 'the'), ('the', 'required'), ('required', 'storage'), ('storage', 'space')]\n",
      "\n",
      "Trigrams: [('Data', 'compression', 'aims'), ('compression', 'aims', 'to'), ('aims', 'to', 'reduce'), ('to', 'reduce', 'the'), ('reduce', 'the', 'size'), ('the', 'size', 'of'), ('size', 'of', 'data'), ('of', 'data', 'files'), ('data', 'files', 'enhancing'), ('files', 'enhancing', 'storage'), ('enhancing', 'storage', 'efficiency'), ('storage', 'efficiency', 'and'), ('efficiency', 'and', 'speeding'), ('and', 'speeding', 'up'), ('speeding', 'up', 'data'), ('up', 'data', 'transmission'), ('data', 'transmission', 'Kmeans'), ('transmission', 'Kmeans', 'clustering'), ('Kmeans', 'clustering', 'an'), ('clustering', 'an', 'unsupervised'), ('an', 'unsupervised', 'machine'), ('unsupervised', 'machine', 'learning'), ('machine', 'learning', 'algorithm'), ('learning', 'algorithm', 'is'), ('algorithm', 'is', 'employed'), ('is', 'employed', 'to'), ('employed', 'to', 'partition'), ('to', 'partition', 'a'), ('partition', 'a', 'dataset'), ('a', 'dataset', 'into'), ('dataset', 'into', 'a'), ('into', 'a', 'specified'), ('a', 'specified', 'number'), ('specified', 'number', 'of'), ('number', 'of', 'clusters'), ('of', 'clusters', 'k'), ('clusters', 'k', 'each'), ('k', 'each', 'represented'), ('each', 'represented', 'by'), ('represented', 'by', 'the'), ('by', 'the', 'centroid'), ('the', 'centroid', 'of'), ('centroid', 'of', 'its'), ('of', 'its', 'points'), ('its', 'points', 'This'), ('points', 'This', 'process'), ('This', 'process', 'condenses'), ('process', 'condenses', 'extensive'), ('condenses', 'extensive', 'datasets'), ('extensive', 'datasets', 'into'), ('datasets', 'into', 'a'), ('into', 'a', 'more'), ('a', 'more', 'compact'), ('more', 'compact', 'set'), ('compact', 'set', 'of'), ('set', 'of', 'representative'), ('of', 'representative', 'points'), ('representative', 'points', 'Particularly'), ('points', 'Particularly', 'beneficial'), ('Particularly', 'beneficial', 'in'), ('beneficial', 'in', 'image'), ('in', 'image', 'and'), ('image', 'and', 'signal'), ('and', 'signal', 'processing'), ('signal', 'processing', 'kmeans'), ('processing', 'kmeans', 'clustering'), ('kmeans', 'clustering', 'aids'), ('clustering', 'aids', 'in'), ('aids', 'in', 'data'), ('in', 'data', 'reduction'), ('data', 'reduction', 'by'), ('reduction', 'by', 'replacing'), ('by', 'replacing', 'groups'), ('replacing', 'groups', 'of'), ('groups', 'of', 'data'), ('of', 'data', 'points'), ('data', 'points', 'with'), ('points', 'with', 'their'), ('with', 'their', 'centroids'), ('their', 'centroids', 'thereby'), ('centroids', 'thereby', 'preserving'), ('thereby', 'preserving', 'the'), ('preserving', 'the', 'core'), ('the', 'core', 'information'), ('core', 'information', 'of'), ('information', 'of', 'the'), ('of', 'the', 'original'), ('the', 'original', 'data'), ('original', 'data', 'while'), ('data', 'while', 'significantly'), ('while', 'significantly', 'decreasing'), ('significantly', 'decreasing', 'the'), ('decreasing', 'the', 'required'), ('the', 'required', 'storage'), ('required', 'storage', 'space')]\n",
      "\n",
      "Document: Machine learning and data mining often employ the same methods and overlap significantly but while machine learning focuses on prediction based on known properties learned from the training data data mining focuses on the discovery of previously unknown properties in the data this is the analysis step of knowledge discovery in databases Data mining uses many machine learning methods but with different goals on the other hand machine learning also employs data mining methods as unsupervised learning or as a preprocessing step to improve learner accuracy Much of the confusion between these two research communities which do often have separate conferences and separate journals ECML PKDD being a major exception comes from the basic assumptions they work with in machine learning performance is usually evaluated with respect to the ability to reproduce known knowledge while in knowledge discovery and data mining KDD the key task is the discovery of previously unknown knowledge Evaluated with respect to known knowledge an uninformed unsupervised method will easily be outperformed by other supervised methods while in a typical KDD task supervised methods cannot be used due to the unavailability of training data\n",
      "\n",
      "\n",
      "Unigrams: [('Machine',), ('learning',), ('and',), ('data',), ('mining',), ('often',), ('employ',), ('the',), ('same',), ('methods',), ('and',), ('overlap',), ('significantly',), ('but',), ('while',), ('machine',), ('learning',), ('focuses',), ('on',), ('prediction',), ('based',), ('on',), ('known',), ('properties',), ('learned',), ('from',), ('the',), ('training',), ('data',), ('data',), ('mining',), ('focuses',), ('on',), ('the',), ('discovery',), ('of',), ('previously',), ('unknown',), ('properties',), ('in',), ('the',), ('data',), ('this',), ('is',), ('the',), ('analysis',), ('step',), ('of',), ('knowledge',), ('discovery',), ('in',), ('databases',), ('Data',), ('mining',), ('uses',), ('many',), ('machine',), ('learning',), ('methods',), ('but',), ('with',), ('different',), ('goals',), ('on',), ('the',), ('other',), ('hand',), ('machine',), ('learning',), ('also',), ('employs',), ('data',), ('mining',), ('methods',), ('as',), ('unsupervised',), ('learning',), ('or',), ('as',), ('a',), ('preprocessing',), ('step',), ('to',), ('improve',), ('learner',), ('accuracy',), ('Much',), ('of',), ('the',), ('confusion',), ('between',), ('these',), ('two',), ('research',), ('communities',), ('which',), ('do',), ('often',), ('have',), ('separate',), ('conferences',), ('and',), ('separate',), ('journals',), ('ECML',), ('PKDD',), ('being',), ('a',), ('major',), ('exception',), ('comes',), ('from',), ('the',), ('basic',), ('assumptions',), ('they',), ('work',), ('with',), ('in',), ('machine',), ('learning',), ('performance',), ('is',), ('usually',), ('evaluated',), ('with',), ('respect',), ('to',), ('the',), ('ability',), ('to',), ('reproduce',), ('known',), ('knowledge',), ('while',), ('in',), ('knowledge',), ('discovery',), ('and',), ('data',), ('mining',), ('KDD',), ('the',), ('key',), ('task',), ('is',), ('the',), ('discovery',), ('of',), ('previously',), ('unknown',), ('knowledge',), ('Evaluated',), ('with',), ('respect',), ('to',), ('known',), ('knowledge',), ('an',), ('uninformed',), ('unsupervised',), ('method',), ('will',), ('easily',), ('be',), ('outperformed',), ('by',), ('other',), ('supervised',), ('methods',), ('while',), ('in',), ('a',), ('typical',), ('KDD',), ('task',), ('supervised',), ('methods',), ('cannot',), ('be',), ('used',), ('due',), ('to',), ('the',), ('unavailability',), ('of',), ('training',), ('data',)]\n",
      "\n",
      "Bigrams: [('Machine', 'learning'), ('learning', 'and'), ('and', 'data'), ('data', 'mining'), ('mining', 'often'), ('often', 'employ'), ('employ', 'the'), ('the', 'same'), ('same', 'methods'), ('methods', 'and'), ('and', 'overlap'), ('overlap', 'significantly'), ('significantly', 'but'), ('but', 'while'), ('while', 'machine'), ('machine', 'learning'), ('learning', 'focuses'), ('focuses', 'on'), ('on', 'prediction'), ('prediction', 'based'), ('based', 'on'), ('on', 'known'), ('known', 'properties'), ('properties', 'learned'), ('learned', 'from'), ('from', 'the'), ('the', 'training'), ('training', 'data'), ('data', 'data'), ('data', 'mining'), ('mining', 'focuses'), ('focuses', 'on'), ('on', 'the'), ('the', 'discovery'), ('discovery', 'of'), ('of', 'previously'), ('previously', 'unknown'), ('unknown', 'properties'), ('properties', 'in'), ('in', 'the'), ('the', 'data'), ('data', 'this'), ('this', 'is'), ('is', 'the'), ('the', 'analysis'), ('analysis', 'step'), ('step', 'of'), ('of', 'knowledge'), ('knowledge', 'discovery'), ('discovery', 'in'), ('in', 'databases'), ('databases', 'Data'), ('Data', 'mining'), ('mining', 'uses'), ('uses', 'many'), ('many', 'machine'), ('machine', 'learning'), ('learning', 'methods'), ('methods', 'but'), ('but', 'with'), ('with', 'different'), ('different', 'goals'), ('goals', 'on'), ('on', 'the'), ('the', 'other'), ('other', 'hand'), ('hand', 'machine'), ('machine', 'learning'), ('learning', 'also'), ('also', 'employs'), ('employs', 'data'), ('data', 'mining'), ('mining', 'methods'), ('methods', 'as'), ('as', 'unsupervised'), ('unsupervised', 'learning'), ('learning', 'or'), ('or', 'as'), ('as', 'a'), ('a', 'preprocessing'), ('preprocessing', 'step'), ('step', 'to'), ('to', 'improve'), ('improve', 'learner'), ('learner', 'accuracy'), ('accuracy', 'Much'), ('Much', 'of'), ('of', 'the'), ('the', 'confusion'), ('confusion', 'between'), ('between', 'these'), ('these', 'two'), ('two', 'research'), ('research', 'communities'), ('communities', 'which'), ('which', 'do'), ('do', 'often'), ('often', 'have'), ('have', 'separate'), ('separate', 'conferences'), ('conferences', 'and'), ('and', 'separate'), ('separate', 'journals'), ('journals', 'ECML'), ('ECML', 'PKDD'), ('PKDD', 'being'), ('being', 'a'), ('a', 'major'), ('major', 'exception'), ('exception', 'comes'), ('comes', 'from'), ('from', 'the'), ('the', 'basic'), ('basic', 'assumptions'), ('assumptions', 'they'), ('they', 'work'), ('work', 'with'), ('with', 'in'), ('in', 'machine'), ('machine', 'learning'), ('learning', 'performance'), ('performance', 'is'), ('is', 'usually'), ('usually', 'evaluated'), ('evaluated', 'with'), ('with', 'respect'), ('respect', 'to'), ('to', 'the'), ('the', 'ability'), ('ability', 'to'), ('to', 'reproduce'), ('reproduce', 'known'), ('known', 'knowledge'), ('knowledge', 'while'), ('while', 'in'), ('in', 'knowledge'), ('knowledge', 'discovery'), ('discovery', 'and'), ('and', 'data'), ('data', 'mining'), ('mining', 'KDD'), ('KDD', 'the'), ('the', 'key'), ('key', 'task'), ('task', 'is'), ('is', 'the'), ('the', 'discovery'), ('discovery', 'of'), ('of', 'previously'), ('previously', 'unknown'), ('unknown', 'knowledge'), ('knowledge', 'Evaluated'), ('Evaluated', 'with'), ('with', 'respect'), ('respect', 'to'), ('to', 'known'), ('known', 'knowledge'), ('knowledge', 'an'), ('an', 'uninformed'), ('uninformed', 'unsupervised'), ('unsupervised', 'method'), ('method', 'will'), ('will', 'easily'), ('easily', 'be'), ('be', 'outperformed'), ('outperformed', 'by'), ('by', 'other'), ('other', 'supervised'), ('supervised', 'methods'), ('methods', 'while'), ('while', 'in'), ('in', 'a'), ('a', 'typical'), ('typical', 'KDD'), ('KDD', 'task'), ('task', 'supervised'), ('supervised', 'methods'), ('methods', 'cannot'), ('cannot', 'be'), ('be', 'used'), ('used', 'due'), ('due', 'to'), ('to', 'the'), ('the', 'unavailability'), ('unavailability', 'of'), ('of', 'training'), ('training', 'data')]\n",
      "\n",
      "Trigrams: [('Machine', 'learning', 'and'), ('learning', 'and', 'data'), ('and', 'data', 'mining'), ('data', 'mining', 'often'), ('mining', 'often', 'employ'), ('often', 'employ', 'the'), ('employ', 'the', 'same'), ('the', 'same', 'methods'), ('same', 'methods', 'and'), ('methods', 'and', 'overlap'), ('and', 'overlap', 'significantly'), ('overlap', 'significantly', 'but'), ('significantly', 'but', 'while'), ('but', 'while', 'machine'), ('while', 'machine', 'learning'), ('machine', 'learning', 'focuses'), ('learning', 'focuses', 'on'), ('focuses', 'on', 'prediction'), ('on', 'prediction', 'based'), ('prediction', 'based', 'on'), ('based', 'on', 'known'), ('on', 'known', 'properties'), ('known', 'properties', 'learned'), ('properties', 'learned', 'from'), ('learned', 'from', 'the'), ('from', 'the', 'training'), ('the', 'training', 'data'), ('training', 'data', 'data'), ('data', 'data', 'mining'), ('data', 'mining', 'focuses'), ('mining', 'focuses', 'on'), ('focuses', 'on', 'the'), ('on', 'the', 'discovery'), ('the', 'discovery', 'of'), ('discovery', 'of', 'previously'), ('of', 'previously', 'unknown'), ('previously', 'unknown', 'properties'), ('unknown', 'properties', 'in'), ('properties', 'in', 'the'), ('in', 'the', 'data'), ('the', 'data', 'this'), ('data', 'this', 'is'), ('this', 'is', 'the'), ('is', 'the', 'analysis'), ('the', 'analysis', 'step'), ('analysis', 'step', 'of'), ('step', 'of', 'knowledge'), ('of', 'knowledge', 'discovery'), ('knowledge', 'discovery', 'in'), ('discovery', 'in', 'databases'), ('in', 'databases', 'Data'), ('databases', 'Data', 'mining'), ('Data', 'mining', 'uses'), ('mining', 'uses', 'many'), ('uses', 'many', 'machine'), ('many', 'machine', 'learning'), ('machine', 'learning', 'methods'), ('learning', 'methods', 'but'), ('methods', 'but', 'with'), ('but', 'with', 'different'), ('with', 'different', 'goals'), ('different', 'goals', 'on'), ('goals', 'on', 'the'), ('on', 'the', 'other'), ('the', 'other', 'hand'), ('other', 'hand', 'machine'), ('hand', 'machine', 'learning'), ('machine', 'learning', 'also'), ('learning', 'also', 'employs'), ('also', 'employs', 'data'), ('employs', 'data', 'mining'), ('data', 'mining', 'methods'), ('mining', 'methods', 'as'), ('methods', 'as', 'unsupervised'), ('as', 'unsupervised', 'learning'), ('unsupervised', 'learning', 'or'), ('learning', 'or', 'as'), ('or', 'as', 'a'), ('as', 'a', 'preprocessing'), ('a', 'preprocessing', 'step'), ('preprocessing', 'step', 'to'), ('step', 'to', 'improve'), ('to', 'improve', 'learner'), ('improve', 'learner', 'accuracy'), ('learner', 'accuracy', 'Much'), ('accuracy', 'Much', 'of'), ('Much', 'of', 'the'), ('of', 'the', 'confusion'), ('the', 'confusion', 'between'), ('confusion', 'between', 'these'), ('between', 'these', 'two'), ('these', 'two', 'research'), ('two', 'research', 'communities'), ('research', 'communities', 'which'), ('communities', 'which', 'do'), ('which', 'do', 'often'), ('do', 'often', 'have'), ('often', 'have', 'separate'), ('have', 'separate', 'conferences'), ('separate', 'conferences', 'and'), ('conferences', 'and', 'separate'), ('and', 'separate', 'journals'), ('separate', 'journals', 'ECML'), ('journals', 'ECML', 'PKDD'), ('ECML', 'PKDD', 'being'), ('PKDD', 'being', 'a'), ('being', 'a', 'major'), ('a', 'major', 'exception'), ('major', 'exception', 'comes'), ('exception', 'comes', 'from'), ('comes', 'from', 'the'), ('from', 'the', 'basic'), ('the', 'basic', 'assumptions'), ('basic', 'assumptions', 'they'), ('assumptions', 'they', 'work'), ('they', 'work', 'with'), ('work', 'with', 'in'), ('with', 'in', 'machine'), ('in', 'machine', 'learning'), ('machine', 'learning', 'performance'), ('learning', 'performance', 'is'), ('performance', 'is', 'usually'), ('is', 'usually', 'evaluated'), ('usually', 'evaluated', 'with'), ('evaluated', 'with', 'respect'), ('with', 'respect', 'to'), ('respect', 'to', 'the'), ('to', 'the', 'ability'), ('the', 'ability', 'to'), ('ability', 'to', 'reproduce'), ('to', 'reproduce', 'known'), ('reproduce', 'known', 'knowledge'), ('known', 'knowledge', 'while'), ('knowledge', 'while', 'in'), ('while', 'in', 'knowledge'), ('in', 'knowledge', 'discovery'), ('knowledge', 'discovery', 'and'), ('discovery', 'and', 'data'), ('and', 'data', 'mining'), ('data', 'mining', 'KDD'), ('mining', 'KDD', 'the'), ('KDD', 'the', 'key'), ('the', 'key', 'task'), ('key', 'task', 'is'), ('task', 'is', 'the'), ('is', 'the', 'discovery'), ('the', 'discovery', 'of'), ('discovery', 'of', 'previously'), ('of', 'previously', 'unknown'), ('previously', 'unknown', 'knowledge'), ('unknown', 'knowledge', 'Evaluated'), ('knowledge', 'Evaluated', 'with'), ('Evaluated', 'with', 'respect'), ('with', 'respect', 'to'), ('respect', 'to', 'known'), ('to', 'known', 'knowledge'), ('known', 'knowledge', 'an'), ('knowledge', 'an', 'uninformed'), ('an', 'uninformed', 'unsupervised'), ('uninformed', 'unsupervised', 'method'), ('unsupervised', 'method', 'will'), ('method', 'will', 'easily'), ('will', 'easily', 'be'), ('easily', 'be', 'outperformed'), ('be', 'outperformed', 'by'), ('outperformed', 'by', 'other'), ('by', 'other', 'supervised'), ('other', 'supervised', 'methods'), ('supervised', 'methods', 'while'), ('methods', 'while', 'in'), ('while', 'in', 'a'), ('in', 'a', 'typical'), ('a', 'typical', 'KDD'), ('typical', 'KDD', 'task'), ('KDD', 'task', 'supervised'), ('task', 'supervised', 'methods'), ('supervised', 'methods', 'cannot'), ('methods', 'cannot', 'be'), ('cannot', 'be', 'used'), ('be', 'used', 'due'), ('used', 'due', 'to'), ('due', 'to', 'the'), ('to', 'the', 'unavailability'), ('the', 'unavailability', 'of'), ('unavailability', 'of', 'training'), ('of', 'training', 'data')]\n",
      "\n",
      "Document: Machine learning also has intimate ties to optimisation Many learning problems are formulated as minimisation of some loss function on a training set of examples Loss functions express the discrepancy between the predictions of the model being trained and the actual problem instances for example in classification one wants to assign a label to instances and models are trained to correctly predict the preassigned labels of a set of examples\n",
      "\n",
      "\n",
      "Unigrams: [('Machine',), ('learning',), ('also',), ('has',), ('intimate',), ('ties',), ('to',), ('optimisation',), ('Many',), ('learning',), ('problems',), ('are',), ('formulated',), ('as',), ('minimisation',), ('of',), ('some',), ('loss',), ('function',), ('on',), ('a',), ('training',), ('set',), ('of',), ('examples',), ('Loss',), ('functions',), ('express',), ('the',), ('discrepancy',), ('between',), ('the',), ('predictions',), ('of',), ('the',), ('model',), ('being',), ('trained',), ('and',), ('the',), ('actual',), ('problem',), ('instances',), ('for',), ('example',), ('in',), ('classification',), ('one',), ('wants',), ('to',), ('assign',), ('a',), ('label',), ('to',), ('instances',), ('and',), ('models',), ('are',), ('trained',), ('to',), ('correctly',), ('predict',), ('the',), ('preassigned',), ('labels',), ('of',), ('a',), ('set',), ('of',), ('examples',)]\n",
      "\n",
      "Bigrams: [('Machine', 'learning'), ('learning', 'also'), ('also', 'has'), ('has', 'intimate'), ('intimate', 'ties'), ('ties', 'to'), ('to', 'optimisation'), ('optimisation', 'Many'), ('Many', 'learning'), ('learning', 'problems'), ('problems', 'are'), ('are', 'formulated'), ('formulated', 'as'), ('as', 'minimisation'), ('minimisation', 'of'), ('of', 'some'), ('some', 'loss'), ('loss', 'function'), ('function', 'on'), ('on', 'a'), ('a', 'training'), ('training', 'set'), ('set', 'of'), ('of', 'examples'), ('examples', 'Loss'), ('Loss', 'functions'), ('functions', 'express'), ('express', 'the'), ('the', 'discrepancy'), ('discrepancy', 'between'), ('between', 'the'), ('the', 'predictions'), ('predictions', 'of'), ('of', 'the'), ('the', 'model'), ('model', 'being'), ('being', 'trained'), ('trained', 'and'), ('and', 'the'), ('the', 'actual'), ('actual', 'problem'), ('problem', 'instances'), ('instances', 'for'), ('for', 'example'), ('example', 'in'), ('in', 'classification'), ('classification', 'one'), ('one', 'wants'), ('wants', 'to'), ('to', 'assign'), ('assign', 'a'), ('a', 'label'), ('label', 'to'), ('to', 'instances'), ('instances', 'and'), ('and', 'models'), ('models', 'are'), ('are', 'trained'), ('trained', 'to'), ('to', 'correctly'), ('correctly', 'predict'), ('predict', 'the'), ('the', 'preassigned'), ('preassigned', 'labels'), ('labels', 'of'), ('of', 'a'), ('a', 'set'), ('set', 'of'), ('of', 'examples')]\n",
      "\n",
      "Trigrams: [('Machine', 'learning', 'also'), ('learning', 'also', 'has'), ('also', 'has', 'intimate'), ('has', 'intimate', 'ties'), ('intimate', 'ties', 'to'), ('ties', 'to', 'optimisation'), ('to', 'optimisation', 'Many'), ('optimisation', 'Many', 'learning'), ('Many', 'learning', 'problems'), ('learning', 'problems', 'are'), ('problems', 'are', 'formulated'), ('are', 'formulated', 'as'), ('formulated', 'as', 'minimisation'), ('as', 'minimisation', 'of'), ('minimisation', 'of', 'some'), ('of', 'some', 'loss'), ('some', 'loss', 'function'), ('loss', 'function', 'on'), ('function', 'on', 'a'), ('on', 'a', 'training'), ('a', 'training', 'set'), ('training', 'set', 'of'), ('set', 'of', 'examples'), ('of', 'examples', 'Loss'), ('examples', 'Loss', 'functions'), ('Loss', 'functions', 'express'), ('functions', 'express', 'the'), ('express', 'the', 'discrepancy'), ('the', 'discrepancy', 'between'), ('discrepancy', 'between', 'the'), ('between', 'the', 'predictions'), ('the', 'predictions', 'of'), ('predictions', 'of', 'the'), ('of', 'the', 'model'), ('the', 'model', 'being'), ('model', 'being', 'trained'), ('being', 'trained', 'and'), ('trained', 'and', 'the'), ('and', 'the', 'actual'), ('the', 'actual', 'problem'), ('actual', 'problem', 'instances'), ('problem', 'instances', 'for'), ('instances', 'for', 'example'), ('for', 'example', 'in'), ('example', 'in', 'classification'), ('in', 'classification', 'one'), ('classification', 'one', 'wants'), ('one', 'wants', 'to'), ('wants', 'to', 'assign'), ('to', 'assign', 'a'), ('assign', 'a', 'label'), ('a', 'label', 'to'), ('label', 'to', 'instances'), ('to', 'instances', 'and'), ('instances', 'and', 'models'), ('and', 'models', 'are'), ('models', 'are', 'trained'), ('are', 'trained', 'to'), ('trained', 'to', 'correctly'), ('to', 'correctly', 'predict'), ('correctly', 'predict', 'the'), ('predict', 'the', 'preassigned'), ('the', 'preassigned', 'labels'), ('preassigned', 'labels', 'of'), ('labels', 'of', 'a'), ('of', 'a', 'set'), ('a', 'set', 'of'), ('set', 'of', 'examples')]\n",
      "\n",
      "Document: Characterizing the generalisation of various learning algorithms is an active topic of current research especially for deep learning algorithms\n",
      "\n",
      "\n",
      "Unigrams: [('Characterizing',), ('the',), ('generalisation',), ('of',), ('various',), ('learning',), ('algorithms',), ('is',), ('an',), ('active',), ('topic',), ('of',), ('current',), ('research',), ('especially',), ('for',), ('deep',), ('learning',), ('algorithms',)]\n",
      "\n",
      "Bigrams: [('Characterizing', 'the'), ('the', 'generalisation'), ('generalisation', 'of'), ('of', 'various'), ('various', 'learning'), ('learning', 'algorithms'), ('algorithms', 'is'), ('is', 'an'), ('an', 'active'), ('active', 'topic'), ('topic', 'of'), ('of', 'current'), ('current', 'research'), ('research', 'especially'), ('especially', 'for'), ('for', 'deep'), ('deep', 'learning'), ('learning', 'algorithms')]\n",
      "\n",
      "Trigrams: [('Characterizing', 'the', 'generalisation'), ('the', 'generalisation', 'of'), ('generalisation', 'of', 'various'), ('of', 'various', 'learning'), ('various', 'learning', 'algorithms'), ('learning', 'algorithms', 'is'), ('algorithms', 'is', 'an'), ('is', 'an', 'active'), ('an', 'active', 'topic'), ('active', 'topic', 'of'), ('topic', 'of', 'current'), ('of', 'current', 'research'), ('current', 'research', 'especially'), ('research', 'especially', 'for'), ('especially', 'for', 'deep'), ('for', 'deep', 'learning'), ('deep', 'learning', 'algorithms')]\n",
      "\n",
      "Document: Machine learning and statistics are closely related fields in terms of methods but distinct in their principal goal statistics draws population inferences from a sample while machine learning finds generalisable predictive patterns According to Michael I Jordan the ideas of machine learning from methodological principles to theoretical tools have had a long prehistory in statistics He also suggested the term data science as a placeholder to call the overall field\n",
      "\n",
      "\n",
      "Unigrams: [('Machine',), ('learning',), ('and',), ('statistics',), ('are',), ('closely',), ('related',), ('fields',), ('in',), ('terms',), ('of',), ('methods',), ('but',), ('distinct',), ('in',), ('their',), ('principal',), ('goal',), ('statistics',), ('draws',), ('population',), ('inferences',), ('from',), ('a',), ('sample',), ('while',), ('machine',), ('learning',), ('finds',), ('generalisable',), ('predictive',), ('patterns',), ('According',), ('to',), ('Michael',), ('I',), ('Jordan',), ('the',), ('ideas',), ('of',), ('machine',), ('learning',), ('from',), ('methodological',), ('principles',), ('to',), ('theoretical',), ('tools',), ('have',), ('had',), ('a',), ('long',), ('prehistory',), ('in',), ('statistics',), ('He',), ('also',), ('suggested',), ('the',), ('term',), ('data',), ('science',), ('as',), ('a',), ('placeholder',), ('to',), ('call',), ('the',), ('overall',), ('field',)]\n",
      "\n",
      "Bigrams: [('Machine', 'learning'), ('learning', 'and'), ('and', 'statistics'), ('statistics', 'are'), ('are', 'closely'), ('closely', 'related'), ('related', 'fields'), ('fields', 'in'), ('in', 'terms'), ('terms', 'of'), ('of', 'methods'), ('methods', 'but'), ('but', 'distinct'), ('distinct', 'in'), ('in', 'their'), ('their', 'principal'), ('principal', 'goal'), ('goal', 'statistics'), ('statistics', 'draws'), ('draws', 'population'), ('population', 'inferences'), ('inferences', 'from'), ('from', 'a'), ('a', 'sample'), ('sample', 'while'), ('while', 'machine'), ('machine', 'learning'), ('learning', 'finds'), ('finds', 'generalisable'), ('generalisable', 'predictive'), ('predictive', 'patterns'), ('patterns', 'According'), ('According', 'to'), ('to', 'Michael'), ('Michael', 'I'), ('I', 'Jordan'), ('Jordan', 'the'), ('the', 'ideas'), ('ideas', 'of'), ('of', 'machine'), ('machine', 'learning'), ('learning', 'from'), ('from', 'methodological'), ('methodological', 'principles'), ('principles', 'to'), ('to', 'theoretical'), ('theoretical', 'tools'), ('tools', 'have'), ('have', 'had'), ('had', 'a'), ('a', 'long'), ('long', 'prehistory'), ('prehistory', 'in'), ('in', 'statistics'), ('statistics', 'He'), ('He', 'also'), ('also', 'suggested'), ('suggested', 'the'), ('the', 'term'), ('term', 'data'), ('data', 'science'), ('science', 'as'), ('as', 'a'), ('a', 'placeholder'), ('placeholder', 'to'), ('to', 'call'), ('call', 'the'), ('the', 'overall'), ('overall', 'field')]\n",
      "\n",
      "Trigrams: [('Machine', 'learning', 'and'), ('learning', 'and', 'statistics'), ('and', 'statistics', 'are'), ('statistics', 'are', 'closely'), ('are', 'closely', 'related'), ('closely', 'related', 'fields'), ('related', 'fields', 'in'), ('fields', 'in', 'terms'), ('in', 'terms', 'of'), ('terms', 'of', 'methods'), ('of', 'methods', 'but'), ('methods', 'but', 'distinct'), ('but', 'distinct', 'in'), ('distinct', 'in', 'their'), ('in', 'their', 'principal'), ('their', 'principal', 'goal'), ('principal', 'goal', 'statistics'), ('goal', 'statistics', 'draws'), ('statistics', 'draws', 'population'), ('draws', 'population', 'inferences'), ('population', 'inferences', 'from'), ('inferences', 'from', 'a'), ('from', 'a', 'sample'), ('a', 'sample', 'while'), ('sample', 'while', 'machine'), ('while', 'machine', 'learning'), ('machine', 'learning', 'finds'), ('learning', 'finds', 'generalisable'), ('finds', 'generalisable', 'predictive'), ('generalisable', 'predictive', 'patterns'), ('predictive', 'patterns', 'According'), ('patterns', 'According', 'to'), ('According', 'to', 'Michael'), ('to', 'Michael', 'I'), ('Michael', 'I', 'Jordan'), ('I', 'Jordan', 'the'), ('Jordan', 'the', 'ideas'), ('the', 'ideas', 'of'), ('ideas', 'of', 'machine'), ('of', 'machine', 'learning'), ('machine', 'learning', 'from'), ('learning', 'from', 'methodological'), ('from', 'methodological', 'principles'), ('methodological', 'principles', 'to'), ('principles', 'to', 'theoretical'), ('to', 'theoretical', 'tools'), ('theoretical', 'tools', 'have'), ('tools', 'have', 'had'), ('have', 'had', 'a'), ('had', 'a', 'long'), ('a', 'long', 'prehistory'), ('long', 'prehistory', 'in'), ('prehistory', 'in', 'statistics'), ('in', 'statistics', 'He'), ('statistics', 'He', 'also'), ('He', 'also', 'suggested'), ('also', 'suggested', 'the'), ('suggested', 'the', 'term'), ('the', 'term', 'data'), ('term', 'data', 'science'), ('data', 'science', 'as'), ('science', 'as', 'a'), ('as', 'a', 'placeholder'), ('a', 'placeholder', 'to'), ('placeholder', 'to', 'call'), ('to', 'call', 'the'), ('call', 'the', 'overall'), ('the', 'overall', 'field')]\n",
      "\n",
      "Document: Conventional statistical analyses require the a priori selection of a model most suitable for the study data set In addition only significant or theoretically relevant variables based on previous experience are included for analysis In contrast machine learning is not built on a prestructured model rather the data shape the model by detecting underlying patterns The more variables input used to train the model the more accurate the ultimate model will be\n",
      "\n",
      "\n",
      "Unigrams: [('Conventional',), ('statistical',), ('analyses',), ('require',), ('the',), ('a',), ('priori',), ('selection',), ('of',), ('a',), ('model',), ('most',), ('suitable',), ('for',), ('the',), ('study',), ('data',), ('set',), ('In',), ('addition',), ('only',), ('significant',), ('or',), ('theoretically',), ('relevant',), ('variables',), ('based',), ('on',), ('previous',), ('experience',), ('are',), ('included',), ('for',), ('analysis',), ('In',), ('contrast',), ('machine',), ('learning',), ('is',), ('not',), ('built',), ('on',), ('a',), ('prestructured',), ('model',), ('rather',), ('the',), ('data',), ('shape',), ('the',), ('model',), ('by',), ('detecting',), ('underlying',), ('patterns',), ('The',), ('more',), ('variables',), ('input',), ('used',), ('to',), ('train',), ('the',), ('model',), ('the',), ('more',), ('accurate',), ('the',), ('ultimate',), ('model',), ('will',), ('be',)]\n",
      "\n",
      "Bigrams: [('Conventional', 'statistical'), ('statistical', 'analyses'), ('analyses', 'require'), ('require', 'the'), ('the', 'a'), ('a', 'priori'), ('priori', 'selection'), ('selection', 'of'), ('of', 'a'), ('a', 'model'), ('model', 'most'), ('most', 'suitable'), ('suitable', 'for'), ('for', 'the'), ('the', 'study'), ('study', 'data'), ('data', 'set'), ('set', 'In'), ('In', 'addition'), ('addition', 'only'), ('only', 'significant'), ('significant', 'or'), ('or', 'theoretically'), ('theoretically', 'relevant'), ('relevant', 'variables'), ('variables', 'based'), ('based', 'on'), ('on', 'previous'), ('previous', 'experience'), ('experience', 'are'), ('are', 'included'), ('included', 'for'), ('for', 'analysis'), ('analysis', 'In'), ('In', 'contrast'), ('contrast', 'machine'), ('machine', 'learning'), ('learning', 'is'), ('is', 'not'), ('not', 'built'), ('built', 'on'), ('on', 'a'), ('a', 'prestructured'), ('prestructured', 'model'), ('model', 'rather'), ('rather', 'the'), ('the', 'data'), ('data', 'shape'), ('shape', 'the'), ('the', 'model'), ('model', 'by'), ('by', 'detecting'), ('detecting', 'underlying'), ('underlying', 'patterns'), ('patterns', 'The'), ('The', 'more'), ('more', 'variables'), ('variables', 'input'), ('input', 'used'), ('used', 'to'), ('to', 'train'), ('train', 'the'), ('the', 'model'), ('model', 'the'), ('the', 'more'), ('more', 'accurate'), ('accurate', 'the'), ('the', 'ultimate'), ('ultimate', 'model'), ('model', 'will'), ('will', 'be')]\n",
      "\n",
      "Trigrams: [('Conventional', 'statistical', 'analyses'), ('statistical', 'analyses', 'require'), ('analyses', 'require', 'the'), ('require', 'the', 'a'), ('the', 'a', 'priori'), ('a', 'priori', 'selection'), ('priori', 'selection', 'of'), ('selection', 'of', 'a'), ('of', 'a', 'model'), ('a', 'model', 'most'), ('model', 'most', 'suitable'), ('most', 'suitable', 'for'), ('suitable', 'for', 'the'), ('for', 'the', 'study'), ('the', 'study', 'data'), ('study', 'data', 'set'), ('data', 'set', 'In'), ('set', 'In', 'addition'), ('In', 'addition', 'only'), ('addition', 'only', 'significant'), ('only', 'significant', 'or'), ('significant', 'or', 'theoretically'), ('or', 'theoretically', 'relevant'), ('theoretically', 'relevant', 'variables'), ('relevant', 'variables', 'based'), ('variables', 'based', 'on'), ('based', 'on', 'previous'), ('on', 'previous', 'experience'), ('previous', 'experience', 'are'), ('experience', 'are', 'included'), ('are', 'included', 'for'), ('included', 'for', 'analysis'), ('for', 'analysis', 'In'), ('analysis', 'In', 'contrast'), ('In', 'contrast', 'machine'), ('contrast', 'machine', 'learning'), ('machine', 'learning', 'is'), ('learning', 'is', 'not'), ('is', 'not', 'built'), ('not', 'built', 'on'), ('built', 'on', 'a'), ('on', 'a', 'prestructured'), ('a', 'prestructured', 'model'), ('prestructured', 'model', 'rather'), ('model', 'rather', 'the'), ('rather', 'the', 'data'), ('the', 'data', 'shape'), ('data', 'shape', 'the'), ('shape', 'the', 'model'), ('the', 'model', 'by'), ('model', 'by', 'detecting'), ('by', 'detecting', 'underlying'), ('detecting', 'underlying', 'patterns'), ('underlying', 'patterns', 'The'), ('patterns', 'The', 'more'), ('The', 'more', 'variables'), ('more', 'variables', 'input'), ('variables', 'input', 'used'), ('input', 'used', 'to'), ('used', 'to', 'train'), ('to', 'train', 'the'), ('train', 'the', 'model'), ('the', 'model', 'the'), ('model', 'the', 'more'), ('the', 'more', 'accurate'), ('more', 'accurate', 'the'), ('accurate', 'the', 'ultimate'), ('the', 'ultimate', 'model'), ('ultimate', 'model', 'will'), ('model', 'will', 'be')]\n",
      "\n",
      "Document: Leo Breiman distinguished two statistical modelling paradigms data model and algorithmic model wherein algorithmic model means more or less the machine learning algorithms like Random Forest\n",
      "\n",
      "\n",
      "Unigrams: [('Leo',), ('Breiman',), ('distinguished',), ('two',), ('statistical',), ('modelling',), ('paradigms',), ('data',), ('model',), ('and',), ('algorithmic',), ('model',), ('wherein',), ('algorithmic',), ('model',), ('means',), ('more',), ('or',), ('less',), ('the',), ('machine',), ('learning',), ('algorithms',), ('like',), ('Random',), ('Forest',)]\n",
      "\n",
      "Bigrams: [('Leo', 'Breiman'), ('Breiman', 'distinguished'), ('distinguished', 'two'), ('two', 'statistical'), ('statistical', 'modelling'), ('modelling', 'paradigms'), ('paradigms', 'data'), ('data', 'model'), ('model', 'and'), ('and', 'algorithmic'), ('algorithmic', 'model'), ('model', 'wherein'), ('wherein', 'algorithmic'), ('algorithmic', 'model'), ('model', 'means'), ('means', 'more'), ('more', 'or'), ('or', 'less'), ('less', 'the'), ('the', 'machine'), ('machine', 'learning'), ('learning', 'algorithms'), ('algorithms', 'like'), ('like', 'Random'), ('Random', 'Forest')]\n",
      "\n",
      "Trigrams: [('Leo', 'Breiman', 'distinguished'), ('Breiman', 'distinguished', 'two'), ('distinguished', 'two', 'statistical'), ('two', 'statistical', 'modelling'), ('statistical', 'modelling', 'paradigms'), ('modelling', 'paradigms', 'data'), ('paradigms', 'data', 'model'), ('data', 'model', 'and'), ('model', 'and', 'algorithmic'), ('and', 'algorithmic', 'model'), ('algorithmic', 'model', 'wherein'), ('model', 'wherein', 'algorithmic'), ('wherein', 'algorithmic', 'model'), ('algorithmic', 'model', 'means'), ('model', 'means', 'more'), ('means', 'more', 'or'), ('more', 'or', 'less'), ('or', 'less', 'the'), ('less', 'the', 'machine'), ('the', 'machine', 'learning'), ('machine', 'learning', 'algorithms'), ('learning', 'algorithms', 'like'), ('algorithms', 'like', 'Random'), ('like', 'Random', 'Forest')]\n",
      "\n",
      "Document: Some statisticians have adopted methods from machine learning leading to a combined field that they call statistical learning\n",
      "\n",
      "\n",
      "Unigrams: [('Some',), ('statisticians',), ('have',), ('adopted',), ('methods',), ('from',), ('machine',), ('learning',), ('leading',), ('to',), ('a',), ('combined',), ('field',), ('that',), ('they',), ('call',), ('statistical',), ('learning',)]\n",
      "\n",
      "Bigrams: [('Some', 'statisticians'), ('statisticians', 'have'), ('have', 'adopted'), ('adopted', 'methods'), ('methods', 'from'), ('from', 'machine'), ('machine', 'learning'), ('learning', 'leading'), ('leading', 'to'), ('to', 'a'), ('a', 'combined'), ('combined', 'field'), ('field', 'that'), ('that', 'they'), ('they', 'call'), ('call', 'statistical'), ('statistical', 'learning')]\n",
      "\n",
      "Trigrams: [('Some', 'statisticians', 'have'), ('statisticians', 'have', 'adopted'), ('have', 'adopted', 'methods'), ('adopted', 'methods', 'from'), ('methods', 'from', 'machine'), ('from', 'machine', 'learning'), ('machine', 'learning', 'leading'), ('learning', 'leading', 'to'), ('leading', 'to', 'a'), ('to', 'a', 'combined'), ('a', 'combined', 'field'), ('combined', 'field', 'that'), ('field', 'that', 'they'), ('that', 'they', 'call'), ('they', 'call', 'statistical'), ('call', 'statistical', 'learning')]\n",
      "\n",
      "Document: Analytical and computational techniques derived from deeprooted physics of disordered systems can be extended to largescale problems including machine learning eg to analyse the weight space of deep neural networks Statistical physics is thus finding applications in the area of medical diagnostics\n",
      "\n",
      "\n",
      "Unigrams: [('Analytical',), ('and',), ('computational',), ('techniques',), ('derived',), ('from',), ('deeprooted',), ('physics',), ('of',), ('disordered',), ('systems',), ('can',), ('be',), ('extended',), ('to',), ('largescale',), ('problems',), ('including',), ('machine',), ('learning',), ('eg',), ('to',), ('analyse',), ('the',), ('weight',), ('space',), ('of',), ('deep',), ('neural',), ('networks',), ('Statistical',), ('physics',), ('is',), ('thus',), ('finding',), ('applications',), ('in',), ('the',), ('area',), ('of',), ('medical',), ('diagnostics',)]\n",
      "\n",
      "Bigrams: [('Analytical', 'and'), ('and', 'computational'), ('computational', 'techniques'), ('techniques', 'derived'), ('derived', 'from'), ('from', 'deeprooted'), ('deeprooted', 'physics'), ('physics', 'of'), ('of', 'disordered'), ('disordered', 'systems'), ('systems', 'can'), ('can', 'be'), ('be', 'extended'), ('extended', 'to'), ('to', 'largescale'), ('largescale', 'problems'), ('problems', 'including'), ('including', 'machine'), ('machine', 'learning'), ('learning', 'eg'), ('eg', 'to'), ('to', 'analyse'), ('analyse', 'the'), ('the', 'weight'), ('weight', 'space'), ('space', 'of'), ('of', 'deep'), ('deep', 'neural'), ('neural', 'networks'), ('networks', 'Statistical'), ('Statistical', 'physics'), ('physics', 'is'), ('is', 'thus'), ('thus', 'finding'), ('finding', 'applications'), ('applications', 'in'), ('in', 'the'), ('the', 'area'), ('area', 'of'), ('of', 'medical'), ('medical', 'diagnostics')]\n",
      "\n",
      "Trigrams: [('Analytical', 'and', 'computational'), ('and', 'computational', 'techniques'), ('computational', 'techniques', 'derived'), ('techniques', 'derived', 'from'), ('derived', 'from', 'deeprooted'), ('from', 'deeprooted', 'physics'), ('deeprooted', 'physics', 'of'), ('physics', 'of', 'disordered'), ('of', 'disordered', 'systems'), ('disordered', 'systems', 'can'), ('systems', 'can', 'be'), ('can', 'be', 'extended'), ('be', 'extended', 'to'), ('extended', 'to', 'largescale'), ('to', 'largescale', 'problems'), ('largescale', 'problems', 'including'), ('problems', 'including', 'machine'), ('including', 'machine', 'learning'), ('machine', 'learning', 'eg'), ('learning', 'eg', 'to'), ('eg', 'to', 'analyse'), ('to', 'analyse', 'the'), ('analyse', 'the', 'weight'), ('the', 'weight', 'space'), ('weight', 'space', 'of'), ('space', 'of', 'deep'), ('of', 'deep', 'neural'), ('deep', 'neural', 'networks'), ('neural', 'networks', 'Statistical'), ('networks', 'Statistical', 'physics'), ('Statistical', 'physics', 'is'), ('physics', 'is', 'thus'), ('is', 'thus', 'finding'), ('thus', 'finding', 'applications'), ('finding', 'applications', 'in'), ('applications', 'in', 'the'), ('in', 'the', 'area'), ('the', 'area', 'of'), ('area', 'of', 'medical'), ('of', 'medical', 'diagnostics')]\n",
      "\n",
      "Document: A core objective of a learner is to generalise from its experience Generalisation in this context is the ability of a learning machine to perform accurately on new unseen examplestasks after having experienced a learning data set The training examples come from some generally unknown probability distribution considered representative of the space of occurrences and the learner has to build a general model about this space that enables it to produce sufficiently accurate predictions in new cases\n",
      "\n",
      "\n",
      "Unigrams: [('A',), ('core',), ('objective',), ('of',), ('a',), ('learner',), ('is',), ('to',), ('generalise',), ('from',), ('its',), ('experience',), ('Generalisation',), ('in',), ('this',), ('context',), ('is',), ('the',), ('ability',), ('of',), ('a',), ('learning',), ('machine',), ('to',), ('perform',), ('accurately',), ('on',), ('new',), ('unseen',), ('examplestasks',), ('after',), ('having',), ('experienced',), ('a',), ('learning',), ('data',), ('set',), ('The',), ('training',), ('examples',), ('come',), ('from',), ('some',), ('generally',), ('unknown',), ('probability',), ('distribution',), ('considered',), ('representative',), ('of',), ('the',), ('space',), ('of',), ('occurrences',), ('and',), ('the',), ('learner',), ('has',), ('to',), ('build',), ('a',), ('general',), ('model',), ('about',), ('this',), ('space',), ('that',), ('enables',), ('it',), ('to',), ('produce',), ('sufficiently',), ('accurate',), ('predictions',), ('in',), ('new',), ('cases',)]\n",
      "\n",
      "Bigrams: [('A', 'core'), ('core', 'objective'), ('objective', 'of'), ('of', 'a'), ('a', 'learner'), ('learner', 'is'), ('is', 'to'), ('to', 'generalise'), ('generalise', 'from'), ('from', 'its'), ('its', 'experience'), ('experience', 'Generalisation'), ('Generalisation', 'in'), ('in', 'this'), ('this', 'context'), ('context', 'is'), ('is', 'the'), ('the', 'ability'), ('ability', 'of'), ('of', 'a'), ('a', 'learning'), ('learning', 'machine'), ('machine', 'to'), ('to', 'perform'), ('perform', 'accurately'), ('accurately', 'on'), ('on', 'new'), ('new', 'unseen'), ('unseen', 'examplestasks'), ('examplestasks', 'after'), ('after', 'having'), ('having', 'experienced'), ('experienced', 'a'), ('a', 'learning'), ('learning', 'data'), ('data', 'set'), ('set', 'The'), ('The', 'training'), ('training', 'examples'), ('examples', 'come'), ('come', 'from'), ('from', 'some'), ('some', 'generally'), ('generally', 'unknown'), ('unknown', 'probability'), ('probability', 'distribution'), ('distribution', 'considered'), ('considered', 'representative'), ('representative', 'of'), ('of', 'the'), ('the', 'space'), ('space', 'of'), ('of', 'occurrences'), ('occurrences', 'and'), ('and', 'the'), ('the', 'learner'), ('learner', 'has'), ('has', 'to'), ('to', 'build'), ('build', 'a'), ('a', 'general'), ('general', 'model'), ('model', 'about'), ('about', 'this'), ('this', 'space'), ('space', 'that'), ('that', 'enables'), ('enables', 'it'), ('it', 'to'), ('to', 'produce'), ('produce', 'sufficiently'), ('sufficiently', 'accurate'), ('accurate', 'predictions'), ('predictions', 'in'), ('in', 'new'), ('new', 'cases')]\n",
      "\n",
      "Trigrams: [('A', 'core', 'objective'), ('core', 'objective', 'of'), ('objective', 'of', 'a'), ('of', 'a', 'learner'), ('a', 'learner', 'is'), ('learner', 'is', 'to'), ('is', 'to', 'generalise'), ('to', 'generalise', 'from'), ('generalise', 'from', 'its'), ('from', 'its', 'experience'), ('its', 'experience', 'Generalisation'), ('experience', 'Generalisation', 'in'), ('Generalisation', 'in', 'this'), ('in', 'this', 'context'), ('this', 'context', 'is'), ('context', 'is', 'the'), ('is', 'the', 'ability'), ('the', 'ability', 'of'), ('ability', 'of', 'a'), ('of', 'a', 'learning'), ('a', 'learning', 'machine'), ('learning', 'machine', 'to'), ('machine', 'to', 'perform'), ('to', 'perform', 'accurately'), ('perform', 'accurately', 'on'), ('accurately', 'on', 'new'), ('on', 'new', 'unseen'), ('new', 'unseen', 'examplestasks'), ('unseen', 'examplestasks', 'after'), ('examplestasks', 'after', 'having'), ('after', 'having', 'experienced'), ('having', 'experienced', 'a'), ('experienced', 'a', 'learning'), ('a', 'learning', 'data'), ('learning', 'data', 'set'), ('data', 'set', 'The'), ('set', 'The', 'training'), ('The', 'training', 'examples'), ('training', 'examples', 'come'), ('examples', 'come', 'from'), ('come', 'from', 'some'), ('from', 'some', 'generally'), ('some', 'generally', 'unknown'), ('generally', 'unknown', 'probability'), ('unknown', 'probability', 'distribution'), ('probability', 'distribution', 'considered'), ('distribution', 'considered', 'representative'), ('considered', 'representative', 'of'), ('representative', 'of', 'the'), ('of', 'the', 'space'), ('the', 'space', 'of'), ('space', 'of', 'occurrences'), ('of', 'occurrences', 'and'), ('occurrences', 'and', 'the'), ('and', 'the', 'learner'), ('the', 'learner', 'has'), ('learner', 'has', 'to'), ('has', 'to', 'build'), ('to', 'build', 'a'), ('build', 'a', 'general'), ('a', 'general', 'model'), ('general', 'model', 'about'), ('model', 'about', 'this'), ('about', 'this', 'space'), ('this', 'space', 'that'), ('space', 'that', 'enables'), ('that', 'enables', 'it'), ('enables', 'it', 'to'), ('it', 'to', 'produce'), ('to', 'produce', 'sufficiently'), ('produce', 'sufficiently', 'accurate'), ('sufficiently', 'accurate', 'predictions'), ('accurate', 'predictions', 'in'), ('predictions', 'in', 'new'), ('in', 'new', 'cases')]\n",
      "\n",
      "Document: The computational analysis of machine learning algorithms and their performance is a branch of theoretical computer science known as computational learning theory via the probably approximately correct learning  model Because training sets are finite and the future is uncertain learning theory usually does not yield guarantees of the performance of algorithms Instead probabilistic bounds on the performance are quite common The biasvariance decomposition is one way to quantify generalisation error\n",
      "\n",
      "\n",
      "Unigrams: [('The',), ('computational',), ('analysis',), ('of',), ('machine',), ('learning',), ('algorithms',), ('and',), ('their',), ('performance',), ('is',), ('a',), ('branch',), ('of',), ('theoretical',), ('computer',), ('science',), ('known',), ('as',), ('computational',), ('learning',), ('theory',), ('via',), ('the',), ('probably',), ('approximately',), ('correct',), ('learning',), ('model',), ('Because',), ('training',), ('sets',), ('are',), ('finite',), ('and',), ('the',), ('future',), ('is',), ('uncertain',), ('learning',), ('theory',), ('usually',), ('does',), ('not',), ('yield',), ('guarantees',), ('of',), ('the',), ('performance',), ('of',), ('algorithms',), ('Instead',), ('probabilistic',), ('bounds',), ('on',), ('the',), ('performance',), ('are',), ('quite',), ('common',), ('The',), ('biasvariance',), ('decomposition',), ('is',), ('one',), ('way',), ('to',), ('quantify',), ('generalisation',), ('error',)]\n",
      "\n",
      "Bigrams: [('The', 'computational'), ('computational', 'analysis'), ('analysis', 'of'), ('of', 'machine'), ('machine', 'learning'), ('learning', 'algorithms'), ('algorithms', 'and'), ('and', 'their'), ('their', 'performance'), ('performance', 'is'), ('is', 'a'), ('a', 'branch'), ('branch', 'of'), ('of', 'theoretical'), ('theoretical', 'computer'), ('computer', 'science'), ('science', 'known'), ('known', 'as'), ('as', 'computational'), ('computational', 'learning'), ('learning', 'theory'), ('theory', 'via'), ('via', 'the'), ('the', 'probably'), ('probably', 'approximately'), ('approximately', 'correct'), ('correct', 'learning'), ('learning', 'model'), ('model', 'Because'), ('Because', 'training'), ('training', 'sets'), ('sets', 'are'), ('are', 'finite'), ('finite', 'and'), ('and', 'the'), ('the', 'future'), ('future', 'is'), ('is', 'uncertain'), ('uncertain', 'learning'), ('learning', 'theory'), ('theory', 'usually'), ('usually', 'does'), ('does', 'not'), ('not', 'yield'), ('yield', 'guarantees'), ('guarantees', 'of'), ('of', 'the'), ('the', 'performance'), ('performance', 'of'), ('of', 'algorithms'), ('algorithms', 'Instead'), ('Instead', 'probabilistic'), ('probabilistic', 'bounds'), ('bounds', 'on'), ('on', 'the'), ('the', 'performance'), ('performance', 'are'), ('are', 'quite'), ('quite', 'common'), ('common', 'The'), ('The', 'biasvariance'), ('biasvariance', 'decomposition'), ('decomposition', 'is'), ('is', 'one'), ('one', 'way'), ('way', 'to'), ('to', 'quantify'), ('quantify', 'generalisation'), ('generalisation', 'error')]\n",
      "\n",
      "Trigrams: [('The', 'computational', 'analysis'), ('computational', 'analysis', 'of'), ('analysis', 'of', 'machine'), ('of', 'machine', 'learning'), ('machine', 'learning', 'algorithms'), ('learning', 'algorithms', 'and'), ('algorithms', 'and', 'their'), ('and', 'their', 'performance'), ('their', 'performance', 'is'), ('performance', 'is', 'a'), ('is', 'a', 'branch'), ('a', 'branch', 'of'), ('branch', 'of', 'theoretical'), ('of', 'theoretical', 'computer'), ('theoretical', 'computer', 'science'), ('computer', 'science', 'known'), ('science', 'known', 'as'), ('known', 'as', 'computational'), ('as', 'computational', 'learning'), ('computational', 'learning', 'theory'), ('learning', 'theory', 'via'), ('theory', 'via', 'the'), ('via', 'the', 'probably'), ('the', 'probably', 'approximately'), ('probably', 'approximately', 'correct'), ('approximately', 'correct', 'learning'), ('correct', 'learning', 'model'), ('learning', 'model', 'Because'), ('model', 'Because', 'training'), ('Because', 'training', 'sets'), ('training', 'sets', 'are'), ('sets', 'are', 'finite'), ('are', 'finite', 'and'), ('finite', 'and', 'the'), ('and', 'the', 'future'), ('the', 'future', 'is'), ('future', 'is', 'uncertain'), ('is', 'uncertain', 'learning'), ('uncertain', 'learning', 'theory'), ('learning', 'theory', 'usually'), ('theory', 'usually', 'does'), ('usually', 'does', 'not'), ('does', 'not', 'yield'), ('not', 'yield', 'guarantees'), ('yield', 'guarantees', 'of'), ('guarantees', 'of', 'the'), ('of', 'the', 'performance'), ('the', 'performance', 'of'), ('performance', 'of', 'algorithms'), ('of', 'algorithms', 'Instead'), ('algorithms', 'Instead', 'probabilistic'), ('Instead', 'probabilistic', 'bounds'), ('probabilistic', 'bounds', 'on'), ('bounds', 'on', 'the'), ('on', 'the', 'performance'), ('the', 'performance', 'are'), ('performance', 'are', 'quite'), ('are', 'quite', 'common'), ('quite', 'common', 'The'), ('common', 'The', 'biasvariance'), ('The', 'biasvariance', 'decomposition'), ('biasvariance', 'decomposition', 'is'), ('decomposition', 'is', 'one'), ('is', 'one', 'way'), ('one', 'way', 'to'), ('way', 'to', 'quantify'), ('to', 'quantify', 'generalisation'), ('quantify', 'generalisation', 'error')]\n",
      "\n",
      "Document: For the best performance in the context of generalisation the complexity of the hypothesis should match the complexity of the function underlying the data If the hypothesis is less complex than the function then the model has under fitted the data If the complexity of the model is increased in response then the training error decreases But if the hypothesis is too complex then the model is subject to overfitting and generalisation will be poorer\n",
      "\n",
      "\n",
      "Unigrams: [('For',), ('the',), ('best',), ('performance',), ('in',), ('the',), ('context',), ('of',), ('generalisation',), ('the',), ('complexity',), ('of',), ('the',), ('hypothesis',), ('should',), ('match',), ('the',), ('complexity',), ('of',), ('the',), ('function',), ('underlying',), ('the',), ('data',), ('If',), ('the',), ('hypothesis',), ('is',), ('less',), ('complex',), ('than',), ('the',), ('function',), ('then',), ('the',), ('model',), ('has',), ('under',), ('fitted',), ('the',), ('data',), ('If',), ('the',), ('complexity',), ('of',), ('the',), ('model',), ('is',), ('increased',), ('in',), ('response',), ('then',), ('the',), ('training',), ('error',), ('decreases',), ('But',), ('if',), ('the',), ('hypothesis',), ('is',), ('too',), ('complex',), ('then',), ('the',), ('model',), ('is',), ('subject',), ('to',), ('overfitting',), ('and',), ('generalisation',), ('will',), ('be',), ('poorer',)]\n",
      "\n",
      "Bigrams: [('For', 'the'), ('the', 'best'), ('best', 'performance'), ('performance', 'in'), ('in', 'the'), ('the', 'context'), ('context', 'of'), ('of', 'generalisation'), ('generalisation', 'the'), ('the', 'complexity'), ('complexity', 'of'), ('of', 'the'), ('the', 'hypothesis'), ('hypothesis', 'should'), ('should', 'match'), ('match', 'the'), ('the', 'complexity'), ('complexity', 'of'), ('of', 'the'), ('the', 'function'), ('function', 'underlying'), ('underlying', 'the'), ('the', 'data'), ('data', 'If'), ('If', 'the'), ('the', 'hypothesis'), ('hypothesis', 'is'), ('is', 'less'), ('less', 'complex'), ('complex', 'than'), ('than', 'the'), ('the', 'function'), ('function', 'then'), ('then', 'the'), ('the', 'model'), ('model', 'has'), ('has', 'under'), ('under', 'fitted'), ('fitted', 'the'), ('the', 'data'), ('data', 'If'), ('If', 'the'), ('the', 'complexity'), ('complexity', 'of'), ('of', 'the'), ('the', 'model'), ('model', 'is'), ('is', 'increased'), ('increased', 'in'), ('in', 'response'), ('response', 'then'), ('then', 'the'), ('the', 'training'), ('training', 'error'), ('error', 'decreases'), ('decreases', 'But'), ('But', 'if'), ('if', 'the'), ('the', 'hypothesis'), ('hypothesis', 'is'), ('is', 'too'), ('too', 'complex'), ('complex', 'then'), ('then', 'the'), ('the', 'model'), ('model', 'is'), ('is', 'subject'), ('subject', 'to'), ('to', 'overfitting'), ('overfitting', 'and'), ('and', 'generalisation'), ('generalisation', 'will'), ('will', 'be'), ('be', 'poorer')]\n",
      "\n",
      "Trigrams: [('For', 'the', 'best'), ('the', 'best', 'performance'), ('best', 'performance', 'in'), ('performance', 'in', 'the'), ('in', 'the', 'context'), ('the', 'context', 'of'), ('context', 'of', 'generalisation'), ('of', 'generalisation', 'the'), ('generalisation', 'the', 'complexity'), ('the', 'complexity', 'of'), ('complexity', 'of', 'the'), ('of', 'the', 'hypothesis'), ('the', 'hypothesis', 'should'), ('hypothesis', 'should', 'match'), ('should', 'match', 'the'), ('match', 'the', 'complexity'), ('the', 'complexity', 'of'), ('complexity', 'of', 'the'), ('of', 'the', 'function'), ('the', 'function', 'underlying'), ('function', 'underlying', 'the'), ('underlying', 'the', 'data'), ('the', 'data', 'If'), ('data', 'If', 'the'), ('If', 'the', 'hypothesis'), ('the', 'hypothesis', 'is'), ('hypothesis', 'is', 'less'), ('is', 'less', 'complex'), ('less', 'complex', 'than'), ('complex', 'than', 'the'), ('than', 'the', 'function'), ('the', 'function', 'then'), ('function', 'then', 'the'), ('then', 'the', 'model'), ('the', 'model', 'has'), ('model', 'has', 'under'), ('has', 'under', 'fitted'), ('under', 'fitted', 'the'), ('fitted', 'the', 'data'), ('the', 'data', 'If'), ('data', 'If', 'the'), ('If', 'the', 'complexity'), ('the', 'complexity', 'of'), ('complexity', 'of', 'the'), ('of', 'the', 'model'), ('the', 'model', 'is'), ('model', 'is', 'increased'), ('is', 'increased', 'in'), ('increased', 'in', 'response'), ('in', 'response', 'then'), ('response', 'then', 'the'), ('then', 'the', 'training'), ('the', 'training', 'error'), ('training', 'error', 'decreases'), ('error', 'decreases', 'But'), ('decreases', 'But', 'if'), ('But', 'if', 'the'), ('if', 'the', 'hypothesis'), ('the', 'hypothesis', 'is'), ('hypothesis', 'is', 'too'), ('is', 'too', 'complex'), ('too', 'complex', 'then'), ('complex', 'then', 'the'), ('then', 'the', 'model'), ('the', 'model', 'is'), ('model', 'is', 'subject'), ('is', 'subject', 'to'), ('subject', 'to', 'overfitting'), ('to', 'overfitting', 'and'), ('overfitting', 'and', 'generalisation'), ('and', 'generalisation', 'will'), ('generalisation', 'will', 'be'), ('will', 'be', 'poorer')]\n",
      "\n",
      "Document: In addition to performance bounds learning theorists study the time complexity and feasibility of learning In computational learning theory a computation is considered feasible if it can be done in polynomial time There are two kinds of time complexity results Positive results show that a certain class of functions can be learned in polynomial time Negative results show that certain classes cannot be learned in polynomial time\n",
      "\n",
      "\n",
      "Unigrams: [('In',), ('addition',), ('to',), ('performance',), ('bounds',), ('learning',), ('theorists',), ('study',), ('the',), ('time',), ('complexity',), ('and',), ('feasibility',), ('of',), ('learning',), ('In',), ('computational',), ('learning',), ('theory',), ('a',), ('computation',), ('is',), ('considered',), ('feasible',), ('if',), ('it',), ('can',), ('be',), ('done',), ('in',), ('polynomial',), ('time',), ('There',), ('are',), ('two',), ('kinds',), ('of',), ('time',), ('complexity',), ('results',), ('Positive',), ('results',), ('show',), ('that',), ('a',), ('certain',), ('class',), ('of',), ('functions',), ('can',), ('be',), ('learned',), ('in',), ('polynomial',), ('time',), ('Negative',), ('results',), ('show',), ('that',), ('certain',), ('classes',), ('cannot',), ('be',), ('learned',), ('in',), ('polynomial',), ('time',)]\n",
      "\n",
      "Bigrams: [('In', 'addition'), ('addition', 'to'), ('to', 'performance'), ('performance', 'bounds'), ('bounds', 'learning'), ('learning', 'theorists'), ('theorists', 'study'), ('study', 'the'), ('the', 'time'), ('time', 'complexity'), ('complexity', 'and'), ('and', 'feasibility'), ('feasibility', 'of'), ('of', 'learning'), ('learning', 'In'), ('In', 'computational'), ('computational', 'learning'), ('learning', 'theory'), ('theory', 'a'), ('a', 'computation'), ('computation', 'is'), ('is', 'considered'), ('considered', 'feasible'), ('feasible', 'if'), ('if', 'it'), ('it', 'can'), ('can', 'be'), ('be', 'done'), ('done', 'in'), ('in', 'polynomial'), ('polynomial', 'time'), ('time', 'There'), ('There', 'are'), ('are', 'two'), ('two', 'kinds'), ('kinds', 'of'), ('of', 'time'), ('time', 'complexity'), ('complexity', 'results'), ('results', 'Positive'), ('Positive', 'results'), ('results', 'show'), ('show', 'that'), ('that', 'a'), ('a', 'certain'), ('certain', 'class'), ('class', 'of'), ('of', 'functions'), ('functions', 'can'), ('can', 'be'), ('be', 'learned'), ('learned', 'in'), ('in', 'polynomial'), ('polynomial', 'time'), ('time', 'Negative'), ('Negative', 'results'), ('results', 'show'), ('show', 'that'), ('that', 'certain'), ('certain', 'classes'), ('classes', 'cannot'), ('cannot', 'be'), ('be', 'learned'), ('learned', 'in'), ('in', 'polynomial'), ('polynomial', 'time')]\n",
      "\n",
      "Trigrams: [('In', 'addition', 'to'), ('addition', 'to', 'performance'), ('to', 'performance', 'bounds'), ('performance', 'bounds', 'learning'), ('bounds', 'learning', 'theorists'), ('learning', 'theorists', 'study'), ('theorists', 'study', 'the'), ('study', 'the', 'time'), ('the', 'time', 'complexity'), ('time', 'complexity', 'and'), ('complexity', 'and', 'feasibility'), ('and', 'feasibility', 'of'), ('feasibility', 'of', 'learning'), ('of', 'learning', 'In'), ('learning', 'In', 'computational'), ('In', 'computational', 'learning'), ('computational', 'learning', 'theory'), ('learning', 'theory', 'a'), ('theory', 'a', 'computation'), ('a', 'computation', 'is'), ('computation', 'is', 'considered'), ('is', 'considered', 'feasible'), ('considered', 'feasible', 'if'), ('feasible', 'if', 'it'), ('if', 'it', 'can'), ('it', 'can', 'be'), ('can', 'be', 'done'), ('be', 'done', 'in'), ('done', 'in', 'polynomial'), ('in', 'polynomial', 'time'), ('polynomial', 'time', 'There'), ('time', 'There', 'are'), ('There', 'are', 'two'), ('are', 'two', 'kinds'), ('two', 'kinds', 'of'), ('kinds', 'of', 'time'), ('of', 'time', 'complexity'), ('time', 'complexity', 'results'), ('complexity', 'results', 'Positive'), ('results', 'Positive', 'results'), ('Positive', 'results', 'show'), ('results', 'show', 'that'), ('show', 'that', 'a'), ('that', 'a', 'certain'), ('a', 'certain', 'class'), ('certain', 'class', 'of'), ('class', 'of', 'functions'), ('of', 'functions', 'can'), ('functions', 'can', 'be'), ('can', 'be', 'learned'), ('be', 'learned', 'in'), ('learned', 'in', 'polynomial'), ('in', 'polynomial', 'time'), ('polynomial', 'time', 'Negative'), ('time', 'Negative', 'results'), ('Negative', 'results', 'show'), ('results', 'show', 'that'), ('show', 'that', 'certain'), ('that', 'certain', 'classes'), ('certain', 'classes', 'cannot'), ('classes', 'cannot', 'be'), ('cannot', 'be', 'learned'), ('be', 'learned', 'in'), ('learned', 'in', 'polynomial'), ('in', 'polynomial', 'time')]\n",
      "\n",
      "Document: \n",
      "\n",
      "\n",
      "Unigrams: []\n",
      "\n",
      "Bigrams: []\n",
      "\n",
      "Trigrams: []\n",
      "\n",
      "Document: Machine learning approaches are traditionally divided into three broad categories which correspond to learning paradigms depending on the nature of the signal or feedback available to the learning system\n",
      "\n",
      "\n",
      "Unigrams: [('Machine',), ('learning',), ('approaches',), ('are',), ('traditionally',), ('divided',), ('into',), ('three',), ('broad',), ('categories',), ('which',), ('correspond',), ('to',), ('learning',), ('paradigms',), ('depending',), ('on',), ('the',), ('nature',), ('of',), ('the',), ('signal',), ('or',), ('feedback',), ('available',), ('to',), ('the',), ('learning',), ('system',)]\n",
      "\n",
      "Bigrams: [('Machine', 'learning'), ('learning', 'approaches'), ('approaches', 'are'), ('are', 'traditionally'), ('traditionally', 'divided'), ('divided', 'into'), ('into', 'three'), ('three', 'broad'), ('broad', 'categories'), ('categories', 'which'), ('which', 'correspond'), ('correspond', 'to'), ('to', 'learning'), ('learning', 'paradigms'), ('paradigms', 'depending'), ('depending', 'on'), ('on', 'the'), ('the', 'nature'), ('nature', 'of'), ('of', 'the'), ('the', 'signal'), ('signal', 'or'), ('or', 'feedback'), ('feedback', 'available'), ('available', 'to'), ('to', 'the'), ('the', 'learning'), ('learning', 'system')]\n",
      "\n",
      "Trigrams: [('Machine', 'learning', 'approaches'), ('learning', 'approaches', 'are'), ('approaches', 'are', 'traditionally'), ('are', 'traditionally', 'divided'), ('traditionally', 'divided', 'into'), ('divided', 'into', 'three'), ('into', 'three', 'broad'), ('three', 'broad', 'categories'), ('broad', 'categories', 'which'), ('categories', 'which', 'correspond'), ('which', 'correspond', 'to'), ('correspond', 'to', 'learning'), ('to', 'learning', 'paradigms'), ('learning', 'paradigms', 'depending'), ('paradigms', 'depending', 'on'), ('depending', 'on', 'the'), ('on', 'the', 'nature'), ('the', 'nature', 'of'), ('nature', 'of', 'the'), ('of', 'the', 'signal'), ('the', 'signal', 'or'), ('signal', 'or', 'feedback'), ('or', 'feedback', 'available'), ('feedback', 'available', 'to'), ('available', 'to', 'the'), ('to', 'the', 'learning'), ('the', 'learning', 'system')]\n",
      "\n",
      "Document: Although each algorithm has advantages and limitations no single algorithm works for all problems\n",
      "\n",
      "\n",
      "Unigrams: [('Although',), ('each',), ('algorithm',), ('has',), ('advantages',), ('and',), ('limitations',), ('no',), ('single',), ('algorithm',), ('works',), ('for',), ('all',), ('problems',)]\n",
      "\n",
      "Bigrams: [('Although', 'each'), ('each', 'algorithm'), ('algorithm', 'has'), ('has', 'advantages'), ('advantages', 'and'), ('and', 'limitations'), ('limitations', 'no'), ('no', 'single'), ('single', 'algorithm'), ('algorithm', 'works'), ('works', 'for'), ('for', 'all'), ('all', 'problems')]\n",
      "\n",
      "Trigrams: [('Although', 'each', 'algorithm'), ('each', 'algorithm', 'has'), ('algorithm', 'has', 'advantages'), ('has', 'advantages', 'and'), ('advantages', 'and', 'limitations'), ('and', 'limitations', 'no'), ('limitations', 'no', 'single'), ('no', 'single', 'algorithm'), ('single', 'algorithm', 'works'), ('algorithm', 'works', 'for'), ('works', 'for', 'all'), ('for', 'all', 'problems')]\n",
      "\n",
      "Document: Supervised learning algorithms build a mathematical model of a set of data that contains both the inputs and the desired outputs The data known as training data consists of a set of training examples Each training example has one or more inputs and the desired output also known as a supervisory signal In the mathematical model each training example is represented by an array or vector sometimes called a feature vector and the training data is represented by a matrix Through iterative optimisation of an objective function supervised learning algorithms learn a function that can be used to predict the output associated with new inputs An optimal function allows the algorithm to correctly determine the output for inputs that were not a part of the training data An algorithm that improves the accuracy of its outputs or predictions over time is said to have learned to perform that task\n",
      "\n",
      "\n",
      "Unigrams: [('Supervised',), ('learning',), ('algorithms',), ('build',), ('a',), ('mathematical',), ('model',), ('of',), ('a',), ('set',), ('of',), ('data',), ('that',), ('contains',), ('both',), ('the',), ('inputs',), ('and',), ('the',), ('desired',), ('outputs',), ('The',), ('data',), ('known',), ('as',), ('training',), ('data',), ('consists',), ('of',), ('a',), ('set',), ('of',), ('training',), ('examples',), ('Each',), ('training',), ('example',), ('has',), ('one',), ('or',), ('more',), ('inputs',), ('and',), ('the',), ('desired',), ('output',), ('also',), ('known',), ('as',), ('a',), ('supervisory',), ('signal',), ('In',), ('the',), ('mathematical',), ('model',), ('each',), ('training',), ('example',), ('is',), ('represented',), ('by',), ('an',), ('array',), ('or',), ('vector',), ('sometimes',), ('called',), ('a',), ('feature',), ('vector',), ('and',), ('the',), ('training',), ('data',), ('is',), ('represented',), ('by',), ('a',), ('matrix',), ('Through',), ('iterative',), ('optimisation',), ('of',), ('an',), ('objective',), ('function',), ('supervised',), ('learning',), ('algorithms',), ('learn',), ('a',), ('function',), ('that',), ('can',), ('be',), ('used',), ('to',), ('predict',), ('the',), ('output',), ('associated',), ('with',), ('new',), ('inputs',), ('An',), ('optimal',), ('function',), ('allows',), ('the',), ('algorithm',), ('to',), ('correctly',), ('determine',), ('the',), ('output',), ('for',), ('inputs',), ('that',), ('were',), ('not',), ('a',), ('part',), ('of',), ('the',), ('training',), ('data',), ('An',), ('algorithm',), ('that',), ('improves',), ('the',), ('accuracy',), ('of',), ('its',), ('outputs',), ('or',), ('predictions',), ('over',), ('time',), ('is',), ('said',), ('to',), ('have',), ('learned',), ('to',), ('perform',), ('that',), ('task',)]\n",
      "\n",
      "Bigrams: [('Supervised', 'learning'), ('learning', 'algorithms'), ('algorithms', 'build'), ('build', 'a'), ('a', 'mathematical'), ('mathematical', 'model'), ('model', 'of'), ('of', 'a'), ('a', 'set'), ('set', 'of'), ('of', 'data'), ('data', 'that'), ('that', 'contains'), ('contains', 'both'), ('both', 'the'), ('the', 'inputs'), ('inputs', 'and'), ('and', 'the'), ('the', 'desired'), ('desired', 'outputs'), ('outputs', 'The'), ('The', 'data'), ('data', 'known'), ('known', 'as'), ('as', 'training'), ('training', 'data'), ('data', 'consists'), ('consists', 'of'), ('of', 'a'), ('a', 'set'), ('set', 'of'), ('of', 'training'), ('training', 'examples'), ('examples', 'Each'), ('Each', 'training'), ('training', 'example'), ('example', 'has'), ('has', 'one'), ('one', 'or'), ('or', 'more'), ('more', 'inputs'), ('inputs', 'and'), ('and', 'the'), ('the', 'desired'), ('desired', 'output'), ('output', 'also'), ('also', 'known'), ('known', 'as'), ('as', 'a'), ('a', 'supervisory'), ('supervisory', 'signal'), ('signal', 'In'), ('In', 'the'), ('the', 'mathematical'), ('mathematical', 'model'), ('model', 'each'), ('each', 'training'), ('training', 'example'), ('example', 'is'), ('is', 'represented'), ('represented', 'by'), ('by', 'an'), ('an', 'array'), ('array', 'or'), ('or', 'vector'), ('vector', 'sometimes'), ('sometimes', 'called'), ('called', 'a'), ('a', 'feature'), ('feature', 'vector'), ('vector', 'and'), ('and', 'the'), ('the', 'training'), ('training', 'data'), ('data', 'is'), ('is', 'represented'), ('represented', 'by'), ('by', 'a'), ('a', 'matrix'), ('matrix', 'Through'), ('Through', 'iterative'), ('iterative', 'optimisation'), ('optimisation', 'of'), ('of', 'an'), ('an', 'objective'), ('objective', 'function'), ('function', 'supervised'), ('supervised', 'learning'), ('learning', 'algorithms'), ('algorithms', 'learn'), ('learn', 'a'), ('a', 'function'), ('function', 'that'), ('that', 'can'), ('can', 'be'), ('be', 'used'), ('used', 'to'), ('to', 'predict'), ('predict', 'the'), ('the', 'output'), ('output', 'associated'), ('associated', 'with'), ('with', 'new'), ('new', 'inputs'), ('inputs', 'An'), ('An', 'optimal'), ('optimal', 'function'), ('function', 'allows'), ('allows', 'the'), ('the', 'algorithm'), ('algorithm', 'to'), ('to', 'correctly'), ('correctly', 'determine'), ('determine', 'the'), ('the', 'output'), ('output', 'for'), ('for', 'inputs'), ('inputs', 'that'), ('that', 'were'), ('were', 'not'), ('not', 'a'), ('a', 'part'), ('part', 'of'), ('of', 'the'), ('the', 'training'), ('training', 'data'), ('data', 'An'), ('An', 'algorithm'), ('algorithm', 'that'), ('that', 'improves'), ('improves', 'the'), ('the', 'accuracy'), ('accuracy', 'of'), ('of', 'its'), ('its', 'outputs'), ('outputs', 'or'), ('or', 'predictions'), ('predictions', 'over'), ('over', 'time'), ('time', 'is'), ('is', 'said'), ('said', 'to'), ('to', 'have'), ('have', 'learned'), ('learned', 'to'), ('to', 'perform'), ('perform', 'that'), ('that', 'task')]\n",
      "\n",
      "Trigrams: [('Supervised', 'learning', 'algorithms'), ('learning', 'algorithms', 'build'), ('algorithms', 'build', 'a'), ('build', 'a', 'mathematical'), ('a', 'mathematical', 'model'), ('mathematical', 'model', 'of'), ('model', 'of', 'a'), ('of', 'a', 'set'), ('a', 'set', 'of'), ('set', 'of', 'data'), ('of', 'data', 'that'), ('data', 'that', 'contains'), ('that', 'contains', 'both'), ('contains', 'both', 'the'), ('both', 'the', 'inputs'), ('the', 'inputs', 'and'), ('inputs', 'and', 'the'), ('and', 'the', 'desired'), ('the', 'desired', 'outputs'), ('desired', 'outputs', 'The'), ('outputs', 'The', 'data'), ('The', 'data', 'known'), ('data', 'known', 'as'), ('known', 'as', 'training'), ('as', 'training', 'data'), ('training', 'data', 'consists'), ('data', 'consists', 'of'), ('consists', 'of', 'a'), ('of', 'a', 'set'), ('a', 'set', 'of'), ('set', 'of', 'training'), ('of', 'training', 'examples'), ('training', 'examples', 'Each'), ('examples', 'Each', 'training'), ('Each', 'training', 'example'), ('training', 'example', 'has'), ('example', 'has', 'one'), ('has', 'one', 'or'), ('one', 'or', 'more'), ('or', 'more', 'inputs'), ('more', 'inputs', 'and'), ('inputs', 'and', 'the'), ('and', 'the', 'desired'), ('the', 'desired', 'output'), ('desired', 'output', 'also'), ('output', 'also', 'known'), ('also', 'known', 'as'), ('known', 'as', 'a'), ('as', 'a', 'supervisory'), ('a', 'supervisory', 'signal'), ('supervisory', 'signal', 'In'), ('signal', 'In', 'the'), ('In', 'the', 'mathematical'), ('the', 'mathematical', 'model'), ('mathematical', 'model', 'each'), ('model', 'each', 'training'), ('each', 'training', 'example'), ('training', 'example', 'is'), ('example', 'is', 'represented'), ('is', 'represented', 'by'), ('represented', 'by', 'an'), ('by', 'an', 'array'), ('an', 'array', 'or'), ('array', 'or', 'vector'), ('or', 'vector', 'sometimes'), ('vector', 'sometimes', 'called'), ('sometimes', 'called', 'a'), ('called', 'a', 'feature'), ('a', 'feature', 'vector'), ('feature', 'vector', 'and'), ('vector', 'and', 'the'), ('and', 'the', 'training'), ('the', 'training', 'data'), ('training', 'data', 'is'), ('data', 'is', 'represented'), ('is', 'represented', 'by'), ('represented', 'by', 'a'), ('by', 'a', 'matrix'), ('a', 'matrix', 'Through'), ('matrix', 'Through', 'iterative'), ('Through', 'iterative', 'optimisation'), ('iterative', 'optimisation', 'of'), ('optimisation', 'of', 'an'), ('of', 'an', 'objective'), ('an', 'objective', 'function'), ('objective', 'function', 'supervised'), ('function', 'supervised', 'learning'), ('supervised', 'learning', 'algorithms'), ('learning', 'algorithms', 'learn'), ('algorithms', 'learn', 'a'), ('learn', 'a', 'function'), ('a', 'function', 'that'), ('function', 'that', 'can'), ('that', 'can', 'be'), ('can', 'be', 'used'), ('be', 'used', 'to'), ('used', 'to', 'predict'), ('to', 'predict', 'the'), ('predict', 'the', 'output'), ('the', 'output', 'associated'), ('output', 'associated', 'with'), ('associated', 'with', 'new'), ('with', 'new', 'inputs'), ('new', 'inputs', 'An'), ('inputs', 'An', 'optimal'), ('An', 'optimal', 'function'), ('optimal', 'function', 'allows'), ('function', 'allows', 'the'), ('allows', 'the', 'algorithm'), ('the', 'algorithm', 'to'), ('algorithm', 'to', 'correctly'), ('to', 'correctly', 'determine'), ('correctly', 'determine', 'the'), ('determine', 'the', 'output'), ('the', 'output', 'for'), ('output', 'for', 'inputs'), ('for', 'inputs', 'that'), ('inputs', 'that', 'were'), ('that', 'were', 'not'), ('were', 'not', 'a'), ('not', 'a', 'part'), ('a', 'part', 'of'), ('part', 'of', 'the'), ('of', 'the', 'training'), ('the', 'training', 'data'), ('training', 'data', 'An'), ('data', 'An', 'algorithm'), ('An', 'algorithm', 'that'), ('algorithm', 'that', 'improves'), ('that', 'improves', 'the'), ('improves', 'the', 'accuracy'), ('the', 'accuracy', 'of'), ('accuracy', 'of', 'its'), ('of', 'its', 'outputs'), ('its', 'outputs', 'or'), ('outputs', 'or', 'predictions'), ('or', 'predictions', 'over'), ('predictions', 'over', 'time'), ('over', 'time', 'is'), ('time', 'is', 'said'), ('is', 'said', 'to'), ('said', 'to', 'have'), ('to', 'have', 'learned'), ('have', 'learned', 'to'), ('learned', 'to', 'perform'), ('to', 'perform', 'that'), ('perform', 'that', 'task')]\n",
      "\n",
      "Document: Types of supervisedlearning algorithms include active learning classification and regression Classification algorithms are used when the outputs are restricted to a limited set of values while regression algorithms are used when the outputs can take any numerical value within a range For example in a classification algorithm that filters emails the input is an incoming email and the output is the folder in which to file the email In contrast regression is used for tasks such as predicting a persons height based on factors like age and genetics or forecasting future temperatures based on historical data\n",
      "\n",
      "\n",
      "Unigrams: [('Types',), ('of',), ('supervisedlearning',), ('algorithms',), ('include',), ('active',), ('learning',), ('classification',), ('and',), ('regression',), ('Classification',), ('algorithms',), ('are',), ('used',), ('when',), ('the',), ('outputs',), ('are',), ('restricted',), ('to',), ('a',), ('limited',), ('set',), ('of',), ('values',), ('while',), ('regression',), ('algorithms',), ('are',), ('used',), ('when',), ('the',), ('outputs',), ('can',), ('take',), ('any',), ('numerical',), ('value',), ('within',), ('a',), ('range',), ('For',), ('example',), ('in',), ('a',), ('classification',), ('algorithm',), ('that',), ('filters',), ('emails',), ('the',), ('input',), ('is',), ('an',), ('incoming',), ('email',), ('and',), ('the',), ('output',), ('is',), ('the',), ('folder',), ('in',), ('which',), ('to',), ('file',), ('the',), ('email',), ('In',), ('contrast',), ('regression',), ('is',), ('used',), ('for',), ('tasks',), ('such',), ('as',), ('predicting',), ('a',), ('persons',), ('height',), ('based',), ('on',), ('factors',), ('like',), ('age',), ('and',), ('genetics',), ('or',), ('forecasting',), ('future',), ('temperatures',), ('based',), ('on',), ('historical',), ('data',)]\n",
      "\n",
      "Bigrams: [('Types', 'of'), ('of', 'supervisedlearning'), ('supervisedlearning', 'algorithms'), ('algorithms', 'include'), ('include', 'active'), ('active', 'learning'), ('learning', 'classification'), ('classification', 'and'), ('and', 'regression'), ('regression', 'Classification'), ('Classification', 'algorithms'), ('algorithms', 'are'), ('are', 'used'), ('used', 'when'), ('when', 'the'), ('the', 'outputs'), ('outputs', 'are'), ('are', 'restricted'), ('restricted', 'to'), ('to', 'a'), ('a', 'limited'), ('limited', 'set'), ('set', 'of'), ('of', 'values'), ('values', 'while'), ('while', 'regression'), ('regression', 'algorithms'), ('algorithms', 'are'), ('are', 'used'), ('used', 'when'), ('when', 'the'), ('the', 'outputs'), ('outputs', 'can'), ('can', 'take'), ('take', 'any'), ('any', 'numerical'), ('numerical', 'value'), ('value', 'within'), ('within', 'a'), ('a', 'range'), ('range', 'For'), ('For', 'example'), ('example', 'in'), ('in', 'a'), ('a', 'classification'), ('classification', 'algorithm'), ('algorithm', 'that'), ('that', 'filters'), ('filters', 'emails'), ('emails', 'the'), ('the', 'input'), ('input', 'is'), ('is', 'an'), ('an', 'incoming'), ('incoming', 'email'), ('email', 'and'), ('and', 'the'), ('the', 'output'), ('output', 'is'), ('is', 'the'), ('the', 'folder'), ('folder', 'in'), ('in', 'which'), ('which', 'to'), ('to', 'file'), ('file', 'the'), ('the', 'email'), ('email', 'In'), ('In', 'contrast'), ('contrast', 'regression'), ('regression', 'is'), ('is', 'used'), ('used', 'for'), ('for', 'tasks'), ('tasks', 'such'), ('such', 'as'), ('as', 'predicting'), ('predicting', 'a'), ('a', 'persons'), ('persons', 'height'), ('height', 'based'), ('based', 'on'), ('on', 'factors'), ('factors', 'like'), ('like', 'age'), ('age', 'and'), ('and', 'genetics'), ('genetics', 'or'), ('or', 'forecasting'), ('forecasting', 'future'), ('future', 'temperatures'), ('temperatures', 'based'), ('based', 'on'), ('on', 'historical'), ('historical', 'data')]\n",
      "\n",
      "Trigrams: [('Types', 'of', 'supervisedlearning'), ('of', 'supervisedlearning', 'algorithms'), ('supervisedlearning', 'algorithms', 'include'), ('algorithms', 'include', 'active'), ('include', 'active', 'learning'), ('active', 'learning', 'classification'), ('learning', 'classification', 'and'), ('classification', 'and', 'regression'), ('and', 'regression', 'Classification'), ('regression', 'Classification', 'algorithms'), ('Classification', 'algorithms', 'are'), ('algorithms', 'are', 'used'), ('are', 'used', 'when'), ('used', 'when', 'the'), ('when', 'the', 'outputs'), ('the', 'outputs', 'are'), ('outputs', 'are', 'restricted'), ('are', 'restricted', 'to'), ('restricted', 'to', 'a'), ('to', 'a', 'limited'), ('a', 'limited', 'set'), ('limited', 'set', 'of'), ('set', 'of', 'values'), ('of', 'values', 'while'), ('values', 'while', 'regression'), ('while', 'regression', 'algorithms'), ('regression', 'algorithms', 'are'), ('algorithms', 'are', 'used'), ('are', 'used', 'when'), ('used', 'when', 'the'), ('when', 'the', 'outputs'), ('the', 'outputs', 'can'), ('outputs', 'can', 'take'), ('can', 'take', 'any'), ('take', 'any', 'numerical'), ('any', 'numerical', 'value'), ('numerical', 'value', 'within'), ('value', 'within', 'a'), ('within', 'a', 'range'), ('a', 'range', 'For'), ('range', 'For', 'example'), ('For', 'example', 'in'), ('example', 'in', 'a'), ('in', 'a', 'classification'), ('a', 'classification', 'algorithm'), ('classification', 'algorithm', 'that'), ('algorithm', 'that', 'filters'), ('that', 'filters', 'emails'), ('filters', 'emails', 'the'), ('emails', 'the', 'input'), ('the', 'input', 'is'), ('input', 'is', 'an'), ('is', 'an', 'incoming'), ('an', 'incoming', 'email'), ('incoming', 'email', 'and'), ('email', 'and', 'the'), ('and', 'the', 'output'), ('the', 'output', 'is'), ('output', 'is', 'the'), ('is', 'the', 'folder'), ('the', 'folder', 'in'), ('folder', 'in', 'which'), ('in', 'which', 'to'), ('which', 'to', 'file'), ('to', 'file', 'the'), ('file', 'the', 'email'), ('the', 'email', 'In'), ('email', 'In', 'contrast'), ('In', 'contrast', 'regression'), ('contrast', 'regression', 'is'), ('regression', 'is', 'used'), ('is', 'used', 'for'), ('used', 'for', 'tasks'), ('for', 'tasks', 'such'), ('tasks', 'such', 'as'), ('such', 'as', 'predicting'), ('as', 'predicting', 'a'), ('predicting', 'a', 'persons'), ('a', 'persons', 'height'), ('persons', 'height', 'based'), ('height', 'based', 'on'), ('based', 'on', 'factors'), ('on', 'factors', 'like'), ('factors', 'like', 'age'), ('like', 'age', 'and'), ('age', 'and', 'genetics'), ('and', 'genetics', 'or'), ('genetics', 'or', 'forecasting'), ('or', 'forecasting', 'future'), ('forecasting', 'future', 'temperatures'), ('future', 'temperatures', 'based'), ('temperatures', 'based', 'on'), ('based', 'on', 'historical'), ('on', 'historical', 'data')]\n",
      "\n",
      "Document: Similarity learning is an area of supervised machine learning closely related to regression and classification but the goal is to learn from examples using a similarity function that measures how similar or related two objects are It has applications in ranking recommendation systems visual identity tracking face verification and speaker verification\n",
      "\n",
      "\n",
      "Unigrams: [('Similarity',), ('learning',), ('is',), ('an',), ('area',), ('of',), ('supervised',), ('machine',), ('learning',), ('closely',), ('related',), ('to',), ('regression',), ('and',), ('classification',), ('but',), ('the',), ('goal',), ('is',), ('to',), ('learn',), ('from',), ('examples',), ('using',), ('a',), ('similarity',), ('function',), ('that',), ('measures',), ('how',), ('similar',), ('or',), ('related',), ('two',), ('objects',), ('are',), ('It',), ('has',), ('applications',), ('in',), ('ranking',), ('recommendation',), ('systems',), ('visual',), ('identity',), ('tracking',), ('face',), ('verification',), ('and',), ('speaker',), ('verification',)]\n",
      "\n",
      "Bigrams: [('Similarity', 'learning'), ('learning', 'is'), ('is', 'an'), ('an', 'area'), ('area', 'of'), ('of', 'supervised'), ('supervised', 'machine'), ('machine', 'learning'), ('learning', 'closely'), ('closely', 'related'), ('related', 'to'), ('to', 'regression'), ('regression', 'and'), ('and', 'classification'), ('classification', 'but'), ('but', 'the'), ('the', 'goal'), ('goal', 'is'), ('is', 'to'), ('to', 'learn'), ('learn', 'from'), ('from', 'examples'), ('examples', 'using'), ('using', 'a'), ('a', 'similarity'), ('similarity', 'function'), ('function', 'that'), ('that', 'measures'), ('measures', 'how'), ('how', 'similar'), ('similar', 'or'), ('or', 'related'), ('related', 'two'), ('two', 'objects'), ('objects', 'are'), ('are', 'It'), ('It', 'has'), ('has', 'applications'), ('applications', 'in'), ('in', 'ranking'), ('ranking', 'recommendation'), ('recommendation', 'systems'), ('systems', 'visual'), ('visual', 'identity'), ('identity', 'tracking'), ('tracking', 'face'), ('face', 'verification'), ('verification', 'and'), ('and', 'speaker'), ('speaker', 'verification')]\n",
      "\n",
      "Trigrams: [('Similarity', 'learning', 'is'), ('learning', 'is', 'an'), ('is', 'an', 'area'), ('an', 'area', 'of'), ('area', 'of', 'supervised'), ('of', 'supervised', 'machine'), ('supervised', 'machine', 'learning'), ('machine', 'learning', 'closely'), ('learning', 'closely', 'related'), ('closely', 'related', 'to'), ('related', 'to', 'regression'), ('to', 'regression', 'and'), ('regression', 'and', 'classification'), ('and', 'classification', 'but'), ('classification', 'but', 'the'), ('but', 'the', 'goal'), ('the', 'goal', 'is'), ('goal', 'is', 'to'), ('is', 'to', 'learn'), ('to', 'learn', 'from'), ('learn', 'from', 'examples'), ('from', 'examples', 'using'), ('examples', 'using', 'a'), ('using', 'a', 'similarity'), ('a', 'similarity', 'function'), ('similarity', 'function', 'that'), ('function', 'that', 'measures'), ('that', 'measures', 'how'), ('measures', 'how', 'similar'), ('how', 'similar', 'or'), ('similar', 'or', 'related'), ('or', 'related', 'two'), ('related', 'two', 'objects'), ('two', 'objects', 'are'), ('objects', 'are', 'It'), ('are', 'It', 'has'), ('It', 'has', 'applications'), ('has', 'applications', 'in'), ('applications', 'in', 'ranking'), ('in', 'ranking', 'recommendation'), ('ranking', 'recommendation', 'systems'), ('recommendation', 'systems', 'visual'), ('systems', 'visual', 'identity'), ('visual', 'identity', 'tracking'), ('identity', 'tracking', 'face'), ('tracking', 'face', 'verification'), ('face', 'verification', 'and'), ('verification', 'and', 'speaker'), ('and', 'speaker', 'verification')]\n",
      "\n",
      "Document: Unsupervised learning algorithms find structures in data that has not been labelled classified or categorised Instead of responding to feedback unsupervised learning algorithms identify commonalities in the data and react based on the presence or absence of such commonalities in each new piece of data Central applications of unsupervised machine learning include clustering dimensionality reduction and density estimation\n",
      "\n",
      "\n",
      "Unigrams: [('Unsupervised',), ('learning',), ('algorithms',), ('find',), ('structures',), ('in',), ('data',), ('that',), ('has',), ('not',), ('been',), ('labelled',), ('classified',), ('or',), ('categorised',), ('Instead',), ('of',), ('responding',), ('to',), ('feedback',), ('unsupervised',), ('learning',), ('algorithms',), ('identify',), ('commonalities',), ('in',), ('the',), ('data',), ('and',), ('react',), ('based',), ('on',), ('the',), ('presence',), ('or',), ('absence',), ('of',), ('such',), ('commonalities',), ('in',), ('each',), ('new',), ('piece',), ('of',), ('data',), ('Central',), ('applications',), ('of',), ('unsupervised',), ('machine',), ('learning',), ('include',), ('clustering',), ('dimensionality',), ('reduction',), ('and',), ('density',), ('estimation',)]\n",
      "\n",
      "Bigrams: [('Unsupervised', 'learning'), ('learning', 'algorithms'), ('algorithms', 'find'), ('find', 'structures'), ('structures', 'in'), ('in', 'data'), ('data', 'that'), ('that', 'has'), ('has', 'not'), ('not', 'been'), ('been', 'labelled'), ('labelled', 'classified'), ('classified', 'or'), ('or', 'categorised'), ('categorised', 'Instead'), ('Instead', 'of'), ('of', 'responding'), ('responding', 'to'), ('to', 'feedback'), ('feedback', 'unsupervised'), ('unsupervised', 'learning'), ('learning', 'algorithms'), ('algorithms', 'identify'), ('identify', 'commonalities'), ('commonalities', 'in'), ('in', 'the'), ('the', 'data'), ('data', 'and'), ('and', 'react'), ('react', 'based'), ('based', 'on'), ('on', 'the'), ('the', 'presence'), ('presence', 'or'), ('or', 'absence'), ('absence', 'of'), ('of', 'such'), ('such', 'commonalities'), ('commonalities', 'in'), ('in', 'each'), ('each', 'new'), ('new', 'piece'), ('piece', 'of'), ('of', 'data'), ('data', 'Central'), ('Central', 'applications'), ('applications', 'of'), ('of', 'unsupervised'), ('unsupervised', 'machine'), ('machine', 'learning'), ('learning', 'include'), ('include', 'clustering'), ('clustering', 'dimensionality'), ('dimensionality', 'reduction'), ('reduction', 'and'), ('and', 'density'), ('density', 'estimation')]\n",
      "\n",
      "Trigrams: [('Unsupervised', 'learning', 'algorithms'), ('learning', 'algorithms', 'find'), ('algorithms', 'find', 'structures'), ('find', 'structures', 'in'), ('structures', 'in', 'data'), ('in', 'data', 'that'), ('data', 'that', 'has'), ('that', 'has', 'not'), ('has', 'not', 'been'), ('not', 'been', 'labelled'), ('been', 'labelled', 'classified'), ('labelled', 'classified', 'or'), ('classified', 'or', 'categorised'), ('or', 'categorised', 'Instead'), ('categorised', 'Instead', 'of'), ('Instead', 'of', 'responding'), ('of', 'responding', 'to'), ('responding', 'to', 'feedback'), ('to', 'feedback', 'unsupervised'), ('feedback', 'unsupervised', 'learning'), ('unsupervised', 'learning', 'algorithms'), ('learning', 'algorithms', 'identify'), ('algorithms', 'identify', 'commonalities'), ('identify', 'commonalities', 'in'), ('commonalities', 'in', 'the'), ('in', 'the', 'data'), ('the', 'data', 'and'), ('data', 'and', 'react'), ('and', 'react', 'based'), ('react', 'based', 'on'), ('based', 'on', 'the'), ('on', 'the', 'presence'), ('the', 'presence', 'or'), ('presence', 'or', 'absence'), ('or', 'absence', 'of'), ('absence', 'of', 'such'), ('of', 'such', 'commonalities'), ('such', 'commonalities', 'in'), ('commonalities', 'in', 'each'), ('in', 'each', 'new'), ('each', 'new', 'piece'), ('new', 'piece', 'of'), ('piece', 'of', 'data'), ('of', 'data', 'Central'), ('data', 'Central', 'applications'), ('Central', 'applications', 'of'), ('applications', 'of', 'unsupervised'), ('of', 'unsupervised', 'machine'), ('unsupervised', 'machine', 'learning'), ('machine', 'learning', 'include'), ('learning', 'include', 'clustering'), ('include', 'clustering', 'dimensionality'), ('clustering', 'dimensionality', 'reduction'), ('dimensionality', 'reduction', 'and'), ('reduction', 'and', 'density'), ('and', 'density', 'estimation')]\n",
      "\n",
      "Document: Cluster analysis is the assignment of a set of observations into subsets called clusters so that observations within the same cluster are similar according to one or more predesignated criteria while observations drawn from different clusters are dissimilar Different clustering techniques make different assumptions on the structure of the data often defined by some similarity metric and evaluated for example by internal compactness or the similarity between members of the same cluster and separation the difference between clusters Other methods are based on estimated density and graph connectivity\n",
      "\n",
      "\n",
      "Unigrams: [('Cluster',), ('analysis',), ('is',), ('the',), ('assignment',), ('of',), ('a',), ('set',), ('of',), ('observations',), ('into',), ('subsets',), ('called',), ('clusters',), ('so',), ('that',), ('observations',), ('within',), ('the',), ('same',), ('cluster',), ('are',), ('similar',), ('according',), ('to',), ('one',), ('or',), ('more',), ('predesignated',), ('criteria',), ('while',), ('observations',), ('drawn',), ('from',), ('different',), ('clusters',), ('are',), ('dissimilar',), ('Different',), ('clustering',), ('techniques',), ('make',), ('different',), ('assumptions',), ('on',), ('the',), ('structure',), ('of',), ('the',), ('data',), ('often',), ('defined',), ('by',), ('some',), ('similarity',), ('metric',), ('and',), ('evaluated',), ('for',), ('example',), ('by',), ('internal',), ('compactness',), ('or',), ('the',), ('similarity',), ('between',), ('members',), ('of',), ('the',), ('same',), ('cluster',), ('and',), ('separation',), ('the',), ('difference',), ('between',), ('clusters',), ('Other',), ('methods',), ('are',), ('based',), ('on',), ('estimated',), ('density',), ('and',), ('graph',), ('connectivity',)]\n",
      "\n",
      "Bigrams: [('Cluster', 'analysis'), ('analysis', 'is'), ('is', 'the'), ('the', 'assignment'), ('assignment', 'of'), ('of', 'a'), ('a', 'set'), ('set', 'of'), ('of', 'observations'), ('observations', 'into'), ('into', 'subsets'), ('subsets', 'called'), ('called', 'clusters'), ('clusters', 'so'), ('so', 'that'), ('that', 'observations'), ('observations', 'within'), ('within', 'the'), ('the', 'same'), ('same', 'cluster'), ('cluster', 'are'), ('are', 'similar'), ('similar', 'according'), ('according', 'to'), ('to', 'one'), ('one', 'or'), ('or', 'more'), ('more', 'predesignated'), ('predesignated', 'criteria'), ('criteria', 'while'), ('while', 'observations'), ('observations', 'drawn'), ('drawn', 'from'), ('from', 'different'), ('different', 'clusters'), ('clusters', 'are'), ('are', 'dissimilar'), ('dissimilar', 'Different'), ('Different', 'clustering'), ('clustering', 'techniques'), ('techniques', 'make'), ('make', 'different'), ('different', 'assumptions'), ('assumptions', 'on'), ('on', 'the'), ('the', 'structure'), ('structure', 'of'), ('of', 'the'), ('the', 'data'), ('data', 'often'), ('often', 'defined'), ('defined', 'by'), ('by', 'some'), ('some', 'similarity'), ('similarity', 'metric'), ('metric', 'and'), ('and', 'evaluated'), ('evaluated', 'for'), ('for', 'example'), ('example', 'by'), ('by', 'internal'), ('internal', 'compactness'), ('compactness', 'or'), ('or', 'the'), ('the', 'similarity'), ('similarity', 'between'), ('between', 'members'), ('members', 'of'), ('of', 'the'), ('the', 'same'), ('same', 'cluster'), ('cluster', 'and'), ('and', 'separation'), ('separation', 'the'), ('the', 'difference'), ('difference', 'between'), ('between', 'clusters'), ('clusters', 'Other'), ('Other', 'methods'), ('methods', 'are'), ('are', 'based'), ('based', 'on'), ('on', 'estimated'), ('estimated', 'density'), ('density', 'and'), ('and', 'graph'), ('graph', 'connectivity')]\n",
      "\n",
      "Trigrams: [('Cluster', 'analysis', 'is'), ('analysis', 'is', 'the'), ('is', 'the', 'assignment'), ('the', 'assignment', 'of'), ('assignment', 'of', 'a'), ('of', 'a', 'set'), ('a', 'set', 'of'), ('set', 'of', 'observations'), ('of', 'observations', 'into'), ('observations', 'into', 'subsets'), ('into', 'subsets', 'called'), ('subsets', 'called', 'clusters'), ('called', 'clusters', 'so'), ('clusters', 'so', 'that'), ('so', 'that', 'observations'), ('that', 'observations', 'within'), ('observations', 'within', 'the'), ('within', 'the', 'same'), ('the', 'same', 'cluster'), ('same', 'cluster', 'are'), ('cluster', 'are', 'similar'), ('are', 'similar', 'according'), ('similar', 'according', 'to'), ('according', 'to', 'one'), ('to', 'one', 'or'), ('one', 'or', 'more'), ('or', 'more', 'predesignated'), ('more', 'predesignated', 'criteria'), ('predesignated', 'criteria', 'while'), ('criteria', 'while', 'observations'), ('while', 'observations', 'drawn'), ('observations', 'drawn', 'from'), ('drawn', 'from', 'different'), ('from', 'different', 'clusters'), ('different', 'clusters', 'are'), ('clusters', 'are', 'dissimilar'), ('are', 'dissimilar', 'Different'), ('dissimilar', 'Different', 'clustering'), ('Different', 'clustering', 'techniques'), ('clustering', 'techniques', 'make'), ('techniques', 'make', 'different'), ('make', 'different', 'assumptions'), ('different', 'assumptions', 'on'), ('assumptions', 'on', 'the'), ('on', 'the', 'structure'), ('the', 'structure', 'of'), ('structure', 'of', 'the'), ('of', 'the', 'data'), ('the', 'data', 'often'), ('data', 'often', 'defined'), ('often', 'defined', 'by'), ('defined', 'by', 'some'), ('by', 'some', 'similarity'), ('some', 'similarity', 'metric'), ('similarity', 'metric', 'and'), ('metric', 'and', 'evaluated'), ('and', 'evaluated', 'for'), ('evaluated', 'for', 'example'), ('for', 'example', 'by'), ('example', 'by', 'internal'), ('by', 'internal', 'compactness'), ('internal', 'compactness', 'or'), ('compactness', 'or', 'the'), ('or', 'the', 'similarity'), ('the', 'similarity', 'between'), ('similarity', 'between', 'members'), ('between', 'members', 'of'), ('members', 'of', 'the'), ('of', 'the', 'same'), ('the', 'same', 'cluster'), ('same', 'cluster', 'and'), ('cluster', 'and', 'separation'), ('and', 'separation', 'the'), ('separation', 'the', 'difference'), ('the', 'difference', 'between'), ('difference', 'between', 'clusters'), ('between', 'clusters', 'Other'), ('clusters', 'Other', 'methods'), ('Other', 'methods', 'are'), ('methods', 'are', 'based'), ('are', 'based', 'on'), ('based', 'on', 'estimated'), ('on', 'estimated', 'density'), ('estimated', 'density', 'and'), ('density', 'and', 'graph'), ('and', 'graph', 'connectivity')]\n",
      "\n",
      "Document: A special type of unsupervised learning called selfsupervised learning involves training a model by generating the supervisory signal from the data itself\n",
      "\n",
      "\n",
      "Unigrams: [('A',), ('special',), ('type',), ('of',), ('unsupervised',), ('learning',), ('called',), ('selfsupervised',), ('learning',), ('involves',), ('training',), ('a',), ('model',), ('by',), ('generating',), ('the',), ('supervisory',), ('signal',), ('from',), ('the',), ('data',), ('itself',)]\n",
      "\n",
      "Bigrams: [('A', 'special'), ('special', 'type'), ('type', 'of'), ('of', 'unsupervised'), ('unsupervised', 'learning'), ('learning', 'called'), ('called', 'selfsupervised'), ('selfsupervised', 'learning'), ('learning', 'involves'), ('involves', 'training'), ('training', 'a'), ('a', 'model'), ('model', 'by'), ('by', 'generating'), ('generating', 'the'), ('the', 'supervisory'), ('supervisory', 'signal'), ('signal', 'from'), ('from', 'the'), ('the', 'data'), ('data', 'itself')]\n",
      "\n",
      "Trigrams: [('A', 'special', 'type'), ('special', 'type', 'of'), ('type', 'of', 'unsupervised'), ('of', 'unsupervised', 'learning'), ('unsupervised', 'learning', 'called'), ('learning', 'called', 'selfsupervised'), ('called', 'selfsupervised', 'learning'), ('selfsupervised', 'learning', 'involves'), ('learning', 'involves', 'training'), ('involves', 'training', 'a'), ('training', 'a', 'model'), ('a', 'model', 'by'), ('model', 'by', 'generating'), ('by', 'generating', 'the'), ('generating', 'the', 'supervisory'), ('the', 'supervisory', 'signal'), ('supervisory', 'signal', 'from'), ('signal', 'from', 'the'), ('from', 'the', 'data'), ('the', 'data', 'itself')]\n",
      "\n",
      "Document: Semisupervised learning falls between unsupervised learning without any labelled training data and supervised learning with completely labelled training data Some of the training examples are missing training labels yet many machinelearning researchers have found that unlabelled data when used in conjunction with a small amount of labelled data can produce a considerable improvement in learning accuracy\n",
      "\n",
      "\n",
      "Unigrams: [('Semisupervised',), ('learning',), ('falls',), ('between',), ('unsupervised',), ('learning',), ('without',), ('any',), ('labelled',), ('training',), ('data',), ('and',), ('supervised',), ('learning',), ('with',), ('completely',), ('labelled',), ('training',), ('data',), ('Some',), ('of',), ('the',), ('training',), ('examples',), ('are',), ('missing',), ('training',), ('labels',), ('yet',), ('many',), ('machinelearning',), ('researchers',), ('have',), ('found',), ('that',), ('unlabelled',), ('data',), ('when',), ('used',), ('in',), ('conjunction',), ('with',), ('a',), ('small',), ('amount',), ('of',), ('labelled',), ('data',), ('can',), ('produce',), ('a',), ('considerable',), ('improvement',), ('in',), ('learning',), ('accuracy',)]\n",
      "\n",
      "Bigrams: [('Semisupervised', 'learning'), ('learning', 'falls'), ('falls', 'between'), ('between', 'unsupervised'), ('unsupervised', 'learning'), ('learning', 'without'), ('without', 'any'), ('any', 'labelled'), ('labelled', 'training'), ('training', 'data'), ('data', 'and'), ('and', 'supervised'), ('supervised', 'learning'), ('learning', 'with'), ('with', 'completely'), ('completely', 'labelled'), ('labelled', 'training'), ('training', 'data'), ('data', 'Some'), ('Some', 'of'), ('of', 'the'), ('the', 'training'), ('training', 'examples'), ('examples', 'are'), ('are', 'missing'), ('missing', 'training'), ('training', 'labels'), ('labels', 'yet'), ('yet', 'many'), ('many', 'machinelearning'), ('machinelearning', 'researchers'), ('researchers', 'have'), ('have', 'found'), ('found', 'that'), ('that', 'unlabelled'), ('unlabelled', 'data'), ('data', 'when'), ('when', 'used'), ('used', 'in'), ('in', 'conjunction'), ('conjunction', 'with'), ('with', 'a'), ('a', 'small'), ('small', 'amount'), ('amount', 'of'), ('of', 'labelled'), ('labelled', 'data'), ('data', 'can'), ('can', 'produce'), ('produce', 'a'), ('a', 'considerable'), ('considerable', 'improvement'), ('improvement', 'in'), ('in', 'learning'), ('learning', 'accuracy')]\n",
      "\n",
      "Trigrams: [('Semisupervised', 'learning', 'falls'), ('learning', 'falls', 'between'), ('falls', 'between', 'unsupervised'), ('between', 'unsupervised', 'learning'), ('unsupervised', 'learning', 'without'), ('learning', 'without', 'any'), ('without', 'any', 'labelled'), ('any', 'labelled', 'training'), ('labelled', 'training', 'data'), ('training', 'data', 'and'), ('data', 'and', 'supervised'), ('and', 'supervised', 'learning'), ('supervised', 'learning', 'with'), ('learning', 'with', 'completely'), ('with', 'completely', 'labelled'), ('completely', 'labelled', 'training'), ('labelled', 'training', 'data'), ('training', 'data', 'Some'), ('data', 'Some', 'of'), ('Some', 'of', 'the'), ('of', 'the', 'training'), ('the', 'training', 'examples'), ('training', 'examples', 'are'), ('examples', 'are', 'missing'), ('are', 'missing', 'training'), ('missing', 'training', 'labels'), ('training', 'labels', 'yet'), ('labels', 'yet', 'many'), ('yet', 'many', 'machinelearning'), ('many', 'machinelearning', 'researchers'), ('machinelearning', 'researchers', 'have'), ('researchers', 'have', 'found'), ('have', 'found', 'that'), ('found', 'that', 'unlabelled'), ('that', 'unlabelled', 'data'), ('unlabelled', 'data', 'when'), ('data', 'when', 'used'), ('when', 'used', 'in'), ('used', 'in', 'conjunction'), ('in', 'conjunction', 'with'), ('conjunction', 'with', 'a'), ('with', 'a', 'small'), ('a', 'small', 'amount'), ('small', 'amount', 'of'), ('amount', 'of', 'labelled'), ('of', 'labelled', 'data'), ('labelled', 'data', 'can'), ('data', 'can', 'produce'), ('can', 'produce', 'a'), ('produce', 'a', 'considerable'), ('a', 'considerable', 'improvement'), ('considerable', 'improvement', 'in'), ('improvement', 'in', 'learning'), ('in', 'learning', 'accuracy')]\n",
      "\n",
      "Document: In weakly supervised learning the training labels are noisy limited or imprecise however these labels are often cheaper to obtain resulting in larger effective training sets\n",
      "\n",
      "\n",
      "Unigrams: [('In',), ('weakly',), ('supervised',), ('learning',), ('the',), ('training',), ('labels',), ('are',), ('noisy',), ('limited',), ('or',), ('imprecise',), ('however',), ('these',), ('labels',), ('are',), ('often',), ('cheaper',), ('to',), ('obtain',), ('resulting',), ('in',), ('larger',), ('effective',), ('training',), ('sets',)]\n",
      "\n",
      "Bigrams: [('In', 'weakly'), ('weakly', 'supervised'), ('supervised', 'learning'), ('learning', 'the'), ('the', 'training'), ('training', 'labels'), ('labels', 'are'), ('are', 'noisy'), ('noisy', 'limited'), ('limited', 'or'), ('or', 'imprecise'), ('imprecise', 'however'), ('however', 'these'), ('these', 'labels'), ('labels', 'are'), ('are', 'often'), ('often', 'cheaper'), ('cheaper', 'to'), ('to', 'obtain'), ('obtain', 'resulting'), ('resulting', 'in'), ('in', 'larger'), ('larger', 'effective'), ('effective', 'training'), ('training', 'sets')]\n",
      "\n",
      "Trigrams: [('In', 'weakly', 'supervised'), ('weakly', 'supervised', 'learning'), ('supervised', 'learning', 'the'), ('learning', 'the', 'training'), ('the', 'training', 'labels'), ('training', 'labels', 'are'), ('labels', 'are', 'noisy'), ('are', 'noisy', 'limited'), ('noisy', 'limited', 'or'), ('limited', 'or', 'imprecise'), ('or', 'imprecise', 'however'), ('imprecise', 'however', 'these'), ('however', 'these', 'labels'), ('these', 'labels', 'are'), ('labels', 'are', 'often'), ('are', 'often', 'cheaper'), ('often', 'cheaper', 'to'), ('cheaper', 'to', 'obtain'), ('to', 'obtain', 'resulting'), ('obtain', 'resulting', 'in'), ('resulting', 'in', 'larger'), ('in', 'larger', 'effective'), ('larger', 'effective', 'training'), ('effective', 'training', 'sets')]\n",
      "\n",
      "Document: Reinforcement learning is an area of machine learning concerned with how software agents ought to take actions in an environment so as to maximise some notion of cumulative reward Due to its generality the field is studied in many other disciplines such as game theory control theory operations research information theory simulationbased optimisation multiagent systems swarm intelligence statistics and genetic algorithms In reinforcement learning the environment is typically represented as a Markov decision process MDP Many reinforcement learning algorithms use dynamic programming techniques Reinforcement learning algorithms do not assume knowledge of an exact mathematical model of the MDP and are used when exact models are infeasible Reinforcement learning algorithms are used in autonomous vehicles or in learning to play a game against a human opponent\n",
      "\n",
      "\n",
      "Unigrams: [('Reinforcement',), ('learning',), ('is',), ('an',), ('area',), ('of',), ('machine',), ('learning',), ('concerned',), ('with',), ('how',), ('software',), ('agents',), ('ought',), ('to',), ('take',), ('actions',), ('in',), ('an',), ('environment',), ('so',), ('as',), ('to',), ('maximise',), ('some',), ('notion',), ('of',), ('cumulative',), ('reward',), ('Due',), ('to',), ('its',), ('generality',), ('the',), ('field',), ('is',), ('studied',), ('in',), ('many',), ('other',), ('disciplines',), ('such',), ('as',), ('game',), ('theory',), ('control',), ('theory',), ('operations',), ('research',), ('information',), ('theory',), ('simulationbased',), ('optimisation',), ('multiagent',), ('systems',), ('swarm',), ('intelligence',), ('statistics',), ('and',), ('genetic',), ('algorithms',), ('In',), ('reinforcement',), ('learning',), ('the',), ('environment',), ('is',), ('typically',), ('represented',), ('as',), ('a',), ('Markov',), ('decision',), ('process',), ('MDP',), ('Many',), ('reinforcement',), ('learning',), ('algorithms',), ('use',), ('dynamic',), ('programming',), ('techniques',), ('Reinforcement',), ('learning',), ('algorithms',), ('do',), ('not',), ('assume',), ('knowledge',), ('of',), ('an',), ('exact',), ('mathematical',), ('model',), ('of',), ('the',), ('MDP',), ('and',), ('are',), ('used',), ('when',), ('exact',), ('models',), ('are',), ('infeasible',), ('Reinforcement',), ('learning',), ('algorithms',), ('are',), ('used',), ('in',), ('autonomous',), ('vehicles',), ('or',), ('in',), ('learning',), ('to',), ('play',), ('a',), ('game',), ('against',), ('a',), ('human',), ('opponent',)]\n",
      "\n",
      "Bigrams: [('Reinforcement', 'learning'), ('learning', 'is'), ('is', 'an'), ('an', 'area'), ('area', 'of'), ('of', 'machine'), ('machine', 'learning'), ('learning', 'concerned'), ('concerned', 'with'), ('with', 'how'), ('how', 'software'), ('software', 'agents'), ('agents', 'ought'), ('ought', 'to'), ('to', 'take'), ('take', 'actions'), ('actions', 'in'), ('in', 'an'), ('an', 'environment'), ('environment', 'so'), ('so', 'as'), ('as', 'to'), ('to', 'maximise'), ('maximise', 'some'), ('some', 'notion'), ('notion', 'of'), ('of', 'cumulative'), ('cumulative', 'reward'), ('reward', 'Due'), ('Due', 'to'), ('to', 'its'), ('its', 'generality'), ('generality', 'the'), ('the', 'field'), ('field', 'is'), ('is', 'studied'), ('studied', 'in'), ('in', 'many'), ('many', 'other'), ('other', 'disciplines'), ('disciplines', 'such'), ('such', 'as'), ('as', 'game'), ('game', 'theory'), ('theory', 'control'), ('control', 'theory'), ('theory', 'operations'), ('operations', 'research'), ('research', 'information'), ('information', 'theory'), ('theory', 'simulationbased'), ('simulationbased', 'optimisation'), ('optimisation', 'multiagent'), ('multiagent', 'systems'), ('systems', 'swarm'), ('swarm', 'intelligence'), ('intelligence', 'statistics'), ('statistics', 'and'), ('and', 'genetic'), ('genetic', 'algorithms'), ('algorithms', 'In'), ('In', 'reinforcement'), ('reinforcement', 'learning'), ('learning', 'the'), ('the', 'environment'), ('environment', 'is'), ('is', 'typically'), ('typically', 'represented'), ('represented', 'as'), ('as', 'a'), ('a', 'Markov'), ('Markov', 'decision'), ('decision', 'process'), ('process', 'MDP'), ('MDP', 'Many'), ('Many', 'reinforcement'), ('reinforcement', 'learning'), ('learning', 'algorithms'), ('algorithms', 'use'), ('use', 'dynamic'), ('dynamic', 'programming'), ('programming', 'techniques'), ('techniques', 'Reinforcement'), ('Reinforcement', 'learning'), ('learning', 'algorithms'), ('algorithms', 'do'), ('do', 'not'), ('not', 'assume'), ('assume', 'knowledge'), ('knowledge', 'of'), ('of', 'an'), ('an', 'exact'), ('exact', 'mathematical'), ('mathematical', 'model'), ('model', 'of'), ('of', 'the'), ('the', 'MDP'), ('MDP', 'and'), ('and', 'are'), ('are', 'used'), ('used', 'when'), ('when', 'exact'), ('exact', 'models'), ('models', 'are'), ('are', 'infeasible'), ('infeasible', 'Reinforcement'), ('Reinforcement', 'learning'), ('learning', 'algorithms'), ('algorithms', 'are'), ('are', 'used'), ('used', 'in'), ('in', 'autonomous'), ('autonomous', 'vehicles'), ('vehicles', 'or'), ('or', 'in'), ('in', 'learning'), ('learning', 'to'), ('to', 'play'), ('play', 'a'), ('a', 'game'), ('game', 'against'), ('against', 'a'), ('a', 'human'), ('human', 'opponent')]\n",
      "\n",
      "Trigrams: [('Reinforcement', 'learning', 'is'), ('learning', 'is', 'an'), ('is', 'an', 'area'), ('an', 'area', 'of'), ('area', 'of', 'machine'), ('of', 'machine', 'learning'), ('machine', 'learning', 'concerned'), ('learning', 'concerned', 'with'), ('concerned', 'with', 'how'), ('with', 'how', 'software'), ('how', 'software', 'agents'), ('software', 'agents', 'ought'), ('agents', 'ought', 'to'), ('ought', 'to', 'take'), ('to', 'take', 'actions'), ('take', 'actions', 'in'), ('actions', 'in', 'an'), ('in', 'an', 'environment'), ('an', 'environment', 'so'), ('environment', 'so', 'as'), ('so', 'as', 'to'), ('as', 'to', 'maximise'), ('to', 'maximise', 'some'), ('maximise', 'some', 'notion'), ('some', 'notion', 'of'), ('notion', 'of', 'cumulative'), ('of', 'cumulative', 'reward'), ('cumulative', 'reward', 'Due'), ('reward', 'Due', 'to'), ('Due', 'to', 'its'), ('to', 'its', 'generality'), ('its', 'generality', 'the'), ('generality', 'the', 'field'), ('the', 'field', 'is'), ('field', 'is', 'studied'), ('is', 'studied', 'in'), ('studied', 'in', 'many'), ('in', 'many', 'other'), ('many', 'other', 'disciplines'), ('other', 'disciplines', 'such'), ('disciplines', 'such', 'as'), ('such', 'as', 'game'), ('as', 'game', 'theory'), ('game', 'theory', 'control'), ('theory', 'control', 'theory'), ('control', 'theory', 'operations'), ('theory', 'operations', 'research'), ('operations', 'research', 'information'), ('research', 'information', 'theory'), ('information', 'theory', 'simulationbased'), ('theory', 'simulationbased', 'optimisation'), ('simulationbased', 'optimisation', 'multiagent'), ('optimisation', 'multiagent', 'systems'), ('multiagent', 'systems', 'swarm'), ('systems', 'swarm', 'intelligence'), ('swarm', 'intelligence', 'statistics'), ('intelligence', 'statistics', 'and'), ('statistics', 'and', 'genetic'), ('and', 'genetic', 'algorithms'), ('genetic', 'algorithms', 'In'), ('algorithms', 'In', 'reinforcement'), ('In', 'reinforcement', 'learning'), ('reinforcement', 'learning', 'the'), ('learning', 'the', 'environment'), ('the', 'environment', 'is'), ('environment', 'is', 'typically'), ('is', 'typically', 'represented'), ('typically', 'represented', 'as'), ('represented', 'as', 'a'), ('as', 'a', 'Markov'), ('a', 'Markov', 'decision'), ('Markov', 'decision', 'process'), ('decision', 'process', 'MDP'), ('process', 'MDP', 'Many'), ('MDP', 'Many', 'reinforcement'), ('Many', 'reinforcement', 'learning'), ('reinforcement', 'learning', 'algorithms'), ('learning', 'algorithms', 'use'), ('algorithms', 'use', 'dynamic'), ('use', 'dynamic', 'programming'), ('dynamic', 'programming', 'techniques'), ('programming', 'techniques', 'Reinforcement'), ('techniques', 'Reinforcement', 'learning'), ('Reinforcement', 'learning', 'algorithms'), ('learning', 'algorithms', 'do'), ('algorithms', 'do', 'not'), ('do', 'not', 'assume'), ('not', 'assume', 'knowledge'), ('assume', 'knowledge', 'of'), ('knowledge', 'of', 'an'), ('of', 'an', 'exact'), ('an', 'exact', 'mathematical'), ('exact', 'mathematical', 'model'), ('mathematical', 'model', 'of'), ('model', 'of', 'the'), ('of', 'the', 'MDP'), ('the', 'MDP', 'and'), ('MDP', 'and', 'are'), ('and', 'are', 'used'), ('are', 'used', 'when'), ('used', 'when', 'exact'), ('when', 'exact', 'models'), ('exact', 'models', 'are'), ('models', 'are', 'infeasible'), ('are', 'infeasible', 'Reinforcement'), ('infeasible', 'Reinforcement', 'learning'), ('Reinforcement', 'learning', 'algorithms'), ('learning', 'algorithms', 'are'), ('algorithms', 'are', 'used'), ('are', 'used', 'in'), ('used', 'in', 'autonomous'), ('in', 'autonomous', 'vehicles'), ('autonomous', 'vehicles', 'or'), ('vehicles', 'or', 'in'), ('or', 'in', 'learning'), ('in', 'learning', 'to'), ('learning', 'to', 'play'), ('to', 'play', 'a'), ('play', 'a', 'game'), ('a', 'game', 'against'), ('game', 'against', 'a'), ('against', 'a', 'human'), ('a', 'human', 'opponent')]\n",
      "\n",
      "Document: Dimensionality reduction is a process of reducing the number of random variables under consideration by obtaining a set of principal variables In other words it is a process of reducing the dimension of the feature set also called the number of features Most of the dimensionality reduction techniques can be considered as either feature elimination or extraction One of the popular methods of dimensionality reduction is principal component analysis PCA PCA involves changing higherdimensional data eg D to a smaller space eg DThe manifold hypothesis proposes that highdimensional data sets lie along lowdimensional manifolds and many dimensionality reduction techniques make this assumption leading to the area of manifold learning and manifold regularisation\n",
      "\n",
      "\n",
      "Unigrams: [('Dimensionality',), ('reduction',), ('is',), ('a',), ('process',), ('of',), ('reducing',), ('the',), ('number',), ('of',), ('random',), ('variables',), ('under',), ('consideration',), ('by',), ('obtaining',), ('a',), ('set',), ('of',), ('principal',), ('variables',), ('In',), ('other',), ('words',), ('it',), ('is',), ('a',), ('process',), ('of',), ('reducing',), ('the',), ('dimension',), ('of',), ('the',), ('feature',), ('set',), ('also',), ('called',), ('the',), ('number',), ('of',), ('features',), ('Most',), ('of',), ('the',), ('dimensionality',), ('reduction',), ('techniques',), ('can',), ('be',), ('considered',), ('as',), ('either',), ('feature',), ('elimination',), ('or',), ('extraction',), ('One',), ('of',), ('the',), ('popular',), ('methods',), ('of',), ('dimensionality',), ('reduction',), ('is',), ('principal',), ('component',), ('analysis',), ('PCA',), ('PCA',), ('involves',), ('changing',), ('higherdimensional',), ('data',), ('eg',), ('D',), ('to',), ('a',), ('smaller',), ('space',), ('eg',), ('DThe',), ('manifold',), ('hypothesis',), ('proposes',), ('that',), ('highdimensional',), ('data',), ('sets',), ('lie',), ('along',), ('lowdimensional',), ('manifolds',), ('and',), ('many',), ('dimensionality',), ('reduction',), ('techniques',), ('make',), ('this',), ('assumption',), ('leading',), ('to',), ('the',), ('area',), ('of',), ('manifold',), ('learning',), ('and',), ('manifold',), ('regularisation',)]\n",
      "\n",
      "Bigrams: [('Dimensionality', 'reduction'), ('reduction', 'is'), ('is', 'a'), ('a', 'process'), ('process', 'of'), ('of', 'reducing'), ('reducing', 'the'), ('the', 'number'), ('number', 'of'), ('of', 'random'), ('random', 'variables'), ('variables', 'under'), ('under', 'consideration'), ('consideration', 'by'), ('by', 'obtaining'), ('obtaining', 'a'), ('a', 'set'), ('set', 'of'), ('of', 'principal'), ('principal', 'variables'), ('variables', 'In'), ('In', 'other'), ('other', 'words'), ('words', 'it'), ('it', 'is'), ('is', 'a'), ('a', 'process'), ('process', 'of'), ('of', 'reducing'), ('reducing', 'the'), ('the', 'dimension'), ('dimension', 'of'), ('of', 'the'), ('the', 'feature'), ('feature', 'set'), ('set', 'also'), ('also', 'called'), ('called', 'the'), ('the', 'number'), ('number', 'of'), ('of', 'features'), ('features', 'Most'), ('Most', 'of'), ('of', 'the'), ('the', 'dimensionality'), ('dimensionality', 'reduction'), ('reduction', 'techniques'), ('techniques', 'can'), ('can', 'be'), ('be', 'considered'), ('considered', 'as'), ('as', 'either'), ('either', 'feature'), ('feature', 'elimination'), ('elimination', 'or'), ('or', 'extraction'), ('extraction', 'One'), ('One', 'of'), ('of', 'the'), ('the', 'popular'), ('popular', 'methods'), ('methods', 'of'), ('of', 'dimensionality'), ('dimensionality', 'reduction'), ('reduction', 'is'), ('is', 'principal'), ('principal', 'component'), ('component', 'analysis'), ('analysis', 'PCA'), ('PCA', 'PCA'), ('PCA', 'involves'), ('involves', 'changing'), ('changing', 'higherdimensional'), ('higherdimensional', 'data'), ('data', 'eg'), ('eg', 'D'), ('D', 'to'), ('to', 'a'), ('a', 'smaller'), ('smaller', 'space'), ('space', 'eg'), ('eg', 'DThe'), ('DThe', 'manifold'), ('manifold', 'hypothesis'), ('hypothesis', 'proposes'), ('proposes', 'that'), ('that', 'highdimensional'), ('highdimensional', 'data'), ('data', 'sets'), ('sets', 'lie'), ('lie', 'along'), ('along', 'lowdimensional'), ('lowdimensional', 'manifolds'), ('manifolds', 'and'), ('and', 'many'), ('many', 'dimensionality'), ('dimensionality', 'reduction'), ('reduction', 'techniques'), ('techniques', 'make'), ('make', 'this'), ('this', 'assumption'), ('assumption', 'leading'), ('leading', 'to'), ('to', 'the'), ('the', 'area'), ('area', 'of'), ('of', 'manifold'), ('manifold', 'learning'), ('learning', 'and'), ('and', 'manifold'), ('manifold', 'regularisation')]\n",
      "\n",
      "Trigrams: [('Dimensionality', 'reduction', 'is'), ('reduction', 'is', 'a'), ('is', 'a', 'process'), ('a', 'process', 'of'), ('process', 'of', 'reducing'), ('of', 'reducing', 'the'), ('reducing', 'the', 'number'), ('the', 'number', 'of'), ('number', 'of', 'random'), ('of', 'random', 'variables'), ('random', 'variables', 'under'), ('variables', 'under', 'consideration'), ('under', 'consideration', 'by'), ('consideration', 'by', 'obtaining'), ('by', 'obtaining', 'a'), ('obtaining', 'a', 'set'), ('a', 'set', 'of'), ('set', 'of', 'principal'), ('of', 'principal', 'variables'), ('principal', 'variables', 'In'), ('variables', 'In', 'other'), ('In', 'other', 'words'), ('other', 'words', 'it'), ('words', 'it', 'is'), ('it', 'is', 'a'), ('is', 'a', 'process'), ('a', 'process', 'of'), ('process', 'of', 'reducing'), ('of', 'reducing', 'the'), ('reducing', 'the', 'dimension'), ('the', 'dimension', 'of'), ('dimension', 'of', 'the'), ('of', 'the', 'feature'), ('the', 'feature', 'set'), ('feature', 'set', 'also'), ('set', 'also', 'called'), ('also', 'called', 'the'), ('called', 'the', 'number'), ('the', 'number', 'of'), ('number', 'of', 'features'), ('of', 'features', 'Most'), ('features', 'Most', 'of'), ('Most', 'of', 'the'), ('of', 'the', 'dimensionality'), ('the', 'dimensionality', 'reduction'), ('dimensionality', 'reduction', 'techniques'), ('reduction', 'techniques', 'can'), ('techniques', 'can', 'be'), ('can', 'be', 'considered'), ('be', 'considered', 'as'), ('considered', 'as', 'either'), ('as', 'either', 'feature'), ('either', 'feature', 'elimination'), ('feature', 'elimination', 'or'), ('elimination', 'or', 'extraction'), ('or', 'extraction', 'One'), ('extraction', 'One', 'of'), ('One', 'of', 'the'), ('of', 'the', 'popular'), ('the', 'popular', 'methods'), ('popular', 'methods', 'of'), ('methods', 'of', 'dimensionality'), ('of', 'dimensionality', 'reduction'), ('dimensionality', 'reduction', 'is'), ('reduction', 'is', 'principal'), ('is', 'principal', 'component'), ('principal', 'component', 'analysis'), ('component', 'analysis', 'PCA'), ('analysis', 'PCA', 'PCA'), ('PCA', 'PCA', 'involves'), ('PCA', 'involves', 'changing'), ('involves', 'changing', 'higherdimensional'), ('changing', 'higherdimensional', 'data'), ('higherdimensional', 'data', 'eg'), ('data', 'eg', 'D'), ('eg', 'D', 'to'), ('D', 'to', 'a'), ('to', 'a', 'smaller'), ('a', 'smaller', 'space'), ('smaller', 'space', 'eg'), ('space', 'eg', 'DThe'), ('eg', 'DThe', 'manifold'), ('DThe', 'manifold', 'hypothesis'), ('manifold', 'hypothesis', 'proposes'), ('hypothesis', 'proposes', 'that'), ('proposes', 'that', 'highdimensional'), ('that', 'highdimensional', 'data'), ('highdimensional', 'data', 'sets'), ('data', 'sets', 'lie'), ('sets', 'lie', 'along'), ('lie', 'along', 'lowdimensional'), ('along', 'lowdimensional', 'manifolds'), ('lowdimensional', 'manifolds', 'and'), ('manifolds', 'and', 'many'), ('and', 'many', 'dimensionality'), ('many', 'dimensionality', 'reduction'), ('dimensionality', 'reduction', 'techniques'), ('reduction', 'techniques', 'make'), ('techniques', 'make', 'this'), ('make', 'this', 'assumption'), ('this', 'assumption', 'leading'), ('assumption', 'leading', 'to'), ('leading', 'to', 'the'), ('to', 'the', 'area'), ('the', 'area', 'of'), ('area', 'of', 'manifold'), ('of', 'manifold', 'learning'), ('manifold', 'learning', 'and'), ('learning', 'and', 'manifold'), ('and', 'manifold', 'regularisation')]\n",
      "\n",
      "Document: Other approaches have been developed which do not fit neatly into this threefold categorisation and sometimes more than one is used by the same machine learning system For example topic modelling metalearning\n",
      "\n",
      "\n",
      "Unigrams: [('Other',), ('approaches',), ('have',), ('been',), ('developed',), ('which',), ('do',), ('not',), ('fit',), ('neatly',), ('into',), ('this',), ('threefold',), ('categorisation',), ('and',), ('sometimes',), ('more',), ('than',), ('one',), ('is',), ('used',), ('by',), ('the',), ('same',), ('machine',), ('learning',), ('system',), ('For',), ('example',), ('topic',), ('modelling',), ('metalearning',)]\n",
      "\n",
      "Bigrams: [('Other', 'approaches'), ('approaches', 'have'), ('have', 'been'), ('been', 'developed'), ('developed', 'which'), ('which', 'do'), ('do', 'not'), ('not', 'fit'), ('fit', 'neatly'), ('neatly', 'into'), ('into', 'this'), ('this', 'threefold'), ('threefold', 'categorisation'), ('categorisation', 'and'), ('and', 'sometimes'), ('sometimes', 'more'), ('more', 'than'), ('than', 'one'), ('one', 'is'), ('is', 'used'), ('used', 'by'), ('by', 'the'), ('the', 'same'), ('same', 'machine'), ('machine', 'learning'), ('learning', 'system'), ('system', 'For'), ('For', 'example'), ('example', 'topic'), ('topic', 'modelling'), ('modelling', 'metalearning')]\n",
      "\n",
      "Trigrams: [('Other', 'approaches', 'have'), ('approaches', 'have', 'been'), ('have', 'been', 'developed'), ('been', 'developed', 'which'), ('developed', 'which', 'do'), ('which', 'do', 'not'), ('do', 'not', 'fit'), ('not', 'fit', 'neatly'), ('fit', 'neatly', 'into'), ('neatly', 'into', 'this'), ('into', 'this', 'threefold'), ('this', 'threefold', 'categorisation'), ('threefold', 'categorisation', 'and'), ('categorisation', 'and', 'sometimes'), ('and', 'sometimes', 'more'), ('sometimes', 'more', 'than'), ('more', 'than', 'one'), ('than', 'one', 'is'), ('one', 'is', 'used'), ('is', 'used', 'by'), ('used', 'by', 'the'), ('by', 'the', 'same'), ('the', 'same', 'machine'), ('same', 'machine', 'learning'), ('machine', 'learning', 'system'), ('learning', 'system', 'For'), ('system', 'For', 'example'), ('For', 'example', 'topic'), ('example', 'topic', 'modelling'), ('topic', 'modelling', 'metalearning')]\n",
      "\n",
      "Document: Selflearning as a machine learning paradigm was introduced in  along with a neural network capable of selflearning named crossbar adaptive array CAA It gives a solution to the problem learning without any external reward by introducing emotion as an internal reward Emotion is used as state evaluation of a selflearning agent The CAA selflearning algorithm computes in a crossbar fashion both decisions about actions and emotions feelings about consequence situations The system is driven by the interaction between cognition and emotionThe selflearning algorithm updates a memory matrix W was such that in each iteration executes the following machine learning routine \n",
      "\n",
      "\n",
      "Unigrams: [('Selflearning',), ('as',), ('a',), ('machine',), ('learning',), ('paradigm',), ('was',), ('introduced',), ('in',), ('along',), ('with',), ('a',), ('neural',), ('network',), ('capable',), ('of',), ('selflearning',), ('named',), ('crossbar',), ('adaptive',), ('array',), ('CAA',), ('It',), ('gives',), ('a',), ('solution',), ('to',), ('the',), ('problem',), ('learning',), ('without',), ('any',), ('external',), ('reward',), ('by',), ('introducing',), ('emotion',), ('as',), ('an',), ('internal',), ('reward',), ('Emotion',), ('is',), ('used',), ('as',), ('state',), ('evaluation',), ('of',), ('a',), ('selflearning',), ('agent',), ('The',), ('CAA',), ('selflearning',), ('algorithm',), ('computes',), ('in',), ('a',), ('crossbar',), ('fashion',), ('both',), ('decisions',), ('about',), ('actions',), ('and',), ('emotions',), ('feelings',), ('about',), ('consequence',), ('situations',), ('The',), ('system',), ('is',), ('driven',), ('by',), ('the',), ('interaction',), ('between',), ('cognition',), ('and',), ('emotionThe',), ('selflearning',), ('algorithm',), ('updates',), ('a',), ('memory',), ('matrix',), ('W',), ('was',), ('such',), ('that',), ('in',), ('each',), ('iteration',), ('executes',), ('the',), ('following',), ('machine',), ('learning',), ('routine',)]\n",
      "\n",
      "Bigrams: [('Selflearning', 'as'), ('as', 'a'), ('a', 'machine'), ('machine', 'learning'), ('learning', 'paradigm'), ('paradigm', 'was'), ('was', 'introduced'), ('introduced', 'in'), ('in', 'along'), ('along', 'with'), ('with', 'a'), ('a', 'neural'), ('neural', 'network'), ('network', 'capable'), ('capable', 'of'), ('of', 'selflearning'), ('selflearning', 'named'), ('named', 'crossbar'), ('crossbar', 'adaptive'), ('adaptive', 'array'), ('array', 'CAA'), ('CAA', 'It'), ('It', 'gives'), ('gives', 'a'), ('a', 'solution'), ('solution', 'to'), ('to', 'the'), ('the', 'problem'), ('problem', 'learning'), ('learning', 'without'), ('without', 'any'), ('any', 'external'), ('external', 'reward'), ('reward', 'by'), ('by', 'introducing'), ('introducing', 'emotion'), ('emotion', 'as'), ('as', 'an'), ('an', 'internal'), ('internal', 'reward'), ('reward', 'Emotion'), ('Emotion', 'is'), ('is', 'used'), ('used', 'as'), ('as', 'state'), ('state', 'evaluation'), ('evaluation', 'of'), ('of', 'a'), ('a', 'selflearning'), ('selflearning', 'agent'), ('agent', 'The'), ('The', 'CAA'), ('CAA', 'selflearning'), ('selflearning', 'algorithm'), ('algorithm', 'computes'), ('computes', 'in'), ('in', 'a'), ('a', 'crossbar'), ('crossbar', 'fashion'), ('fashion', 'both'), ('both', 'decisions'), ('decisions', 'about'), ('about', 'actions'), ('actions', 'and'), ('and', 'emotions'), ('emotions', 'feelings'), ('feelings', 'about'), ('about', 'consequence'), ('consequence', 'situations'), ('situations', 'The'), ('The', 'system'), ('system', 'is'), ('is', 'driven'), ('driven', 'by'), ('by', 'the'), ('the', 'interaction'), ('interaction', 'between'), ('between', 'cognition'), ('cognition', 'and'), ('and', 'emotionThe'), ('emotionThe', 'selflearning'), ('selflearning', 'algorithm'), ('algorithm', 'updates'), ('updates', 'a'), ('a', 'memory'), ('memory', 'matrix'), ('matrix', 'W'), ('W', 'was'), ('was', 'such'), ('such', 'that'), ('that', 'in'), ('in', 'each'), ('each', 'iteration'), ('iteration', 'executes'), ('executes', 'the'), ('the', 'following'), ('following', 'machine'), ('machine', 'learning'), ('learning', 'routine')]\n",
      "\n",
      "Trigrams: [('Selflearning', 'as', 'a'), ('as', 'a', 'machine'), ('a', 'machine', 'learning'), ('machine', 'learning', 'paradigm'), ('learning', 'paradigm', 'was'), ('paradigm', 'was', 'introduced'), ('was', 'introduced', 'in'), ('introduced', 'in', 'along'), ('in', 'along', 'with'), ('along', 'with', 'a'), ('with', 'a', 'neural'), ('a', 'neural', 'network'), ('neural', 'network', 'capable'), ('network', 'capable', 'of'), ('capable', 'of', 'selflearning'), ('of', 'selflearning', 'named'), ('selflearning', 'named', 'crossbar'), ('named', 'crossbar', 'adaptive'), ('crossbar', 'adaptive', 'array'), ('adaptive', 'array', 'CAA'), ('array', 'CAA', 'It'), ('CAA', 'It', 'gives'), ('It', 'gives', 'a'), ('gives', 'a', 'solution'), ('a', 'solution', 'to'), ('solution', 'to', 'the'), ('to', 'the', 'problem'), ('the', 'problem', 'learning'), ('problem', 'learning', 'without'), ('learning', 'without', 'any'), ('without', 'any', 'external'), ('any', 'external', 'reward'), ('external', 'reward', 'by'), ('reward', 'by', 'introducing'), ('by', 'introducing', 'emotion'), ('introducing', 'emotion', 'as'), ('emotion', 'as', 'an'), ('as', 'an', 'internal'), ('an', 'internal', 'reward'), ('internal', 'reward', 'Emotion'), ('reward', 'Emotion', 'is'), ('Emotion', 'is', 'used'), ('is', 'used', 'as'), ('used', 'as', 'state'), ('as', 'state', 'evaluation'), ('state', 'evaluation', 'of'), ('evaluation', 'of', 'a'), ('of', 'a', 'selflearning'), ('a', 'selflearning', 'agent'), ('selflearning', 'agent', 'The'), ('agent', 'The', 'CAA'), ('The', 'CAA', 'selflearning'), ('CAA', 'selflearning', 'algorithm'), ('selflearning', 'algorithm', 'computes'), ('algorithm', 'computes', 'in'), ('computes', 'in', 'a'), ('in', 'a', 'crossbar'), ('a', 'crossbar', 'fashion'), ('crossbar', 'fashion', 'both'), ('fashion', 'both', 'decisions'), ('both', 'decisions', 'about'), ('decisions', 'about', 'actions'), ('about', 'actions', 'and'), ('actions', 'and', 'emotions'), ('and', 'emotions', 'feelings'), ('emotions', 'feelings', 'about'), ('feelings', 'about', 'consequence'), ('about', 'consequence', 'situations'), ('consequence', 'situations', 'The'), ('situations', 'The', 'system'), ('The', 'system', 'is'), ('system', 'is', 'driven'), ('is', 'driven', 'by'), ('driven', 'by', 'the'), ('by', 'the', 'interaction'), ('the', 'interaction', 'between'), ('interaction', 'between', 'cognition'), ('between', 'cognition', 'and'), ('cognition', 'and', 'emotionThe'), ('and', 'emotionThe', 'selflearning'), ('emotionThe', 'selflearning', 'algorithm'), ('selflearning', 'algorithm', 'updates'), ('algorithm', 'updates', 'a'), ('updates', 'a', 'memory'), ('a', 'memory', 'matrix'), ('memory', 'matrix', 'W'), ('matrix', 'W', 'was'), ('W', 'was', 'such'), ('was', 'such', 'that'), ('such', 'that', 'in'), ('that', 'in', 'each'), ('in', 'each', 'iteration'), ('each', 'iteration', 'executes'), ('iteration', 'executes', 'the'), ('executes', 'the', 'following'), ('the', 'following', 'machine'), ('following', 'machine', 'learning'), ('machine', 'learning', 'routine')]\n",
      "\n",
      "Document: It is a system with only one input situation and only one output action or behaviour a There is neither a separate reinforcement input nor an advice input from the environment The backpropagated value secondary reinforcement is the emotion toward the consequence situation The CAA exists in two environments one is the behavioural environment where it behaves and the other is the genetic environment wherefrom it initially and only once receives initial emotions about situations to be encountered in the behavioural environment After receiving the genome species vector from the genetic environment the CAA learns a goalseeking behaviour in an environment that contains both desirable and undesirable situations\n",
      "\n",
      "\n",
      "Unigrams: [('It',), ('is',), ('a',), ('system',), ('with',), ('only',), ('one',), ('input',), ('situation',), ('and',), ('only',), ('one',), ('output',), ('action',), ('or',), ('behaviour',), ('a',), ('There',), ('is',), ('neither',), ('a',), ('separate',), ('reinforcement',), ('input',), ('nor',), ('an',), ('advice',), ('input',), ('from',), ('the',), ('environment',), ('The',), ('backpropagated',), ('value',), ('secondary',), ('reinforcement',), ('is',), ('the',), ('emotion',), ('toward',), ('the',), ('consequence',), ('situation',), ('The',), ('CAA',), ('exists',), ('in',), ('two',), ('environments',), ('one',), ('is',), ('the',), ('behavioural',), ('environment',), ('where',), ('it',), ('behaves',), ('and',), ('the',), ('other',), ('is',), ('the',), ('genetic',), ('environment',), ('wherefrom',), ('it',), ('initially',), ('and',), ('only',), ('once',), ('receives',), ('initial',), ('emotions',), ('about',), ('situations',), ('to',), ('be',), ('encountered',), ('in',), ('the',), ('behavioural',), ('environment',), ('After',), ('receiving',), ('the',), ('genome',), ('species',), ('vector',), ('from',), ('the',), ('genetic',), ('environment',), ('the',), ('CAA',), ('learns',), ('a',), ('goalseeking',), ('behaviour',), ('in',), ('an',), ('environment',), ('that',), ('contains',), ('both',), ('desirable',), ('and',), ('undesirable',), ('situations',)]\n",
      "\n",
      "Bigrams: [('It', 'is'), ('is', 'a'), ('a', 'system'), ('system', 'with'), ('with', 'only'), ('only', 'one'), ('one', 'input'), ('input', 'situation'), ('situation', 'and'), ('and', 'only'), ('only', 'one'), ('one', 'output'), ('output', 'action'), ('action', 'or'), ('or', 'behaviour'), ('behaviour', 'a'), ('a', 'There'), ('There', 'is'), ('is', 'neither'), ('neither', 'a'), ('a', 'separate'), ('separate', 'reinforcement'), ('reinforcement', 'input'), ('input', 'nor'), ('nor', 'an'), ('an', 'advice'), ('advice', 'input'), ('input', 'from'), ('from', 'the'), ('the', 'environment'), ('environment', 'The'), ('The', 'backpropagated'), ('backpropagated', 'value'), ('value', 'secondary'), ('secondary', 'reinforcement'), ('reinforcement', 'is'), ('is', 'the'), ('the', 'emotion'), ('emotion', 'toward'), ('toward', 'the'), ('the', 'consequence'), ('consequence', 'situation'), ('situation', 'The'), ('The', 'CAA'), ('CAA', 'exists'), ('exists', 'in'), ('in', 'two'), ('two', 'environments'), ('environments', 'one'), ('one', 'is'), ('is', 'the'), ('the', 'behavioural'), ('behavioural', 'environment'), ('environment', 'where'), ('where', 'it'), ('it', 'behaves'), ('behaves', 'and'), ('and', 'the'), ('the', 'other'), ('other', 'is'), ('is', 'the'), ('the', 'genetic'), ('genetic', 'environment'), ('environment', 'wherefrom'), ('wherefrom', 'it'), ('it', 'initially'), ('initially', 'and'), ('and', 'only'), ('only', 'once'), ('once', 'receives'), ('receives', 'initial'), ('initial', 'emotions'), ('emotions', 'about'), ('about', 'situations'), ('situations', 'to'), ('to', 'be'), ('be', 'encountered'), ('encountered', 'in'), ('in', 'the'), ('the', 'behavioural'), ('behavioural', 'environment'), ('environment', 'After'), ('After', 'receiving'), ('receiving', 'the'), ('the', 'genome'), ('genome', 'species'), ('species', 'vector'), ('vector', 'from'), ('from', 'the'), ('the', 'genetic'), ('genetic', 'environment'), ('environment', 'the'), ('the', 'CAA'), ('CAA', 'learns'), ('learns', 'a'), ('a', 'goalseeking'), ('goalseeking', 'behaviour'), ('behaviour', 'in'), ('in', 'an'), ('an', 'environment'), ('environment', 'that'), ('that', 'contains'), ('contains', 'both'), ('both', 'desirable'), ('desirable', 'and'), ('and', 'undesirable'), ('undesirable', 'situations')]\n",
      "\n",
      "Trigrams: [('It', 'is', 'a'), ('is', 'a', 'system'), ('a', 'system', 'with'), ('system', 'with', 'only'), ('with', 'only', 'one'), ('only', 'one', 'input'), ('one', 'input', 'situation'), ('input', 'situation', 'and'), ('situation', 'and', 'only'), ('and', 'only', 'one'), ('only', 'one', 'output'), ('one', 'output', 'action'), ('output', 'action', 'or'), ('action', 'or', 'behaviour'), ('or', 'behaviour', 'a'), ('behaviour', 'a', 'There'), ('a', 'There', 'is'), ('There', 'is', 'neither'), ('is', 'neither', 'a'), ('neither', 'a', 'separate'), ('a', 'separate', 'reinforcement'), ('separate', 'reinforcement', 'input'), ('reinforcement', 'input', 'nor'), ('input', 'nor', 'an'), ('nor', 'an', 'advice'), ('an', 'advice', 'input'), ('advice', 'input', 'from'), ('input', 'from', 'the'), ('from', 'the', 'environment'), ('the', 'environment', 'The'), ('environment', 'The', 'backpropagated'), ('The', 'backpropagated', 'value'), ('backpropagated', 'value', 'secondary'), ('value', 'secondary', 'reinforcement'), ('secondary', 'reinforcement', 'is'), ('reinforcement', 'is', 'the'), ('is', 'the', 'emotion'), ('the', 'emotion', 'toward'), ('emotion', 'toward', 'the'), ('toward', 'the', 'consequence'), ('the', 'consequence', 'situation'), ('consequence', 'situation', 'The'), ('situation', 'The', 'CAA'), ('The', 'CAA', 'exists'), ('CAA', 'exists', 'in'), ('exists', 'in', 'two'), ('in', 'two', 'environments'), ('two', 'environments', 'one'), ('environments', 'one', 'is'), ('one', 'is', 'the'), ('is', 'the', 'behavioural'), ('the', 'behavioural', 'environment'), ('behavioural', 'environment', 'where'), ('environment', 'where', 'it'), ('where', 'it', 'behaves'), ('it', 'behaves', 'and'), ('behaves', 'and', 'the'), ('and', 'the', 'other'), ('the', 'other', 'is'), ('other', 'is', 'the'), ('is', 'the', 'genetic'), ('the', 'genetic', 'environment'), ('genetic', 'environment', 'wherefrom'), ('environment', 'wherefrom', 'it'), ('wherefrom', 'it', 'initially'), ('it', 'initially', 'and'), ('initially', 'and', 'only'), ('and', 'only', 'once'), ('only', 'once', 'receives'), ('once', 'receives', 'initial'), ('receives', 'initial', 'emotions'), ('initial', 'emotions', 'about'), ('emotions', 'about', 'situations'), ('about', 'situations', 'to'), ('situations', 'to', 'be'), ('to', 'be', 'encountered'), ('be', 'encountered', 'in'), ('encountered', 'in', 'the'), ('in', 'the', 'behavioural'), ('the', 'behavioural', 'environment'), ('behavioural', 'environment', 'After'), ('environment', 'After', 'receiving'), ('After', 'receiving', 'the'), ('receiving', 'the', 'genome'), ('the', 'genome', 'species'), ('genome', 'species', 'vector'), ('species', 'vector', 'from'), ('vector', 'from', 'the'), ('from', 'the', 'genetic'), ('the', 'genetic', 'environment'), ('genetic', 'environment', 'the'), ('environment', 'the', 'CAA'), ('the', 'CAA', 'learns'), ('CAA', 'learns', 'a'), ('learns', 'a', 'goalseeking'), ('a', 'goalseeking', 'behaviour'), ('goalseeking', 'behaviour', 'in'), ('behaviour', 'in', 'an'), ('in', 'an', 'environment'), ('an', 'environment', 'that'), ('environment', 'that', 'contains'), ('that', 'contains', 'both'), ('contains', 'both', 'desirable'), ('both', 'desirable', 'and'), ('desirable', 'and', 'undesirable'), ('and', 'undesirable', 'situations')]\n",
      "\n",
      "Document: Several learning algorithms aim at discovering better representations of the inputs provided during training Classic examples include principal component analysis and cluster analysis Feature learning algorithms also called representation learning algorithms often attempt to preserve the information in their input but also transform it in a way that makes it useful often as a preprocessing step before performing classification or predictions This technique allows reconstruction of the inputs coming from the unknown datagenerating distribution while not being necessarily faithful to configurations that are implausible under that distribution This replaces manual feature engineering and allows a machine to both learn the features and use them to perform a specific task\n",
      "\n",
      "\n",
      "Unigrams: [('Several',), ('learning',), ('algorithms',), ('aim',), ('at',), ('discovering',), ('better',), ('representations',), ('of',), ('the',), ('inputs',), ('provided',), ('during',), ('training',), ('Classic',), ('examples',), ('include',), ('principal',), ('component',), ('analysis',), ('and',), ('cluster',), ('analysis',), ('Feature',), ('learning',), ('algorithms',), ('also',), ('called',), ('representation',), ('learning',), ('algorithms',), ('often',), ('attempt',), ('to',), ('preserve',), ('the',), ('information',), ('in',), ('their',), ('input',), ('but',), ('also',), ('transform',), ('it',), ('in',), ('a',), ('way',), ('that',), ('makes',), ('it',), ('useful',), ('often',), ('as',), ('a',), ('preprocessing',), ('step',), ('before',), ('performing',), ('classification',), ('or',), ('predictions',), ('This',), ('technique',), ('allows',), ('reconstruction',), ('of',), ('the',), ('inputs',), ('coming',), ('from',), ('the',), ('unknown',), ('datagenerating',), ('distribution',), ('while',), ('not',), ('being',), ('necessarily',), ('faithful',), ('to',), ('configurations',), ('that',), ('are',), ('implausible',), ('under',), ('that',), ('distribution',), ('This',), ('replaces',), ('manual',), ('feature',), ('engineering',), ('and',), ('allows',), ('a',), ('machine',), ('to',), ('both',), ('learn',), ('the',), ('features',), ('and',), ('use',), ('them',), ('to',), ('perform',), ('a',), ('specific',), ('task',)]\n",
      "\n",
      "Bigrams: [('Several', 'learning'), ('learning', 'algorithms'), ('algorithms', 'aim'), ('aim', 'at'), ('at', 'discovering'), ('discovering', 'better'), ('better', 'representations'), ('representations', 'of'), ('of', 'the'), ('the', 'inputs'), ('inputs', 'provided'), ('provided', 'during'), ('during', 'training'), ('training', 'Classic'), ('Classic', 'examples'), ('examples', 'include'), ('include', 'principal'), ('principal', 'component'), ('component', 'analysis'), ('analysis', 'and'), ('and', 'cluster'), ('cluster', 'analysis'), ('analysis', 'Feature'), ('Feature', 'learning'), ('learning', 'algorithms'), ('algorithms', 'also'), ('also', 'called'), ('called', 'representation'), ('representation', 'learning'), ('learning', 'algorithms'), ('algorithms', 'often'), ('often', 'attempt'), ('attempt', 'to'), ('to', 'preserve'), ('preserve', 'the'), ('the', 'information'), ('information', 'in'), ('in', 'their'), ('their', 'input'), ('input', 'but'), ('but', 'also'), ('also', 'transform'), ('transform', 'it'), ('it', 'in'), ('in', 'a'), ('a', 'way'), ('way', 'that'), ('that', 'makes'), ('makes', 'it'), ('it', 'useful'), ('useful', 'often'), ('often', 'as'), ('as', 'a'), ('a', 'preprocessing'), ('preprocessing', 'step'), ('step', 'before'), ('before', 'performing'), ('performing', 'classification'), ('classification', 'or'), ('or', 'predictions'), ('predictions', 'This'), ('This', 'technique'), ('technique', 'allows'), ('allows', 'reconstruction'), ('reconstruction', 'of'), ('of', 'the'), ('the', 'inputs'), ('inputs', 'coming'), ('coming', 'from'), ('from', 'the'), ('the', 'unknown'), ('unknown', 'datagenerating'), ('datagenerating', 'distribution'), ('distribution', 'while'), ('while', 'not'), ('not', 'being'), ('being', 'necessarily'), ('necessarily', 'faithful'), ('faithful', 'to'), ('to', 'configurations'), ('configurations', 'that'), ('that', 'are'), ('are', 'implausible'), ('implausible', 'under'), ('under', 'that'), ('that', 'distribution'), ('distribution', 'This'), ('This', 'replaces'), ('replaces', 'manual'), ('manual', 'feature'), ('feature', 'engineering'), ('engineering', 'and'), ('and', 'allows'), ('allows', 'a'), ('a', 'machine'), ('machine', 'to'), ('to', 'both'), ('both', 'learn'), ('learn', 'the'), ('the', 'features'), ('features', 'and'), ('and', 'use'), ('use', 'them'), ('them', 'to'), ('to', 'perform'), ('perform', 'a'), ('a', 'specific'), ('specific', 'task')]\n",
      "\n",
      "Trigrams: [('Several', 'learning', 'algorithms'), ('learning', 'algorithms', 'aim'), ('algorithms', 'aim', 'at'), ('aim', 'at', 'discovering'), ('at', 'discovering', 'better'), ('discovering', 'better', 'representations'), ('better', 'representations', 'of'), ('representations', 'of', 'the'), ('of', 'the', 'inputs'), ('the', 'inputs', 'provided'), ('inputs', 'provided', 'during'), ('provided', 'during', 'training'), ('during', 'training', 'Classic'), ('training', 'Classic', 'examples'), ('Classic', 'examples', 'include'), ('examples', 'include', 'principal'), ('include', 'principal', 'component'), ('principal', 'component', 'analysis'), ('component', 'analysis', 'and'), ('analysis', 'and', 'cluster'), ('and', 'cluster', 'analysis'), ('cluster', 'analysis', 'Feature'), ('analysis', 'Feature', 'learning'), ('Feature', 'learning', 'algorithms'), ('learning', 'algorithms', 'also'), ('algorithms', 'also', 'called'), ('also', 'called', 'representation'), ('called', 'representation', 'learning'), ('representation', 'learning', 'algorithms'), ('learning', 'algorithms', 'often'), ('algorithms', 'often', 'attempt'), ('often', 'attempt', 'to'), ('attempt', 'to', 'preserve'), ('to', 'preserve', 'the'), ('preserve', 'the', 'information'), ('the', 'information', 'in'), ('information', 'in', 'their'), ('in', 'their', 'input'), ('their', 'input', 'but'), ('input', 'but', 'also'), ('but', 'also', 'transform'), ('also', 'transform', 'it'), ('transform', 'it', 'in'), ('it', 'in', 'a'), ('in', 'a', 'way'), ('a', 'way', 'that'), ('way', 'that', 'makes'), ('that', 'makes', 'it'), ('makes', 'it', 'useful'), ('it', 'useful', 'often'), ('useful', 'often', 'as'), ('often', 'as', 'a'), ('as', 'a', 'preprocessing'), ('a', 'preprocessing', 'step'), ('preprocessing', 'step', 'before'), ('step', 'before', 'performing'), ('before', 'performing', 'classification'), ('performing', 'classification', 'or'), ('classification', 'or', 'predictions'), ('or', 'predictions', 'This'), ('predictions', 'This', 'technique'), ('This', 'technique', 'allows'), ('technique', 'allows', 'reconstruction'), ('allows', 'reconstruction', 'of'), ('reconstruction', 'of', 'the'), ('of', 'the', 'inputs'), ('the', 'inputs', 'coming'), ('inputs', 'coming', 'from'), ('coming', 'from', 'the'), ('from', 'the', 'unknown'), ('the', 'unknown', 'datagenerating'), ('unknown', 'datagenerating', 'distribution'), ('datagenerating', 'distribution', 'while'), ('distribution', 'while', 'not'), ('while', 'not', 'being'), ('not', 'being', 'necessarily'), ('being', 'necessarily', 'faithful'), ('necessarily', 'faithful', 'to'), ('faithful', 'to', 'configurations'), ('to', 'configurations', 'that'), ('configurations', 'that', 'are'), ('that', 'are', 'implausible'), ('are', 'implausible', 'under'), ('implausible', 'under', 'that'), ('under', 'that', 'distribution'), ('that', 'distribution', 'This'), ('distribution', 'This', 'replaces'), ('This', 'replaces', 'manual'), ('replaces', 'manual', 'feature'), ('manual', 'feature', 'engineering'), ('feature', 'engineering', 'and'), ('engineering', 'and', 'allows'), ('and', 'allows', 'a'), ('allows', 'a', 'machine'), ('a', 'machine', 'to'), ('machine', 'to', 'both'), ('to', 'both', 'learn'), ('both', 'learn', 'the'), ('learn', 'the', 'features'), ('the', 'features', 'and'), ('features', 'and', 'use'), ('and', 'use', 'them'), ('use', 'them', 'to'), ('them', 'to', 'perform'), ('to', 'perform', 'a'), ('perform', 'a', 'specific'), ('a', 'specific', 'task')]\n",
      "\n",
      "Document: Feature learning can be either supervised or unsupervised In supervised feature learning features are learned using labelled input data Examples include artificial neural networks multilayer perceptrons and supervised dictionary learning In unsupervised feature learning features are learned with unlabelled input data  Examples include dictionary learning independent component analysis autoencoders matrix factorisation and various forms of clustering\n",
      "\n",
      "\n",
      "Unigrams: [('Feature',), ('learning',), ('can',), ('be',), ('either',), ('supervised',), ('or',), ('unsupervised',), ('In',), ('supervised',), ('feature',), ('learning',), ('features',), ('are',), ('learned',), ('using',), ('labelled',), ('input',), ('data',), ('Examples',), ('include',), ('artificial',), ('neural',), ('networks',), ('multilayer',), ('perceptrons',), ('and',), ('supervised',), ('dictionary',), ('learning',), ('In',), ('unsupervised',), ('feature',), ('learning',), ('features',), ('are',), ('learned',), ('with',), ('unlabelled',), ('input',), ('data',), ('Examples',), ('include',), ('dictionary',), ('learning',), ('independent',), ('component',), ('analysis',), ('autoencoders',), ('matrix',), ('factorisation',), ('and',), ('various',), ('forms',), ('of',), ('clustering',)]\n",
      "\n",
      "Bigrams: [('Feature', 'learning'), ('learning', 'can'), ('can', 'be'), ('be', 'either'), ('either', 'supervised'), ('supervised', 'or'), ('or', 'unsupervised'), ('unsupervised', 'In'), ('In', 'supervised'), ('supervised', 'feature'), ('feature', 'learning'), ('learning', 'features'), ('features', 'are'), ('are', 'learned'), ('learned', 'using'), ('using', 'labelled'), ('labelled', 'input'), ('input', 'data'), ('data', 'Examples'), ('Examples', 'include'), ('include', 'artificial'), ('artificial', 'neural'), ('neural', 'networks'), ('networks', 'multilayer'), ('multilayer', 'perceptrons'), ('perceptrons', 'and'), ('and', 'supervised'), ('supervised', 'dictionary'), ('dictionary', 'learning'), ('learning', 'In'), ('In', 'unsupervised'), ('unsupervised', 'feature'), ('feature', 'learning'), ('learning', 'features'), ('features', 'are'), ('are', 'learned'), ('learned', 'with'), ('with', 'unlabelled'), ('unlabelled', 'input'), ('input', 'data'), ('data', 'Examples'), ('Examples', 'include'), ('include', 'dictionary'), ('dictionary', 'learning'), ('learning', 'independent'), ('independent', 'component'), ('component', 'analysis'), ('analysis', 'autoencoders'), ('autoencoders', 'matrix'), ('matrix', 'factorisation'), ('factorisation', 'and'), ('and', 'various'), ('various', 'forms'), ('forms', 'of'), ('of', 'clustering')]\n",
      "\n",
      "Trigrams: [('Feature', 'learning', 'can'), ('learning', 'can', 'be'), ('can', 'be', 'either'), ('be', 'either', 'supervised'), ('either', 'supervised', 'or'), ('supervised', 'or', 'unsupervised'), ('or', 'unsupervised', 'In'), ('unsupervised', 'In', 'supervised'), ('In', 'supervised', 'feature'), ('supervised', 'feature', 'learning'), ('feature', 'learning', 'features'), ('learning', 'features', 'are'), ('features', 'are', 'learned'), ('are', 'learned', 'using'), ('learned', 'using', 'labelled'), ('using', 'labelled', 'input'), ('labelled', 'input', 'data'), ('input', 'data', 'Examples'), ('data', 'Examples', 'include'), ('Examples', 'include', 'artificial'), ('include', 'artificial', 'neural'), ('artificial', 'neural', 'networks'), ('neural', 'networks', 'multilayer'), ('networks', 'multilayer', 'perceptrons'), ('multilayer', 'perceptrons', 'and'), ('perceptrons', 'and', 'supervised'), ('and', 'supervised', 'dictionary'), ('supervised', 'dictionary', 'learning'), ('dictionary', 'learning', 'In'), ('learning', 'In', 'unsupervised'), ('In', 'unsupervised', 'feature'), ('unsupervised', 'feature', 'learning'), ('feature', 'learning', 'features'), ('learning', 'features', 'are'), ('features', 'are', 'learned'), ('are', 'learned', 'with'), ('learned', 'with', 'unlabelled'), ('with', 'unlabelled', 'input'), ('unlabelled', 'input', 'data'), ('input', 'data', 'Examples'), ('data', 'Examples', 'include'), ('Examples', 'include', 'dictionary'), ('include', 'dictionary', 'learning'), ('dictionary', 'learning', 'independent'), ('learning', 'independent', 'component'), ('independent', 'component', 'analysis'), ('component', 'analysis', 'autoencoders'), ('analysis', 'autoencoders', 'matrix'), ('autoencoders', 'matrix', 'factorisation'), ('matrix', 'factorisation', 'and'), ('factorisation', 'and', 'various'), ('and', 'various', 'forms'), ('various', 'forms', 'of'), ('forms', 'of', 'clustering')]\n",
      "\n",
      "Document: Manifold learning algorithms attempt to do so under the constraint that the learned representation is lowdimensional Sparse coding algorithms attempt to do so under the constraint that the learned representation is sparse meaning that the mathematical model has many zeros Multilinear subspace learning algorithms aim to learn lowdimensional representations directly from tensor representations for multidimensional data without reshaping them into higherdimensional vectors Deep learning algorithms discover multiple levels of representation or a hierarchy of features with higherlevel more abstract features defined in terms of or generating lowerlevel features It has been argued that an intelligent machine is one that learns a representation that disentangles the underlying factors of variation that explain the observed data\n",
      "\n",
      "\n",
      "Unigrams: [('Manifold',), ('learning',), ('algorithms',), ('attempt',), ('to',), ('do',), ('so',), ('under',), ('the',), ('constraint',), ('that',), ('the',), ('learned',), ('representation',), ('is',), ('lowdimensional',), ('Sparse',), ('coding',), ('algorithms',), ('attempt',), ('to',), ('do',), ('so',), ('under',), ('the',), ('constraint',), ('that',), ('the',), ('learned',), ('representation',), ('is',), ('sparse',), ('meaning',), ('that',), ('the',), ('mathematical',), ('model',), ('has',), ('many',), ('zeros',), ('Multilinear',), ('subspace',), ('learning',), ('algorithms',), ('aim',), ('to',), ('learn',), ('lowdimensional',), ('representations',), ('directly',), ('from',), ('tensor',), ('representations',), ('for',), ('multidimensional',), ('data',), ('without',), ('reshaping',), ('them',), ('into',), ('higherdimensional',), ('vectors',), ('Deep',), ('learning',), ('algorithms',), ('discover',), ('multiple',), ('levels',), ('of',), ('representation',), ('or',), ('a',), ('hierarchy',), ('of',), ('features',), ('with',), ('higherlevel',), ('more',), ('abstract',), ('features',), ('defined',), ('in',), ('terms',), ('of',), ('or',), ('generating',), ('lowerlevel',), ('features',), ('It',), ('has',), ('been',), ('argued',), ('that',), ('an',), ('intelligent',), ('machine',), ('is',), ('one',), ('that',), ('learns',), ('a',), ('representation',), ('that',), ('disentangles',), ('the',), ('underlying',), ('factors',), ('of',), ('variation',), ('that',), ('explain',), ('the',), ('observed',), ('data',)]\n",
      "\n",
      "Bigrams: [('Manifold', 'learning'), ('learning', 'algorithms'), ('algorithms', 'attempt'), ('attempt', 'to'), ('to', 'do'), ('do', 'so'), ('so', 'under'), ('under', 'the'), ('the', 'constraint'), ('constraint', 'that'), ('that', 'the'), ('the', 'learned'), ('learned', 'representation'), ('representation', 'is'), ('is', 'lowdimensional'), ('lowdimensional', 'Sparse'), ('Sparse', 'coding'), ('coding', 'algorithms'), ('algorithms', 'attempt'), ('attempt', 'to'), ('to', 'do'), ('do', 'so'), ('so', 'under'), ('under', 'the'), ('the', 'constraint'), ('constraint', 'that'), ('that', 'the'), ('the', 'learned'), ('learned', 'representation'), ('representation', 'is'), ('is', 'sparse'), ('sparse', 'meaning'), ('meaning', 'that'), ('that', 'the'), ('the', 'mathematical'), ('mathematical', 'model'), ('model', 'has'), ('has', 'many'), ('many', 'zeros'), ('zeros', 'Multilinear'), ('Multilinear', 'subspace'), ('subspace', 'learning'), ('learning', 'algorithms'), ('algorithms', 'aim'), ('aim', 'to'), ('to', 'learn'), ('learn', 'lowdimensional'), ('lowdimensional', 'representations'), ('representations', 'directly'), ('directly', 'from'), ('from', 'tensor'), ('tensor', 'representations'), ('representations', 'for'), ('for', 'multidimensional'), ('multidimensional', 'data'), ('data', 'without'), ('without', 'reshaping'), ('reshaping', 'them'), ('them', 'into'), ('into', 'higherdimensional'), ('higherdimensional', 'vectors'), ('vectors', 'Deep'), ('Deep', 'learning'), ('learning', 'algorithms'), ('algorithms', 'discover'), ('discover', 'multiple'), ('multiple', 'levels'), ('levels', 'of'), ('of', 'representation'), ('representation', 'or'), ('or', 'a'), ('a', 'hierarchy'), ('hierarchy', 'of'), ('of', 'features'), ('features', 'with'), ('with', 'higherlevel'), ('higherlevel', 'more'), ('more', 'abstract'), ('abstract', 'features'), ('features', 'defined'), ('defined', 'in'), ('in', 'terms'), ('terms', 'of'), ('of', 'or'), ('or', 'generating'), ('generating', 'lowerlevel'), ('lowerlevel', 'features'), ('features', 'It'), ('It', 'has'), ('has', 'been'), ('been', 'argued'), ('argued', 'that'), ('that', 'an'), ('an', 'intelligent'), ('intelligent', 'machine'), ('machine', 'is'), ('is', 'one'), ('one', 'that'), ('that', 'learns'), ('learns', 'a'), ('a', 'representation'), ('representation', 'that'), ('that', 'disentangles'), ('disentangles', 'the'), ('the', 'underlying'), ('underlying', 'factors'), ('factors', 'of'), ('of', 'variation'), ('variation', 'that'), ('that', 'explain'), ('explain', 'the'), ('the', 'observed'), ('observed', 'data')]\n",
      "\n",
      "Trigrams: [('Manifold', 'learning', 'algorithms'), ('learning', 'algorithms', 'attempt'), ('algorithms', 'attempt', 'to'), ('attempt', 'to', 'do'), ('to', 'do', 'so'), ('do', 'so', 'under'), ('so', 'under', 'the'), ('under', 'the', 'constraint'), ('the', 'constraint', 'that'), ('constraint', 'that', 'the'), ('that', 'the', 'learned'), ('the', 'learned', 'representation'), ('learned', 'representation', 'is'), ('representation', 'is', 'lowdimensional'), ('is', 'lowdimensional', 'Sparse'), ('lowdimensional', 'Sparse', 'coding'), ('Sparse', 'coding', 'algorithms'), ('coding', 'algorithms', 'attempt'), ('algorithms', 'attempt', 'to'), ('attempt', 'to', 'do'), ('to', 'do', 'so'), ('do', 'so', 'under'), ('so', 'under', 'the'), ('under', 'the', 'constraint'), ('the', 'constraint', 'that'), ('constraint', 'that', 'the'), ('that', 'the', 'learned'), ('the', 'learned', 'representation'), ('learned', 'representation', 'is'), ('representation', 'is', 'sparse'), ('is', 'sparse', 'meaning'), ('sparse', 'meaning', 'that'), ('meaning', 'that', 'the'), ('that', 'the', 'mathematical'), ('the', 'mathematical', 'model'), ('mathematical', 'model', 'has'), ('model', 'has', 'many'), ('has', 'many', 'zeros'), ('many', 'zeros', 'Multilinear'), ('zeros', 'Multilinear', 'subspace'), ('Multilinear', 'subspace', 'learning'), ('subspace', 'learning', 'algorithms'), ('learning', 'algorithms', 'aim'), ('algorithms', 'aim', 'to'), ('aim', 'to', 'learn'), ('to', 'learn', 'lowdimensional'), ('learn', 'lowdimensional', 'representations'), ('lowdimensional', 'representations', 'directly'), ('representations', 'directly', 'from'), ('directly', 'from', 'tensor'), ('from', 'tensor', 'representations'), ('tensor', 'representations', 'for'), ('representations', 'for', 'multidimensional'), ('for', 'multidimensional', 'data'), ('multidimensional', 'data', 'without'), ('data', 'without', 'reshaping'), ('without', 'reshaping', 'them'), ('reshaping', 'them', 'into'), ('them', 'into', 'higherdimensional'), ('into', 'higherdimensional', 'vectors'), ('higherdimensional', 'vectors', 'Deep'), ('vectors', 'Deep', 'learning'), ('Deep', 'learning', 'algorithms'), ('learning', 'algorithms', 'discover'), ('algorithms', 'discover', 'multiple'), ('discover', 'multiple', 'levels'), ('multiple', 'levels', 'of'), ('levels', 'of', 'representation'), ('of', 'representation', 'or'), ('representation', 'or', 'a'), ('or', 'a', 'hierarchy'), ('a', 'hierarchy', 'of'), ('hierarchy', 'of', 'features'), ('of', 'features', 'with'), ('features', 'with', 'higherlevel'), ('with', 'higherlevel', 'more'), ('higherlevel', 'more', 'abstract'), ('more', 'abstract', 'features'), ('abstract', 'features', 'defined'), ('features', 'defined', 'in'), ('defined', 'in', 'terms'), ('in', 'terms', 'of'), ('terms', 'of', 'or'), ('of', 'or', 'generating'), ('or', 'generating', 'lowerlevel'), ('generating', 'lowerlevel', 'features'), ('lowerlevel', 'features', 'It'), ('features', 'It', 'has'), ('It', 'has', 'been'), ('has', 'been', 'argued'), ('been', 'argued', 'that'), ('argued', 'that', 'an'), ('that', 'an', 'intelligent'), ('an', 'intelligent', 'machine'), ('intelligent', 'machine', 'is'), ('machine', 'is', 'one'), ('is', 'one', 'that'), ('one', 'that', 'learns'), ('that', 'learns', 'a'), ('learns', 'a', 'representation'), ('a', 'representation', 'that'), ('representation', 'that', 'disentangles'), ('that', 'disentangles', 'the'), ('disentangles', 'the', 'underlying'), ('the', 'underlying', 'factors'), ('underlying', 'factors', 'of'), ('factors', 'of', 'variation'), ('of', 'variation', 'that'), ('variation', 'that', 'explain'), ('that', 'explain', 'the'), ('explain', 'the', 'observed'), ('the', 'observed', 'data')]\n",
      "\n",
      "Document: Feature learning is motivated by the fact that machine learning tasks such as classification often require input that is mathematically and computationally convenient to process However realworld data such as images video and sensory data has not yielded attempts to algorithmically define specific features An alternative is to discover such features or representations through examination without relying on explicit algorithms\n",
      "\n",
      "\n",
      "Unigrams: [('Feature',), ('learning',), ('is',), ('motivated',), ('by',), ('the',), ('fact',), ('that',), ('machine',), ('learning',), ('tasks',), ('such',), ('as',), ('classification',), ('often',), ('require',), ('input',), ('that',), ('is',), ('mathematically',), ('and',), ('computationally',), ('convenient',), ('to',), ('process',), ('However',), ('realworld',), ('data',), ('such',), ('as',), ('images',), ('video',), ('and',), ('sensory',), ('data',), ('has',), ('not',), ('yielded',), ('attempts',), ('to',), ('algorithmically',), ('define',), ('specific',), ('features',), ('An',), ('alternative',), ('is',), ('to',), ('discover',), ('such',), ('features',), ('or',), ('representations',), ('through',), ('examination',), ('without',), ('relying',), ('on',), ('explicit',), ('algorithms',)]\n",
      "\n",
      "Bigrams: [('Feature', 'learning'), ('learning', 'is'), ('is', 'motivated'), ('motivated', 'by'), ('by', 'the'), ('the', 'fact'), ('fact', 'that'), ('that', 'machine'), ('machine', 'learning'), ('learning', 'tasks'), ('tasks', 'such'), ('such', 'as'), ('as', 'classification'), ('classification', 'often'), ('often', 'require'), ('require', 'input'), ('input', 'that'), ('that', 'is'), ('is', 'mathematically'), ('mathematically', 'and'), ('and', 'computationally'), ('computationally', 'convenient'), ('convenient', 'to'), ('to', 'process'), ('process', 'However'), ('However', 'realworld'), ('realworld', 'data'), ('data', 'such'), ('such', 'as'), ('as', 'images'), ('images', 'video'), ('video', 'and'), ('and', 'sensory'), ('sensory', 'data'), ('data', 'has'), ('has', 'not'), ('not', 'yielded'), ('yielded', 'attempts'), ('attempts', 'to'), ('to', 'algorithmically'), ('algorithmically', 'define'), ('define', 'specific'), ('specific', 'features'), ('features', 'An'), ('An', 'alternative'), ('alternative', 'is'), ('is', 'to'), ('to', 'discover'), ('discover', 'such'), ('such', 'features'), ('features', 'or'), ('or', 'representations'), ('representations', 'through'), ('through', 'examination'), ('examination', 'without'), ('without', 'relying'), ('relying', 'on'), ('on', 'explicit'), ('explicit', 'algorithms')]\n",
      "\n",
      "Trigrams: [('Feature', 'learning', 'is'), ('learning', 'is', 'motivated'), ('is', 'motivated', 'by'), ('motivated', 'by', 'the'), ('by', 'the', 'fact'), ('the', 'fact', 'that'), ('fact', 'that', 'machine'), ('that', 'machine', 'learning'), ('machine', 'learning', 'tasks'), ('learning', 'tasks', 'such'), ('tasks', 'such', 'as'), ('such', 'as', 'classification'), ('as', 'classification', 'often'), ('classification', 'often', 'require'), ('often', 'require', 'input'), ('require', 'input', 'that'), ('input', 'that', 'is'), ('that', 'is', 'mathematically'), ('is', 'mathematically', 'and'), ('mathematically', 'and', 'computationally'), ('and', 'computationally', 'convenient'), ('computationally', 'convenient', 'to'), ('convenient', 'to', 'process'), ('to', 'process', 'However'), ('process', 'However', 'realworld'), ('However', 'realworld', 'data'), ('realworld', 'data', 'such'), ('data', 'such', 'as'), ('such', 'as', 'images'), ('as', 'images', 'video'), ('images', 'video', 'and'), ('video', 'and', 'sensory'), ('and', 'sensory', 'data'), ('sensory', 'data', 'has'), ('data', 'has', 'not'), ('has', 'not', 'yielded'), ('not', 'yielded', 'attempts'), ('yielded', 'attempts', 'to'), ('attempts', 'to', 'algorithmically'), ('to', 'algorithmically', 'define'), ('algorithmically', 'define', 'specific'), ('define', 'specific', 'features'), ('specific', 'features', 'An'), ('features', 'An', 'alternative'), ('An', 'alternative', 'is'), ('alternative', 'is', 'to'), ('is', 'to', 'discover'), ('to', 'discover', 'such'), ('discover', 'such', 'features'), ('such', 'features', 'or'), ('features', 'or', 'representations'), ('or', 'representations', 'through'), ('representations', 'through', 'examination'), ('through', 'examination', 'without'), ('examination', 'without', 'relying'), ('without', 'relying', 'on'), ('relying', 'on', 'explicit'), ('on', 'explicit', 'algorithms')]\n",
      "\n",
      "Document: Sparse dictionary learning is a feature learning method where a training example is represented as a linear combination of basis functions and assumed to be a sparse matrix The method is strongly NPhard and difficult to solve approximately A popular heuristic method for sparse dictionary learning is the kSVD algorithm Sparse dictionary learning has been applied in several contexts In classification the problem is to determine the class to which a previously unseen training example belongs For a dictionary where each class has already been built a new training example is associated with the class that is best sparsely represented by the corresponding dictionary Sparse dictionary learning has also been applied in image denoising The key idea is that a clean image patch can be sparsely represented by an image dictionary but the noise cannot\n",
      "\n",
      "\n",
      "Unigrams: [('Sparse',), ('dictionary',), ('learning',), ('is',), ('a',), ('feature',), ('learning',), ('method',), ('where',), ('a',), ('training',), ('example',), ('is',), ('represented',), ('as',), ('a',), ('linear',), ('combination',), ('of',), ('basis',), ('functions',), ('and',), ('assumed',), ('to',), ('be',), ('a',), ('sparse',), ('matrix',), ('The',), ('method',), ('is',), ('strongly',), ('NPhard',), ('and',), ('difficult',), ('to',), ('solve',), ('approximately',), ('A',), ('popular',), ('heuristic',), ('method',), ('for',), ('sparse',), ('dictionary',), ('learning',), ('is',), ('the',), ('kSVD',), ('algorithm',), ('Sparse',), ('dictionary',), ('learning',), ('has',), ('been',), ('applied',), ('in',), ('several',), ('contexts',), ('In',), ('classification',), ('the',), ('problem',), ('is',), ('to',), ('determine',), ('the',), ('class',), ('to',), ('which',), ('a',), ('previously',), ('unseen',), ('training',), ('example',), ('belongs',), ('For',), ('a',), ('dictionary',), ('where',), ('each',), ('class',), ('has',), ('already',), ('been',), ('built',), ('a',), ('new',), ('training',), ('example',), ('is',), ('associated',), ('with',), ('the',), ('class',), ('that',), ('is',), ('best',), ('sparsely',), ('represented',), ('by',), ('the',), ('corresponding',), ('dictionary',), ('Sparse',), ('dictionary',), ('learning',), ('has',), ('also',), ('been',), ('applied',), ('in',), ('image',), ('denoising',), ('The',), ('key',), ('idea',), ('is',), ('that',), ('a',), ('clean',), ('image',), ('patch',), ('can',), ('be',), ('sparsely',), ('represented',), ('by',), ('an',), ('image',), ('dictionary',), ('but',), ('the',), ('noise',), ('cannot',)]\n",
      "\n",
      "Bigrams: [('Sparse', 'dictionary'), ('dictionary', 'learning'), ('learning', 'is'), ('is', 'a'), ('a', 'feature'), ('feature', 'learning'), ('learning', 'method'), ('method', 'where'), ('where', 'a'), ('a', 'training'), ('training', 'example'), ('example', 'is'), ('is', 'represented'), ('represented', 'as'), ('as', 'a'), ('a', 'linear'), ('linear', 'combination'), ('combination', 'of'), ('of', 'basis'), ('basis', 'functions'), ('functions', 'and'), ('and', 'assumed'), ('assumed', 'to'), ('to', 'be'), ('be', 'a'), ('a', 'sparse'), ('sparse', 'matrix'), ('matrix', 'The'), ('The', 'method'), ('method', 'is'), ('is', 'strongly'), ('strongly', 'NPhard'), ('NPhard', 'and'), ('and', 'difficult'), ('difficult', 'to'), ('to', 'solve'), ('solve', 'approximately'), ('approximately', 'A'), ('A', 'popular'), ('popular', 'heuristic'), ('heuristic', 'method'), ('method', 'for'), ('for', 'sparse'), ('sparse', 'dictionary'), ('dictionary', 'learning'), ('learning', 'is'), ('is', 'the'), ('the', 'kSVD'), ('kSVD', 'algorithm'), ('algorithm', 'Sparse'), ('Sparse', 'dictionary'), ('dictionary', 'learning'), ('learning', 'has'), ('has', 'been'), ('been', 'applied'), ('applied', 'in'), ('in', 'several'), ('several', 'contexts'), ('contexts', 'In'), ('In', 'classification'), ('classification', 'the'), ('the', 'problem'), ('problem', 'is'), ('is', 'to'), ('to', 'determine'), ('determine', 'the'), ('the', 'class'), ('class', 'to'), ('to', 'which'), ('which', 'a'), ('a', 'previously'), ('previously', 'unseen'), ('unseen', 'training'), ('training', 'example'), ('example', 'belongs'), ('belongs', 'For'), ('For', 'a'), ('a', 'dictionary'), ('dictionary', 'where'), ('where', 'each'), ('each', 'class'), ('class', 'has'), ('has', 'already'), ('already', 'been'), ('been', 'built'), ('built', 'a'), ('a', 'new'), ('new', 'training'), ('training', 'example'), ('example', 'is'), ('is', 'associated'), ('associated', 'with'), ('with', 'the'), ('the', 'class'), ('class', 'that'), ('that', 'is'), ('is', 'best'), ('best', 'sparsely'), ('sparsely', 'represented'), ('represented', 'by'), ('by', 'the'), ('the', 'corresponding'), ('corresponding', 'dictionary'), ('dictionary', 'Sparse'), ('Sparse', 'dictionary'), ('dictionary', 'learning'), ('learning', 'has'), ('has', 'also'), ('also', 'been'), ('been', 'applied'), ('applied', 'in'), ('in', 'image'), ('image', 'denoising'), ('denoising', 'The'), ('The', 'key'), ('key', 'idea'), ('idea', 'is'), ('is', 'that'), ('that', 'a'), ('a', 'clean'), ('clean', 'image'), ('image', 'patch'), ('patch', 'can'), ('can', 'be'), ('be', 'sparsely'), ('sparsely', 'represented'), ('represented', 'by'), ('by', 'an'), ('an', 'image'), ('image', 'dictionary'), ('dictionary', 'but'), ('but', 'the'), ('the', 'noise'), ('noise', 'cannot')]\n",
      "\n",
      "Trigrams: [('Sparse', 'dictionary', 'learning'), ('dictionary', 'learning', 'is'), ('learning', 'is', 'a'), ('is', 'a', 'feature'), ('a', 'feature', 'learning'), ('feature', 'learning', 'method'), ('learning', 'method', 'where'), ('method', 'where', 'a'), ('where', 'a', 'training'), ('a', 'training', 'example'), ('training', 'example', 'is'), ('example', 'is', 'represented'), ('is', 'represented', 'as'), ('represented', 'as', 'a'), ('as', 'a', 'linear'), ('a', 'linear', 'combination'), ('linear', 'combination', 'of'), ('combination', 'of', 'basis'), ('of', 'basis', 'functions'), ('basis', 'functions', 'and'), ('functions', 'and', 'assumed'), ('and', 'assumed', 'to'), ('assumed', 'to', 'be'), ('to', 'be', 'a'), ('be', 'a', 'sparse'), ('a', 'sparse', 'matrix'), ('sparse', 'matrix', 'The'), ('matrix', 'The', 'method'), ('The', 'method', 'is'), ('method', 'is', 'strongly'), ('is', 'strongly', 'NPhard'), ('strongly', 'NPhard', 'and'), ('NPhard', 'and', 'difficult'), ('and', 'difficult', 'to'), ('difficult', 'to', 'solve'), ('to', 'solve', 'approximately'), ('solve', 'approximately', 'A'), ('approximately', 'A', 'popular'), ('A', 'popular', 'heuristic'), ('popular', 'heuristic', 'method'), ('heuristic', 'method', 'for'), ('method', 'for', 'sparse'), ('for', 'sparse', 'dictionary'), ('sparse', 'dictionary', 'learning'), ('dictionary', 'learning', 'is'), ('learning', 'is', 'the'), ('is', 'the', 'kSVD'), ('the', 'kSVD', 'algorithm'), ('kSVD', 'algorithm', 'Sparse'), ('algorithm', 'Sparse', 'dictionary'), ('Sparse', 'dictionary', 'learning'), ('dictionary', 'learning', 'has'), ('learning', 'has', 'been'), ('has', 'been', 'applied'), ('been', 'applied', 'in'), ('applied', 'in', 'several'), ('in', 'several', 'contexts'), ('several', 'contexts', 'In'), ('contexts', 'In', 'classification'), ('In', 'classification', 'the'), ('classification', 'the', 'problem'), ('the', 'problem', 'is'), ('problem', 'is', 'to'), ('is', 'to', 'determine'), ('to', 'determine', 'the'), ('determine', 'the', 'class'), ('the', 'class', 'to'), ('class', 'to', 'which'), ('to', 'which', 'a'), ('which', 'a', 'previously'), ('a', 'previously', 'unseen'), ('previously', 'unseen', 'training'), ('unseen', 'training', 'example'), ('training', 'example', 'belongs'), ('example', 'belongs', 'For'), ('belongs', 'For', 'a'), ('For', 'a', 'dictionary'), ('a', 'dictionary', 'where'), ('dictionary', 'where', 'each'), ('where', 'each', 'class'), ('each', 'class', 'has'), ('class', 'has', 'already'), ('has', 'already', 'been'), ('already', 'been', 'built'), ('been', 'built', 'a'), ('built', 'a', 'new'), ('a', 'new', 'training'), ('new', 'training', 'example'), ('training', 'example', 'is'), ('example', 'is', 'associated'), ('is', 'associated', 'with'), ('associated', 'with', 'the'), ('with', 'the', 'class'), ('the', 'class', 'that'), ('class', 'that', 'is'), ('that', 'is', 'best'), ('is', 'best', 'sparsely'), ('best', 'sparsely', 'represented'), ('sparsely', 'represented', 'by'), ('represented', 'by', 'the'), ('by', 'the', 'corresponding'), ('the', 'corresponding', 'dictionary'), ('corresponding', 'dictionary', 'Sparse'), ('dictionary', 'Sparse', 'dictionary'), ('Sparse', 'dictionary', 'learning'), ('dictionary', 'learning', 'has'), ('learning', 'has', 'also'), ('has', 'also', 'been'), ('also', 'been', 'applied'), ('been', 'applied', 'in'), ('applied', 'in', 'image'), ('in', 'image', 'denoising'), ('image', 'denoising', 'The'), ('denoising', 'The', 'key'), ('The', 'key', 'idea'), ('key', 'idea', 'is'), ('idea', 'is', 'that'), ('is', 'that', 'a'), ('that', 'a', 'clean'), ('a', 'clean', 'image'), ('clean', 'image', 'patch'), ('image', 'patch', 'can'), ('patch', 'can', 'be'), ('can', 'be', 'sparsely'), ('be', 'sparsely', 'represented'), ('sparsely', 'represented', 'by'), ('represented', 'by', 'an'), ('by', 'an', 'image'), ('an', 'image', 'dictionary'), ('image', 'dictionary', 'but'), ('dictionary', 'but', 'the'), ('but', 'the', 'noise'), ('the', 'noise', 'cannot')]\n",
      "\n",
      "Document: In data mining anomaly detection also known as outlier detection is the identification of rare items events or observations which raise suspicions by differing significantly from the majority of the data Typically the anomalous items represent an issue such as bank fraud a structural defect medical problems or errors in a text Anomalies are referred to as outliers novelties noise deviations and exceptions\n",
      "\n",
      "\n",
      "Unigrams: [('In',), ('data',), ('mining',), ('anomaly',), ('detection',), ('also',), ('known',), ('as',), ('outlier',), ('detection',), ('is',), ('the',), ('identification',), ('of',), ('rare',), ('items',), ('events',), ('or',), ('observations',), ('which',), ('raise',), ('suspicions',), ('by',), ('differing',), ('significantly',), ('from',), ('the',), ('majority',), ('of',), ('the',), ('data',), ('Typically',), ('the',), ('anomalous',), ('items',), ('represent',), ('an',), ('issue',), ('such',), ('as',), ('bank',), ('fraud',), ('a',), ('structural',), ('defect',), ('medical',), ('problems',), ('or',), ('errors',), ('in',), ('a',), ('text',), ('Anomalies',), ('are',), ('referred',), ('to',), ('as',), ('outliers',), ('novelties',), ('noise',), ('deviations',), ('and',), ('exceptions',)]\n",
      "\n",
      "Bigrams: [('In', 'data'), ('data', 'mining'), ('mining', 'anomaly'), ('anomaly', 'detection'), ('detection', 'also'), ('also', 'known'), ('known', 'as'), ('as', 'outlier'), ('outlier', 'detection'), ('detection', 'is'), ('is', 'the'), ('the', 'identification'), ('identification', 'of'), ('of', 'rare'), ('rare', 'items'), ('items', 'events'), ('events', 'or'), ('or', 'observations'), ('observations', 'which'), ('which', 'raise'), ('raise', 'suspicions'), ('suspicions', 'by'), ('by', 'differing'), ('differing', 'significantly'), ('significantly', 'from'), ('from', 'the'), ('the', 'majority'), ('majority', 'of'), ('of', 'the'), ('the', 'data'), ('data', 'Typically'), ('Typically', 'the'), ('the', 'anomalous'), ('anomalous', 'items'), ('items', 'represent'), ('represent', 'an'), ('an', 'issue'), ('issue', 'such'), ('such', 'as'), ('as', 'bank'), ('bank', 'fraud'), ('fraud', 'a'), ('a', 'structural'), ('structural', 'defect'), ('defect', 'medical'), ('medical', 'problems'), ('problems', 'or'), ('or', 'errors'), ('errors', 'in'), ('in', 'a'), ('a', 'text'), ('text', 'Anomalies'), ('Anomalies', 'are'), ('are', 'referred'), ('referred', 'to'), ('to', 'as'), ('as', 'outliers'), ('outliers', 'novelties'), ('novelties', 'noise'), ('noise', 'deviations'), ('deviations', 'and'), ('and', 'exceptions')]\n",
      "\n",
      "Trigrams: [('In', 'data', 'mining'), ('data', 'mining', 'anomaly'), ('mining', 'anomaly', 'detection'), ('anomaly', 'detection', 'also'), ('detection', 'also', 'known'), ('also', 'known', 'as'), ('known', 'as', 'outlier'), ('as', 'outlier', 'detection'), ('outlier', 'detection', 'is'), ('detection', 'is', 'the'), ('is', 'the', 'identification'), ('the', 'identification', 'of'), ('identification', 'of', 'rare'), ('of', 'rare', 'items'), ('rare', 'items', 'events'), ('items', 'events', 'or'), ('events', 'or', 'observations'), ('or', 'observations', 'which'), ('observations', 'which', 'raise'), ('which', 'raise', 'suspicions'), ('raise', 'suspicions', 'by'), ('suspicions', 'by', 'differing'), ('by', 'differing', 'significantly'), ('differing', 'significantly', 'from'), ('significantly', 'from', 'the'), ('from', 'the', 'majority'), ('the', 'majority', 'of'), ('majority', 'of', 'the'), ('of', 'the', 'data'), ('the', 'data', 'Typically'), ('data', 'Typically', 'the'), ('Typically', 'the', 'anomalous'), ('the', 'anomalous', 'items'), ('anomalous', 'items', 'represent'), ('items', 'represent', 'an'), ('represent', 'an', 'issue'), ('an', 'issue', 'such'), ('issue', 'such', 'as'), ('such', 'as', 'bank'), ('as', 'bank', 'fraud'), ('bank', 'fraud', 'a'), ('fraud', 'a', 'structural'), ('a', 'structural', 'defect'), ('structural', 'defect', 'medical'), ('defect', 'medical', 'problems'), ('medical', 'problems', 'or'), ('problems', 'or', 'errors'), ('or', 'errors', 'in'), ('errors', 'in', 'a'), ('in', 'a', 'text'), ('a', 'text', 'Anomalies'), ('text', 'Anomalies', 'are'), ('Anomalies', 'are', 'referred'), ('are', 'referred', 'to'), ('referred', 'to', 'as'), ('to', 'as', 'outliers'), ('as', 'outliers', 'novelties'), ('outliers', 'novelties', 'noise'), ('novelties', 'noise', 'deviations'), ('noise', 'deviations', 'and'), ('deviations', 'and', 'exceptions')]\n",
      "\n",
      "Document: In particular in the context of abuse and network intrusion detection the interesting objects are often not rare objects but unexpected bursts of inactivity This pattern does not adhere to the common statistical definition of an outlier as a rare object Many outlier detection methods in particular unsupervised algorithms will fail on such data unless aggregated appropriately Instead a cluster analysis algorithm may be able to detect the microclusters formed by these patterns\n",
      "\n",
      "\n",
      "Unigrams: [('In',), ('particular',), ('in',), ('the',), ('context',), ('of',), ('abuse',), ('and',), ('network',), ('intrusion',), ('detection',), ('the',), ('interesting',), ('objects',), ('are',), ('often',), ('not',), ('rare',), ('objects',), ('but',), ('unexpected',), ('bursts',), ('of',), ('inactivity',), ('This',), ('pattern',), ('does',), ('not',), ('adhere',), ('to',), ('the',), ('common',), ('statistical',), ('definition',), ('of',), ('an',), ('outlier',), ('as',), ('a',), ('rare',), ('object',), ('Many',), ('outlier',), ('detection',), ('methods',), ('in',), ('particular',), ('unsupervised',), ('algorithms',), ('will',), ('fail',), ('on',), ('such',), ('data',), ('unless',), ('aggregated',), ('appropriately',), ('Instead',), ('a',), ('cluster',), ('analysis',), ('algorithm',), ('may',), ('be',), ('able',), ('to',), ('detect',), ('the',), ('microclusters',), ('formed',), ('by',), ('these',), ('patterns',)]\n",
      "\n",
      "Bigrams: [('In', 'particular'), ('particular', 'in'), ('in', 'the'), ('the', 'context'), ('context', 'of'), ('of', 'abuse'), ('abuse', 'and'), ('and', 'network'), ('network', 'intrusion'), ('intrusion', 'detection'), ('detection', 'the'), ('the', 'interesting'), ('interesting', 'objects'), ('objects', 'are'), ('are', 'often'), ('often', 'not'), ('not', 'rare'), ('rare', 'objects'), ('objects', 'but'), ('but', 'unexpected'), ('unexpected', 'bursts'), ('bursts', 'of'), ('of', 'inactivity'), ('inactivity', 'This'), ('This', 'pattern'), ('pattern', 'does'), ('does', 'not'), ('not', 'adhere'), ('adhere', 'to'), ('to', 'the'), ('the', 'common'), ('common', 'statistical'), ('statistical', 'definition'), ('definition', 'of'), ('of', 'an'), ('an', 'outlier'), ('outlier', 'as'), ('as', 'a'), ('a', 'rare'), ('rare', 'object'), ('object', 'Many'), ('Many', 'outlier'), ('outlier', 'detection'), ('detection', 'methods'), ('methods', 'in'), ('in', 'particular'), ('particular', 'unsupervised'), ('unsupervised', 'algorithms'), ('algorithms', 'will'), ('will', 'fail'), ('fail', 'on'), ('on', 'such'), ('such', 'data'), ('data', 'unless'), ('unless', 'aggregated'), ('aggregated', 'appropriately'), ('appropriately', 'Instead'), ('Instead', 'a'), ('a', 'cluster'), ('cluster', 'analysis'), ('analysis', 'algorithm'), ('algorithm', 'may'), ('may', 'be'), ('be', 'able'), ('able', 'to'), ('to', 'detect'), ('detect', 'the'), ('the', 'microclusters'), ('microclusters', 'formed'), ('formed', 'by'), ('by', 'these'), ('these', 'patterns')]\n",
      "\n",
      "Trigrams: [('In', 'particular', 'in'), ('particular', 'in', 'the'), ('in', 'the', 'context'), ('the', 'context', 'of'), ('context', 'of', 'abuse'), ('of', 'abuse', 'and'), ('abuse', 'and', 'network'), ('and', 'network', 'intrusion'), ('network', 'intrusion', 'detection'), ('intrusion', 'detection', 'the'), ('detection', 'the', 'interesting'), ('the', 'interesting', 'objects'), ('interesting', 'objects', 'are'), ('objects', 'are', 'often'), ('are', 'often', 'not'), ('often', 'not', 'rare'), ('not', 'rare', 'objects'), ('rare', 'objects', 'but'), ('objects', 'but', 'unexpected'), ('but', 'unexpected', 'bursts'), ('unexpected', 'bursts', 'of'), ('bursts', 'of', 'inactivity'), ('of', 'inactivity', 'This'), ('inactivity', 'This', 'pattern'), ('This', 'pattern', 'does'), ('pattern', 'does', 'not'), ('does', 'not', 'adhere'), ('not', 'adhere', 'to'), ('adhere', 'to', 'the'), ('to', 'the', 'common'), ('the', 'common', 'statistical'), ('common', 'statistical', 'definition'), ('statistical', 'definition', 'of'), ('definition', 'of', 'an'), ('of', 'an', 'outlier'), ('an', 'outlier', 'as'), ('outlier', 'as', 'a'), ('as', 'a', 'rare'), ('a', 'rare', 'object'), ('rare', 'object', 'Many'), ('object', 'Many', 'outlier'), ('Many', 'outlier', 'detection'), ('outlier', 'detection', 'methods'), ('detection', 'methods', 'in'), ('methods', 'in', 'particular'), ('in', 'particular', 'unsupervised'), ('particular', 'unsupervised', 'algorithms'), ('unsupervised', 'algorithms', 'will'), ('algorithms', 'will', 'fail'), ('will', 'fail', 'on'), ('fail', 'on', 'such'), ('on', 'such', 'data'), ('such', 'data', 'unless'), ('data', 'unless', 'aggregated'), ('unless', 'aggregated', 'appropriately'), ('aggregated', 'appropriately', 'Instead'), ('appropriately', 'Instead', 'a'), ('Instead', 'a', 'cluster'), ('a', 'cluster', 'analysis'), ('cluster', 'analysis', 'algorithm'), ('analysis', 'algorithm', 'may'), ('algorithm', 'may', 'be'), ('may', 'be', 'able'), ('be', 'able', 'to'), ('able', 'to', 'detect'), ('to', 'detect', 'the'), ('detect', 'the', 'microclusters'), ('the', 'microclusters', 'formed'), ('microclusters', 'formed', 'by'), ('formed', 'by', 'these'), ('by', 'these', 'patterns')]\n",
      "\n",
      "Document: Three broad categories of anomaly detection techniques exist Unsupervised anomaly detection techniques detect anomalies in an unlabelled test data set under the assumption that the majority of the instances in the data set are normal by looking for instances that seem to fit the least to the remainder of the data set Supervised anomaly detection techniques require a data set that has been labelled as normal and abnormal and involves training a classifier the key difference from many other statistical classification problems is the inherently unbalanced nature of outlier detection Semisupervised anomaly detection techniques construct a model representing normal behaviour from a given normal training data set and then test the likelihood of a test instance to be generated by the model\n",
      "\n",
      "\n",
      "Unigrams: [('Three',), ('broad',), ('categories',), ('of',), ('anomaly',), ('detection',), ('techniques',), ('exist',), ('Unsupervised',), ('anomaly',), ('detection',), ('techniques',), ('detect',), ('anomalies',), ('in',), ('an',), ('unlabelled',), ('test',), ('data',), ('set',), ('under',), ('the',), ('assumption',), ('that',), ('the',), ('majority',), ('of',), ('the',), ('instances',), ('in',), ('the',), ('data',), ('set',), ('are',), ('normal',), ('by',), ('looking',), ('for',), ('instances',), ('that',), ('seem',), ('to',), ('fit',), ('the',), ('least',), ('to',), ('the',), ('remainder',), ('of',), ('the',), ('data',), ('set',), ('Supervised',), ('anomaly',), ('detection',), ('techniques',), ('require',), ('a',), ('data',), ('set',), ('that',), ('has',), ('been',), ('labelled',), ('as',), ('normal',), ('and',), ('abnormal',), ('and',), ('involves',), ('training',), ('a',), ('classifier',), ('the',), ('key',), ('difference',), ('from',), ('many',), ('other',), ('statistical',), ('classification',), ('problems',), ('is',), ('the',), ('inherently',), ('unbalanced',), ('nature',), ('of',), ('outlier',), ('detection',), ('Semisupervised',), ('anomaly',), ('detection',), ('techniques',), ('construct',), ('a',), ('model',), ('representing',), ('normal',), ('behaviour',), ('from',), ('a',), ('given',), ('normal',), ('training',), ('data',), ('set',), ('and',), ('then',), ('test',), ('the',), ('likelihood',), ('of',), ('a',), ('test',), ('instance',), ('to',), ('be',), ('generated',), ('by',), ('the',), ('model',)]\n",
      "\n",
      "Bigrams: [('Three', 'broad'), ('broad', 'categories'), ('categories', 'of'), ('of', 'anomaly'), ('anomaly', 'detection'), ('detection', 'techniques'), ('techniques', 'exist'), ('exist', 'Unsupervised'), ('Unsupervised', 'anomaly'), ('anomaly', 'detection'), ('detection', 'techniques'), ('techniques', 'detect'), ('detect', 'anomalies'), ('anomalies', 'in'), ('in', 'an'), ('an', 'unlabelled'), ('unlabelled', 'test'), ('test', 'data'), ('data', 'set'), ('set', 'under'), ('under', 'the'), ('the', 'assumption'), ('assumption', 'that'), ('that', 'the'), ('the', 'majority'), ('majority', 'of'), ('of', 'the'), ('the', 'instances'), ('instances', 'in'), ('in', 'the'), ('the', 'data'), ('data', 'set'), ('set', 'are'), ('are', 'normal'), ('normal', 'by'), ('by', 'looking'), ('looking', 'for'), ('for', 'instances'), ('instances', 'that'), ('that', 'seem'), ('seem', 'to'), ('to', 'fit'), ('fit', 'the'), ('the', 'least'), ('least', 'to'), ('to', 'the'), ('the', 'remainder'), ('remainder', 'of'), ('of', 'the'), ('the', 'data'), ('data', 'set'), ('set', 'Supervised'), ('Supervised', 'anomaly'), ('anomaly', 'detection'), ('detection', 'techniques'), ('techniques', 'require'), ('require', 'a'), ('a', 'data'), ('data', 'set'), ('set', 'that'), ('that', 'has'), ('has', 'been'), ('been', 'labelled'), ('labelled', 'as'), ('as', 'normal'), ('normal', 'and'), ('and', 'abnormal'), ('abnormal', 'and'), ('and', 'involves'), ('involves', 'training'), ('training', 'a'), ('a', 'classifier'), ('classifier', 'the'), ('the', 'key'), ('key', 'difference'), ('difference', 'from'), ('from', 'many'), ('many', 'other'), ('other', 'statistical'), ('statistical', 'classification'), ('classification', 'problems'), ('problems', 'is'), ('is', 'the'), ('the', 'inherently'), ('inherently', 'unbalanced'), ('unbalanced', 'nature'), ('nature', 'of'), ('of', 'outlier'), ('outlier', 'detection'), ('detection', 'Semisupervised'), ('Semisupervised', 'anomaly'), ('anomaly', 'detection'), ('detection', 'techniques'), ('techniques', 'construct'), ('construct', 'a'), ('a', 'model'), ('model', 'representing'), ('representing', 'normal'), ('normal', 'behaviour'), ('behaviour', 'from'), ('from', 'a'), ('a', 'given'), ('given', 'normal'), ('normal', 'training'), ('training', 'data'), ('data', 'set'), ('set', 'and'), ('and', 'then'), ('then', 'test'), ('test', 'the'), ('the', 'likelihood'), ('likelihood', 'of'), ('of', 'a'), ('a', 'test'), ('test', 'instance'), ('instance', 'to'), ('to', 'be'), ('be', 'generated'), ('generated', 'by'), ('by', 'the'), ('the', 'model')]\n",
      "\n",
      "Trigrams: [('Three', 'broad', 'categories'), ('broad', 'categories', 'of'), ('categories', 'of', 'anomaly'), ('of', 'anomaly', 'detection'), ('anomaly', 'detection', 'techniques'), ('detection', 'techniques', 'exist'), ('techniques', 'exist', 'Unsupervised'), ('exist', 'Unsupervised', 'anomaly'), ('Unsupervised', 'anomaly', 'detection'), ('anomaly', 'detection', 'techniques'), ('detection', 'techniques', 'detect'), ('techniques', 'detect', 'anomalies'), ('detect', 'anomalies', 'in'), ('anomalies', 'in', 'an'), ('in', 'an', 'unlabelled'), ('an', 'unlabelled', 'test'), ('unlabelled', 'test', 'data'), ('test', 'data', 'set'), ('data', 'set', 'under'), ('set', 'under', 'the'), ('under', 'the', 'assumption'), ('the', 'assumption', 'that'), ('assumption', 'that', 'the'), ('that', 'the', 'majority'), ('the', 'majority', 'of'), ('majority', 'of', 'the'), ('of', 'the', 'instances'), ('the', 'instances', 'in'), ('instances', 'in', 'the'), ('in', 'the', 'data'), ('the', 'data', 'set'), ('data', 'set', 'are'), ('set', 'are', 'normal'), ('are', 'normal', 'by'), ('normal', 'by', 'looking'), ('by', 'looking', 'for'), ('looking', 'for', 'instances'), ('for', 'instances', 'that'), ('instances', 'that', 'seem'), ('that', 'seem', 'to'), ('seem', 'to', 'fit'), ('to', 'fit', 'the'), ('fit', 'the', 'least'), ('the', 'least', 'to'), ('least', 'to', 'the'), ('to', 'the', 'remainder'), ('the', 'remainder', 'of'), ('remainder', 'of', 'the'), ('of', 'the', 'data'), ('the', 'data', 'set'), ('data', 'set', 'Supervised'), ('set', 'Supervised', 'anomaly'), ('Supervised', 'anomaly', 'detection'), ('anomaly', 'detection', 'techniques'), ('detection', 'techniques', 'require'), ('techniques', 'require', 'a'), ('require', 'a', 'data'), ('a', 'data', 'set'), ('data', 'set', 'that'), ('set', 'that', 'has'), ('that', 'has', 'been'), ('has', 'been', 'labelled'), ('been', 'labelled', 'as'), ('labelled', 'as', 'normal'), ('as', 'normal', 'and'), ('normal', 'and', 'abnormal'), ('and', 'abnormal', 'and'), ('abnormal', 'and', 'involves'), ('and', 'involves', 'training'), ('involves', 'training', 'a'), ('training', 'a', 'classifier'), ('a', 'classifier', 'the'), ('classifier', 'the', 'key'), ('the', 'key', 'difference'), ('key', 'difference', 'from'), ('difference', 'from', 'many'), ('from', 'many', 'other'), ('many', 'other', 'statistical'), ('other', 'statistical', 'classification'), ('statistical', 'classification', 'problems'), ('classification', 'problems', 'is'), ('problems', 'is', 'the'), ('is', 'the', 'inherently'), ('the', 'inherently', 'unbalanced'), ('inherently', 'unbalanced', 'nature'), ('unbalanced', 'nature', 'of'), ('nature', 'of', 'outlier'), ('of', 'outlier', 'detection'), ('outlier', 'detection', 'Semisupervised'), ('detection', 'Semisupervised', 'anomaly'), ('Semisupervised', 'anomaly', 'detection'), ('anomaly', 'detection', 'techniques'), ('detection', 'techniques', 'construct'), ('techniques', 'construct', 'a'), ('construct', 'a', 'model'), ('a', 'model', 'representing'), ('model', 'representing', 'normal'), ('representing', 'normal', 'behaviour'), ('normal', 'behaviour', 'from'), ('behaviour', 'from', 'a'), ('from', 'a', 'given'), ('a', 'given', 'normal'), ('given', 'normal', 'training'), ('normal', 'training', 'data'), ('training', 'data', 'set'), ('data', 'set', 'and'), ('set', 'and', 'then'), ('and', 'then', 'test'), ('then', 'test', 'the'), ('test', 'the', 'likelihood'), ('the', 'likelihood', 'of'), ('likelihood', 'of', 'a'), ('of', 'a', 'test'), ('a', 'test', 'instance'), ('test', 'instance', 'to'), ('instance', 'to', 'be'), ('to', 'be', 'generated'), ('be', 'generated', 'by'), ('generated', 'by', 'the'), ('by', 'the', 'model')]\n",
      "\n",
      "Document: Robot learning is inspired by a multitude of machine learning methods starting from supervised learning reinforcement learning and finally metalearning eg MAML\n",
      "\n",
      "\n",
      "Unigrams: [('Robot',), ('learning',), ('is',), ('inspired',), ('by',), ('a',), ('multitude',), ('of',), ('machine',), ('learning',), ('methods',), ('starting',), ('from',), ('supervised',), ('learning',), ('reinforcement',), ('learning',), ('and',), ('finally',), ('metalearning',), ('eg',), ('MAML',)]\n",
      "\n",
      "Bigrams: [('Robot', 'learning'), ('learning', 'is'), ('is', 'inspired'), ('inspired', 'by'), ('by', 'a'), ('a', 'multitude'), ('multitude', 'of'), ('of', 'machine'), ('machine', 'learning'), ('learning', 'methods'), ('methods', 'starting'), ('starting', 'from'), ('from', 'supervised'), ('supervised', 'learning'), ('learning', 'reinforcement'), ('reinforcement', 'learning'), ('learning', 'and'), ('and', 'finally'), ('finally', 'metalearning'), ('metalearning', 'eg'), ('eg', 'MAML')]\n",
      "\n",
      "Trigrams: [('Robot', 'learning', 'is'), ('learning', 'is', 'inspired'), ('is', 'inspired', 'by'), ('inspired', 'by', 'a'), ('by', 'a', 'multitude'), ('a', 'multitude', 'of'), ('multitude', 'of', 'machine'), ('of', 'machine', 'learning'), ('machine', 'learning', 'methods'), ('learning', 'methods', 'starting'), ('methods', 'starting', 'from'), ('starting', 'from', 'supervised'), ('from', 'supervised', 'learning'), ('supervised', 'learning', 'reinforcement'), ('learning', 'reinforcement', 'learning'), ('reinforcement', 'learning', 'and'), ('learning', 'and', 'finally'), ('and', 'finally', 'metalearning'), ('finally', 'metalearning', 'eg'), ('metalearning', 'eg', 'MAML')]\n",
      "\n",
      "Document: Association rule learning is a rulebased machine learning method for discovering relationships between variables in large databases It is intended to identify strong rules discovered in databases using some measure of interestingness\n",
      "\n",
      "\n",
      "Unigrams: [('Association',), ('rule',), ('learning',), ('is',), ('a',), ('rulebased',), ('machine',), ('learning',), ('method',), ('for',), ('discovering',), ('relationships',), ('between',), ('variables',), ('in',), ('large',), ('databases',), ('It',), ('is',), ('intended',), ('to',), ('identify',), ('strong',), ('rules',), ('discovered',), ('in',), ('databases',), ('using',), ('some',), ('measure',), ('of',), ('interestingness',)]\n",
      "\n",
      "Bigrams: [('Association', 'rule'), ('rule', 'learning'), ('learning', 'is'), ('is', 'a'), ('a', 'rulebased'), ('rulebased', 'machine'), ('machine', 'learning'), ('learning', 'method'), ('method', 'for'), ('for', 'discovering'), ('discovering', 'relationships'), ('relationships', 'between'), ('between', 'variables'), ('variables', 'in'), ('in', 'large'), ('large', 'databases'), ('databases', 'It'), ('It', 'is'), ('is', 'intended'), ('intended', 'to'), ('to', 'identify'), ('identify', 'strong'), ('strong', 'rules'), ('rules', 'discovered'), ('discovered', 'in'), ('in', 'databases'), ('databases', 'using'), ('using', 'some'), ('some', 'measure'), ('measure', 'of'), ('of', 'interestingness')]\n",
      "\n",
      "Trigrams: [('Association', 'rule', 'learning'), ('rule', 'learning', 'is'), ('learning', 'is', 'a'), ('is', 'a', 'rulebased'), ('a', 'rulebased', 'machine'), ('rulebased', 'machine', 'learning'), ('machine', 'learning', 'method'), ('learning', 'method', 'for'), ('method', 'for', 'discovering'), ('for', 'discovering', 'relationships'), ('discovering', 'relationships', 'between'), ('relationships', 'between', 'variables'), ('between', 'variables', 'in'), ('variables', 'in', 'large'), ('in', 'large', 'databases'), ('large', 'databases', 'It'), ('databases', 'It', 'is'), ('It', 'is', 'intended'), ('is', 'intended', 'to'), ('intended', 'to', 'identify'), ('to', 'identify', 'strong'), ('identify', 'strong', 'rules'), ('strong', 'rules', 'discovered'), ('rules', 'discovered', 'in'), ('discovered', 'in', 'databases'), ('in', 'databases', 'using'), ('databases', 'using', 'some'), ('using', 'some', 'measure'), ('some', 'measure', 'of'), ('measure', 'of', 'interestingness')]\n",
      "\n",
      "Document: Rulebased machine learning is a general term for any machine learning method that identifies learns or evolves rules to store manipulate or apply knowledge The defining characteristic of a rulebased machine learning algorithm is the identification and utilisation of a set of relational rules that collectively represent the knowledge captured by the system This is in contrast to other machine learning algorithms that commonly identify a singular model that can be universally applied to any instance in order to make a prediction Rulebased machine learning approaches include learning classifier systems association rule learning and artificial immune systems\n",
      "\n",
      "\n",
      "Unigrams: [('Rulebased',), ('machine',), ('learning',), ('is',), ('a',), ('general',), ('term',), ('for',), ('any',), ('machine',), ('learning',), ('method',), ('that',), ('identifies',), ('learns',), ('or',), ('evolves',), ('rules',), ('to',), ('store',), ('manipulate',), ('or',), ('apply',), ('knowledge',), ('The',), ('defining',), ('characteristic',), ('of',), ('a',), ('rulebased',), ('machine',), ('learning',), ('algorithm',), ('is',), ('the',), ('identification',), ('and',), ('utilisation',), ('of',), ('a',), ('set',), ('of',), ('relational',), ('rules',), ('that',), ('collectively',), ('represent',), ('the',), ('knowledge',), ('captured',), ('by',), ('the',), ('system',), ('This',), ('is',), ('in',), ('contrast',), ('to',), ('other',), ('machine',), ('learning',), ('algorithms',), ('that',), ('commonly',), ('identify',), ('a',), ('singular',), ('model',), ('that',), ('can',), ('be',), ('universally',), ('applied',), ('to',), ('any',), ('instance',), ('in',), ('order',), ('to',), ('make',), ('a',), ('prediction',), ('Rulebased',), ('machine',), ('learning',), ('approaches',), ('include',), ('learning',), ('classifier',), ('systems',), ('association',), ('rule',), ('learning',), ('and',), ('artificial',), ('immune',), ('systems',)]\n",
      "\n",
      "Bigrams: [('Rulebased', 'machine'), ('machine', 'learning'), ('learning', 'is'), ('is', 'a'), ('a', 'general'), ('general', 'term'), ('term', 'for'), ('for', 'any'), ('any', 'machine'), ('machine', 'learning'), ('learning', 'method'), ('method', 'that'), ('that', 'identifies'), ('identifies', 'learns'), ('learns', 'or'), ('or', 'evolves'), ('evolves', 'rules'), ('rules', 'to'), ('to', 'store'), ('store', 'manipulate'), ('manipulate', 'or'), ('or', 'apply'), ('apply', 'knowledge'), ('knowledge', 'The'), ('The', 'defining'), ('defining', 'characteristic'), ('characteristic', 'of'), ('of', 'a'), ('a', 'rulebased'), ('rulebased', 'machine'), ('machine', 'learning'), ('learning', 'algorithm'), ('algorithm', 'is'), ('is', 'the'), ('the', 'identification'), ('identification', 'and'), ('and', 'utilisation'), ('utilisation', 'of'), ('of', 'a'), ('a', 'set'), ('set', 'of'), ('of', 'relational'), ('relational', 'rules'), ('rules', 'that'), ('that', 'collectively'), ('collectively', 'represent'), ('represent', 'the'), ('the', 'knowledge'), ('knowledge', 'captured'), ('captured', 'by'), ('by', 'the'), ('the', 'system'), ('system', 'This'), ('This', 'is'), ('is', 'in'), ('in', 'contrast'), ('contrast', 'to'), ('to', 'other'), ('other', 'machine'), ('machine', 'learning'), ('learning', 'algorithms'), ('algorithms', 'that'), ('that', 'commonly'), ('commonly', 'identify'), ('identify', 'a'), ('a', 'singular'), ('singular', 'model'), ('model', 'that'), ('that', 'can'), ('can', 'be'), ('be', 'universally'), ('universally', 'applied'), ('applied', 'to'), ('to', 'any'), ('any', 'instance'), ('instance', 'in'), ('in', 'order'), ('order', 'to'), ('to', 'make'), ('make', 'a'), ('a', 'prediction'), ('prediction', 'Rulebased'), ('Rulebased', 'machine'), ('machine', 'learning'), ('learning', 'approaches'), ('approaches', 'include'), ('include', 'learning'), ('learning', 'classifier'), ('classifier', 'systems'), ('systems', 'association'), ('association', 'rule'), ('rule', 'learning'), ('learning', 'and'), ('and', 'artificial'), ('artificial', 'immune'), ('immune', 'systems')]\n",
      "\n",
      "Trigrams: [('Rulebased', 'machine', 'learning'), ('machine', 'learning', 'is'), ('learning', 'is', 'a'), ('is', 'a', 'general'), ('a', 'general', 'term'), ('general', 'term', 'for'), ('term', 'for', 'any'), ('for', 'any', 'machine'), ('any', 'machine', 'learning'), ('machine', 'learning', 'method'), ('learning', 'method', 'that'), ('method', 'that', 'identifies'), ('that', 'identifies', 'learns'), ('identifies', 'learns', 'or'), ('learns', 'or', 'evolves'), ('or', 'evolves', 'rules'), ('evolves', 'rules', 'to'), ('rules', 'to', 'store'), ('to', 'store', 'manipulate'), ('store', 'manipulate', 'or'), ('manipulate', 'or', 'apply'), ('or', 'apply', 'knowledge'), ('apply', 'knowledge', 'The'), ('knowledge', 'The', 'defining'), ('The', 'defining', 'characteristic'), ('defining', 'characteristic', 'of'), ('characteristic', 'of', 'a'), ('of', 'a', 'rulebased'), ('a', 'rulebased', 'machine'), ('rulebased', 'machine', 'learning'), ('machine', 'learning', 'algorithm'), ('learning', 'algorithm', 'is'), ('algorithm', 'is', 'the'), ('is', 'the', 'identification'), ('the', 'identification', 'and'), ('identification', 'and', 'utilisation'), ('and', 'utilisation', 'of'), ('utilisation', 'of', 'a'), ('of', 'a', 'set'), ('a', 'set', 'of'), ('set', 'of', 'relational'), ('of', 'relational', 'rules'), ('relational', 'rules', 'that'), ('rules', 'that', 'collectively'), ('that', 'collectively', 'represent'), ('collectively', 'represent', 'the'), ('represent', 'the', 'knowledge'), ('the', 'knowledge', 'captured'), ('knowledge', 'captured', 'by'), ('captured', 'by', 'the'), ('by', 'the', 'system'), ('the', 'system', 'This'), ('system', 'This', 'is'), ('This', 'is', 'in'), ('is', 'in', 'contrast'), ('in', 'contrast', 'to'), ('contrast', 'to', 'other'), ('to', 'other', 'machine'), ('other', 'machine', 'learning'), ('machine', 'learning', 'algorithms'), ('learning', 'algorithms', 'that'), ('algorithms', 'that', 'commonly'), ('that', 'commonly', 'identify'), ('commonly', 'identify', 'a'), ('identify', 'a', 'singular'), ('a', 'singular', 'model'), ('singular', 'model', 'that'), ('model', 'that', 'can'), ('that', 'can', 'be'), ('can', 'be', 'universally'), ('be', 'universally', 'applied'), ('universally', 'applied', 'to'), ('applied', 'to', 'any'), ('to', 'any', 'instance'), ('any', 'instance', 'in'), ('instance', 'in', 'order'), ('in', 'order', 'to'), ('order', 'to', 'make'), ('to', 'make', 'a'), ('make', 'a', 'prediction'), ('a', 'prediction', 'Rulebased'), ('prediction', 'Rulebased', 'machine'), ('Rulebased', 'machine', 'learning'), ('machine', 'learning', 'approaches'), ('learning', 'approaches', 'include'), ('approaches', 'include', 'learning'), ('include', 'learning', 'classifier'), ('learning', 'classifier', 'systems'), ('classifier', 'systems', 'association'), ('systems', 'association', 'rule'), ('association', 'rule', 'learning'), ('rule', 'learning', 'and'), ('learning', 'and', 'artificial'), ('and', 'artificial', 'immune'), ('artificial', 'immune', 'systems')]\n",
      "\n",
      "Document: Based on the concept of strong rules Rakesh Agrawal Tomasz ImieliÅ„ski and Arun Swami introduced association rules for discovering regularities between products in largescale transaction data recorded by pointofsale POS systems in supermarkets For example the rule onionspotatoesburgerdisplaystyle mathrm onionspotatoes Rightarrow mathrm burger  found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together they are likely to also buy hamburger meat Such information can be used as the basis for decisions about marketing activities such as promotional pricing or product placements In addition to market basket analysis association rules are employed today in application areas including Web usage mining intrusion detection continuous production and bioinformatics In contrast with sequence mining association rule learning typically does not consider the order of items either within a transaction or across transactions\n",
      "\n",
      "\n",
      "Unigrams: [('Based',), ('on',), ('the',), ('concept',), ('of',), ('strong',), ('rules',), ('Rakesh',), ('Agrawal',), ('Tomasz',), ('ImieliÅ„ski',), ('and',), ('Arun',), ('Swami',), ('introduced',), ('association',), ('rules',), ('for',), ('discovering',), ('regularities',), ('between',), ('products',), ('in',), ('largescale',), ('transaction',), ('data',), ('recorded',), ('by',), ('pointofsale',), ('POS',), ('systems',), ('in',), ('supermarkets',), ('For',), ('example',), ('the',), ('rule',), ('onionspotatoesburgerdisplaystyle',), ('mathrm',), ('onionspotatoes',), ('Rightarrow',), ('mathrm',), ('burger',), ('found',), ('in',), ('the',), ('sales',), ('data',), ('of',), ('a',), ('supermarket',), ('would',), ('indicate',), ('that',), ('if',), ('a',), ('customer',), ('buys',), ('onions',), ('and',), ('potatoes',), ('together',), ('they',), ('are',), ('likely',), ('to',), ('also',), ('buy',), ('hamburger',), ('meat',), ('Such',), ('information',), ('can',), ('be',), ('used',), ('as',), ('the',), ('basis',), ('for',), ('decisions',), ('about',), ('marketing',), ('activities',), ('such',), ('as',), ('promotional',), ('pricing',), ('or',), ('product',), ('placements',), ('In',), ('addition',), ('to',), ('market',), ('basket',), ('analysis',), ('association',), ('rules',), ('are',), ('employed',), ('today',), ('in',), ('application',), ('areas',), ('including',), ('Web',), ('usage',), ('mining',), ('intrusion',), ('detection',), ('continuous',), ('production',), ('and',), ('bioinformatics',), ('In',), ('contrast',), ('with',), ('sequence',), ('mining',), ('association',), ('rule',), ('learning',), ('typically',), ('does',), ('not',), ('consider',), ('the',), ('order',), ('of',), ('items',), ('either',), ('within',), ('a',), ('transaction',), ('or',), ('across',), ('transactions',)]\n",
      "\n",
      "Bigrams: [('Based', 'on'), ('on', 'the'), ('the', 'concept'), ('concept', 'of'), ('of', 'strong'), ('strong', 'rules'), ('rules', 'Rakesh'), ('Rakesh', 'Agrawal'), ('Agrawal', 'Tomasz'), ('Tomasz', 'ImieliÅ„ski'), ('ImieliÅ„ski', 'and'), ('and', 'Arun'), ('Arun', 'Swami'), ('Swami', 'introduced'), ('introduced', 'association'), ('association', 'rules'), ('rules', 'for'), ('for', 'discovering'), ('discovering', 'regularities'), ('regularities', 'between'), ('between', 'products'), ('products', 'in'), ('in', 'largescale'), ('largescale', 'transaction'), ('transaction', 'data'), ('data', 'recorded'), ('recorded', 'by'), ('by', 'pointofsale'), ('pointofsale', 'POS'), ('POS', 'systems'), ('systems', 'in'), ('in', 'supermarkets'), ('supermarkets', 'For'), ('For', 'example'), ('example', 'the'), ('the', 'rule'), ('rule', 'onionspotatoesburgerdisplaystyle'), ('onionspotatoesburgerdisplaystyle', 'mathrm'), ('mathrm', 'onionspotatoes'), ('onionspotatoes', 'Rightarrow'), ('Rightarrow', 'mathrm'), ('mathrm', 'burger'), ('burger', 'found'), ('found', 'in'), ('in', 'the'), ('the', 'sales'), ('sales', 'data'), ('data', 'of'), ('of', 'a'), ('a', 'supermarket'), ('supermarket', 'would'), ('would', 'indicate'), ('indicate', 'that'), ('that', 'if'), ('if', 'a'), ('a', 'customer'), ('customer', 'buys'), ('buys', 'onions'), ('onions', 'and'), ('and', 'potatoes'), ('potatoes', 'together'), ('together', 'they'), ('they', 'are'), ('are', 'likely'), ('likely', 'to'), ('to', 'also'), ('also', 'buy'), ('buy', 'hamburger'), ('hamburger', 'meat'), ('meat', 'Such'), ('Such', 'information'), ('information', 'can'), ('can', 'be'), ('be', 'used'), ('used', 'as'), ('as', 'the'), ('the', 'basis'), ('basis', 'for'), ('for', 'decisions'), ('decisions', 'about'), ('about', 'marketing'), ('marketing', 'activities'), ('activities', 'such'), ('such', 'as'), ('as', 'promotional'), ('promotional', 'pricing'), ('pricing', 'or'), ('or', 'product'), ('product', 'placements'), ('placements', 'In'), ('In', 'addition'), ('addition', 'to'), ('to', 'market'), ('market', 'basket'), ('basket', 'analysis'), ('analysis', 'association'), ('association', 'rules'), ('rules', 'are'), ('are', 'employed'), ('employed', 'today'), ('today', 'in'), ('in', 'application'), ('application', 'areas'), ('areas', 'including'), ('including', 'Web'), ('Web', 'usage'), ('usage', 'mining'), ('mining', 'intrusion'), ('intrusion', 'detection'), ('detection', 'continuous'), ('continuous', 'production'), ('production', 'and'), ('and', 'bioinformatics'), ('bioinformatics', 'In'), ('In', 'contrast'), ('contrast', 'with'), ('with', 'sequence'), ('sequence', 'mining'), ('mining', 'association'), ('association', 'rule'), ('rule', 'learning'), ('learning', 'typically'), ('typically', 'does'), ('does', 'not'), ('not', 'consider'), ('consider', 'the'), ('the', 'order'), ('order', 'of'), ('of', 'items'), ('items', 'either'), ('either', 'within'), ('within', 'a'), ('a', 'transaction'), ('transaction', 'or'), ('or', 'across'), ('across', 'transactions')]\n",
      "\n",
      "Trigrams: [('Based', 'on', 'the'), ('on', 'the', 'concept'), ('the', 'concept', 'of'), ('concept', 'of', 'strong'), ('of', 'strong', 'rules'), ('strong', 'rules', 'Rakesh'), ('rules', 'Rakesh', 'Agrawal'), ('Rakesh', 'Agrawal', 'Tomasz'), ('Agrawal', 'Tomasz', 'ImieliÅ„ski'), ('Tomasz', 'ImieliÅ„ski', 'and'), ('ImieliÅ„ski', 'and', 'Arun'), ('and', 'Arun', 'Swami'), ('Arun', 'Swami', 'introduced'), ('Swami', 'introduced', 'association'), ('introduced', 'association', 'rules'), ('association', 'rules', 'for'), ('rules', 'for', 'discovering'), ('for', 'discovering', 'regularities'), ('discovering', 'regularities', 'between'), ('regularities', 'between', 'products'), ('between', 'products', 'in'), ('products', 'in', 'largescale'), ('in', 'largescale', 'transaction'), ('largescale', 'transaction', 'data'), ('transaction', 'data', 'recorded'), ('data', 'recorded', 'by'), ('recorded', 'by', 'pointofsale'), ('by', 'pointofsale', 'POS'), ('pointofsale', 'POS', 'systems'), ('POS', 'systems', 'in'), ('systems', 'in', 'supermarkets'), ('in', 'supermarkets', 'For'), ('supermarkets', 'For', 'example'), ('For', 'example', 'the'), ('example', 'the', 'rule'), ('the', 'rule', 'onionspotatoesburgerdisplaystyle'), ('rule', 'onionspotatoesburgerdisplaystyle', 'mathrm'), ('onionspotatoesburgerdisplaystyle', 'mathrm', 'onionspotatoes'), ('mathrm', 'onionspotatoes', 'Rightarrow'), ('onionspotatoes', 'Rightarrow', 'mathrm'), ('Rightarrow', 'mathrm', 'burger'), ('mathrm', 'burger', 'found'), ('burger', 'found', 'in'), ('found', 'in', 'the'), ('in', 'the', 'sales'), ('the', 'sales', 'data'), ('sales', 'data', 'of'), ('data', 'of', 'a'), ('of', 'a', 'supermarket'), ('a', 'supermarket', 'would'), ('supermarket', 'would', 'indicate'), ('would', 'indicate', 'that'), ('indicate', 'that', 'if'), ('that', 'if', 'a'), ('if', 'a', 'customer'), ('a', 'customer', 'buys'), ('customer', 'buys', 'onions'), ('buys', 'onions', 'and'), ('onions', 'and', 'potatoes'), ('and', 'potatoes', 'together'), ('potatoes', 'together', 'they'), ('together', 'they', 'are'), ('they', 'are', 'likely'), ('are', 'likely', 'to'), ('likely', 'to', 'also'), ('to', 'also', 'buy'), ('also', 'buy', 'hamburger'), ('buy', 'hamburger', 'meat'), ('hamburger', 'meat', 'Such'), ('meat', 'Such', 'information'), ('Such', 'information', 'can'), ('information', 'can', 'be'), ('can', 'be', 'used'), ('be', 'used', 'as'), ('used', 'as', 'the'), ('as', 'the', 'basis'), ('the', 'basis', 'for'), ('basis', 'for', 'decisions'), ('for', 'decisions', 'about'), ('decisions', 'about', 'marketing'), ('about', 'marketing', 'activities'), ('marketing', 'activities', 'such'), ('activities', 'such', 'as'), ('such', 'as', 'promotional'), ('as', 'promotional', 'pricing'), ('promotional', 'pricing', 'or'), ('pricing', 'or', 'product'), ('or', 'product', 'placements'), ('product', 'placements', 'In'), ('placements', 'In', 'addition'), ('In', 'addition', 'to'), ('addition', 'to', 'market'), ('to', 'market', 'basket'), ('market', 'basket', 'analysis'), ('basket', 'analysis', 'association'), ('analysis', 'association', 'rules'), ('association', 'rules', 'are'), ('rules', 'are', 'employed'), ('are', 'employed', 'today'), ('employed', 'today', 'in'), ('today', 'in', 'application'), ('in', 'application', 'areas'), ('application', 'areas', 'including'), ('areas', 'including', 'Web'), ('including', 'Web', 'usage'), ('Web', 'usage', 'mining'), ('usage', 'mining', 'intrusion'), ('mining', 'intrusion', 'detection'), ('intrusion', 'detection', 'continuous'), ('detection', 'continuous', 'production'), ('continuous', 'production', 'and'), ('production', 'and', 'bioinformatics'), ('and', 'bioinformatics', 'In'), ('bioinformatics', 'In', 'contrast'), ('In', 'contrast', 'with'), ('contrast', 'with', 'sequence'), ('with', 'sequence', 'mining'), ('sequence', 'mining', 'association'), ('mining', 'association', 'rule'), ('association', 'rule', 'learning'), ('rule', 'learning', 'typically'), ('learning', 'typically', 'does'), ('typically', 'does', 'not'), ('does', 'not', 'consider'), ('not', 'consider', 'the'), ('consider', 'the', 'order'), ('the', 'order', 'of'), ('order', 'of', 'items'), ('of', 'items', 'either'), ('items', 'either', 'within'), ('either', 'within', 'a'), ('within', 'a', 'transaction'), ('a', 'transaction', 'or'), ('transaction', 'or', 'across'), ('or', 'across', 'transactions')]\n",
      "\n",
      "Document: Learning classifier systems LCS are a family of rulebased machine learning algorithms that combine a discovery component typically a genetic algorithm with a learning component performing either supervised learning reinforcement learning or unsupervised learning They seek to identify a set of contextdependent rules that collectively store and apply knowledge in a piecewise manner in order to make predictions\n",
      "\n",
      "\n",
      "Unigrams: [('Learning',), ('classifier',), ('systems',), ('LCS',), ('are',), ('a',), ('family',), ('of',), ('rulebased',), ('machine',), ('learning',), ('algorithms',), ('that',), ('combine',), ('a',), ('discovery',), ('component',), ('typically',), ('a',), ('genetic',), ('algorithm',), ('with',), ('a',), ('learning',), ('component',), ('performing',), ('either',), ('supervised',), ('learning',), ('reinforcement',), ('learning',), ('or',), ('unsupervised',), ('learning',), ('They',), ('seek',), ('to',), ('identify',), ('a',), ('set',), ('of',), ('contextdependent',), ('rules',), ('that',), ('collectively',), ('store',), ('and',), ('apply',), ('knowledge',), ('in',), ('a',), ('piecewise',), ('manner',), ('in',), ('order',), ('to',), ('make',), ('predictions',)]\n",
      "\n",
      "Bigrams: [('Learning', 'classifier'), ('classifier', 'systems'), ('systems', 'LCS'), ('LCS', 'are'), ('are', 'a'), ('a', 'family'), ('family', 'of'), ('of', 'rulebased'), ('rulebased', 'machine'), ('machine', 'learning'), ('learning', 'algorithms'), ('algorithms', 'that'), ('that', 'combine'), ('combine', 'a'), ('a', 'discovery'), ('discovery', 'component'), ('component', 'typically'), ('typically', 'a'), ('a', 'genetic'), ('genetic', 'algorithm'), ('algorithm', 'with'), ('with', 'a'), ('a', 'learning'), ('learning', 'component'), ('component', 'performing'), ('performing', 'either'), ('either', 'supervised'), ('supervised', 'learning'), ('learning', 'reinforcement'), ('reinforcement', 'learning'), ('learning', 'or'), ('or', 'unsupervised'), ('unsupervised', 'learning'), ('learning', 'They'), ('They', 'seek'), ('seek', 'to'), ('to', 'identify'), ('identify', 'a'), ('a', 'set'), ('set', 'of'), ('of', 'contextdependent'), ('contextdependent', 'rules'), ('rules', 'that'), ('that', 'collectively'), ('collectively', 'store'), ('store', 'and'), ('and', 'apply'), ('apply', 'knowledge'), ('knowledge', 'in'), ('in', 'a'), ('a', 'piecewise'), ('piecewise', 'manner'), ('manner', 'in'), ('in', 'order'), ('order', 'to'), ('to', 'make'), ('make', 'predictions')]\n",
      "\n",
      "Trigrams: [('Learning', 'classifier', 'systems'), ('classifier', 'systems', 'LCS'), ('systems', 'LCS', 'are'), ('LCS', 'are', 'a'), ('are', 'a', 'family'), ('a', 'family', 'of'), ('family', 'of', 'rulebased'), ('of', 'rulebased', 'machine'), ('rulebased', 'machine', 'learning'), ('machine', 'learning', 'algorithms'), ('learning', 'algorithms', 'that'), ('algorithms', 'that', 'combine'), ('that', 'combine', 'a'), ('combine', 'a', 'discovery'), ('a', 'discovery', 'component'), ('discovery', 'component', 'typically'), ('component', 'typically', 'a'), ('typically', 'a', 'genetic'), ('a', 'genetic', 'algorithm'), ('genetic', 'algorithm', 'with'), ('algorithm', 'with', 'a'), ('with', 'a', 'learning'), ('a', 'learning', 'component'), ('learning', 'component', 'performing'), ('component', 'performing', 'either'), ('performing', 'either', 'supervised'), ('either', 'supervised', 'learning'), ('supervised', 'learning', 'reinforcement'), ('learning', 'reinforcement', 'learning'), ('reinforcement', 'learning', 'or'), ('learning', 'or', 'unsupervised'), ('or', 'unsupervised', 'learning'), ('unsupervised', 'learning', 'They'), ('learning', 'They', 'seek'), ('They', 'seek', 'to'), ('seek', 'to', 'identify'), ('to', 'identify', 'a'), ('identify', 'a', 'set'), ('a', 'set', 'of'), ('set', 'of', 'contextdependent'), ('of', 'contextdependent', 'rules'), ('contextdependent', 'rules', 'that'), ('rules', 'that', 'collectively'), ('that', 'collectively', 'store'), ('collectively', 'store', 'and'), ('store', 'and', 'apply'), ('and', 'apply', 'knowledge'), ('apply', 'knowledge', 'in'), ('knowledge', 'in', 'a'), ('in', 'a', 'piecewise'), ('a', 'piecewise', 'manner'), ('piecewise', 'manner', 'in'), ('manner', 'in', 'order'), ('in', 'order', 'to'), ('order', 'to', 'make'), ('to', 'make', 'predictions')]\n",
      "\n",
      "Document: Inductive logic programming ILP is an approach to rule learning using logic programming as a uniform representation for input examples background knowledge and hypotheses Given an encoding of the known background knowledge and a set of examples represented as a logical database of facts an ILP system will derive a hypothesized logic program that entails all positive and no negative examples Inductive programming is a related field that considers any kind of programming language for representing hypotheses and not only logic programming such as functional programs\n",
      "\n",
      "\n",
      "Unigrams: [('Inductive',), ('logic',), ('programming',), ('ILP',), ('is',), ('an',), ('approach',), ('to',), ('rule',), ('learning',), ('using',), ('logic',), ('programming',), ('as',), ('a',), ('uniform',), ('representation',), ('for',), ('input',), ('examples',), ('background',), ('knowledge',), ('and',), ('hypotheses',), ('Given',), ('an',), ('encoding',), ('of',), ('the',), ('known',), ('background',), ('knowledge',), ('and',), ('a',), ('set',), ('of',), ('examples',), ('represented',), ('as',), ('a',), ('logical',), ('database',), ('of',), ('facts',), ('an',), ('ILP',), ('system',), ('will',), ('derive',), ('a',), ('hypothesized',), ('logic',), ('program',), ('that',), ('entails',), ('all',), ('positive',), ('and',), ('no',), ('negative',), ('examples',), ('Inductive',), ('programming',), ('is',), ('a',), ('related',), ('field',), ('that',), ('considers',), ('any',), ('kind',), ('of',), ('programming',), ('language',), ('for',), ('representing',), ('hypotheses',), ('and',), ('not',), ('only',), ('logic',), ('programming',), ('such',), ('as',), ('functional',), ('programs',)]\n",
      "\n",
      "Bigrams: [('Inductive', 'logic'), ('logic', 'programming'), ('programming', 'ILP'), ('ILP', 'is'), ('is', 'an'), ('an', 'approach'), ('approach', 'to'), ('to', 'rule'), ('rule', 'learning'), ('learning', 'using'), ('using', 'logic'), ('logic', 'programming'), ('programming', 'as'), ('as', 'a'), ('a', 'uniform'), ('uniform', 'representation'), ('representation', 'for'), ('for', 'input'), ('input', 'examples'), ('examples', 'background'), ('background', 'knowledge'), ('knowledge', 'and'), ('and', 'hypotheses'), ('hypotheses', 'Given'), ('Given', 'an'), ('an', 'encoding'), ('encoding', 'of'), ('of', 'the'), ('the', 'known'), ('known', 'background'), ('background', 'knowledge'), ('knowledge', 'and'), ('and', 'a'), ('a', 'set'), ('set', 'of'), ('of', 'examples'), ('examples', 'represented'), ('represented', 'as'), ('as', 'a'), ('a', 'logical'), ('logical', 'database'), ('database', 'of'), ('of', 'facts'), ('facts', 'an'), ('an', 'ILP'), ('ILP', 'system'), ('system', 'will'), ('will', 'derive'), ('derive', 'a'), ('a', 'hypothesized'), ('hypothesized', 'logic'), ('logic', 'program'), ('program', 'that'), ('that', 'entails'), ('entails', 'all'), ('all', 'positive'), ('positive', 'and'), ('and', 'no'), ('no', 'negative'), ('negative', 'examples'), ('examples', 'Inductive'), ('Inductive', 'programming'), ('programming', 'is'), ('is', 'a'), ('a', 'related'), ('related', 'field'), ('field', 'that'), ('that', 'considers'), ('considers', 'any'), ('any', 'kind'), ('kind', 'of'), ('of', 'programming'), ('programming', 'language'), ('language', 'for'), ('for', 'representing'), ('representing', 'hypotheses'), ('hypotheses', 'and'), ('and', 'not'), ('not', 'only'), ('only', 'logic'), ('logic', 'programming'), ('programming', 'such'), ('such', 'as'), ('as', 'functional'), ('functional', 'programs')]\n",
      "\n",
      "Trigrams: [('Inductive', 'logic', 'programming'), ('logic', 'programming', 'ILP'), ('programming', 'ILP', 'is'), ('ILP', 'is', 'an'), ('is', 'an', 'approach'), ('an', 'approach', 'to'), ('approach', 'to', 'rule'), ('to', 'rule', 'learning'), ('rule', 'learning', 'using'), ('learning', 'using', 'logic'), ('using', 'logic', 'programming'), ('logic', 'programming', 'as'), ('programming', 'as', 'a'), ('as', 'a', 'uniform'), ('a', 'uniform', 'representation'), ('uniform', 'representation', 'for'), ('representation', 'for', 'input'), ('for', 'input', 'examples'), ('input', 'examples', 'background'), ('examples', 'background', 'knowledge'), ('background', 'knowledge', 'and'), ('knowledge', 'and', 'hypotheses'), ('and', 'hypotheses', 'Given'), ('hypotheses', 'Given', 'an'), ('Given', 'an', 'encoding'), ('an', 'encoding', 'of'), ('encoding', 'of', 'the'), ('of', 'the', 'known'), ('the', 'known', 'background'), ('known', 'background', 'knowledge'), ('background', 'knowledge', 'and'), ('knowledge', 'and', 'a'), ('and', 'a', 'set'), ('a', 'set', 'of'), ('set', 'of', 'examples'), ('of', 'examples', 'represented'), ('examples', 'represented', 'as'), ('represented', 'as', 'a'), ('as', 'a', 'logical'), ('a', 'logical', 'database'), ('logical', 'database', 'of'), ('database', 'of', 'facts'), ('of', 'facts', 'an'), ('facts', 'an', 'ILP'), ('an', 'ILP', 'system'), ('ILP', 'system', 'will'), ('system', 'will', 'derive'), ('will', 'derive', 'a'), ('derive', 'a', 'hypothesized'), ('a', 'hypothesized', 'logic'), ('hypothesized', 'logic', 'program'), ('logic', 'program', 'that'), ('program', 'that', 'entails'), ('that', 'entails', 'all'), ('entails', 'all', 'positive'), ('all', 'positive', 'and'), ('positive', 'and', 'no'), ('and', 'no', 'negative'), ('no', 'negative', 'examples'), ('negative', 'examples', 'Inductive'), ('examples', 'Inductive', 'programming'), ('Inductive', 'programming', 'is'), ('programming', 'is', 'a'), ('is', 'a', 'related'), ('a', 'related', 'field'), ('related', 'field', 'that'), ('field', 'that', 'considers'), ('that', 'considers', 'any'), ('considers', 'any', 'kind'), ('any', 'kind', 'of'), ('kind', 'of', 'programming'), ('of', 'programming', 'language'), ('programming', 'language', 'for'), ('language', 'for', 'representing'), ('for', 'representing', 'hypotheses'), ('representing', 'hypotheses', 'and'), ('hypotheses', 'and', 'not'), ('and', 'not', 'only'), ('not', 'only', 'logic'), ('only', 'logic', 'programming'), ('logic', 'programming', 'such'), ('programming', 'such', 'as'), ('such', 'as', 'functional'), ('as', 'functional', 'programs')]\n",
      "\n",
      "Document: Inductive logic programming is particularly useful in bioinformatics and natural language processing Gordon Plotkin and Ehud Shapiro laid the initial theoretical foundation for inductive machine learning in a logical setting Shapiro built their first implementation Model Inference System in  a Prolog program that inductively inferred logic programs from positive and negative examples The term inductive here refers to philosophical induction suggesting a theory to explain observed facts rather than mathematical induction proving a property for all members of a wellordered set\n",
      "\n",
      "\n",
      "Unigrams: [('Inductive',), ('logic',), ('programming',), ('is',), ('particularly',), ('useful',), ('in',), ('bioinformatics',), ('and',), ('natural',), ('language',), ('processing',), ('Gordon',), ('Plotkin',), ('and',), ('Ehud',), ('Shapiro',), ('laid',), ('the',), ('initial',), ('theoretical',), ('foundation',), ('for',), ('inductive',), ('machine',), ('learning',), ('in',), ('a',), ('logical',), ('setting',), ('Shapiro',), ('built',), ('their',), ('first',), ('implementation',), ('Model',), ('Inference',), ('System',), ('in',), ('a',), ('Prolog',), ('program',), ('that',), ('inductively',), ('inferred',), ('logic',), ('programs',), ('from',), ('positive',), ('and',), ('negative',), ('examples',), ('The',), ('term',), ('inductive',), ('here',), ('refers',), ('to',), ('philosophical',), ('induction',), ('suggesting',), ('a',), ('theory',), ('to',), ('explain',), ('observed',), ('facts',), ('rather',), ('than',), ('mathematical',), ('induction',), ('proving',), ('a',), ('property',), ('for',), ('all',), ('members',), ('of',), ('a',), ('wellordered',), ('set',)]\n",
      "\n",
      "Bigrams: [('Inductive', 'logic'), ('logic', 'programming'), ('programming', 'is'), ('is', 'particularly'), ('particularly', 'useful'), ('useful', 'in'), ('in', 'bioinformatics'), ('bioinformatics', 'and'), ('and', 'natural'), ('natural', 'language'), ('language', 'processing'), ('processing', 'Gordon'), ('Gordon', 'Plotkin'), ('Plotkin', 'and'), ('and', 'Ehud'), ('Ehud', 'Shapiro'), ('Shapiro', 'laid'), ('laid', 'the'), ('the', 'initial'), ('initial', 'theoretical'), ('theoretical', 'foundation'), ('foundation', 'for'), ('for', 'inductive'), ('inductive', 'machine'), ('machine', 'learning'), ('learning', 'in'), ('in', 'a'), ('a', 'logical'), ('logical', 'setting'), ('setting', 'Shapiro'), ('Shapiro', 'built'), ('built', 'their'), ('their', 'first'), ('first', 'implementation'), ('implementation', 'Model'), ('Model', 'Inference'), ('Inference', 'System'), ('System', 'in'), ('in', 'a'), ('a', 'Prolog'), ('Prolog', 'program'), ('program', 'that'), ('that', 'inductively'), ('inductively', 'inferred'), ('inferred', 'logic'), ('logic', 'programs'), ('programs', 'from'), ('from', 'positive'), ('positive', 'and'), ('and', 'negative'), ('negative', 'examples'), ('examples', 'The'), ('The', 'term'), ('term', 'inductive'), ('inductive', 'here'), ('here', 'refers'), ('refers', 'to'), ('to', 'philosophical'), ('philosophical', 'induction'), ('induction', 'suggesting'), ('suggesting', 'a'), ('a', 'theory'), ('theory', 'to'), ('to', 'explain'), ('explain', 'observed'), ('observed', 'facts'), ('facts', 'rather'), ('rather', 'than'), ('than', 'mathematical'), ('mathematical', 'induction'), ('induction', 'proving'), ('proving', 'a'), ('a', 'property'), ('property', 'for'), ('for', 'all'), ('all', 'members'), ('members', 'of'), ('of', 'a'), ('a', 'wellordered'), ('wellordered', 'set')]\n",
      "\n",
      "Trigrams: [('Inductive', 'logic', 'programming'), ('logic', 'programming', 'is'), ('programming', 'is', 'particularly'), ('is', 'particularly', 'useful'), ('particularly', 'useful', 'in'), ('useful', 'in', 'bioinformatics'), ('in', 'bioinformatics', 'and'), ('bioinformatics', 'and', 'natural'), ('and', 'natural', 'language'), ('natural', 'language', 'processing'), ('language', 'processing', 'Gordon'), ('processing', 'Gordon', 'Plotkin'), ('Gordon', 'Plotkin', 'and'), ('Plotkin', 'and', 'Ehud'), ('and', 'Ehud', 'Shapiro'), ('Ehud', 'Shapiro', 'laid'), ('Shapiro', 'laid', 'the'), ('laid', 'the', 'initial'), ('the', 'initial', 'theoretical'), ('initial', 'theoretical', 'foundation'), ('theoretical', 'foundation', 'for'), ('foundation', 'for', 'inductive'), ('for', 'inductive', 'machine'), ('inductive', 'machine', 'learning'), ('machine', 'learning', 'in'), ('learning', 'in', 'a'), ('in', 'a', 'logical'), ('a', 'logical', 'setting'), ('logical', 'setting', 'Shapiro'), ('setting', 'Shapiro', 'built'), ('Shapiro', 'built', 'their'), ('built', 'their', 'first'), ('their', 'first', 'implementation'), ('first', 'implementation', 'Model'), ('implementation', 'Model', 'Inference'), ('Model', 'Inference', 'System'), ('Inference', 'System', 'in'), ('System', 'in', 'a'), ('in', 'a', 'Prolog'), ('a', 'Prolog', 'program'), ('Prolog', 'program', 'that'), ('program', 'that', 'inductively'), ('that', 'inductively', 'inferred'), ('inductively', 'inferred', 'logic'), ('inferred', 'logic', 'programs'), ('logic', 'programs', 'from'), ('programs', 'from', 'positive'), ('from', 'positive', 'and'), ('positive', 'and', 'negative'), ('and', 'negative', 'examples'), ('negative', 'examples', 'The'), ('examples', 'The', 'term'), ('The', 'term', 'inductive'), ('term', 'inductive', 'here'), ('inductive', 'here', 'refers'), ('here', 'refers', 'to'), ('refers', 'to', 'philosophical'), ('to', 'philosophical', 'induction'), ('philosophical', 'induction', 'suggesting'), ('induction', 'suggesting', 'a'), ('suggesting', 'a', 'theory'), ('a', 'theory', 'to'), ('theory', 'to', 'explain'), ('to', 'explain', 'observed'), ('explain', 'observed', 'facts'), ('observed', 'facts', 'rather'), ('facts', 'rather', 'than'), ('rather', 'than', 'mathematical'), ('than', 'mathematical', 'induction'), ('mathematical', 'induction', 'proving'), ('induction', 'proving', 'a'), ('proving', 'a', 'property'), ('a', 'property', 'for'), ('property', 'for', 'all'), ('for', 'all', 'members'), ('all', 'members', 'of'), ('members', 'of', 'a'), ('of', 'a', 'wellordered'), ('a', 'wellordered', 'set')]\n",
      "\n",
      "Document: A machine learning model is a type of mathematical model that once trained on a given dataset can be used to make predictions or classifications on new data During training a learning algorithm iteratively adjusts the models internal parameters to minimise errors in its predictions By extension the term model can refer to several levels of specificity from a general class of models and their associated learning algorithms to a fully trained model with all its internal parameters tuned\n",
      "\n",
      "\n",
      "Unigrams: [('A',), ('machine',), ('learning',), ('model',), ('is',), ('a',), ('type',), ('of',), ('mathematical',), ('model',), ('that',), ('once',), ('trained',), ('on',), ('a',), ('given',), ('dataset',), ('can',), ('be',), ('used',), ('to',), ('make',), ('predictions',), ('or',), ('classifications',), ('on',), ('new',), ('data',), ('During',), ('training',), ('a',), ('learning',), ('algorithm',), ('iteratively',), ('adjusts',), ('the',), ('models',), ('internal',), ('parameters',), ('to',), ('minimise',), ('errors',), ('in',), ('its',), ('predictions',), ('By',), ('extension',), ('the',), ('term',), ('model',), ('can',), ('refer',), ('to',), ('several',), ('levels',), ('of',), ('specificity',), ('from',), ('a',), ('general',), ('class',), ('of',), ('models',), ('and',), ('their',), ('associated',), ('learning',), ('algorithms',), ('to',), ('a',), ('fully',), ('trained',), ('model',), ('with',), ('all',), ('its',), ('internal',), ('parameters',), ('tuned',)]\n",
      "\n",
      "Bigrams: [('A', 'machine'), ('machine', 'learning'), ('learning', 'model'), ('model', 'is'), ('is', 'a'), ('a', 'type'), ('type', 'of'), ('of', 'mathematical'), ('mathematical', 'model'), ('model', 'that'), ('that', 'once'), ('once', 'trained'), ('trained', 'on'), ('on', 'a'), ('a', 'given'), ('given', 'dataset'), ('dataset', 'can'), ('can', 'be'), ('be', 'used'), ('used', 'to'), ('to', 'make'), ('make', 'predictions'), ('predictions', 'or'), ('or', 'classifications'), ('classifications', 'on'), ('on', 'new'), ('new', 'data'), ('data', 'During'), ('During', 'training'), ('training', 'a'), ('a', 'learning'), ('learning', 'algorithm'), ('algorithm', 'iteratively'), ('iteratively', 'adjusts'), ('adjusts', 'the'), ('the', 'models'), ('models', 'internal'), ('internal', 'parameters'), ('parameters', 'to'), ('to', 'minimise'), ('minimise', 'errors'), ('errors', 'in'), ('in', 'its'), ('its', 'predictions'), ('predictions', 'By'), ('By', 'extension'), ('extension', 'the'), ('the', 'term'), ('term', 'model'), ('model', 'can'), ('can', 'refer'), ('refer', 'to'), ('to', 'several'), ('several', 'levels'), ('levels', 'of'), ('of', 'specificity'), ('specificity', 'from'), ('from', 'a'), ('a', 'general'), ('general', 'class'), ('class', 'of'), ('of', 'models'), ('models', 'and'), ('and', 'their'), ('their', 'associated'), ('associated', 'learning'), ('learning', 'algorithms'), ('algorithms', 'to'), ('to', 'a'), ('a', 'fully'), ('fully', 'trained'), ('trained', 'model'), ('model', 'with'), ('with', 'all'), ('all', 'its'), ('its', 'internal'), ('internal', 'parameters'), ('parameters', 'tuned')]\n",
      "\n",
      "Trigrams: [('A', 'machine', 'learning'), ('machine', 'learning', 'model'), ('learning', 'model', 'is'), ('model', 'is', 'a'), ('is', 'a', 'type'), ('a', 'type', 'of'), ('type', 'of', 'mathematical'), ('of', 'mathematical', 'model'), ('mathematical', 'model', 'that'), ('model', 'that', 'once'), ('that', 'once', 'trained'), ('once', 'trained', 'on'), ('trained', 'on', 'a'), ('on', 'a', 'given'), ('a', 'given', 'dataset'), ('given', 'dataset', 'can'), ('dataset', 'can', 'be'), ('can', 'be', 'used'), ('be', 'used', 'to'), ('used', 'to', 'make'), ('to', 'make', 'predictions'), ('make', 'predictions', 'or'), ('predictions', 'or', 'classifications'), ('or', 'classifications', 'on'), ('classifications', 'on', 'new'), ('on', 'new', 'data'), ('new', 'data', 'During'), ('data', 'During', 'training'), ('During', 'training', 'a'), ('training', 'a', 'learning'), ('a', 'learning', 'algorithm'), ('learning', 'algorithm', 'iteratively'), ('algorithm', 'iteratively', 'adjusts'), ('iteratively', 'adjusts', 'the'), ('adjusts', 'the', 'models'), ('the', 'models', 'internal'), ('models', 'internal', 'parameters'), ('internal', 'parameters', 'to'), ('parameters', 'to', 'minimise'), ('to', 'minimise', 'errors'), ('minimise', 'errors', 'in'), ('errors', 'in', 'its'), ('in', 'its', 'predictions'), ('its', 'predictions', 'By'), ('predictions', 'By', 'extension'), ('By', 'extension', 'the'), ('extension', 'the', 'term'), ('the', 'term', 'model'), ('term', 'model', 'can'), ('model', 'can', 'refer'), ('can', 'refer', 'to'), ('refer', 'to', 'several'), ('to', 'several', 'levels'), ('several', 'levels', 'of'), ('levels', 'of', 'specificity'), ('of', 'specificity', 'from'), ('specificity', 'from', 'a'), ('from', 'a', 'general'), ('a', 'general', 'class'), ('general', 'class', 'of'), ('class', 'of', 'models'), ('of', 'models', 'and'), ('models', 'and', 'their'), ('and', 'their', 'associated'), ('their', 'associated', 'learning'), ('associated', 'learning', 'algorithms'), ('learning', 'algorithms', 'to'), ('algorithms', 'to', 'a'), ('to', 'a', 'fully'), ('a', 'fully', 'trained'), ('fully', 'trained', 'model'), ('trained', 'model', 'with'), ('model', 'with', 'all'), ('with', 'all', 'its'), ('all', 'its', 'internal'), ('its', 'internal', 'parameters'), ('internal', 'parameters', 'tuned')]\n",
      "\n",
      "Document: Various types of models have been used and researched for machine learning systems picking the best model for a task is called model selection\n",
      "\n",
      "\n",
      "Unigrams: [('Various',), ('types',), ('of',), ('models',), ('have',), ('been',), ('used',), ('and',), ('researched',), ('for',), ('machine',), ('learning',), ('systems',), ('picking',), ('the',), ('best',), ('model',), ('for',), ('a',), ('task',), ('is',), ('called',), ('model',), ('selection',)]\n",
      "\n",
      "Bigrams: [('Various', 'types'), ('types', 'of'), ('of', 'models'), ('models', 'have'), ('have', 'been'), ('been', 'used'), ('used', 'and'), ('and', 'researched'), ('researched', 'for'), ('for', 'machine'), ('machine', 'learning'), ('learning', 'systems'), ('systems', 'picking'), ('picking', 'the'), ('the', 'best'), ('best', 'model'), ('model', 'for'), ('for', 'a'), ('a', 'task'), ('task', 'is'), ('is', 'called'), ('called', 'model'), ('model', 'selection')]\n",
      "\n",
      "Trigrams: [('Various', 'types', 'of'), ('types', 'of', 'models'), ('of', 'models', 'have'), ('models', 'have', 'been'), ('have', 'been', 'used'), ('been', 'used', 'and'), ('used', 'and', 'researched'), ('and', 'researched', 'for'), ('researched', 'for', 'machine'), ('for', 'machine', 'learning'), ('machine', 'learning', 'systems'), ('learning', 'systems', 'picking'), ('systems', 'picking', 'the'), ('picking', 'the', 'best'), ('the', 'best', 'model'), ('best', 'model', 'for'), ('model', 'for', 'a'), ('for', 'a', 'task'), ('a', 'task', 'is'), ('task', 'is', 'called'), ('is', 'called', 'model'), ('called', 'model', 'selection')]\n",
      "\n",
      "Document: Artificial neural networks ANNs or connectionist systems are computing systems vaguely inspired by the biological neural networks that constitute animal brains Such systems learn to perform tasks by considering examples generally without being programmed with any taskspecific rules\n",
      "\n",
      "\n",
      "Unigrams: [('Artificial',), ('neural',), ('networks',), ('ANNs',), ('or',), ('connectionist',), ('systems',), ('are',), ('computing',), ('systems',), ('vaguely',), ('inspired',), ('by',), ('the',), ('biological',), ('neural',), ('networks',), ('that',), ('constitute',), ('animal',), ('brains',), ('Such',), ('systems',), ('learn',), ('to',), ('perform',), ('tasks',), ('by',), ('considering',), ('examples',), ('generally',), ('without',), ('being',), ('programmed',), ('with',), ('any',), ('taskspecific',), ('rules',)]\n",
      "\n",
      "Bigrams: [('Artificial', 'neural'), ('neural', 'networks'), ('networks', 'ANNs'), ('ANNs', 'or'), ('or', 'connectionist'), ('connectionist', 'systems'), ('systems', 'are'), ('are', 'computing'), ('computing', 'systems'), ('systems', 'vaguely'), ('vaguely', 'inspired'), ('inspired', 'by'), ('by', 'the'), ('the', 'biological'), ('biological', 'neural'), ('neural', 'networks'), ('networks', 'that'), ('that', 'constitute'), ('constitute', 'animal'), ('animal', 'brains'), ('brains', 'Such'), ('Such', 'systems'), ('systems', 'learn'), ('learn', 'to'), ('to', 'perform'), ('perform', 'tasks'), ('tasks', 'by'), ('by', 'considering'), ('considering', 'examples'), ('examples', 'generally'), ('generally', 'without'), ('without', 'being'), ('being', 'programmed'), ('programmed', 'with'), ('with', 'any'), ('any', 'taskspecific'), ('taskspecific', 'rules')]\n",
      "\n",
      "Trigrams: [('Artificial', 'neural', 'networks'), ('neural', 'networks', 'ANNs'), ('networks', 'ANNs', 'or'), ('ANNs', 'or', 'connectionist'), ('or', 'connectionist', 'systems'), ('connectionist', 'systems', 'are'), ('systems', 'are', 'computing'), ('are', 'computing', 'systems'), ('computing', 'systems', 'vaguely'), ('systems', 'vaguely', 'inspired'), ('vaguely', 'inspired', 'by'), ('inspired', 'by', 'the'), ('by', 'the', 'biological'), ('the', 'biological', 'neural'), ('biological', 'neural', 'networks'), ('neural', 'networks', 'that'), ('networks', 'that', 'constitute'), ('that', 'constitute', 'animal'), ('constitute', 'animal', 'brains'), ('animal', 'brains', 'Such'), ('brains', 'Such', 'systems'), ('Such', 'systems', 'learn'), ('systems', 'learn', 'to'), ('learn', 'to', 'perform'), ('to', 'perform', 'tasks'), ('perform', 'tasks', 'by'), ('tasks', 'by', 'considering'), ('by', 'considering', 'examples'), ('considering', 'examples', 'generally'), ('examples', 'generally', 'without'), ('generally', 'without', 'being'), ('without', 'being', 'programmed'), ('being', 'programmed', 'with'), ('programmed', 'with', 'any'), ('with', 'any', 'taskspecific'), ('any', 'taskspecific', 'rules')]\n",
      "\n",
      "Document: An ANN is a model based on a collection of connected units or nodes called artificial neurons which loosely model the neurons in a biological brain Each connection like the synapses in a biological brain can transmit information a signal from one artificial neuron to another An artificial neuron that receives a signal can process it and then signal additional artificial neurons connected to it In common ANN implementations the signal at a connection between artificial neurons is a real number and the output of each artificial neuron is computed by some nonlinear function of the sum of its inputs The connections between artificial neurons are called edges Artificial neurons and edges typically have a weight that adjusts as learning proceeds The weight increases or decreases the strength of the signal at a connection Artificial neurons may have a threshold such that the signal is only sent if the aggregate signal crosses that threshold Typically artificial neurons are aggregated into layers Different layers may perform different kinds of transformations on their inputs Signals travel from the first layer the input layer to the last layer the output layer possibly after traversing the layers multiple times\n",
      "\n",
      "\n",
      "Unigrams: [('An',), ('ANN',), ('is',), ('a',), ('model',), ('based',), ('on',), ('a',), ('collection',), ('of',), ('connected',), ('units',), ('or',), ('nodes',), ('called',), ('artificial',), ('neurons',), ('which',), ('loosely',), ('model',), ('the',), ('neurons',), ('in',), ('a',), ('biological',), ('brain',), ('Each',), ('connection',), ('like',), ('the',), ('synapses',), ('in',), ('a',), ('biological',), ('brain',), ('can',), ('transmit',), ('information',), ('a',), ('signal',), ('from',), ('one',), ('artificial',), ('neuron',), ('to',), ('another',), ('An',), ('artificial',), ('neuron',), ('that',), ('receives',), ('a',), ('signal',), ('can',), ('process',), ('it',), ('and',), ('then',), ('signal',), ('additional',), ('artificial',), ('neurons',), ('connected',), ('to',), ('it',), ('In',), ('common',), ('ANN',), ('implementations',), ('the',), ('signal',), ('at',), ('a',), ('connection',), ('between',), ('artificial',), ('neurons',), ('is',), ('a',), ('real',), ('number',), ('and',), ('the',), ('output',), ('of',), ('each',), ('artificial',), ('neuron',), ('is',), ('computed',), ('by',), ('some',), ('nonlinear',), ('function',), ('of',), ('the',), ('sum',), ('of',), ('its',), ('inputs',), ('The',), ('connections',), ('between',), ('artificial',), ('neurons',), ('are',), ('called',), ('edges',), ('Artificial',), ('neurons',), ('and',), ('edges',), ('typically',), ('have',), ('a',), ('weight',), ('that',), ('adjusts',), ('as',), ('learning',), ('proceeds',), ('The',), ('weight',), ('increases',), ('or',), ('decreases',), ('the',), ('strength',), ('of',), ('the',), ('signal',), ('at',), ('a',), ('connection',), ('Artificial',), ('neurons',), ('may',), ('have',), ('a',), ('threshold',), ('such',), ('that',), ('the',), ('signal',), ('is',), ('only',), ('sent',), ('if',), ('the',), ('aggregate',), ('signal',), ('crosses',), ('that',), ('threshold',), ('Typically',), ('artificial',), ('neurons',), ('are',), ('aggregated',), ('into',), ('layers',), ('Different',), ('layers',), ('may',), ('perform',), ('different',), ('kinds',), ('of',), ('transformations',), ('on',), ('their',), ('inputs',), ('Signals',), ('travel',), ('from',), ('the',), ('first',), ('layer',), ('the',), ('input',), ('layer',), ('to',), ('the',), ('last',), ('layer',), ('the',), ('output',), ('layer',), ('possibly',), ('after',), ('traversing',), ('the',), ('layers',), ('multiple',), ('times',)]\n",
      "\n",
      "Bigrams: [('An', 'ANN'), ('ANN', 'is'), ('is', 'a'), ('a', 'model'), ('model', 'based'), ('based', 'on'), ('on', 'a'), ('a', 'collection'), ('collection', 'of'), ('of', 'connected'), ('connected', 'units'), ('units', 'or'), ('or', 'nodes'), ('nodes', 'called'), ('called', 'artificial'), ('artificial', 'neurons'), ('neurons', 'which'), ('which', 'loosely'), ('loosely', 'model'), ('model', 'the'), ('the', 'neurons'), ('neurons', 'in'), ('in', 'a'), ('a', 'biological'), ('biological', 'brain'), ('brain', 'Each'), ('Each', 'connection'), ('connection', 'like'), ('like', 'the'), ('the', 'synapses'), ('synapses', 'in'), ('in', 'a'), ('a', 'biological'), ('biological', 'brain'), ('brain', 'can'), ('can', 'transmit'), ('transmit', 'information'), ('information', 'a'), ('a', 'signal'), ('signal', 'from'), ('from', 'one'), ('one', 'artificial'), ('artificial', 'neuron'), ('neuron', 'to'), ('to', 'another'), ('another', 'An'), ('An', 'artificial'), ('artificial', 'neuron'), ('neuron', 'that'), ('that', 'receives'), ('receives', 'a'), ('a', 'signal'), ('signal', 'can'), ('can', 'process'), ('process', 'it'), ('it', 'and'), ('and', 'then'), ('then', 'signal'), ('signal', 'additional'), ('additional', 'artificial'), ('artificial', 'neurons'), ('neurons', 'connected'), ('connected', 'to'), ('to', 'it'), ('it', 'In'), ('In', 'common'), ('common', 'ANN'), ('ANN', 'implementations'), ('implementations', 'the'), ('the', 'signal'), ('signal', 'at'), ('at', 'a'), ('a', 'connection'), ('connection', 'between'), ('between', 'artificial'), ('artificial', 'neurons'), ('neurons', 'is'), ('is', 'a'), ('a', 'real'), ('real', 'number'), ('number', 'and'), ('and', 'the'), ('the', 'output'), ('output', 'of'), ('of', 'each'), ('each', 'artificial'), ('artificial', 'neuron'), ('neuron', 'is'), ('is', 'computed'), ('computed', 'by'), ('by', 'some'), ('some', 'nonlinear'), ('nonlinear', 'function'), ('function', 'of'), ('of', 'the'), ('the', 'sum'), ('sum', 'of'), ('of', 'its'), ('its', 'inputs'), ('inputs', 'The'), ('The', 'connections'), ('connections', 'between'), ('between', 'artificial'), ('artificial', 'neurons'), ('neurons', 'are'), ('are', 'called'), ('called', 'edges'), ('edges', 'Artificial'), ('Artificial', 'neurons'), ('neurons', 'and'), ('and', 'edges'), ('edges', 'typically'), ('typically', 'have'), ('have', 'a'), ('a', 'weight'), ('weight', 'that'), ('that', 'adjusts'), ('adjusts', 'as'), ('as', 'learning'), ('learning', 'proceeds'), ('proceeds', 'The'), ('The', 'weight'), ('weight', 'increases'), ('increases', 'or'), ('or', 'decreases'), ('decreases', 'the'), ('the', 'strength'), ('strength', 'of'), ('of', 'the'), ('the', 'signal'), ('signal', 'at'), ('at', 'a'), ('a', 'connection'), ('connection', 'Artificial'), ('Artificial', 'neurons'), ('neurons', 'may'), ('may', 'have'), ('have', 'a'), ('a', 'threshold'), ('threshold', 'such'), ('such', 'that'), ('that', 'the'), ('the', 'signal'), ('signal', 'is'), ('is', 'only'), ('only', 'sent'), ('sent', 'if'), ('if', 'the'), ('the', 'aggregate'), ('aggregate', 'signal'), ('signal', 'crosses'), ('crosses', 'that'), ('that', 'threshold'), ('threshold', 'Typically'), ('Typically', 'artificial'), ('artificial', 'neurons'), ('neurons', 'are'), ('are', 'aggregated'), ('aggregated', 'into'), ('into', 'layers'), ('layers', 'Different'), ('Different', 'layers'), ('layers', 'may'), ('may', 'perform'), ('perform', 'different'), ('different', 'kinds'), ('kinds', 'of'), ('of', 'transformations'), ('transformations', 'on'), ('on', 'their'), ('their', 'inputs'), ('inputs', 'Signals'), ('Signals', 'travel'), ('travel', 'from'), ('from', 'the'), ('the', 'first'), ('first', 'layer'), ('layer', 'the'), ('the', 'input'), ('input', 'layer'), ('layer', 'to'), ('to', 'the'), ('the', 'last'), ('last', 'layer'), ('layer', 'the'), ('the', 'output'), ('output', 'layer'), ('layer', 'possibly'), ('possibly', 'after'), ('after', 'traversing'), ('traversing', 'the'), ('the', 'layers'), ('layers', 'multiple'), ('multiple', 'times')]\n",
      "\n",
      "Trigrams: [('An', 'ANN', 'is'), ('ANN', 'is', 'a'), ('is', 'a', 'model'), ('a', 'model', 'based'), ('model', 'based', 'on'), ('based', 'on', 'a'), ('on', 'a', 'collection'), ('a', 'collection', 'of'), ('collection', 'of', 'connected'), ('of', 'connected', 'units'), ('connected', 'units', 'or'), ('units', 'or', 'nodes'), ('or', 'nodes', 'called'), ('nodes', 'called', 'artificial'), ('called', 'artificial', 'neurons'), ('artificial', 'neurons', 'which'), ('neurons', 'which', 'loosely'), ('which', 'loosely', 'model'), ('loosely', 'model', 'the'), ('model', 'the', 'neurons'), ('the', 'neurons', 'in'), ('neurons', 'in', 'a'), ('in', 'a', 'biological'), ('a', 'biological', 'brain'), ('biological', 'brain', 'Each'), ('brain', 'Each', 'connection'), ('Each', 'connection', 'like'), ('connection', 'like', 'the'), ('like', 'the', 'synapses'), ('the', 'synapses', 'in'), ('synapses', 'in', 'a'), ('in', 'a', 'biological'), ('a', 'biological', 'brain'), ('biological', 'brain', 'can'), ('brain', 'can', 'transmit'), ('can', 'transmit', 'information'), ('transmit', 'information', 'a'), ('information', 'a', 'signal'), ('a', 'signal', 'from'), ('signal', 'from', 'one'), ('from', 'one', 'artificial'), ('one', 'artificial', 'neuron'), ('artificial', 'neuron', 'to'), ('neuron', 'to', 'another'), ('to', 'another', 'An'), ('another', 'An', 'artificial'), ('An', 'artificial', 'neuron'), ('artificial', 'neuron', 'that'), ('neuron', 'that', 'receives'), ('that', 'receives', 'a'), ('receives', 'a', 'signal'), ('a', 'signal', 'can'), ('signal', 'can', 'process'), ('can', 'process', 'it'), ('process', 'it', 'and'), ('it', 'and', 'then'), ('and', 'then', 'signal'), ('then', 'signal', 'additional'), ('signal', 'additional', 'artificial'), ('additional', 'artificial', 'neurons'), ('artificial', 'neurons', 'connected'), ('neurons', 'connected', 'to'), ('connected', 'to', 'it'), ('to', 'it', 'In'), ('it', 'In', 'common'), ('In', 'common', 'ANN'), ('common', 'ANN', 'implementations'), ('ANN', 'implementations', 'the'), ('implementations', 'the', 'signal'), ('the', 'signal', 'at'), ('signal', 'at', 'a'), ('at', 'a', 'connection'), ('a', 'connection', 'between'), ('connection', 'between', 'artificial'), ('between', 'artificial', 'neurons'), ('artificial', 'neurons', 'is'), ('neurons', 'is', 'a'), ('is', 'a', 'real'), ('a', 'real', 'number'), ('real', 'number', 'and'), ('number', 'and', 'the'), ('and', 'the', 'output'), ('the', 'output', 'of'), ('output', 'of', 'each'), ('of', 'each', 'artificial'), ('each', 'artificial', 'neuron'), ('artificial', 'neuron', 'is'), ('neuron', 'is', 'computed'), ('is', 'computed', 'by'), ('computed', 'by', 'some'), ('by', 'some', 'nonlinear'), ('some', 'nonlinear', 'function'), ('nonlinear', 'function', 'of'), ('function', 'of', 'the'), ('of', 'the', 'sum'), ('the', 'sum', 'of'), ('sum', 'of', 'its'), ('of', 'its', 'inputs'), ('its', 'inputs', 'The'), ('inputs', 'The', 'connections'), ('The', 'connections', 'between'), ('connections', 'between', 'artificial'), ('between', 'artificial', 'neurons'), ('artificial', 'neurons', 'are'), ('neurons', 'are', 'called'), ('are', 'called', 'edges'), ('called', 'edges', 'Artificial'), ('edges', 'Artificial', 'neurons'), ('Artificial', 'neurons', 'and'), ('neurons', 'and', 'edges'), ('and', 'edges', 'typically'), ('edges', 'typically', 'have'), ('typically', 'have', 'a'), ('have', 'a', 'weight'), ('a', 'weight', 'that'), ('weight', 'that', 'adjusts'), ('that', 'adjusts', 'as'), ('adjusts', 'as', 'learning'), ('as', 'learning', 'proceeds'), ('learning', 'proceeds', 'The'), ('proceeds', 'The', 'weight'), ('The', 'weight', 'increases'), ('weight', 'increases', 'or'), ('increases', 'or', 'decreases'), ('or', 'decreases', 'the'), ('decreases', 'the', 'strength'), ('the', 'strength', 'of'), ('strength', 'of', 'the'), ('of', 'the', 'signal'), ('the', 'signal', 'at'), ('signal', 'at', 'a'), ('at', 'a', 'connection'), ('a', 'connection', 'Artificial'), ('connection', 'Artificial', 'neurons'), ('Artificial', 'neurons', 'may'), ('neurons', 'may', 'have'), ('may', 'have', 'a'), ('have', 'a', 'threshold'), ('a', 'threshold', 'such'), ('threshold', 'such', 'that'), ('such', 'that', 'the'), ('that', 'the', 'signal'), ('the', 'signal', 'is'), ('signal', 'is', 'only'), ('is', 'only', 'sent'), ('only', 'sent', 'if'), ('sent', 'if', 'the'), ('if', 'the', 'aggregate'), ('the', 'aggregate', 'signal'), ('aggregate', 'signal', 'crosses'), ('signal', 'crosses', 'that'), ('crosses', 'that', 'threshold'), ('that', 'threshold', 'Typically'), ('threshold', 'Typically', 'artificial'), ('Typically', 'artificial', 'neurons'), ('artificial', 'neurons', 'are'), ('neurons', 'are', 'aggregated'), ('are', 'aggregated', 'into'), ('aggregated', 'into', 'layers'), ('into', 'layers', 'Different'), ('layers', 'Different', 'layers'), ('Different', 'layers', 'may'), ('layers', 'may', 'perform'), ('may', 'perform', 'different'), ('perform', 'different', 'kinds'), ('different', 'kinds', 'of'), ('kinds', 'of', 'transformations'), ('of', 'transformations', 'on'), ('transformations', 'on', 'their'), ('on', 'their', 'inputs'), ('their', 'inputs', 'Signals'), ('inputs', 'Signals', 'travel'), ('Signals', 'travel', 'from'), ('travel', 'from', 'the'), ('from', 'the', 'first'), ('the', 'first', 'layer'), ('first', 'layer', 'the'), ('layer', 'the', 'input'), ('the', 'input', 'layer'), ('input', 'layer', 'to'), ('layer', 'to', 'the'), ('to', 'the', 'last'), ('the', 'last', 'layer'), ('last', 'layer', 'the'), ('layer', 'the', 'output'), ('the', 'output', 'layer'), ('output', 'layer', 'possibly'), ('layer', 'possibly', 'after'), ('possibly', 'after', 'traversing'), ('after', 'traversing', 'the'), ('traversing', 'the', 'layers'), ('the', 'layers', 'multiple'), ('layers', 'multiple', 'times')]\n",
      "\n",
      "Document: The original goal of the ANN approach was to solve problems in the same way that a human brain would However over time attention moved to performing specific tasks leading to deviations from biology Artificial neural networks have been used on a variety of tasks including computer vision speech recognition machine translation social network filtering playing board and video games and medical diagnosis\n",
      "\n",
      "\n",
      "Unigrams: [('The',), ('original',), ('goal',), ('of',), ('the',), ('ANN',), ('approach',), ('was',), ('to',), ('solve',), ('problems',), ('in',), ('the',), ('same',), ('way',), ('that',), ('a',), ('human',), ('brain',), ('would',), ('However',), ('over',), ('time',), ('attention',), ('moved',), ('to',), ('performing',), ('specific',), ('tasks',), ('leading',), ('to',), ('deviations',), ('from',), ('biology',), ('Artificial',), ('neural',), ('networks',), ('have',), ('been',), ('used',), ('on',), ('a',), ('variety',), ('of',), ('tasks',), ('including',), ('computer',), ('vision',), ('speech',), ('recognition',), ('machine',), ('translation',), ('social',), ('network',), ('filtering',), ('playing',), ('board',), ('and',), ('video',), ('games',), ('and',), ('medical',), ('diagnosis',)]\n",
      "\n",
      "Bigrams: [('The', 'original'), ('original', 'goal'), ('goal', 'of'), ('of', 'the'), ('the', 'ANN'), ('ANN', 'approach'), ('approach', 'was'), ('was', 'to'), ('to', 'solve'), ('solve', 'problems'), ('problems', 'in'), ('in', 'the'), ('the', 'same'), ('same', 'way'), ('way', 'that'), ('that', 'a'), ('a', 'human'), ('human', 'brain'), ('brain', 'would'), ('would', 'However'), ('However', 'over'), ('over', 'time'), ('time', 'attention'), ('attention', 'moved'), ('moved', 'to'), ('to', 'performing'), ('performing', 'specific'), ('specific', 'tasks'), ('tasks', 'leading'), ('leading', 'to'), ('to', 'deviations'), ('deviations', 'from'), ('from', 'biology'), ('biology', 'Artificial'), ('Artificial', 'neural'), ('neural', 'networks'), ('networks', 'have'), ('have', 'been'), ('been', 'used'), ('used', 'on'), ('on', 'a'), ('a', 'variety'), ('variety', 'of'), ('of', 'tasks'), ('tasks', 'including'), ('including', 'computer'), ('computer', 'vision'), ('vision', 'speech'), ('speech', 'recognition'), ('recognition', 'machine'), ('machine', 'translation'), ('translation', 'social'), ('social', 'network'), ('network', 'filtering'), ('filtering', 'playing'), ('playing', 'board'), ('board', 'and'), ('and', 'video'), ('video', 'games'), ('games', 'and'), ('and', 'medical'), ('medical', 'diagnosis')]\n",
      "\n",
      "Trigrams: [('The', 'original', 'goal'), ('original', 'goal', 'of'), ('goal', 'of', 'the'), ('of', 'the', 'ANN'), ('the', 'ANN', 'approach'), ('ANN', 'approach', 'was'), ('approach', 'was', 'to'), ('was', 'to', 'solve'), ('to', 'solve', 'problems'), ('solve', 'problems', 'in'), ('problems', 'in', 'the'), ('in', 'the', 'same'), ('the', 'same', 'way'), ('same', 'way', 'that'), ('way', 'that', 'a'), ('that', 'a', 'human'), ('a', 'human', 'brain'), ('human', 'brain', 'would'), ('brain', 'would', 'However'), ('would', 'However', 'over'), ('However', 'over', 'time'), ('over', 'time', 'attention'), ('time', 'attention', 'moved'), ('attention', 'moved', 'to'), ('moved', 'to', 'performing'), ('to', 'performing', 'specific'), ('performing', 'specific', 'tasks'), ('specific', 'tasks', 'leading'), ('tasks', 'leading', 'to'), ('leading', 'to', 'deviations'), ('to', 'deviations', 'from'), ('deviations', 'from', 'biology'), ('from', 'biology', 'Artificial'), ('biology', 'Artificial', 'neural'), ('Artificial', 'neural', 'networks'), ('neural', 'networks', 'have'), ('networks', 'have', 'been'), ('have', 'been', 'used'), ('been', 'used', 'on'), ('used', 'on', 'a'), ('on', 'a', 'variety'), ('a', 'variety', 'of'), ('variety', 'of', 'tasks'), ('of', 'tasks', 'including'), ('tasks', 'including', 'computer'), ('including', 'computer', 'vision'), ('computer', 'vision', 'speech'), ('vision', 'speech', 'recognition'), ('speech', 'recognition', 'machine'), ('recognition', 'machine', 'translation'), ('machine', 'translation', 'social'), ('translation', 'social', 'network'), ('social', 'network', 'filtering'), ('network', 'filtering', 'playing'), ('filtering', 'playing', 'board'), ('playing', 'board', 'and'), ('board', 'and', 'video'), ('and', 'video', 'games'), ('video', 'games', 'and'), ('games', 'and', 'medical'), ('and', 'medical', 'diagnosis')]\n",
      "\n",
      "Document: Deep learning consists of multiple hidden layers in an artificial neural network This approach tries to model the way the human brain processes light and sound into vision and hearing Some successful applications of deep learning are computer vision and speech recognition\n",
      "\n",
      "\n",
      "Unigrams: [('Deep',), ('learning',), ('consists',), ('of',), ('multiple',), ('hidden',), ('layers',), ('in',), ('an',), ('artificial',), ('neural',), ('network',), ('This',), ('approach',), ('tries',), ('to',), ('model',), ('the',), ('way',), ('the',), ('human',), ('brain',), ('processes',), ('light',), ('and',), ('sound',), ('into',), ('vision',), ('and',), ('hearing',), ('Some',), ('successful',), ('applications',), ('of',), ('deep',), ('learning',), ('are',), ('computer',), ('vision',), ('and',), ('speech',), ('recognition',)]\n",
      "\n",
      "Bigrams: [('Deep', 'learning'), ('learning', 'consists'), ('consists', 'of'), ('of', 'multiple'), ('multiple', 'hidden'), ('hidden', 'layers'), ('layers', 'in'), ('in', 'an'), ('an', 'artificial'), ('artificial', 'neural'), ('neural', 'network'), ('network', 'This'), ('This', 'approach'), ('approach', 'tries'), ('tries', 'to'), ('to', 'model'), ('model', 'the'), ('the', 'way'), ('way', 'the'), ('the', 'human'), ('human', 'brain'), ('brain', 'processes'), ('processes', 'light'), ('light', 'and'), ('and', 'sound'), ('sound', 'into'), ('into', 'vision'), ('vision', 'and'), ('and', 'hearing'), ('hearing', 'Some'), ('Some', 'successful'), ('successful', 'applications'), ('applications', 'of'), ('of', 'deep'), ('deep', 'learning'), ('learning', 'are'), ('are', 'computer'), ('computer', 'vision'), ('vision', 'and'), ('and', 'speech'), ('speech', 'recognition')]\n",
      "\n",
      "Trigrams: [('Deep', 'learning', 'consists'), ('learning', 'consists', 'of'), ('consists', 'of', 'multiple'), ('of', 'multiple', 'hidden'), ('multiple', 'hidden', 'layers'), ('hidden', 'layers', 'in'), ('layers', 'in', 'an'), ('in', 'an', 'artificial'), ('an', 'artificial', 'neural'), ('artificial', 'neural', 'network'), ('neural', 'network', 'This'), ('network', 'This', 'approach'), ('This', 'approach', 'tries'), ('approach', 'tries', 'to'), ('tries', 'to', 'model'), ('to', 'model', 'the'), ('model', 'the', 'way'), ('the', 'way', 'the'), ('way', 'the', 'human'), ('the', 'human', 'brain'), ('human', 'brain', 'processes'), ('brain', 'processes', 'light'), ('processes', 'light', 'and'), ('light', 'and', 'sound'), ('and', 'sound', 'into'), ('sound', 'into', 'vision'), ('into', 'vision', 'and'), ('vision', 'and', 'hearing'), ('and', 'hearing', 'Some'), ('hearing', 'Some', 'successful'), ('Some', 'successful', 'applications'), ('successful', 'applications', 'of'), ('applications', 'of', 'deep'), ('of', 'deep', 'learning'), ('deep', 'learning', 'are'), ('learning', 'are', 'computer'), ('are', 'computer', 'vision'), ('computer', 'vision', 'and'), ('vision', 'and', 'speech'), ('and', 'speech', 'recognition')]\n",
      "\n",
      "Document: Decision tree learning uses a decision tree as a predictive model to go from observations about an item represented in the branches to conclusions about the items target value represented in the leaves It is one of the predictive modelling approaches used in statistics data mining and machine learning Tree models where the target variable can take a discrete set of values are called classification trees in these tree structures leaves represent class labels and branches represent conjunctions of features that lead to those class labels Decision trees where the target variable can take continuous values typically real numbers are called regression trees In decision analysis a decision tree can be used to visually and explicitly represent decisions and decision making In data mining a decision tree describes data but the resulting classification tree can be an input for decisionmaking\n",
      "\n",
      "\n",
      "Unigrams: [('Decision',), ('tree',), ('learning',), ('uses',), ('a',), ('decision',), ('tree',), ('as',), ('a',), ('predictive',), ('model',), ('to',), ('go',), ('from',), ('observations',), ('about',), ('an',), ('item',), ('represented',), ('in',), ('the',), ('branches',), ('to',), ('conclusions',), ('about',), ('the',), ('items',), ('target',), ('value',), ('represented',), ('in',), ('the',), ('leaves',), ('It',), ('is',), ('one',), ('of',), ('the',), ('predictive',), ('modelling',), ('approaches',), ('used',), ('in',), ('statistics',), ('data',), ('mining',), ('and',), ('machine',), ('learning',), ('Tree',), ('models',), ('where',), ('the',), ('target',), ('variable',), ('can',), ('take',), ('a',), ('discrete',), ('set',), ('of',), ('values',), ('are',), ('called',), ('classification',), ('trees',), ('in',), ('these',), ('tree',), ('structures',), ('leaves',), ('represent',), ('class',), ('labels',), ('and',), ('branches',), ('represent',), ('conjunctions',), ('of',), ('features',), ('that',), ('lead',), ('to',), ('those',), ('class',), ('labels',), ('Decision',), ('trees',), ('where',), ('the',), ('target',), ('variable',), ('can',), ('take',), ('continuous',), ('values',), ('typically',), ('real',), ('numbers',), ('are',), ('called',), ('regression',), ('trees',), ('In',), ('decision',), ('analysis',), ('a',), ('decision',), ('tree',), ('can',), ('be',), ('used',), ('to',), ('visually',), ('and',), ('explicitly',), ('represent',), ('decisions',), ('and',), ('decision',), ('making',), ('In',), ('data',), ('mining',), ('a',), ('decision',), ('tree',), ('describes',), ('data',), ('but',), ('the',), ('resulting',), ('classification',), ('tree',), ('can',), ('be',), ('an',), ('input',), ('for',), ('decisionmaking',)]\n",
      "\n",
      "Bigrams: [('Decision', 'tree'), ('tree', 'learning'), ('learning', 'uses'), ('uses', 'a'), ('a', 'decision'), ('decision', 'tree'), ('tree', 'as'), ('as', 'a'), ('a', 'predictive'), ('predictive', 'model'), ('model', 'to'), ('to', 'go'), ('go', 'from'), ('from', 'observations'), ('observations', 'about'), ('about', 'an'), ('an', 'item'), ('item', 'represented'), ('represented', 'in'), ('in', 'the'), ('the', 'branches'), ('branches', 'to'), ('to', 'conclusions'), ('conclusions', 'about'), ('about', 'the'), ('the', 'items'), ('items', 'target'), ('target', 'value'), ('value', 'represented'), ('represented', 'in'), ('in', 'the'), ('the', 'leaves'), ('leaves', 'It'), ('It', 'is'), ('is', 'one'), ('one', 'of'), ('of', 'the'), ('the', 'predictive'), ('predictive', 'modelling'), ('modelling', 'approaches'), ('approaches', 'used'), ('used', 'in'), ('in', 'statistics'), ('statistics', 'data'), ('data', 'mining'), ('mining', 'and'), ('and', 'machine'), ('machine', 'learning'), ('learning', 'Tree'), ('Tree', 'models'), ('models', 'where'), ('where', 'the'), ('the', 'target'), ('target', 'variable'), ('variable', 'can'), ('can', 'take'), ('take', 'a'), ('a', 'discrete'), ('discrete', 'set'), ('set', 'of'), ('of', 'values'), ('values', 'are'), ('are', 'called'), ('called', 'classification'), ('classification', 'trees'), ('trees', 'in'), ('in', 'these'), ('these', 'tree'), ('tree', 'structures'), ('structures', 'leaves'), ('leaves', 'represent'), ('represent', 'class'), ('class', 'labels'), ('labels', 'and'), ('and', 'branches'), ('branches', 'represent'), ('represent', 'conjunctions'), ('conjunctions', 'of'), ('of', 'features'), ('features', 'that'), ('that', 'lead'), ('lead', 'to'), ('to', 'those'), ('those', 'class'), ('class', 'labels'), ('labels', 'Decision'), ('Decision', 'trees'), ('trees', 'where'), ('where', 'the'), ('the', 'target'), ('target', 'variable'), ('variable', 'can'), ('can', 'take'), ('take', 'continuous'), ('continuous', 'values'), ('values', 'typically'), ('typically', 'real'), ('real', 'numbers'), ('numbers', 'are'), ('are', 'called'), ('called', 'regression'), ('regression', 'trees'), ('trees', 'In'), ('In', 'decision'), ('decision', 'analysis'), ('analysis', 'a'), ('a', 'decision'), ('decision', 'tree'), ('tree', 'can'), ('can', 'be'), ('be', 'used'), ('used', 'to'), ('to', 'visually'), ('visually', 'and'), ('and', 'explicitly'), ('explicitly', 'represent'), ('represent', 'decisions'), ('decisions', 'and'), ('and', 'decision'), ('decision', 'making'), ('making', 'In'), ('In', 'data'), ('data', 'mining'), ('mining', 'a'), ('a', 'decision'), ('decision', 'tree'), ('tree', 'describes'), ('describes', 'data'), ('data', 'but'), ('but', 'the'), ('the', 'resulting'), ('resulting', 'classification'), ('classification', 'tree'), ('tree', 'can'), ('can', 'be'), ('be', 'an'), ('an', 'input'), ('input', 'for'), ('for', 'decisionmaking')]\n",
      "\n",
      "Trigrams: [('Decision', 'tree', 'learning'), ('tree', 'learning', 'uses'), ('learning', 'uses', 'a'), ('uses', 'a', 'decision'), ('a', 'decision', 'tree'), ('decision', 'tree', 'as'), ('tree', 'as', 'a'), ('as', 'a', 'predictive'), ('a', 'predictive', 'model'), ('predictive', 'model', 'to'), ('model', 'to', 'go'), ('to', 'go', 'from'), ('go', 'from', 'observations'), ('from', 'observations', 'about'), ('observations', 'about', 'an'), ('about', 'an', 'item'), ('an', 'item', 'represented'), ('item', 'represented', 'in'), ('represented', 'in', 'the'), ('in', 'the', 'branches'), ('the', 'branches', 'to'), ('branches', 'to', 'conclusions'), ('to', 'conclusions', 'about'), ('conclusions', 'about', 'the'), ('about', 'the', 'items'), ('the', 'items', 'target'), ('items', 'target', 'value'), ('target', 'value', 'represented'), ('value', 'represented', 'in'), ('represented', 'in', 'the'), ('in', 'the', 'leaves'), ('the', 'leaves', 'It'), ('leaves', 'It', 'is'), ('It', 'is', 'one'), ('is', 'one', 'of'), ('one', 'of', 'the'), ('of', 'the', 'predictive'), ('the', 'predictive', 'modelling'), ('predictive', 'modelling', 'approaches'), ('modelling', 'approaches', 'used'), ('approaches', 'used', 'in'), ('used', 'in', 'statistics'), ('in', 'statistics', 'data'), ('statistics', 'data', 'mining'), ('data', 'mining', 'and'), ('mining', 'and', 'machine'), ('and', 'machine', 'learning'), ('machine', 'learning', 'Tree'), ('learning', 'Tree', 'models'), ('Tree', 'models', 'where'), ('models', 'where', 'the'), ('where', 'the', 'target'), ('the', 'target', 'variable'), ('target', 'variable', 'can'), ('variable', 'can', 'take'), ('can', 'take', 'a'), ('take', 'a', 'discrete'), ('a', 'discrete', 'set'), ('discrete', 'set', 'of'), ('set', 'of', 'values'), ('of', 'values', 'are'), ('values', 'are', 'called'), ('are', 'called', 'classification'), ('called', 'classification', 'trees'), ('classification', 'trees', 'in'), ('trees', 'in', 'these'), ('in', 'these', 'tree'), ('these', 'tree', 'structures'), ('tree', 'structures', 'leaves'), ('structures', 'leaves', 'represent'), ('leaves', 'represent', 'class'), ('represent', 'class', 'labels'), ('class', 'labels', 'and'), ('labels', 'and', 'branches'), ('and', 'branches', 'represent'), ('branches', 'represent', 'conjunctions'), ('represent', 'conjunctions', 'of'), ('conjunctions', 'of', 'features'), ('of', 'features', 'that'), ('features', 'that', 'lead'), ('that', 'lead', 'to'), ('lead', 'to', 'those'), ('to', 'those', 'class'), ('those', 'class', 'labels'), ('class', 'labels', 'Decision'), ('labels', 'Decision', 'trees'), ('Decision', 'trees', 'where'), ('trees', 'where', 'the'), ('where', 'the', 'target'), ('the', 'target', 'variable'), ('target', 'variable', 'can'), ('variable', 'can', 'take'), ('can', 'take', 'continuous'), ('take', 'continuous', 'values'), ('continuous', 'values', 'typically'), ('values', 'typically', 'real'), ('typically', 'real', 'numbers'), ('real', 'numbers', 'are'), ('numbers', 'are', 'called'), ('are', 'called', 'regression'), ('called', 'regression', 'trees'), ('regression', 'trees', 'In'), ('trees', 'In', 'decision'), ('In', 'decision', 'analysis'), ('decision', 'analysis', 'a'), ('analysis', 'a', 'decision'), ('a', 'decision', 'tree'), ('decision', 'tree', 'can'), ('tree', 'can', 'be'), ('can', 'be', 'used'), ('be', 'used', 'to'), ('used', 'to', 'visually'), ('to', 'visually', 'and'), ('visually', 'and', 'explicitly'), ('and', 'explicitly', 'represent'), ('explicitly', 'represent', 'decisions'), ('represent', 'decisions', 'and'), ('decisions', 'and', 'decision'), ('and', 'decision', 'making'), ('decision', 'making', 'In'), ('making', 'In', 'data'), ('In', 'data', 'mining'), ('data', 'mining', 'a'), ('mining', 'a', 'decision'), ('a', 'decision', 'tree'), ('decision', 'tree', 'describes'), ('tree', 'describes', 'data'), ('describes', 'data', 'but'), ('data', 'but', 'the'), ('but', 'the', 'resulting'), ('the', 'resulting', 'classification'), ('resulting', 'classification', 'tree'), ('classification', 'tree', 'can'), ('tree', 'can', 'be'), ('can', 'be', 'an'), ('be', 'an', 'input'), ('an', 'input', 'for'), ('input', 'for', 'decisionmaking')]\n",
      "\n",
      "Document: Random forest regression RFR falls under umbrella of decision treebased models RFR is an ensemble learning method that builds multiple decision trees and averages their predictions to improve accuracy and to avoid overfitting To build decision trees RFR uses bootstrapped sampling for instance each decision tree is trained on random data of from training set This random selection of RFR for training enables model to reduce bias predictions and achieve accuracy RFR generates independent decision trees and it can work on single output data as well multiple regressor task This makes RFR compatible to be used in various application\n",
      "\n",
      "\n",
      "Unigrams: [('Random',), ('forest',), ('regression',), ('RFR',), ('falls',), ('under',), ('umbrella',), ('of',), ('decision',), ('treebased',), ('models',), ('RFR',), ('is',), ('an',), ('ensemble',), ('learning',), ('method',), ('that',), ('builds',), ('multiple',), ('decision',), ('trees',), ('and',), ('averages',), ('their',), ('predictions',), ('to',), ('improve',), ('accuracy',), ('and',), ('to',), ('avoid',), ('overfitting',), ('To',), ('build',), ('decision',), ('trees',), ('RFR',), ('uses',), ('bootstrapped',), ('sampling',), ('for',), ('instance',), ('each',), ('decision',), ('tree',), ('is',), ('trained',), ('on',), ('random',), ('data',), ('of',), ('from',), ('training',), ('set',), ('This',), ('random',), ('selection',), ('of',), ('RFR',), ('for',), ('training',), ('enables',), ('model',), ('to',), ('reduce',), ('bias',), ('predictions',), ('and',), ('achieve',), ('accuracy',), ('RFR',), ('generates',), ('independent',), ('decision',), ('trees',), ('and',), ('it',), ('can',), ('work',), ('on',), ('single',), ('output',), ('data',), ('as',), ('well',), ('multiple',), ('regressor',), ('task',), ('This',), ('makes',), ('RFR',), ('compatible',), ('to',), ('be',), ('used',), ('in',), ('various',), ('application',)]\n",
      "\n",
      "Bigrams: [('Random', 'forest'), ('forest', 'regression'), ('regression', 'RFR'), ('RFR', 'falls'), ('falls', 'under'), ('under', 'umbrella'), ('umbrella', 'of'), ('of', 'decision'), ('decision', 'treebased'), ('treebased', 'models'), ('models', 'RFR'), ('RFR', 'is'), ('is', 'an'), ('an', 'ensemble'), ('ensemble', 'learning'), ('learning', 'method'), ('method', 'that'), ('that', 'builds'), ('builds', 'multiple'), ('multiple', 'decision'), ('decision', 'trees'), ('trees', 'and'), ('and', 'averages'), ('averages', 'their'), ('their', 'predictions'), ('predictions', 'to'), ('to', 'improve'), ('improve', 'accuracy'), ('accuracy', 'and'), ('and', 'to'), ('to', 'avoid'), ('avoid', 'overfitting'), ('overfitting', 'To'), ('To', 'build'), ('build', 'decision'), ('decision', 'trees'), ('trees', 'RFR'), ('RFR', 'uses'), ('uses', 'bootstrapped'), ('bootstrapped', 'sampling'), ('sampling', 'for'), ('for', 'instance'), ('instance', 'each'), ('each', 'decision'), ('decision', 'tree'), ('tree', 'is'), ('is', 'trained'), ('trained', 'on'), ('on', 'random'), ('random', 'data'), ('data', 'of'), ('of', 'from'), ('from', 'training'), ('training', 'set'), ('set', 'This'), ('This', 'random'), ('random', 'selection'), ('selection', 'of'), ('of', 'RFR'), ('RFR', 'for'), ('for', 'training'), ('training', 'enables'), ('enables', 'model'), ('model', 'to'), ('to', 'reduce'), ('reduce', 'bias'), ('bias', 'predictions'), ('predictions', 'and'), ('and', 'achieve'), ('achieve', 'accuracy'), ('accuracy', 'RFR'), ('RFR', 'generates'), ('generates', 'independent'), ('independent', 'decision'), ('decision', 'trees'), ('trees', 'and'), ('and', 'it'), ('it', 'can'), ('can', 'work'), ('work', 'on'), ('on', 'single'), ('single', 'output'), ('output', 'data'), ('data', 'as'), ('as', 'well'), ('well', 'multiple'), ('multiple', 'regressor'), ('regressor', 'task'), ('task', 'This'), ('This', 'makes'), ('makes', 'RFR'), ('RFR', 'compatible'), ('compatible', 'to'), ('to', 'be'), ('be', 'used'), ('used', 'in'), ('in', 'various'), ('various', 'application')]\n",
      "\n",
      "Trigrams: [('Random', 'forest', 'regression'), ('forest', 'regression', 'RFR'), ('regression', 'RFR', 'falls'), ('RFR', 'falls', 'under'), ('falls', 'under', 'umbrella'), ('under', 'umbrella', 'of'), ('umbrella', 'of', 'decision'), ('of', 'decision', 'treebased'), ('decision', 'treebased', 'models'), ('treebased', 'models', 'RFR'), ('models', 'RFR', 'is'), ('RFR', 'is', 'an'), ('is', 'an', 'ensemble'), ('an', 'ensemble', 'learning'), ('ensemble', 'learning', 'method'), ('learning', 'method', 'that'), ('method', 'that', 'builds'), ('that', 'builds', 'multiple'), ('builds', 'multiple', 'decision'), ('multiple', 'decision', 'trees'), ('decision', 'trees', 'and'), ('trees', 'and', 'averages'), ('and', 'averages', 'their'), ('averages', 'their', 'predictions'), ('their', 'predictions', 'to'), ('predictions', 'to', 'improve'), ('to', 'improve', 'accuracy'), ('improve', 'accuracy', 'and'), ('accuracy', 'and', 'to'), ('and', 'to', 'avoid'), ('to', 'avoid', 'overfitting'), ('avoid', 'overfitting', 'To'), ('overfitting', 'To', 'build'), ('To', 'build', 'decision'), ('build', 'decision', 'trees'), ('decision', 'trees', 'RFR'), ('trees', 'RFR', 'uses'), ('RFR', 'uses', 'bootstrapped'), ('uses', 'bootstrapped', 'sampling'), ('bootstrapped', 'sampling', 'for'), ('sampling', 'for', 'instance'), ('for', 'instance', 'each'), ('instance', 'each', 'decision'), ('each', 'decision', 'tree'), ('decision', 'tree', 'is'), ('tree', 'is', 'trained'), ('is', 'trained', 'on'), ('trained', 'on', 'random'), ('on', 'random', 'data'), ('random', 'data', 'of'), ('data', 'of', 'from'), ('of', 'from', 'training'), ('from', 'training', 'set'), ('training', 'set', 'This'), ('set', 'This', 'random'), ('This', 'random', 'selection'), ('random', 'selection', 'of'), ('selection', 'of', 'RFR'), ('of', 'RFR', 'for'), ('RFR', 'for', 'training'), ('for', 'training', 'enables'), ('training', 'enables', 'model'), ('enables', 'model', 'to'), ('model', 'to', 'reduce'), ('to', 'reduce', 'bias'), ('reduce', 'bias', 'predictions'), ('bias', 'predictions', 'and'), ('predictions', 'and', 'achieve'), ('and', 'achieve', 'accuracy'), ('achieve', 'accuracy', 'RFR'), ('accuracy', 'RFR', 'generates'), ('RFR', 'generates', 'independent'), ('generates', 'independent', 'decision'), ('independent', 'decision', 'trees'), ('decision', 'trees', 'and'), ('trees', 'and', 'it'), ('and', 'it', 'can'), ('it', 'can', 'work'), ('can', 'work', 'on'), ('work', 'on', 'single'), ('on', 'single', 'output'), ('single', 'output', 'data'), ('output', 'data', 'as'), ('data', 'as', 'well'), ('as', 'well', 'multiple'), ('well', 'multiple', 'regressor'), ('multiple', 'regressor', 'task'), ('regressor', 'task', 'This'), ('task', 'This', 'makes'), ('This', 'makes', 'RFR'), ('makes', 'RFR', 'compatible'), ('RFR', 'compatible', 'to'), ('compatible', 'to', 'be'), ('to', 'be', 'used'), ('be', 'used', 'in'), ('used', 'in', 'various'), ('in', 'various', 'application')]\n",
      "\n",
      "Document: Supportvector machines SVMs also known as supportvector networks are a set of related supervised learning methods used for classification and regression Given a set of training examples each marked as belonging to one of two categories an SVM training algorithm builds a model that predicts whether a new example falls into one category An SVM training algorithm is a nonprobabilistic binary linear classifier although methods such as Platt scaling exist to use SVM in a probabilistic classification setting In addition to performing linear classification SVMs can efficiently perform a nonlinear classification using what is called the kernel trick implicitly mapping their inputs into highdimensional feature spaces\n",
      "\n",
      "\n",
      "Unigrams: [('Supportvector',), ('machines',), ('SVMs',), ('also',), ('known',), ('as',), ('supportvector',), ('networks',), ('are',), ('a',), ('set',), ('of',), ('related',), ('supervised',), ('learning',), ('methods',), ('used',), ('for',), ('classification',), ('and',), ('regression',), ('Given',), ('a',), ('set',), ('of',), ('training',), ('examples',), ('each',), ('marked',), ('as',), ('belonging',), ('to',), ('one',), ('of',), ('two',), ('categories',), ('an',), ('SVM',), ('training',), ('algorithm',), ('builds',), ('a',), ('model',), ('that',), ('predicts',), ('whether',), ('a',), ('new',), ('example',), ('falls',), ('into',), ('one',), ('category',), ('An',), ('SVM',), ('training',), ('algorithm',), ('is',), ('a',), ('nonprobabilistic',), ('binary',), ('linear',), ('classifier',), ('although',), ('methods',), ('such',), ('as',), ('Platt',), ('scaling',), ('exist',), ('to',), ('use',), ('SVM',), ('in',), ('a',), ('probabilistic',), ('classification',), ('setting',), ('In',), ('addition',), ('to',), ('performing',), ('linear',), ('classification',), ('SVMs',), ('can',), ('efficiently',), ('perform',), ('a',), ('nonlinear',), ('classification',), ('using',), ('what',), ('is',), ('called',), ('the',), ('kernel',), ('trick',), ('implicitly',), ('mapping',), ('their',), ('inputs',), ('into',), ('highdimensional',), ('feature',), ('spaces',)]\n",
      "\n",
      "Bigrams: [('Supportvector', 'machines'), ('machines', 'SVMs'), ('SVMs', 'also'), ('also', 'known'), ('known', 'as'), ('as', 'supportvector'), ('supportvector', 'networks'), ('networks', 'are'), ('are', 'a'), ('a', 'set'), ('set', 'of'), ('of', 'related'), ('related', 'supervised'), ('supervised', 'learning'), ('learning', 'methods'), ('methods', 'used'), ('used', 'for'), ('for', 'classification'), ('classification', 'and'), ('and', 'regression'), ('regression', 'Given'), ('Given', 'a'), ('a', 'set'), ('set', 'of'), ('of', 'training'), ('training', 'examples'), ('examples', 'each'), ('each', 'marked'), ('marked', 'as'), ('as', 'belonging'), ('belonging', 'to'), ('to', 'one'), ('one', 'of'), ('of', 'two'), ('two', 'categories'), ('categories', 'an'), ('an', 'SVM'), ('SVM', 'training'), ('training', 'algorithm'), ('algorithm', 'builds'), ('builds', 'a'), ('a', 'model'), ('model', 'that'), ('that', 'predicts'), ('predicts', 'whether'), ('whether', 'a'), ('a', 'new'), ('new', 'example'), ('example', 'falls'), ('falls', 'into'), ('into', 'one'), ('one', 'category'), ('category', 'An'), ('An', 'SVM'), ('SVM', 'training'), ('training', 'algorithm'), ('algorithm', 'is'), ('is', 'a'), ('a', 'nonprobabilistic'), ('nonprobabilistic', 'binary'), ('binary', 'linear'), ('linear', 'classifier'), ('classifier', 'although'), ('although', 'methods'), ('methods', 'such'), ('such', 'as'), ('as', 'Platt'), ('Platt', 'scaling'), ('scaling', 'exist'), ('exist', 'to'), ('to', 'use'), ('use', 'SVM'), ('SVM', 'in'), ('in', 'a'), ('a', 'probabilistic'), ('probabilistic', 'classification'), ('classification', 'setting'), ('setting', 'In'), ('In', 'addition'), ('addition', 'to'), ('to', 'performing'), ('performing', 'linear'), ('linear', 'classification'), ('classification', 'SVMs'), ('SVMs', 'can'), ('can', 'efficiently'), ('efficiently', 'perform'), ('perform', 'a'), ('a', 'nonlinear'), ('nonlinear', 'classification'), ('classification', 'using'), ('using', 'what'), ('what', 'is'), ('is', 'called'), ('called', 'the'), ('the', 'kernel'), ('kernel', 'trick'), ('trick', 'implicitly'), ('implicitly', 'mapping'), ('mapping', 'their'), ('their', 'inputs'), ('inputs', 'into'), ('into', 'highdimensional'), ('highdimensional', 'feature'), ('feature', 'spaces')]\n",
      "\n",
      "Trigrams: [('Supportvector', 'machines', 'SVMs'), ('machines', 'SVMs', 'also'), ('SVMs', 'also', 'known'), ('also', 'known', 'as'), ('known', 'as', 'supportvector'), ('as', 'supportvector', 'networks'), ('supportvector', 'networks', 'are'), ('networks', 'are', 'a'), ('are', 'a', 'set'), ('a', 'set', 'of'), ('set', 'of', 'related'), ('of', 'related', 'supervised'), ('related', 'supervised', 'learning'), ('supervised', 'learning', 'methods'), ('learning', 'methods', 'used'), ('methods', 'used', 'for'), ('used', 'for', 'classification'), ('for', 'classification', 'and'), ('classification', 'and', 'regression'), ('and', 'regression', 'Given'), ('regression', 'Given', 'a'), ('Given', 'a', 'set'), ('a', 'set', 'of'), ('set', 'of', 'training'), ('of', 'training', 'examples'), ('training', 'examples', 'each'), ('examples', 'each', 'marked'), ('each', 'marked', 'as'), ('marked', 'as', 'belonging'), ('as', 'belonging', 'to'), ('belonging', 'to', 'one'), ('to', 'one', 'of'), ('one', 'of', 'two'), ('of', 'two', 'categories'), ('two', 'categories', 'an'), ('categories', 'an', 'SVM'), ('an', 'SVM', 'training'), ('SVM', 'training', 'algorithm'), ('training', 'algorithm', 'builds'), ('algorithm', 'builds', 'a'), ('builds', 'a', 'model'), ('a', 'model', 'that'), ('model', 'that', 'predicts'), ('that', 'predicts', 'whether'), ('predicts', 'whether', 'a'), ('whether', 'a', 'new'), ('a', 'new', 'example'), ('new', 'example', 'falls'), ('example', 'falls', 'into'), ('falls', 'into', 'one'), ('into', 'one', 'category'), ('one', 'category', 'An'), ('category', 'An', 'SVM'), ('An', 'SVM', 'training'), ('SVM', 'training', 'algorithm'), ('training', 'algorithm', 'is'), ('algorithm', 'is', 'a'), ('is', 'a', 'nonprobabilistic'), ('a', 'nonprobabilistic', 'binary'), ('nonprobabilistic', 'binary', 'linear'), ('binary', 'linear', 'classifier'), ('linear', 'classifier', 'although'), ('classifier', 'although', 'methods'), ('although', 'methods', 'such'), ('methods', 'such', 'as'), ('such', 'as', 'Platt'), ('as', 'Platt', 'scaling'), ('Platt', 'scaling', 'exist'), ('scaling', 'exist', 'to'), ('exist', 'to', 'use'), ('to', 'use', 'SVM'), ('use', 'SVM', 'in'), ('SVM', 'in', 'a'), ('in', 'a', 'probabilistic'), ('a', 'probabilistic', 'classification'), ('probabilistic', 'classification', 'setting'), ('classification', 'setting', 'In'), ('setting', 'In', 'addition'), ('In', 'addition', 'to'), ('addition', 'to', 'performing'), ('to', 'performing', 'linear'), ('performing', 'linear', 'classification'), ('linear', 'classification', 'SVMs'), ('classification', 'SVMs', 'can'), ('SVMs', 'can', 'efficiently'), ('can', 'efficiently', 'perform'), ('efficiently', 'perform', 'a'), ('perform', 'a', 'nonlinear'), ('a', 'nonlinear', 'classification'), ('nonlinear', 'classification', 'using'), ('classification', 'using', 'what'), ('using', 'what', 'is'), ('what', 'is', 'called'), ('is', 'called', 'the'), ('called', 'the', 'kernel'), ('the', 'kernel', 'trick'), ('kernel', 'trick', 'implicitly'), ('trick', 'implicitly', 'mapping'), ('implicitly', 'mapping', 'their'), ('mapping', 'their', 'inputs'), ('their', 'inputs', 'into'), ('inputs', 'into', 'highdimensional'), ('into', 'highdimensional', 'feature'), ('highdimensional', 'feature', 'spaces')]\n",
      "\n",
      "Document: Regression analysis encompasses a large variety of statistical methods to estimate the relationship between input variables and their associated features Its most common form is linear regression where a single line is drawn to best fit the given data according to a mathematical criterion such as ordinary least squares The latter is often extended by regularisation methods to mitigate overfitting and bias as in ridge regression When dealing with nonlinear problems goto models include polynomial regression for example used for trendline fitting in Microsoft Excel logistic regression often used in statistical classification or even kernel regression which introduces nonlinearity by taking advantage of the kernel trick to implicitly map input variables to higherdimensional space\n",
      "\n",
      "\n",
      "Unigrams: [('Regression',), ('analysis',), ('encompasses',), ('a',), ('large',), ('variety',), ('of',), ('statistical',), ('methods',), ('to',), ('estimate',), ('the',), ('relationship',), ('between',), ('input',), ('variables',), ('and',), ('their',), ('associated',), ('features',), ('Its',), ('most',), ('common',), ('form',), ('is',), ('linear',), ('regression',), ('where',), ('a',), ('single',), ('line',), ('is',), ('drawn',), ('to',), ('best',), ('fit',), ('the',), ('given',), ('data',), ('according',), ('to',), ('a',), ('mathematical',), ('criterion',), ('such',), ('as',), ('ordinary',), ('least',), ('squares',), ('The',), ('latter',), ('is',), ('often',), ('extended',), ('by',), ('regularisation',), ('methods',), ('to',), ('mitigate',), ('overfitting',), ('and',), ('bias',), ('as',), ('in',), ('ridge',), ('regression',), ('When',), ('dealing',), ('with',), ('nonlinear',), ('problems',), ('goto',), ('models',), ('include',), ('polynomial',), ('regression',), ('for',), ('example',), ('used',), ('for',), ('trendline',), ('fitting',), ('in',), ('Microsoft',), ('Excel',), ('logistic',), ('regression',), ('often',), ('used',), ('in',), ('statistical',), ('classification',), ('or',), ('even',), ('kernel',), ('regression',), ('which',), ('introduces',), ('nonlinearity',), ('by',), ('taking',), ('advantage',), ('of',), ('the',), ('kernel',), ('trick',), ('to',), ('implicitly',), ('map',), ('input',), ('variables',), ('to',), ('higherdimensional',), ('space',)]\n",
      "\n",
      "Bigrams: [('Regression', 'analysis'), ('analysis', 'encompasses'), ('encompasses', 'a'), ('a', 'large'), ('large', 'variety'), ('variety', 'of'), ('of', 'statistical'), ('statistical', 'methods'), ('methods', 'to'), ('to', 'estimate'), ('estimate', 'the'), ('the', 'relationship'), ('relationship', 'between'), ('between', 'input'), ('input', 'variables'), ('variables', 'and'), ('and', 'their'), ('their', 'associated'), ('associated', 'features'), ('features', 'Its'), ('Its', 'most'), ('most', 'common'), ('common', 'form'), ('form', 'is'), ('is', 'linear'), ('linear', 'regression'), ('regression', 'where'), ('where', 'a'), ('a', 'single'), ('single', 'line'), ('line', 'is'), ('is', 'drawn'), ('drawn', 'to'), ('to', 'best'), ('best', 'fit'), ('fit', 'the'), ('the', 'given'), ('given', 'data'), ('data', 'according'), ('according', 'to'), ('to', 'a'), ('a', 'mathematical'), ('mathematical', 'criterion'), ('criterion', 'such'), ('such', 'as'), ('as', 'ordinary'), ('ordinary', 'least'), ('least', 'squares'), ('squares', 'The'), ('The', 'latter'), ('latter', 'is'), ('is', 'often'), ('often', 'extended'), ('extended', 'by'), ('by', 'regularisation'), ('regularisation', 'methods'), ('methods', 'to'), ('to', 'mitigate'), ('mitigate', 'overfitting'), ('overfitting', 'and'), ('and', 'bias'), ('bias', 'as'), ('as', 'in'), ('in', 'ridge'), ('ridge', 'regression'), ('regression', 'When'), ('When', 'dealing'), ('dealing', 'with'), ('with', 'nonlinear'), ('nonlinear', 'problems'), ('problems', 'goto'), ('goto', 'models'), ('models', 'include'), ('include', 'polynomial'), ('polynomial', 'regression'), ('regression', 'for'), ('for', 'example'), ('example', 'used'), ('used', 'for'), ('for', 'trendline'), ('trendline', 'fitting'), ('fitting', 'in'), ('in', 'Microsoft'), ('Microsoft', 'Excel'), ('Excel', 'logistic'), ('logistic', 'regression'), ('regression', 'often'), ('often', 'used'), ('used', 'in'), ('in', 'statistical'), ('statistical', 'classification'), ('classification', 'or'), ('or', 'even'), ('even', 'kernel'), ('kernel', 'regression'), ('regression', 'which'), ('which', 'introduces'), ('introduces', 'nonlinearity'), ('nonlinearity', 'by'), ('by', 'taking'), ('taking', 'advantage'), ('advantage', 'of'), ('of', 'the'), ('the', 'kernel'), ('kernel', 'trick'), ('trick', 'to'), ('to', 'implicitly'), ('implicitly', 'map'), ('map', 'input'), ('input', 'variables'), ('variables', 'to'), ('to', 'higherdimensional'), ('higherdimensional', 'space')]\n",
      "\n",
      "Trigrams: [('Regression', 'analysis', 'encompasses'), ('analysis', 'encompasses', 'a'), ('encompasses', 'a', 'large'), ('a', 'large', 'variety'), ('large', 'variety', 'of'), ('variety', 'of', 'statistical'), ('of', 'statistical', 'methods'), ('statistical', 'methods', 'to'), ('methods', 'to', 'estimate'), ('to', 'estimate', 'the'), ('estimate', 'the', 'relationship'), ('the', 'relationship', 'between'), ('relationship', 'between', 'input'), ('between', 'input', 'variables'), ('input', 'variables', 'and'), ('variables', 'and', 'their'), ('and', 'their', 'associated'), ('their', 'associated', 'features'), ('associated', 'features', 'Its'), ('features', 'Its', 'most'), ('Its', 'most', 'common'), ('most', 'common', 'form'), ('common', 'form', 'is'), ('form', 'is', 'linear'), ('is', 'linear', 'regression'), ('linear', 'regression', 'where'), ('regression', 'where', 'a'), ('where', 'a', 'single'), ('a', 'single', 'line'), ('single', 'line', 'is'), ('line', 'is', 'drawn'), ('is', 'drawn', 'to'), ('drawn', 'to', 'best'), ('to', 'best', 'fit'), ('best', 'fit', 'the'), ('fit', 'the', 'given'), ('the', 'given', 'data'), ('given', 'data', 'according'), ('data', 'according', 'to'), ('according', 'to', 'a'), ('to', 'a', 'mathematical'), ('a', 'mathematical', 'criterion'), ('mathematical', 'criterion', 'such'), ('criterion', 'such', 'as'), ('such', 'as', 'ordinary'), ('as', 'ordinary', 'least'), ('ordinary', 'least', 'squares'), ('least', 'squares', 'The'), ('squares', 'The', 'latter'), ('The', 'latter', 'is'), ('latter', 'is', 'often'), ('is', 'often', 'extended'), ('often', 'extended', 'by'), ('extended', 'by', 'regularisation'), ('by', 'regularisation', 'methods'), ('regularisation', 'methods', 'to'), ('methods', 'to', 'mitigate'), ('to', 'mitigate', 'overfitting'), ('mitigate', 'overfitting', 'and'), ('overfitting', 'and', 'bias'), ('and', 'bias', 'as'), ('bias', 'as', 'in'), ('as', 'in', 'ridge'), ('in', 'ridge', 'regression'), ('ridge', 'regression', 'When'), ('regression', 'When', 'dealing'), ('When', 'dealing', 'with'), ('dealing', 'with', 'nonlinear'), ('with', 'nonlinear', 'problems'), ('nonlinear', 'problems', 'goto'), ('problems', 'goto', 'models'), ('goto', 'models', 'include'), ('models', 'include', 'polynomial'), ('include', 'polynomial', 'regression'), ('polynomial', 'regression', 'for'), ('regression', 'for', 'example'), ('for', 'example', 'used'), ('example', 'used', 'for'), ('used', 'for', 'trendline'), ('for', 'trendline', 'fitting'), ('trendline', 'fitting', 'in'), ('fitting', 'in', 'Microsoft'), ('in', 'Microsoft', 'Excel'), ('Microsoft', 'Excel', 'logistic'), ('Excel', 'logistic', 'regression'), ('logistic', 'regression', 'often'), ('regression', 'often', 'used'), ('often', 'used', 'in'), ('used', 'in', 'statistical'), ('in', 'statistical', 'classification'), ('statistical', 'classification', 'or'), ('classification', 'or', 'even'), ('or', 'even', 'kernel'), ('even', 'kernel', 'regression'), ('kernel', 'regression', 'which'), ('regression', 'which', 'introduces'), ('which', 'introduces', 'nonlinearity'), ('introduces', 'nonlinearity', 'by'), ('nonlinearity', 'by', 'taking'), ('by', 'taking', 'advantage'), ('taking', 'advantage', 'of'), ('advantage', 'of', 'the'), ('of', 'the', 'kernel'), ('the', 'kernel', 'trick'), ('kernel', 'trick', 'to'), ('trick', 'to', 'implicitly'), ('to', 'implicitly', 'map'), ('implicitly', 'map', 'input'), ('map', 'input', 'variables'), ('input', 'variables', 'to'), ('variables', 'to', 'higherdimensional'), ('to', 'higherdimensional', 'space')]\n",
      "\n",
      "Document: Multivariate linear regression extends the concept of linear regression to handle multiple dependent variables simultaneously This approach estimates the relationships between a set of input variables and several output variables by fitting a multidimensional linear model It is particularly useful in scenarios where outputs are interdependent or share underlying patterns such as predicting multiple economic indicators or reconstructing images which are inherently multidimensional\n",
      "\n",
      "\n",
      "Unigrams: [('Multivariate',), ('linear',), ('regression',), ('extends',), ('the',), ('concept',), ('of',), ('linear',), ('regression',), ('to',), ('handle',), ('multiple',), ('dependent',), ('variables',), ('simultaneously',), ('This',), ('approach',), ('estimates',), ('the',), ('relationships',), ('between',), ('a',), ('set',), ('of',), ('input',), ('variables',), ('and',), ('several',), ('output',), ('variables',), ('by',), ('fitting',), ('a',), ('multidimensional',), ('linear',), ('model',), ('It',), ('is',), ('particularly',), ('useful',), ('in',), ('scenarios',), ('where',), ('outputs',), ('are',), ('interdependent',), ('or',), ('share',), ('underlying',), ('patterns',), ('such',), ('as',), ('predicting',), ('multiple',), ('economic',), ('indicators',), ('or',), ('reconstructing',), ('images',), ('which',), ('are',), ('inherently',), ('multidimensional',)]\n",
      "\n",
      "Bigrams: [('Multivariate', 'linear'), ('linear', 'regression'), ('regression', 'extends'), ('extends', 'the'), ('the', 'concept'), ('concept', 'of'), ('of', 'linear'), ('linear', 'regression'), ('regression', 'to'), ('to', 'handle'), ('handle', 'multiple'), ('multiple', 'dependent'), ('dependent', 'variables'), ('variables', 'simultaneously'), ('simultaneously', 'This'), ('This', 'approach'), ('approach', 'estimates'), ('estimates', 'the'), ('the', 'relationships'), ('relationships', 'between'), ('between', 'a'), ('a', 'set'), ('set', 'of'), ('of', 'input'), ('input', 'variables'), ('variables', 'and'), ('and', 'several'), ('several', 'output'), ('output', 'variables'), ('variables', 'by'), ('by', 'fitting'), ('fitting', 'a'), ('a', 'multidimensional'), ('multidimensional', 'linear'), ('linear', 'model'), ('model', 'It'), ('It', 'is'), ('is', 'particularly'), ('particularly', 'useful'), ('useful', 'in'), ('in', 'scenarios'), ('scenarios', 'where'), ('where', 'outputs'), ('outputs', 'are'), ('are', 'interdependent'), ('interdependent', 'or'), ('or', 'share'), ('share', 'underlying'), ('underlying', 'patterns'), ('patterns', 'such'), ('such', 'as'), ('as', 'predicting'), ('predicting', 'multiple'), ('multiple', 'economic'), ('economic', 'indicators'), ('indicators', 'or'), ('or', 'reconstructing'), ('reconstructing', 'images'), ('images', 'which'), ('which', 'are'), ('are', 'inherently'), ('inherently', 'multidimensional')]\n",
      "\n",
      "Trigrams: [('Multivariate', 'linear', 'regression'), ('linear', 'regression', 'extends'), ('regression', 'extends', 'the'), ('extends', 'the', 'concept'), ('the', 'concept', 'of'), ('concept', 'of', 'linear'), ('of', 'linear', 'regression'), ('linear', 'regression', 'to'), ('regression', 'to', 'handle'), ('to', 'handle', 'multiple'), ('handle', 'multiple', 'dependent'), ('multiple', 'dependent', 'variables'), ('dependent', 'variables', 'simultaneously'), ('variables', 'simultaneously', 'This'), ('simultaneously', 'This', 'approach'), ('This', 'approach', 'estimates'), ('approach', 'estimates', 'the'), ('estimates', 'the', 'relationships'), ('the', 'relationships', 'between'), ('relationships', 'between', 'a'), ('between', 'a', 'set'), ('a', 'set', 'of'), ('set', 'of', 'input'), ('of', 'input', 'variables'), ('input', 'variables', 'and'), ('variables', 'and', 'several'), ('and', 'several', 'output'), ('several', 'output', 'variables'), ('output', 'variables', 'by'), ('variables', 'by', 'fitting'), ('by', 'fitting', 'a'), ('fitting', 'a', 'multidimensional'), ('a', 'multidimensional', 'linear'), ('multidimensional', 'linear', 'model'), ('linear', 'model', 'It'), ('model', 'It', 'is'), ('It', 'is', 'particularly'), ('is', 'particularly', 'useful'), ('particularly', 'useful', 'in'), ('useful', 'in', 'scenarios'), ('in', 'scenarios', 'where'), ('scenarios', 'where', 'outputs'), ('where', 'outputs', 'are'), ('outputs', 'are', 'interdependent'), ('are', 'interdependent', 'or'), ('interdependent', 'or', 'share'), ('or', 'share', 'underlying'), ('share', 'underlying', 'patterns'), ('underlying', 'patterns', 'such'), ('patterns', 'such', 'as'), ('such', 'as', 'predicting'), ('as', 'predicting', 'multiple'), ('predicting', 'multiple', 'economic'), ('multiple', 'economic', 'indicators'), ('economic', 'indicators', 'or'), ('indicators', 'or', 'reconstructing'), ('or', 'reconstructing', 'images'), ('reconstructing', 'images', 'which'), ('images', 'which', 'are'), ('which', 'are', 'inherently'), ('are', 'inherently', 'multidimensional')]\n",
      "\n",
      "Document: A Bayesian network belief network or directed acyclic graphical model is a probabilistic graphical model that represents a set of random variables and their conditional independence with a directed acyclic graph DAG For example a Bayesian network could represent the probabilistic relationships between diseases and symptoms Given symptoms the network can be used to compute the probabilities of the presence of various diseases Efficient algorithms exist that perform inference and learning Bayesian networks that model sequences of variables like speech signals or protein sequences are called dynamic Bayesian networks Generalisations of Bayesian networks that can represent and solve decision problems under uncertainty are called influence diagrams\n",
      "\n",
      "\n",
      "Unigrams: [('A',), ('Bayesian',), ('network',), ('belief',), ('network',), ('or',), ('directed',), ('acyclic',), ('graphical',), ('model',), ('is',), ('a',), ('probabilistic',), ('graphical',), ('model',), ('that',), ('represents',), ('a',), ('set',), ('of',), ('random',), ('variables',), ('and',), ('their',), ('conditional',), ('independence',), ('with',), ('a',), ('directed',), ('acyclic',), ('graph',), ('DAG',), ('For',), ('example',), ('a',), ('Bayesian',), ('network',), ('could',), ('represent',), ('the',), ('probabilistic',), ('relationships',), ('between',), ('diseases',), ('and',), ('symptoms',), ('Given',), ('symptoms',), ('the',), ('network',), ('can',), ('be',), ('used',), ('to',), ('compute',), ('the',), ('probabilities',), ('of',), ('the',), ('presence',), ('of',), ('various',), ('diseases',), ('Efficient',), ('algorithms',), ('exist',), ('that',), ('perform',), ('inference',), ('and',), ('learning',), ('Bayesian',), ('networks',), ('that',), ('model',), ('sequences',), ('of',), ('variables',), ('like',), ('speech',), ('signals',), ('or',), ('protein',), ('sequences',), ('are',), ('called',), ('dynamic',), ('Bayesian',), ('networks',), ('Generalisations',), ('of',), ('Bayesian',), ('networks',), ('that',), ('can',), ('represent',), ('and',), ('solve',), ('decision',), ('problems',), ('under',), ('uncertainty',), ('are',), ('called',), ('influence',), ('diagrams',)]\n",
      "\n",
      "Bigrams: [('A', 'Bayesian'), ('Bayesian', 'network'), ('network', 'belief'), ('belief', 'network'), ('network', 'or'), ('or', 'directed'), ('directed', 'acyclic'), ('acyclic', 'graphical'), ('graphical', 'model'), ('model', 'is'), ('is', 'a'), ('a', 'probabilistic'), ('probabilistic', 'graphical'), ('graphical', 'model'), ('model', 'that'), ('that', 'represents'), ('represents', 'a'), ('a', 'set'), ('set', 'of'), ('of', 'random'), ('random', 'variables'), ('variables', 'and'), ('and', 'their'), ('their', 'conditional'), ('conditional', 'independence'), ('independence', 'with'), ('with', 'a'), ('a', 'directed'), ('directed', 'acyclic'), ('acyclic', 'graph'), ('graph', 'DAG'), ('DAG', 'For'), ('For', 'example'), ('example', 'a'), ('a', 'Bayesian'), ('Bayesian', 'network'), ('network', 'could'), ('could', 'represent'), ('represent', 'the'), ('the', 'probabilistic'), ('probabilistic', 'relationships'), ('relationships', 'between'), ('between', 'diseases'), ('diseases', 'and'), ('and', 'symptoms'), ('symptoms', 'Given'), ('Given', 'symptoms'), ('symptoms', 'the'), ('the', 'network'), ('network', 'can'), ('can', 'be'), ('be', 'used'), ('used', 'to'), ('to', 'compute'), ('compute', 'the'), ('the', 'probabilities'), ('probabilities', 'of'), ('of', 'the'), ('the', 'presence'), ('presence', 'of'), ('of', 'various'), ('various', 'diseases'), ('diseases', 'Efficient'), ('Efficient', 'algorithms'), ('algorithms', 'exist'), ('exist', 'that'), ('that', 'perform'), ('perform', 'inference'), ('inference', 'and'), ('and', 'learning'), ('learning', 'Bayesian'), ('Bayesian', 'networks'), ('networks', 'that'), ('that', 'model'), ('model', 'sequences'), ('sequences', 'of'), ('of', 'variables'), ('variables', 'like'), ('like', 'speech'), ('speech', 'signals'), ('signals', 'or'), ('or', 'protein'), ('protein', 'sequences'), ('sequences', 'are'), ('are', 'called'), ('called', 'dynamic'), ('dynamic', 'Bayesian'), ('Bayesian', 'networks'), ('networks', 'Generalisations'), ('Generalisations', 'of'), ('of', 'Bayesian'), ('Bayesian', 'networks'), ('networks', 'that'), ('that', 'can'), ('can', 'represent'), ('represent', 'and'), ('and', 'solve'), ('solve', 'decision'), ('decision', 'problems'), ('problems', 'under'), ('under', 'uncertainty'), ('uncertainty', 'are'), ('are', 'called'), ('called', 'influence'), ('influence', 'diagrams')]\n",
      "\n",
      "Trigrams: [('A', 'Bayesian', 'network'), ('Bayesian', 'network', 'belief'), ('network', 'belief', 'network'), ('belief', 'network', 'or'), ('network', 'or', 'directed'), ('or', 'directed', 'acyclic'), ('directed', 'acyclic', 'graphical'), ('acyclic', 'graphical', 'model'), ('graphical', 'model', 'is'), ('model', 'is', 'a'), ('is', 'a', 'probabilistic'), ('a', 'probabilistic', 'graphical'), ('probabilistic', 'graphical', 'model'), ('graphical', 'model', 'that'), ('model', 'that', 'represents'), ('that', 'represents', 'a'), ('represents', 'a', 'set'), ('a', 'set', 'of'), ('set', 'of', 'random'), ('of', 'random', 'variables'), ('random', 'variables', 'and'), ('variables', 'and', 'their'), ('and', 'their', 'conditional'), ('their', 'conditional', 'independence'), ('conditional', 'independence', 'with'), ('independence', 'with', 'a'), ('with', 'a', 'directed'), ('a', 'directed', 'acyclic'), ('directed', 'acyclic', 'graph'), ('acyclic', 'graph', 'DAG'), ('graph', 'DAG', 'For'), ('DAG', 'For', 'example'), ('For', 'example', 'a'), ('example', 'a', 'Bayesian'), ('a', 'Bayesian', 'network'), ('Bayesian', 'network', 'could'), ('network', 'could', 'represent'), ('could', 'represent', 'the'), ('represent', 'the', 'probabilistic'), ('the', 'probabilistic', 'relationships'), ('probabilistic', 'relationships', 'between'), ('relationships', 'between', 'diseases'), ('between', 'diseases', 'and'), ('diseases', 'and', 'symptoms'), ('and', 'symptoms', 'Given'), ('symptoms', 'Given', 'symptoms'), ('Given', 'symptoms', 'the'), ('symptoms', 'the', 'network'), ('the', 'network', 'can'), ('network', 'can', 'be'), ('can', 'be', 'used'), ('be', 'used', 'to'), ('used', 'to', 'compute'), ('to', 'compute', 'the'), ('compute', 'the', 'probabilities'), ('the', 'probabilities', 'of'), ('probabilities', 'of', 'the'), ('of', 'the', 'presence'), ('the', 'presence', 'of'), ('presence', 'of', 'various'), ('of', 'various', 'diseases'), ('various', 'diseases', 'Efficient'), ('diseases', 'Efficient', 'algorithms'), ('Efficient', 'algorithms', 'exist'), ('algorithms', 'exist', 'that'), ('exist', 'that', 'perform'), ('that', 'perform', 'inference'), ('perform', 'inference', 'and'), ('inference', 'and', 'learning'), ('and', 'learning', 'Bayesian'), ('learning', 'Bayesian', 'networks'), ('Bayesian', 'networks', 'that'), ('networks', 'that', 'model'), ('that', 'model', 'sequences'), ('model', 'sequences', 'of'), ('sequences', 'of', 'variables'), ('of', 'variables', 'like'), ('variables', 'like', 'speech'), ('like', 'speech', 'signals'), ('speech', 'signals', 'or'), ('signals', 'or', 'protein'), ('or', 'protein', 'sequences'), ('protein', 'sequences', 'are'), ('sequences', 'are', 'called'), ('are', 'called', 'dynamic'), ('called', 'dynamic', 'Bayesian'), ('dynamic', 'Bayesian', 'networks'), ('Bayesian', 'networks', 'Generalisations'), ('networks', 'Generalisations', 'of'), ('Generalisations', 'of', 'Bayesian'), ('of', 'Bayesian', 'networks'), ('Bayesian', 'networks', 'that'), ('networks', 'that', 'can'), ('that', 'can', 'represent'), ('can', 'represent', 'and'), ('represent', 'and', 'solve'), ('and', 'solve', 'decision'), ('solve', 'decision', 'problems'), ('decision', 'problems', 'under'), ('problems', 'under', 'uncertainty'), ('under', 'uncertainty', 'are'), ('uncertainty', 'are', 'called'), ('are', 'called', 'influence'), ('called', 'influence', 'diagrams')]\n",
      "\n",
      "Document: A Gaussian process is a stochastic process in which every finite collection of the random variables in the process has a multivariate normal distribution and it relies on a predefined covariance function or kernel that models how pairs of points relate to each other depending on their locations\n",
      "\n",
      "\n",
      "Unigrams: [('A',), ('Gaussian',), ('process',), ('is',), ('a',), ('stochastic',), ('process',), ('in',), ('which',), ('every',), ('finite',), ('collection',), ('of',), ('the',), ('random',), ('variables',), ('in',), ('the',), ('process',), ('has',), ('a',), ('multivariate',), ('normal',), ('distribution',), ('and',), ('it',), ('relies',), ('on',), ('a',), ('predefined',), ('covariance',), ('function',), ('or',), ('kernel',), ('that',), ('models',), ('how',), ('pairs',), ('of',), ('points',), ('relate',), ('to',), ('each',), ('other',), ('depending',), ('on',), ('their',), ('locations',)]\n",
      "\n",
      "Bigrams: [('A', 'Gaussian'), ('Gaussian', 'process'), ('process', 'is'), ('is', 'a'), ('a', 'stochastic'), ('stochastic', 'process'), ('process', 'in'), ('in', 'which'), ('which', 'every'), ('every', 'finite'), ('finite', 'collection'), ('collection', 'of'), ('of', 'the'), ('the', 'random'), ('random', 'variables'), ('variables', 'in'), ('in', 'the'), ('the', 'process'), ('process', 'has'), ('has', 'a'), ('a', 'multivariate'), ('multivariate', 'normal'), ('normal', 'distribution'), ('distribution', 'and'), ('and', 'it'), ('it', 'relies'), ('relies', 'on'), ('on', 'a'), ('a', 'predefined'), ('predefined', 'covariance'), ('covariance', 'function'), ('function', 'or'), ('or', 'kernel'), ('kernel', 'that'), ('that', 'models'), ('models', 'how'), ('how', 'pairs'), ('pairs', 'of'), ('of', 'points'), ('points', 'relate'), ('relate', 'to'), ('to', 'each'), ('each', 'other'), ('other', 'depending'), ('depending', 'on'), ('on', 'their'), ('their', 'locations')]\n",
      "\n",
      "Trigrams: [('A', 'Gaussian', 'process'), ('Gaussian', 'process', 'is'), ('process', 'is', 'a'), ('is', 'a', 'stochastic'), ('a', 'stochastic', 'process'), ('stochastic', 'process', 'in'), ('process', 'in', 'which'), ('in', 'which', 'every'), ('which', 'every', 'finite'), ('every', 'finite', 'collection'), ('finite', 'collection', 'of'), ('collection', 'of', 'the'), ('of', 'the', 'random'), ('the', 'random', 'variables'), ('random', 'variables', 'in'), ('variables', 'in', 'the'), ('in', 'the', 'process'), ('the', 'process', 'has'), ('process', 'has', 'a'), ('has', 'a', 'multivariate'), ('a', 'multivariate', 'normal'), ('multivariate', 'normal', 'distribution'), ('normal', 'distribution', 'and'), ('distribution', 'and', 'it'), ('and', 'it', 'relies'), ('it', 'relies', 'on'), ('relies', 'on', 'a'), ('on', 'a', 'predefined'), ('a', 'predefined', 'covariance'), ('predefined', 'covariance', 'function'), ('covariance', 'function', 'or'), ('function', 'or', 'kernel'), ('or', 'kernel', 'that'), ('kernel', 'that', 'models'), ('that', 'models', 'how'), ('models', 'how', 'pairs'), ('how', 'pairs', 'of'), ('pairs', 'of', 'points'), ('of', 'points', 'relate'), ('points', 'relate', 'to'), ('relate', 'to', 'each'), ('to', 'each', 'other'), ('each', 'other', 'depending'), ('other', 'depending', 'on'), ('depending', 'on', 'their'), ('on', 'their', 'locations')]\n",
      "\n",
      "Document: Given a set of observed points or inputoutput examples the distribution of the unobserved output of a new point as function of its input data can be directly computed by looking like the observed points and the covariances between those points and the new unobserved point\n",
      "\n",
      "\n",
      "Unigrams: [('Given',), ('a',), ('set',), ('of',), ('observed',), ('points',), ('or',), ('inputoutput',), ('examples',), ('the',), ('distribution',), ('of',), ('the',), ('unobserved',), ('output',), ('of',), ('a',), ('new',), ('point',), ('as',), ('function',), ('of',), ('its',), ('input',), ('data',), ('can',), ('be',), ('directly',), ('computed',), ('by',), ('looking',), ('like',), ('the',), ('observed',), ('points',), ('and',), ('the',), ('covariances',), ('between',), ('those',), ('points',), ('and',), ('the',), ('new',), ('unobserved',), ('point',)]\n",
      "\n",
      "Bigrams: [('Given', 'a'), ('a', 'set'), ('set', 'of'), ('of', 'observed'), ('observed', 'points'), ('points', 'or'), ('or', 'inputoutput'), ('inputoutput', 'examples'), ('examples', 'the'), ('the', 'distribution'), ('distribution', 'of'), ('of', 'the'), ('the', 'unobserved'), ('unobserved', 'output'), ('output', 'of'), ('of', 'a'), ('a', 'new'), ('new', 'point'), ('point', 'as'), ('as', 'function'), ('function', 'of'), ('of', 'its'), ('its', 'input'), ('input', 'data'), ('data', 'can'), ('can', 'be'), ('be', 'directly'), ('directly', 'computed'), ('computed', 'by'), ('by', 'looking'), ('looking', 'like'), ('like', 'the'), ('the', 'observed'), ('observed', 'points'), ('points', 'and'), ('and', 'the'), ('the', 'covariances'), ('covariances', 'between'), ('between', 'those'), ('those', 'points'), ('points', 'and'), ('and', 'the'), ('the', 'new'), ('new', 'unobserved'), ('unobserved', 'point')]\n",
      "\n",
      "Trigrams: [('Given', 'a', 'set'), ('a', 'set', 'of'), ('set', 'of', 'observed'), ('of', 'observed', 'points'), ('observed', 'points', 'or'), ('points', 'or', 'inputoutput'), ('or', 'inputoutput', 'examples'), ('inputoutput', 'examples', 'the'), ('examples', 'the', 'distribution'), ('the', 'distribution', 'of'), ('distribution', 'of', 'the'), ('of', 'the', 'unobserved'), ('the', 'unobserved', 'output'), ('unobserved', 'output', 'of'), ('output', 'of', 'a'), ('of', 'a', 'new'), ('a', 'new', 'point'), ('new', 'point', 'as'), ('point', 'as', 'function'), ('as', 'function', 'of'), ('function', 'of', 'its'), ('of', 'its', 'input'), ('its', 'input', 'data'), ('input', 'data', 'can'), ('data', 'can', 'be'), ('can', 'be', 'directly'), ('be', 'directly', 'computed'), ('directly', 'computed', 'by'), ('computed', 'by', 'looking'), ('by', 'looking', 'like'), ('looking', 'like', 'the'), ('like', 'the', 'observed'), ('the', 'observed', 'points'), ('observed', 'points', 'and'), ('points', 'and', 'the'), ('and', 'the', 'covariances'), ('the', 'covariances', 'between'), ('covariances', 'between', 'those'), ('between', 'those', 'points'), ('those', 'points', 'and'), ('points', 'and', 'the'), ('and', 'the', 'new'), ('the', 'new', 'unobserved'), ('new', 'unobserved', 'point')]\n",
      "\n",
      "Document: Gaussian processes are popular surrogate models in Bayesian optimisation used to do hyperparameter optimisation\n",
      "\n",
      "\n",
      "Unigrams: [('Gaussian',), ('processes',), ('are',), ('popular',), ('surrogate',), ('models',), ('in',), ('Bayesian',), ('optimisation',), ('used',), ('to',), ('do',), ('hyperparameter',), ('optimisation',)]\n",
      "\n",
      "Bigrams: [('Gaussian', 'processes'), ('processes', 'are'), ('are', 'popular'), ('popular', 'surrogate'), ('surrogate', 'models'), ('models', 'in'), ('in', 'Bayesian'), ('Bayesian', 'optimisation'), ('optimisation', 'used'), ('used', 'to'), ('to', 'do'), ('do', 'hyperparameter'), ('hyperparameter', 'optimisation')]\n",
      "\n",
      "Trigrams: [('Gaussian', 'processes', 'are'), ('processes', 'are', 'popular'), ('are', 'popular', 'surrogate'), ('popular', 'surrogate', 'models'), ('surrogate', 'models', 'in'), ('models', 'in', 'Bayesian'), ('in', 'Bayesian', 'optimisation'), ('Bayesian', 'optimisation', 'used'), ('optimisation', 'used', 'to'), ('used', 'to', 'do'), ('to', 'do', 'hyperparameter'), ('do', 'hyperparameter', 'optimisation')]\n",
      "\n",
      "Document: A genetic algorithm GA is a search algorithm and heuristic technique that mimics the process of natural selection using methods such as mutation and crossover to generate new genotypes in the hope of finding good solutions to a given problem In machine learning genetic algorithms were used in the s and s Conversely machine learning techniques have been used to improve the performance of genetic and evolutionary algorithms\n",
      "\n",
      "\n",
      "Unigrams: [('A',), ('genetic',), ('algorithm',), ('GA',), ('is',), ('a',), ('search',), ('algorithm',), ('and',), ('heuristic',), ('technique',), ('that',), ('mimics',), ('the',), ('process',), ('of',), ('natural',), ('selection',), ('using',), ('methods',), ('such',), ('as',), ('mutation',), ('and',), ('crossover',), ('to',), ('generate',), ('new',), ('genotypes',), ('in',), ('the',), ('hope',), ('of',), ('finding',), ('good',), ('solutions',), ('to',), ('a',), ('given',), ('problem',), ('In',), ('machine',), ('learning',), ('genetic',), ('algorithms',), ('were',), ('used',), ('in',), ('the',), ('s',), ('and',), ('s',), ('Conversely',), ('machine',), ('learning',), ('techniques',), ('have',), ('been',), ('used',), ('to',), ('improve',), ('the',), ('performance',), ('of',), ('genetic',), ('and',), ('evolutionary',), ('algorithms',)]\n",
      "\n",
      "Bigrams: [('A', 'genetic'), ('genetic', 'algorithm'), ('algorithm', 'GA'), ('GA', 'is'), ('is', 'a'), ('a', 'search'), ('search', 'algorithm'), ('algorithm', 'and'), ('and', 'heuristic'), ('heuristic', 'technique'), ('technique', 'that'), ('that', 'mimics'), ('mimics', 'the'), ('the', 'process'), ('process', 'of'), ('of', 'natural'), ('natural', 'selection'), ('selection', 'using'), ('using', 'methods'), ('methods', 'such'), ('such', 'as'), ('as', 'mutation'), ('mutation', 'and'), ('and', 'crossover'), ('crossover', 'to'), ('to', 'generate'), ('generate', 'new'), ('new', 'genotypes'), ('genotypes', 'in'), ('in', 'the'), ('the', 'hope'), ('hope', 'of'), ('of', 'finding'), ('finding', 'good'), ('good', 'solutions'), ('solutions', 'to'), ('to', 'a'), ('a', 'given'), ('given', 'problem'), ('problem', 'In'), ('In', 'machine'), ('machine', 'learning'), ('learning', 'genetic'), ('genetic', 'algorithms'), ('algorithms', 'were'), ('were', 'used'), ('used', 'in'), ('in', 'the'), ('the', 's'), ('s', 'and'), ('and', 's'), ('s', 'Conversely'), ('Conversely', 'machine'), ('machine', 'learning'), ('learning', 'techniques'), ('techniques', 'have'), ('have', 'been'), ('been', 'used'), ('used', 'to'), ('to', 'improve'), ('improve', 'the'), ('the', 'performance'), ('performance', 'of'), ('of', 'genetic'), ('genetic', 'and'), ('and', 'evolutionary'), ('evolutionary', 'algorithms')]\n",
      "\n",
      "Trigrams: [('A', 'genetic', 'algorithm'), ('genetic', 'algorithm', 'GA'), ('algorithm', 'GA', 'is'), ('GA', 'is', 'a'), ('is', 'a', 'search'), ('a', 'search', 'algorithm'), ('search', 'algorithm', 'and'), ('algorithm', 'and', 'heuristic'), ('and', 'heuristic', 'technique'), ('heuristic', 'technique', 'that'), ('technique', 'that', 'mimics'), ('that', 'mimics', 'the'), ('mimics', 'the', 'process'), ('the', 'process', 'of'), ('process', 'of', 'natural'), ('of', 'natural', 'selection'), ('natural', 'selection', 'using'), ('selection', 'using', 'methods'), ('using', 'methods', 'such'), ('methods', 'such', 'as'), ('such', 'as', 'mutation'), ('as', 'mutation', 'and'), ('mutation', 'and', 'crossover'), ('and', 'crossover', 'to'), ('crossover', 'to', 'generate'), ('to', 'generate', 'new'), ('generate', 'new', 'genotypes'), ('new', 'genotypes', 'in'), ('genotypes', 'in', 'the'), ('in', 'the', 'hope'), ('the', 'hope', 'of'), ('hope', 'of', 'finding'), ('of', 'finding', 'good'), ('finding', 'good', 'solutions'), ('good', 'solutions', 'to'), ('solutions', 'to', 'a'), ('to', 'a', 'given'), ('a', 'given', 'problem'), ('given', 'problem', 'In'), ('problem', 'In', 'machine'), ('In', 'machine', 'learning'), ('machine', 'learning', 'genetic'), ('learning', 'genetic', 'algorithms'), ('genetic', 'algorithms', 'were'), ('algorithms', 'were', 'used'), ('were', 'used', 'in'), ('used', 'in', 'the'), ('in', 'the', 's'), ('the', 's', 'and'), ('s', 'and', 's'), ('and', 's', 'Conversely'), ('s', 'Conversely', 'machine'), ('Conversely', 'machine', 'learning'), ('machine', 'learning', 'techniques'), ('learning', 'techniques', 'have'), ('techniques', 'have', 'been'), ('have', 'been', 'used'), ('been', 'used', 'to'), ('used', 'to', 'improve'), ('to', 'improve', 'the'), ('improve', 'the', 'performance'), ('the', 'performance', 'of'), ('performance', 'of', 'genetic'), ('of', 'genetic', 'and'), ('genetic', 'and', 'evolutionary'), ('and', 'evolutionary', 'algorithms')]\n",
      "\n",
      "Document: The theory of belief functions also referred to as evidence theory or DempsterShafer theory is a general framework for reasoning with uncertainty with understood connections to other frameworks such as probability possibility and  imprecise probability theories These theoretical frameworks can be thought of as a kind of learner and have some analogous properties of how evidence is combined eg  Dempsters rule of combination just like how in a pmfbased Bayesian approach would combine probabilities However there are many caveats to these beliefs functions when compared to Bayesian approaches in order to incorporate ignorance and uncertainty quantification These belief function approaches that are implemented within the machine learning domain typically leverage a fusion approach of various ensemble methods to better handle the learners decision boundary low samples and ambiguous class issues that standard machine learning approach tend to have difficulty resolving However the computational complexity of these algorithms are dependent on the number of propositions classes and can lead to a much higher computation time when compared to other machine learning approaches\n",
      "\n",
      "\n",
      "Unigrams: [('The',), ('theory',), ('of',), ('belief',), ('functions',), ('also',), ('referred',), ('to',), ('as',), ('evidence',), ('theory',), ('or',), ('DempsterShafer',), ('theory',), ('is',), ('a',), ('general',), ('framework',), ('for',), ('reasoning',), ('with',), ('uncertainty',), ('with',), ('understood',), ('connections',), ('to',), ('other',), ('frameworks',), ('such',), ('as',), ('probability',), ('possibility',), ('and',), ('imprecise',), ('probability',), ('theories',), ('These',), ('theoretical',), ('frameworks',), ('can',), ('be',), ('thought',), ('of',), ('as',), ('a',), ('kind',), ('of',), ('learner',), ('and',), ('have',), ('some',), ('analogous',), ('properties',), ('of',), ('how',), ('evidence',), ('is',), ('combined',), ('eg',), ('Dempsters',), ('rule',), ('of',), ('combination',), ('just',), ('like',), ('how',), ('in',), ('a',), ('pmfbased',), ('Bayesian',), ('approach',), ('would',), ('combine',), ('probabilities',), ('However',), ('there',), ('are',), ('many',), ('caveats',), ('to',), ('these',), ('beliefs',), ('functions',), ('when',), ('compared',), ('to',), ('Bayesian',), ('approaches',), ('in',), ('order',), ('to',), ('incorporate',), ('ignorance',), ('and',), ('uncertainty',), ('quantification',), ('These',), ('belief',), ('function',), ('approaches',), ('that',), ('are',), ('implemented',), ('within',), ('the',), ('machine',), ('learning',), ('domain',), ('typically',), ('leverage',), ('a',), ('fusion',), ('approach',), ('of',), ('various',), ('ensemble',), ('methods',), ('to',), ('better',), ('handle',), ('the',), ('learners',), ('decision',), ('boundary',), ('low',), ('samples',), ('and',), ('ambiguous',), ('class',), ('issues',), ('that',), ('standard',), ('machine',), ('learning',), ('approach',), ('tend',), ('to',), ('have',), ('difficulty',), ('resolving',), ('However',), ('the',), ('computational',), ('complexity',), ('of',), ('these',), ('algorithms',), ('are',), ('dependent',), ('on',), ('the',), ('number',), ('of',), ('propositions',), ('classes',), ('and',), ('can',), ('lead',), ('to',), ('a',), ('much',), ('higher',), ('computation',), ('time',), ('when',), ('compared',), ('to',), ('other',), ('machine',), ('learning',), ('approaches',)]\n",
      "\n",
      "Bigrams: [('The', 'theory'), ('theory', 'of'), ('of', 'belief'), ('belief', 'functions'), ('functions', 'also'), ('also', 'referred'), ('referred', 'to'), ('to', 'as'), ('as', 'evidence'), ('evidence', 'theory'), ('theory', 'or'), ('or', 'DempsterShafer'), ('DempsterShafer', 'theory'), ('theory', 'is'), ('is', 'a'), ('a', 'general'), ('general', 'framework'), ('framework', 'for'), ('for', 'reasoning'), ('reasoning', 'with'), ('with', 'uncertainty'), ('uncertainty', 'with'), ('with', 'understood'), ('understood', 'connections'), ('connections', 'to'), ('to', 'other'), ('other', 'frameworks'), ('frameworks', 'such'), ('such', 'as'), ('as', 'probability'), ('probability', 'possibility'), ('possibility', 'and'), ('and', 'imprecise'), ('imprecise', 'probability'), ('probability', 'theories'), ('theories', 'These'), ('These', 'theoretical'), ('theoretical', 'frameworks'), ('frameworks', 'can'), ('can', 'be'), ('be', 'thought'), ('thought', 'of'), ('of', 'as'), ('as', 'a'), ('a', 'kind'), ('kind', 'of'), ('of', 'learner'), ('learner', 'and'), ('and', 'have'), ('have', 'some'), ('some', 'analogous'), ('analogous', 'properties'), ('properties', 'of'), ('of', 'how'), ('how', 'evidence'), ('evidence', 'is'), ('is', 'combined'), ('combined', 'eg'), ('eg', 'Dempsters'), ('Dempsters', 'rule'), ('rule', 'of'), ('of', 'combination'), ('combination', 'just'), ('just', 'like'), ('like', 'how'), ('how', 'in'), ('in', 'a'), ('a', 'pmfbased'), ('pmfbased', 'Bayesian'), ('Bayesian', 'approach'), ('approach', 'would'), ('would', 'combine'), ('combine', 'probabilities'), ('probabilities', 'However'), ('However', 'there'), ('there', 'are'), ('are', 'many'), ('many', 'caveats'), ('caveats', 'to'), ('to', 'these'), ('these', 'beliefs'), ('beliefs', 'functions'), ('functions', 'when'), ('when', 'compared'), ('compared', 'to'), ('to', 'Bayesian'), ('Bayesian', 'approaches'), ('approaches', 'in'), ('in', 'order'), ('order', 'to'), ('to', 'incorporate'), ('incorporate', 'ignorance'), ('ignorance', 'and'), ('and', 'uncertainty'), ('uncertainty', 'quantification'), ('quantification', 'These'), ('These', 'belief'), ('belief', 'function'), ('function', 'approaches'), ('approaches', 'that'), ('that', 'are'), ('are', 'implemented'), ('implemented', 'within'), ('within', 'the'), ('the', 'machine'), ('machine', 'learning'), ('learning', 'domain'), ('domain', 'typically'), ('typically', 'leverage'), ('leverage', 'a'), ('a', 'fusion'), ('fusion', 'approach'), ('approach', 'of'), ('of', 'various'), ('various', 'ensemble'), ('ensemble', 'methods'), ('methods', 'to'), ('to', 'better'), ('better', 'handle'), ('handle', 'the'), ('the', 'learners'), ('learners', 'decision'), ('decision', 'boundary'), ('boundary', 'low'), ('low', 'samples'), ('samples', 'and'), ('and', 'ambiguous'), ('ambiguous', 'class'), ('class', 'issues'), ('issues', 'that'), ('that', 'standard'), ('standard', 'machine'), ('machine', 'learning'), ('learning', 'approach'), ('approach', 'tend'), ('tend', 'to'), ('to', 'have'), ('have', 'difficulty'), ('difficulty', 'resolving'), ('resolving', 'However'), ('However', 'the'), ('the', 'computational'), ('computational', 'complexity'), ('complexity', 'of'), ('of', 'these'), ('these', 'algorithms'), ('algorithms', 'are'), ('are', 'dependent'), ('dependent', 'on'), ('on', 'the'), ('the', 'number'), ('number', 'of'), ('of', 'propositions'), ('propositions', 'classes'), ('classes', 'and'), ('and', 'can'), ('can', 'lead'), ('lead', 'to'), ('to', 'a'), ('a', 'much'), ('much', 'higher'), ('higher', 'computation'), ('computation', 'time'), ('time', 'when'), ('when', 'compared'), ('compared', 'to'), ('to', 'other'), ('other', 'machine'), ('machine', 'learning'), ('learning', 'approaches')]\n",
      "\n",
      "Trigrams: [('The', 'theory', 'of'), ('theory', 'of', 'belief'), ('of', 'belief', 'functions'), ('belief', 'functions', 'also'), ('functions', 'also', 'referred'), ('also', 'referred', 'to'), ('referred', 'to', 'as'), ('to', 'as', 'evidence'), ('as', 'evidence', 'theory'), ('evidence', 'theory', 'or'), ('theory', 'or', 'DempsterShafer'), ('or', 'DempsterShafer', 'theory'), ('DempsterShafer', 'theory', 'is'), ('theory', 'is', 'a'), ('is', 'a', 'general'), ('a', 'general', 'framework'), ('general', 'framework', 'for'), ('framework', 'for', 'reasoning'), ('for', 'reasoning', 'with'), ('reasoning', 'with', 'uncertainty'), ('with', 'uncertainty', 'with'), ('uncertainty', 'with', 'understood'), ('with', 'understood', 'connections'), ('understood', 'connections', 'to'), ('connections', 'to', 'other'), ('to', 'other', 'frameworks'), ('other', 'frameworks', 'such'), ('frameworks', 'such', 'as'), ('such', 'as', 'probability'), ('as', 'probability', 'possibility'), ('probability', 'possibility', 'and'), ('possibility', 'and', 'imprecise'), ('and', 'imprecise', 'probability'), ('imprecise', 'probability', 'theories'), ('probability', 'theories', 'These'), ('theories', 'These', 'theoretical'), ('These', 'theoretical', 'frameworks'), ('theoretical', 'frameworks', 'can'), ('frameworks', 'can', 'be'), ('can', 'be', 'thought'), ('be', 'thought', 'of'), ('thought', 'of', 'as'), ('of', 'as', 'a'), ('as', 'a', 'kind'), ('a', 'kind', 'of'), ('kind', 'of', 'learner'), ('of', 'learner', 'and'), ('learner', 'and', 'have'), ('and', 'have', 'some'), ('have', 'some', 'analogous'), ('some', 'analogous', 'properties'), ('analogous', 'properties', 'of'), ('properties', 'of', 'how'), ('of', 'how', 'evidence'), ('how', 'evidence', 'is'), ('evidence', 'is', 'combined'), ('is', 'combined', 'eg'), ('combined', 'eg', 'Dempsters'), ('eg', 'Dempsters', 'rule'), ('Dempsters', 'rule', 'of'), ('rule', 'of', 'combination'), ('of', 'combination', 'just'), ('combination', 'just', 'like'), ('just', 'like', 'how'), ('like', 'how', 'in'), ('how', 'in', 'a'), ('in', 'a', 'pmfbased'), ('a', 'pmfbased', 'Bayesian'), ('pmfbased', 'Bayesian', 'approach'), ('Bayesian', 'approach', 'would'), ('approach', 'would', 'combine'), ('would', 'combine', 'probabilities'), ('combine', 'probabilities', 'However'), ('probabilities', 'However', 'there'), ('However', 'there', 'are'), ('there', 'are', 'many'), ('are', 'many', 'caveats'), ('many', 'caveats', 'to'), ('caveats', 'to', 'these'), ('to', 'these', 'beliefs'), ('these', 'beliefs', 'functions'), ('beliefs', 'functions', 'when'), ('functions', 'when', 'compared'), ('when', 'compared', 'to'), ('compared', 'to', 'Bayesian'), ('to', 'Bayesian', 'approaches'), ('Bayesian', 'approaches', 'in'), ('approaches', 'in', 'order'), ('in', 'order', 'to'), ('order', 'to', 'incorporate'), ('to', 'incorporate', 'ignorance'), ('incorporate', 'ignorance', 'and'), ('ignorance', 'and', 'uncertainty'), ('and', 'uncertainty', 'quantification'), ('uncertainty', 'quantification', 'These'), ('quantification', 'These', 'belief'), ('These', 'belief', 'function'), ('belief', 'function', 'approaches'), ('function', 'approaches', 'that'), ('approaches', 'that', 'are'), ('that', 'are', 'implemented'), ('are', 'implemented', 'within'), ('implemented', 'within', 'the'), ('within', 'the', 'machine'), ('the', 'machine', 'learning'), ('machine', 'learning', 'domain'), ('learning', 'domain', 'typically'), ('domain', 'typically', 'leverage'), ('typically', 'leverage', 'a'), ('leverage', 'a', 'fusion'), ('a', 'fusion', 'approach'), ('fusion', 'approach', 'of'), ('approach', 'of', 'various'), ('of', 'various', 'ensemble'), ('various', 'ensemble', 'methods'), ('ensemble', 'methods', 'to'), ('methods', 'to', 'better'), ('to', 'better', 'handle'), ('better', 'handle', 'the'), ('handle', 'the', 'learners'), ('the', 'learners', 'decision'), ('learners', 'decision', 'boundary'), ('decision', 'boundary', 'low'), ('boundary', 'low', 'samples'), ('low', 'samples', 'and'), ('samples', 'and', 'ambiguous'), ('and', 'ambiguous', 'class'), ('ambiguous', 'class', 'issues'), ('class', 'issues', 'that'), ('issues', 'that', 'standard'), ('that', 'standard', 'machine'), ('standard', 'machine', 'learning'), ('machine', 'learning', 'approach'), ('learning', 'approach', 'tend'), ('approach', 'tend', 'to'), ('tend', 'to', 'have'), ('to', 'have', 'difficulty'), ('have', 'difficulty', 'resolving'), ('difficulty', 'resolving', 'However'), ('resolving', 'However', 'the'), ('However', 'the', 'computational'), ('the', 'computational', 'complexity'), ('computational', 'complexity', 'of'), ('complexity', 'of', 'these'), ('of', 'these', 'algorithms'), ('these', 'algorithms', 'are'), ('algorithms', 'are', 'dependent'), ('are', 'dependent', 'on'), ('dependent', 'on', 'the'), ('on', 'the', 'number'), ('the', 'number', 'of'), ('number', 'of', 'propositions'), ('of', 'propositions', 'classes'), ('propositions', 'classes', 'and'), ('classes', 'and', 'can'), ('and', 'can', 'lead'), ('can', 'lead', 'to'), ('lead', 'to', 'a'), ('to', 'a', 'much'), ('a', 'much', 'higher'), ('much', 'higher', 'computation'), ('higher', 'computation', 'time'), ('computation', 'time', 'when'), ('time', 'when', 'compared'), ('when', 'compared', 'to'), ('compared', 'to', 'other'), ('to', 'other', 'machine'), ('other', 'machine', 'learning'), ('machine', 'learning', 'approaches')]\n",
      "\n",
      "Document: Rulebased machine learning RBML is a branch of machine learning that automatically discovers and learns rules from data It provides interpretable models making it useful for decisionmaking in fields like healthcare fraud detection and cybersecurity Key RBML techniques includes learning classifier systems association rule learning artificial immune systems and other similar models These methods extract patterns from data and evolve rules over time\n",
      "\n",
      "\n",
      "Unigrams: [('Rulebased',), ('machine',), ('learning',), ('RBML',), ('is',), ('a',), ('branch',), ('of',), ('machine',), ('learning',), ('that',), ('automatically',), ('discovers',), ('and',), ('learns',), ('rules',), ('from',), ('data',), ('It',), ('provides',), ('interpretable',), ('models',), ('making',), ('it',), ('useful',), ('for',), ('decisionmaking',), ('in',), ('fields',), ('like',), ('healthcare',), ('fraud',), ('detection',), ('and',), ('cybersecurity',), ('Key',), ('RBML',), ('techniques',), ('includes',), ('learning',), ('classifier',), ('systems',), ('association',), ('rule',), ('learning',), ('artificial',), ('immune',), ('systems',), ('and',), ('other',), ('similar',), ('models',), ('These',), ('methods',), ('extract',), ('patterns',), ('from',), ('data',), ('and',), ('evolve',), ('rules',), ('over',), ('time',)]\n",
      "\n",
      "Bigrams: [('Rulebased', 'machine'), ('machine', 'learning'), ('learning', 'RBML'), ('RBML', 'is'), ('is', 'a'), ('a', 'branch'), ('branch', 'of'), ('of', 'machine'), ('machine', 'learning'), ('learning', 'that'), ('that', 'automatically'), ('automatically', 'discovers'), ('discovers', 'and'), ('and', 'learns'), ('learns', 'rules'), ('rules', 'from'), ('from', 'data'), ('data', 'It'), ('It', 'provides'), ('provides', 'interpretable'), ('interpretable', 'models'), ('models', 'making'), ('making', 'it'), ('it', 'useful'), ('useful', 'for'), ('for', 'decisionmaking'), ('decisionmaking', 'in'), ('in', 'fields'), ('fields', 'like'), ('like', 'healthcare'), ('healthcare', 'fraud'), ('fraud', 'detection'), ('detection', 'and'), ('and', 'cybersecurity'), ('cybersecurity', 'Key'), ('Key', 'RBML'), ('RBML', 'techniques'), ('techniques', 'includes'), ('includes', 'learning'), ('learning', 'classifier'), ('classifier', 'systems'), ('systems', 'association'), ('association', 'rule'), ('rule', 'learning'), ('learning', 'artificial'), ('artificial', 'immune'), ('immune', 'systems'), ('systems', 'and'), ('and', 'other'), ('other', 'similar'), ('similar', 'models'), ('models', 'These'), ('These', 'methods'), ('methods', 'extract'), ('extract', 'patterns'), ('patterns', 'from'), ('from', 'data'), ('data', 'and'), ('and', 'evolve'), ('evolve', 'rules'), ('rules', 'over'), ('over', 'time')]\n",
      "\n",
      "Trigrams: [('Rulebased', 'machine', 'learning'), ('machine', 'learning', 'RBML'), ('learning', 'RBML', 'is'), ('RBML', 'is', 'a'), ('is', 'a', 'branch'), ('a', 'branch', 'of'), ('branch', 'of', 'machine'), ('of', 'machine', 'learning'), ('machine', 'learning', 'that'), ('learning', 'that', 'automatically'), ('that', 'automatically', 'discovers'), ('automatically', 'discovers', 'and'), ('discovers', 'and', 'learns'), ('and', 'learns', 'rules'), ('learns', 'rules', 'from'), ('rules', 'from', 'data'), ('from', 'data', 'It'), ('data', 'It', 'provides'), ('It', 'provides', 'interpretable'), ('provides', 'interpretable', 'models'), ('interpretable', 'models', 'making'), ('models', 'making', 'it'), ('making', 'it', 'useful'), ('it', 'useful', 'for'), ('useful', 'for', 'decisionmaking'), ('for', 'decisionmaking', 'in'), ('decisionmaking', 'in', 'fields'), ('in', 'fields', 'like'), ('fields', 'like', 'healthcare'), ('like', 'healthcare', 'fraud'), ('healthcare', 'fraud', 'detection'), ('fraud', 'detection', 'and'), ('detection', 'and', 'cybersecurity'), ('and', 'cybersecurity', 'Key'), ('cybersecurity', 'Key', 'RBML'), ('Key', 'RBML', 'techniques'), ('RBML', 'techniques', 'includes'), ('techniques', 'includes', 'learning'), ('includes', 'learning', 'classifier'), ('learning', 'classifier', 'systems'), ('classifier', 'systems', 'association'), ('systems', 'association', 'rule'), ('association', 'rule', 'learning'), ('rule', 'learning', 'artificial'), ('learning', 'artificial', 'immune'), ('artificial', 'immune', 'systems'), ('immune', 'systems', 'and'), ('systems', 'and', 'other'), ('and', 'other', 'similar'), ('other', 'similar', 'models'), ('similar', 'models', 'These'), ('models', 'These', 'methods'), ('These', 'methods', 'extract'), ('methods', 'extract', 'patterns'), ('extract', 'patterns', 'from'), ('patterns', 'from', 'data'), ('from', 'data', 'and'), ('data', 'and', 'evolve'), ('and', 'evolve', 'rules'), ('evolve', 'rules', 'over'), ('rules', 'over', 'time')]\n",
      "\n",
      "Document: Typically machine learning models require a high quantity of reliable data to perform accurate predictions When training a machine learning model machine learning engineers need to target and collect a large and representative sample of data Data from the training set can be as varied as a corpus of text a collection of images sensor data and data collected from individual users of a service Overfitting is something to watch out for when training a machine learning model Trained models derived from biased or nonevaluated data can result in skewed or undesired predictions Biased models may result in detrimental outcomes thereby furthering the negative impacts on society or objectives Algorithmic bias is a potential result of data not being fully prepared for training Machine learning ethics is becoming a field of study and notably becoming integrated within machine learning engineering teams\n",
      "\n",
      "\n",
      "Unigrams: [('Typically',), ('machine',), ('learning',), ('models',), ('require',), ('a',), ('high',), ('quantity',), ('of',), ('reliable',), ('data',), ('to',), ('perform',), ('accurate',), ('predictions',), ('When',), ('training',), ('a',), ('machine',), ('learning',), ('model',), ('machine',), ('learning',), ('engineers',), ('need',), ('to',), ('target',), ('and',), ('collect',), ('a',), ('large',), ('and',), ('representative',), ('sample',), ('of',), ('data',), ('Data',), ('from',), ('the',), ('training',), ('set',), ('can',), ('be',), ('as',), ('varied',), ('as',), ('a',), ('corpus',), ('of',), ('text',), ('a',), ('collection',), ('of',), ('images',), ('sensor',), ('data',), ('and',), ('data',), ('collected',), ('from',), ('individual',), ('users',), ('of',), ('a',), ('service',), ('Overfitting',), ('is',), ('something',), ('to',), ('watch',), ('out',), ('for',), ('when',), ('training',), ('a',), ('machine',), ('learning',), ('model',), ('Trained',), ('models',), ('derived',), ('from',), ('biased',), ('or',), ('nonevaluated',), ('data',), ('can',), ('result',), ('in',), ('skewed',), ('or',), ('undesired',), ('predictions',), ('Biased',), ('models',), ('may',), ('result',), ('in',), ('detrimental',), ('outcomes',), ('thereby',), ('furthering',), ('the',), ('negative',), ('impacts',), ('on',), ('society',), ('or',), ('objectives',), ('Algorithmic',), ('bias',), ('is',), ('a',), ('potential',), ('result',), ('of',), ('data',), ('not',), ('being',), ('fully',), ('prepared',), ('for',), ('training',), ('Machine',), ('learning',), ('ethics',), ('is',), ('becoming',), ('a',), ('field',), ('of',), ('study',), ('and',), ('notably',), ('becoming',), ('integrated',), ('within',), ('machine',), ('learning',), ('engineering',), ('teams',)]\n",
      "\n",
      "Bigrams: [('Typically', 'machine'), ('machine', 'learning'), ('learning', 'models'), ('models', 'require'), ('require', 'a'), ('a', 'high'), ('high', 'quantity'), ('quantity', 'of'), ('of', 'reliable'), ('reliable', 'data'), ('data', 'to'), ('to', 'perform'), ('perform', 'accurate'), ('accurate', 'predictions'), ('predictions', 'When'), ('When', 'training'), ('training', 'a'), ('a', 'machine'), ('machine', 'learning'), ('learning', 'model'), ('model', 'machine'), ('machine', 'learning'), ('learning', 'engineers'), ('engineers', 'need'), ('need', 'to'), ('to', 'target'), ('target', 'and'), ('and', 'collect'), ('collect', 'a'), ('a', 'large'), ('large', 'and'), ('and', 'representative'), ('representative', 'sample'), ('sample', 'of'), ('of', 'data'), ('data', 'Data'), ('Data', 'from'), ('from', 'the'), ('the', 'training'), ('training', 'set'), ('set', 'can'), ('can', 'be'), ('be', 'as'), ('as', 'varied'), ('varied', 'as'), ('as', 'a'), ('a', 'corpus'), ('corpus', 'of'), ('of', 'text'), ('text', 'a'), ('a', 'collection'), ('collection', 'of'), ('of', 'images'), ('images', 'sensor'), ('sensor', 'data'), ('data', 'and'), ('and', 'data'), ('data', 'collected'), ('collected', 'from'), ('from', 'individual'), ('individual', 'users'), ('users', 'of'), ('of', 'a'), ('a', 'service'), ('service', 'Overfitting'), ('Overfitting', 'is'), ('is', 'something'), ('something', 'to'), ('to', 'watch'), ('watch', 'out'), ('out', 'for'), ('for', 'when'), ('when', 'training'), ('training', 'a'), ('a', 'machine'), ('machine', 'learning'), ('learning', 'model'), ('model', 'Trained'), ('Trained', 'models'), ('models', 'derived'), ('derived', 'from'), ('from', 'biased'), ('biased', 'or'), ('or', 'nonevaluated'), ('nonevaluated', 'data'), ('data', 'can'), ('can', 'result'), ('result', 'in'), ('in', 'skewed'), ('skewed', 'or'), ('or', 'undesired'), ('undesired', 'predictions'), ('predictions', 'Biased'), ('Biased', 'models'), ('models', 'may'), ('may', 'result'), ('result', 'in'), ('in', 'detrimental'), ('detrimental', 'outcomes'), ('outcomes', 'thereby'), ('thereby', 'furthering'), ('furthering', 'the'), ('the', 'negative'), ('negative', 'impacts'), ('impacts', 'on'), ('on', 'society'), ('society', 'or'), ('or', 'objectives'), ('objectives', 'Algorithmic'), ('Algorithmic', 'bias'), ('bias', 'is'), ('is', 'a'), ('a', 'potential'), ('potential', 'result'), ('result', 'of'), ('of', 'data'), ('data', 'not'), ('not', 'being'), ('being', 'fully'), ('fully', 'prepared'), ('prepared', 'for'), ('for', 'training'), ('training', 'Machine'), ('Machine', 'learning'), ('learning', 'ethics'), ('ethics', 'is'), ('is', 'becoming'), ('becoming', 'a'), ('a', 'field'), ('field', 'of'), ('of', 'study'), ('study', 'and'), ('and', 'notably'), ('notably', 'becoming'), ('becoming', 'integrated'), ('integrated', 'within'), ('within', 'machine'), ('machine', 'learning'), ('learning', 'engineering'), ('engineering', 'teams')]\n",
      "\n",
      "Trigrams: [('Typically', 'machine', 'learning'), ('machine', 'learning', 'models'), ('learning', 'models', 'require'), ('models', 'require', 'a'), ('require', 'a', 'high'), ('a', 'high', 'quantity'), ('high', 'quantity', 'of'), ('quantity', 'of', 'reliable'), ('of', 'reliable', 'data'), ('reliable', 'data', 'to'), ('data', 'to', 'perform'), ('to', 'perform', 'accurate'), ('perform', 'accurate', 'predictions'), ('accurate', 'predictions', 'When'), ('predictions', 'When', 'training'), ('When', 'training', 'a'), ('training', 'a', 'machine'), ('a', 'machine', 'learning'), ('machine', 'learning', 'model'), ('learning', 'model', 'machine'), ('model', 'machine', 'learning'), ('machine', 'learning', 'engineers'), ('learning', 'engineers', 'need'), ('engineers', 'need', 'to'), ('need', 'to', 'target'), ('to', 'target', 'and'), ('target', 'and', 'collect'), ('and', 'collect', 'a'), ('collect', 'a', 'large'), ('a', 'large', 'and'), ('large', 'and', 'representative'), ('and', 'representative', 'sample'), ('representative', 'sample', 'of'), ('sample', 'of', 'data'), ('of', 'data', 'Data'), ('data', 'Data', 'from'), ('Data', 'from', 'the'), ('from', 'the', 'training'), ('the', 'training', 'set'), ('training', 'set', 'can'), ('set', 'can', 'be'), ('can', 'be', 'as'), ('be', 'as', 'varied'), ('as', 'varied', 'as'), ('varied', 'as', 'a'), ('as', 'a', 'corpus'), ('a', 'corpus', 'of'), ('corpus', 'of', 'text'), ('of', 'text', 'a'), ('text', 'a', 'collection'), ('a', 'collection', 'of'), ('collection', 'of', 'images'), ('of', 'images', 'sensor'), ('images', 'sensor', 'data'), ('sensor', 'data', 'and'), ('data', 'and', 'data'), ('and', 'data', 'collected'), ('data', 'collected', 'from'), ('collected', 'from', 'individual'), ('from', 'individual', 'users'), ('individual', 'users', 'of'), ('users', 'of', 'a'), ('of', 'a', 'service'), ('a', 'service', 'Overfitting'), ('service', 'Overfitting', 'is'), ('Overfitting', 'is', 'something'), ('is', 'something', 'to'), ('something', 'to', 'watch'), ('to', 'watch', 'out'), ('watch', 'out', 'for'), ('out', 'for', 'when'), ('for', 'when', 'training'), ('when', 'training', 'a'), ('training', 'a', 'machine'), ('a', 'machine', 'learning'), ('machine', 'learning', 'model'), ('learning', 'model', 'Trained'), ('model', 'Trained', 'models'), ('Trained', 'models', 'derived'), ('models', 'derived', 'from'), ('derived', 'from', 'biased'), ('from', 'biased', 'or'), ('biased', 'or', 'nonevaluated'), ('or', 'nonevaluated', 'data'), ('nonevaluated', 'data', 'can'), ('data', 'can', 'result'), ('can', 'result', 'in'), ('result', 'in', 'skewed'), ('in', 'skewed', 'or'), ('skewed', 'or', 'undesired'), ('or', 'undesired', 'predictions'), ('undesired', 'predictions', 'Biased'), ('predictions', 'Biased', 'models'), ('Biased', 'models', 'may'), ('models', 'may', 'result'), ('may', 'result', 'in'), ('result', 'in', 'detrimental'), ('in', 'detrimental', 'outcomes'), ('detrimental', 'outcomes', 'thereby'), ('outcomes', 'thereby', 'furthering'), ('thereby', 'furthering', 'the'), ('furthering', 'the', 'negative'), ('the', 'negative', 'impacts'), ('negative', 'impacts', 'on'), ('impacts', 'on', 'society'), ('on', 'society', 'or'), ('society', 'or', 'objectives'), ('or', 'objectives', 'Algorithmic'), ('objectives', 'Algorithmic', 'bias'), ('Algorithmic', 'bias', 'is'), ('bias', 'is', 'a'), ('is', 'a', 'potential'), ('a', 'potential', 'result'), ('potential', 'result', 'of'), ('result', 'of', 'data'), ('of', 'data', 'not'), ('data', 'not', 'being'), ('not', 'being', 'fully'), ('being', 'fully', 'prepared'), ('fully', 'prepared', 'for'), ('prepared', 'for', 'training'), ('for', 'training', 'Machine'), ('training', 'Machine', 'learning'), ('Machine', 'learning', 'ethics'), ('learning', 'ethics', 'is'), ('ethics', 'is', 'becoming'), ('is', 'becoming', 'a'), ('becoming', 'a', 'field'), ('a', 'field', 'of'), ('field', 'of', 'study'), ('of', 'study', 'and'), ('study', 'and', 'notably'), ('and', 'notably', 'becoming'), ('notably', 'becoming', 'integrated'), ('becoming', 'integrated', 'within'), ('integrated', 'within', 'machine'), ('within', 'machine', 'learning'), ('machine', 'learning', 'engineering'), ('learning', 'engineering', 'teams')]\n",
      "\n",
      "Document: Federated learning is an adapted form of distributed artificial intelligence to training machine learning models that decentralises the training process allowing for users privacy to be maintained by not needing to send their data to a centralised server This also increases efficiency by decentralising the training process to many devices For example Gboard uses federated machine learning to train search query prediction models on users mobile phones without having to send individual searches back to Google\n",
      "\n",
      "\n",
      "Unigrams: [('Federated',), ('learning',), ('is',), ('an',), ('adapted',), ('form',), ('of',), ('distributed',), ('artificial',), ('intelligence',), ('to',), ('training',), ('machine',), ('learning',), ('models',), ('that',), ('decentralises',), ('the',), ('training',), ('process',), ('allowing',), ('for',), ('users',), ('privacy',), ('to',), ('be',), ('maintained',), ('by',), ('not',), ('needing',), ('to',), ('send',), ('their',), ('data',), ('to',), ('a',), ('centralised',), ('server',), ('This',), ('also',), ('increases',), ('efficiency',), ('by',), ('decentralising',), ('the',), ('training',), ('process',), ('to',), ('many',), ('devices',), ('For',), ('example',), ('Gboard',), ('uses',), ('federated',), ('machine',), ('learning',), ('to',), ('train',), ('search',), ('query',), ('prediction',), ('models',), ('on',), ('users',), ('mobile',), ('phones',), ('without',), ('having',), ('to',), ('send',), ('individual',), ('searches',), ('back',), ('to',), ('Google',)]\n",
      "\n",
      "Bigrams: [('Federated', 'learning'), ('learning', 'is'), ('is', 'an'), ('an', 'adapted'), ('adapted', 'form'), ('form', 'of'), ('of', 'distributed'), ('distributed', 'artificial'), ('artificial', 'intelligence'), ('intelligence', 'to'), ('to', 'training'), ('training', 'machine'), ('machine', 'learning'), ('learning', 'models'), ('models', 'that'), ('that', 'decentralises'), ('decentralises', 'the'), ('the', 'training'), ('training', 'process'), ('process', 'allowing'), ('allowing', 'for'), ('for', 'users'), ('users', 'privacy'), ('privacy', 'to'), ('to', 'be'), ('be', 'maintained'), ('maintained', 'by'), ('by', 'not'), ('not', 'needing'), ('needing', 'to'), ('to', 'send'), ('send', 'their'), ('their', 'data'), ('data', 'to'), ('to', 'a'), ('a', 'centralised'), ('centralised', 'server'), ('server', 'This'), ('This', 'also'), ('also', 'increases'), ('increases', 'efficiency'), ('efficiency', 'by'), ('by', 'decentralising'), ('decentralising', 'the'), ('the', 'training'), ('training', 'process'), ('process', 'to'), ('to', 'many'), ('many', 'devices'), ('devices', 'For'), ('For', 'example'), ('example', 'Gboard'), ('Gboard', 'uses'), ('uses', 'federated'), ('federated', 'machine'), ('machine', 'learning'), ('learning', 'to'), ('to', 'train'), ('train', 'search'), ('search', 'query'), ('query', 'prediction'), ('prediction', 'models'), ('models', 'on'), ('on', 'users'), ('users', 'mobile'), ('mobile', 'phones'), ('phones', 'without'), ('without', 'having'), ('having', 'to'), ('to', 'send'), ('send', 'individual'), ('individual', 'searches'), ('searches', 'back'), ('back', 'to'), ('to', 'Google')]\n",
      "\n",
      "Trigrams: [('Federated', 'learning', 'is'), ('learning', 'is', 'an'), ('is', 'an', 'adapted'), ('an', 'adapted', 'form'), ('adapted', 'form', 'of'), ('form', 'of', 'distributed'), ('of', 'distributed', 'artificial'), ('distributed', 'artificial', 'intelligence'), ('artificial', 'intelligence', 'to'), ('intelligence', 'to', 'training'), ('to', 'training', 'machine'), ('training', 'machine', 'learning'), ('machine', 'learning', 'models'), ('learning', 'models', 'that'), ('models', 'that', 'decentralises'), ('that', 'decentralises', 'the'), ('decentralises', 'the', 'training'), ('the', 'training', 'process'), ('training', 'process', 'allowing'), ('process', 'allowing', 'for'), ('allowing', 'for', 'users'), ('for', 'users', 'privacy'), ('users', 'privacy', 'to'), ('privacy', 'to', 'be'), ('to', 'be', 'maintained'), ('be', 'maintained', 'by'), ('maintained', 'by', 'not'), ('by', 'not', 'needing'), ('not', 'needing', 'to'), ('needing', 'to', 'send'), ('to', 'send', 'their'), ('send', 'their', 'data'), ('their', 'data', 'to'), ('data', 'to', 'a'), ('to', 'a', 'centralised'), ('a', 'centralised', 'server'), ('centralised', 'server', 'This'), ('server', 'This', 'also'), ('This', 'also', 'increases'), ('also', 'increases', 'efficiency'), ('increases', 'efficiency', 'by'), ('efficiency', 'by', 'decentralising'), ('by', 'decentralising', 'the'), ('decentralising', 'the', 'training'), ('the', 'training', 'process'), ('training', 'process', 'to'), ('process', 'to', 'many'), ('to', 'many', 'devices'), ('many', 'devices', 'For'), ('devices', 'For', 'example'), ('For', 'example', 'Gboard'), ('example', 'Gboard', 'uses'), ('Gboard', 'uses', 'federated'), ('uses', 'federated', 'machine'), ('federated', 'machine', 'learning'), ('machine', 'learning', 'to'), ('learning', 'to', 'train'), ('to', 'train', 'search'), ('train', 'search', 'query'), ('search', 'query', 'prediction'), ('query', 'prediction', 'models'), ('prediction', 'models', 'on'), ('models', 'on', 'users'), ('on', 'users', 'mobile'), ('users', 'mobile', 'phones'), ('mobile', 'phones', 'without'), ('phones', 'without', 'having'), ('without', 'having', 'to'), ('having', 'to', 'send'), ('to', 'send', 'individual'), ('send', 'individual', 'searches'), ('individual', 'searches', 'back'), ('searches', 'back', 'to'), ('back', 'to', 'Google')]\n",
      "\n",
      "Document: There are many applications for machine learning including\n",
      "\n",
      "\n",
      "Unigrams: [('There',), ('are',), ('many',), ('applications',), ('for',), ('machine',), ('learning',), ('including',)]\n",
      "\n",
      "Bigrams: [('There', 'are'), ('are', 'many'), ('many', 'applications'), ('applications', 'for'), ('for', 'machine'), ('machine', 'learning'), ('learning', 'including')]\n",
      "\n",
      "Trigrams: [('There', 'are', 'many'), ('are', 'many', 'applications'), ('many', 'applications', 'for'), ('applications', 'for', 'machine'), ('for', 'machine', 'learning'), ('machine', 'learning', 'including')]\n",
      "\n",
      "Document: In  the mediaservices provider Netflix held the first Netflix Prize competition to find a program to better predict user preferences and improve the accuracy of its existing Cinematch movie recommendation algorithm by at least  A joint team made up of researchers from ATT LabsResearch in collaboration with the teams Big Chaos and Pragmatic Theory built an ensemble model to win the Grand Prize in  for  million Shortly after the prize was awarded Netflix realised that viewers ratings were not the best indicators of their viewing patterns everything is a recommendation and they changed their recommendation engine accordingly In  The Wall Street Journal wrote about the firm Rebellion Research and their use of machine learning to predict the financial crisis In  cofounder of Sun Microsystems Vinod Khosla predicted that  of medical doctors jobs would be lost in the next two decades to automated machine learning medical diagnostic software In  it was reported that a machine learning algorithm had been applied in the field of art history to study fine art paintings and that it may have revealed previously unrecognised influences among artists In  Springer Nature published the first research book created using machine learning In  machine learning technology was used to help make diagnoses and aid researchers in developing a cure for COVID Machine learning was recently applied to predict the proenvironmental behaviour of travellers Recently machine learning technology was also applied to optimise smartphones performance and thermal behaviour based on the users interaction with the phone When applied correctly machine learning algorithms MLAs can utilise a wide range of company characteristics to predict stock returns without overfitting By employing effective feature engineering and combining forecasts MLAs can generate results that far surpass those obtained from basic linear techniques like OLS\n",
      "\n",
      "\n",
      "Unigrams: [('In',), ('the',), ('mediaservices',), ('provider',), ('Netflix',), ('held',), ('the',), ('first',), ('Netflix',), ('Prize',), ('competition',), ('to',), ('find',), ('a',), ('program',), ('to',), ('better',), ('predict',), ('user',), ('preferences',), ('and',), ('improve',), ('the',), ('accuracy',), ('of',), ('its',), ('existing',), ('Cinematch',), ('movie',), ('recommendation',), ('algorithm',), ('by',), ('at',), ('least',), ('A',), ('joint',), ('team',), ('made',), ('up',), ('of',), ('researchers',), ('from',), ('ATT',), ('LabsResearch',), ('in',), ('collaboration',), ('with',), ('the',), ('teams',), ('Big',), ('Chaos',), ('and',), ('Pragmatic',), ('Theory',), ('built',), ('an',), ('ensemble',), ('model',), ('to',), ('win',), ('the',), ('Grand',), ('Prize',), ('in',), ('for',), ('million',), ('Shortly',), ('after',), ('the',), ('prize',), ('was',), ('awarded',), ('Netflix',), ('realised',), ('that',), ('viewers',), ('ratings',), ('were',), ('not',), ('the',), ('best',), ('indicators',), ('of',), ('their',), ('viewing',), ('patterns',), ('everything',), ('is',), ('a',), ('recommendation',), ('and',), ('they',), ('changed',), ('their',), ('recommendation',), ('engine',), ('accordingly',), ('In',), ('The',), ('Wall',), ('Street',), ('Journal',), ('wrote',), ('about',), ('the',), ('firm',), ('Rebellion',), ('Research',), ('and',), ('their',), ('use',), ('of',), ('machine',), ('learning',), ('to',), ('predict',), ('the',), ('financial',), ('crisis',), ('In',), ('cofounder',), ('of',), ('Sun',), ('Microsystems',), ('Vinod',), ('Khosla',), ('predicted',), ('that',), ('of',), ('medical',), ('doctors',), ('jobs',), ('would',), ('be',), ('lost',), ('in',), ('the',), ('next',), ('two',), ('decades',), ('to',), ('automated',), ('machine',), ('learning',), ('medical',), ('diagnostic',), ('software',), ('In',), ('it',), ('was',), ('reported',), ('that',), ('a',), ('machine',), ('learning',), ('algorithm',), ('had',), ('been',), ('applied',), ('in',), ('the',), ('field',), ('of',), ('art',), ('history',), ('to',), ('study',), ('fine',), ('art',), ('paintings',), ('and',), ('that',), ('it',), ('may',), ('have',), ('revealed',), ('previously',), ('unrecognised',), ('influences',), ('among',), ('artists',), ('In',), ('Springer',), ('Nature',), ('published',), ('the',), ('first',), ('research',), ('book',), ('created',), ('using',), ('machine',), ('learning',), ('In',), ('machine',), ('learning',), ('technology',), ('was',), ('used',), ('to',), ('help',), ('make',), ('diagnoses',), ('and',), ('aid',), ('researchers',), ('in',), ('developing',), ('a',), ('cure',), ('for',), ('COVID',), ('Machine',), ('learning',), ('was',), ('recently',), ('applied',), ('to',), ('predict',), ('the',), ('proenvironmental',), ('behaviour',), ('of',), ('travellers',), ('Recently',), ('machine',), ('learning',), ('technology',), ('was',), ('also',), ('applied',), ('to',), ('optimise',), ('smartphones',), ('performance',), ('and',), ('thermal',), ('behaviour',), ('based',), ('on',), ('the',), ('users',), ('interaction',), ('with',), ('the',), ('phone',), ('When',), ('applied',), ('correctly',), ('machine',), ('learning',), ('algorithms',), ('MLAs',), ('can',), ('utilise',), ('a',), ('wide',), ('range',), ('of',), ('company',), ('characteristics',), ('to',), ('predict',), ('stock',), ('returns',), ('without',), ('overfitting',), ('By',), ('employing',), ('effective',), ('feature',), ('engineering',), ('and',), ('combining',), ('forecasts',), ('MLAs',), ('can',), ('generate',), ('results',), ('that',), ('far',), ('surpass',), ('those',), ('obtained',), ('from',), ('basic',), ('linear',), ('techniques',), ('like',), ('OLS',)]\n",
      "\n",
      "Bigrams: [('In', 'the'), ('the', 'mediaservices'), ('mediaservices', 'provider'), ('provider', 'Netflix'), ('Netflix', 'held'), ('held', 'the'), ('the', 'first'), ('first', 'Netflix'), ('Netflix', 'Prize'), ('Prize', 'competition'), ('competition', 'to'), ('to', 'find'), ('find', 'a'), ('a', 'program'), ('program', 'to'), ('to', 'better'), ('better', 'predict'), ('predict', 'user'), ('user', 'preferences'), ('preferences', 'and'), ('and', 'improve'), ('improve', 'the'), ('the', 'accuracy'), ('accuracy', 'of'), ('of', 'its'), ('its', 'existing'), ('existing', 'Cinematch'), ('Cinematch', 'movie'), ('movie', 'recommendation'), ('recommendation', 'algorithm'), ('algorithm', 'by'), ('by', 'at'), ('at', 'least'), ('least', 'A'), ('A', 'joint'), ('joint', 'team'), ('team', 'made'), ('made', 'up'), ('up', 'of'), ('of', 'researchers'), ('researchers', 'from'), ('from', 'ATT'), ('ATT', 'LabsResearch'), ('LabsResearch', 'in'), ('in', 'collaboration'), ('collaboration', 'with'), ('with', 'the'), ('the', 'teams'), ('teams', 'Big'), ('Big', 'Chaos'), ('Chaos', 'and'), ('and', 'Pragmatic'), ('Pragmatic', 'Theory'), ('Theory', 'built'), ('built', 'an'), ('an', 'ensemble'), ('ensemble', 'model'), ('model', 'to'), ('to', 'win'), ('win', 'the'), ('the', 'Grand'), ('Grand', 'Prize'), ('Prize', 'in'), ('in', 'for'), ('for', 'million'), ('million', 'Shortly'), ('Shortly', 'after'), ('after', 'the'), ('the', 'prize'), ('prize', 'was'), ('was', 'awarded'), ('awarded', 'Netflix'), ('Netflix', 'realised'), ('realised', 'that'), ('that', 'viewers'), ('viewers', 'ratings'), ('ratings', 'were'), ('were', 'not'), ('not', 'the'), ('the', 'best'), ('best', 'indicators'), ('indicators', 'of'), ('of', 'their'), ('their', 'viewing'), ('viewing', 'patterns'), ('patterns', 'everything'), ('everything', 'is'), ('is', 'a'), ('a', 'recommendation'), ('recommendation', 'and'), ('and', 'they'), ('they', 'changed'), ('changed', 'their'), ('their', 'recommendation'), ('recommendation', 'engine'), ('engine', 'accordingly'), ('accordingly', 'In'), ('In', 'The'), ('The', 'Wall'), ('Wall', 'Street'), ('Street', 'Journal'), ('Journal', 'wrote'), ('wrote', 'about'), ('about', 'the'), ('the', 'firm'), ('firm', 'Rebellion'), ('Rebellion', 'Research'), ('Research', 'and'), ('and', 'their'), ('their', 'use'), ('use', 'of'), ('of', 'machine'), ('machine', 'learning'), ('learning', 'to'), ('to', 'predict'), ('predict', 'the'), ('the', 'financial'), ('financial', 'crisis'), ('crisis', 'In'), ('In', 'cofounder'), ('cofounder', 'of'), ('of', 'Sun'), ('Sun', 'Microsystems'), ('Microsystems', 'Vinod'), ('Vinod', 'Khosla'), ('Khosla', 'predicted'), ('predicted', 'that'), ('that', 'of'), ('of', 'medical'), ('medical', 'doctors'), ('doctors', 'jobs'), ('jobs', 'would'), ('would', 'be'), ('be', 'lost'), ('lost', 'in'), ('in', 'the'), ('the', 'next'), ('next', 'two'), ('two', 'decades'), ('decades', 'to'), ('to', 'automated'), ('automated', 'machine'), ('machine', 'learning'), ('learning', 'medical'), ('medical', 'diagnostic'), ('diagnostic', 'software'), ('software', 'In'), ('In', 'it'), ('it', 'was'), ('was', 'reported'), ('reported', 'that'), ('that', 'a'), ('a', 'machine'), ('machine', 'learning'), ('learning', 'algorithm'), ('algorithm', 'had'), ('had', 'been'), ('been', 'applied'), ('applied', 'in'), ('in', 'the'), ('the', 'field'), ('field', 'of'), ('of', 'art'), ('art', 'history'), ('history', 'to'), ('to', 'study'), ('study', 'fine'), ('fine', 'art'), ('art', 'paintings'), ('paintings', 'and'), ('and', 'that'), ('that', 'it'), ('it', 'may'), ('may', 'have'), ('have', 'revealed'), ('revealed', 'previously'), ('previously', 'unrecognised'), ('unrecognised', 'influences'), ('influences', 'among'), ('among', 'artists'), ('artists', 'In'), ('In', 'Springer'), ('Springer', 'Nature'), ('Nature', 'published'), ('published', 'the'), ('the', 'first'), ('first', 'research'), ('research', 'book'), ('book', 'created'), ('created', 'using'), ('using', 'machine'), ('machine', 'learning'), ('learning', 'In'), ('In', 'machine'), ('machine', 'learning'), ('learning', 'technology'), ('technology', 'was'), ('was', 'used'), ('used', 'to'), ('to', 'help'), ('help', 'make'), ('make', 'diagnoses'), ('diagnoses', 'and'), ('and', 'aid'), ('aid', 'researchers'), ('researchers', 'in'), ('in', 'developing'), ('developing', 'a'), ('a', 'cure'), ('cure', 'for'), ('for', 'COVID'), ('COVID', 'Machine'), ('Machine', 'learning'), ('learning', 'was'), ('was', 'recently'), ('recently', 'applied'), ('applied', 'to'), ('to', 'predict'), ('predict', 'the'), ('the', 'proenvironmental'), ('proenvironmental', 'behaviour'), ('behaviour', 'of'), ('of', 'travellers'), ('travellers', 'Recently'), ('Recently', 'machine'), ('machine', 'learning'), ('learning', 'technology'), ('technology', 'was'), ('was', 'also'), ('also', 'applied'), ('applied', 'to'), ('to', 'optimise'), ('optimise', 'smartphones'), ('smartphones', 'performance'), ('performance', 'and'), ('and', 'thermal'), ('thermal', 'behaviour'), ('behaviour', 'based'), ('based', 'on'), ('on', 'the'), ('the', 'users'), ('users', 'interaction'), ('interaction', 'with'), ('with', 'the'), ('the', 'phone'), ('phone', 'When'), ('When', 'applied'), ('applied', 'correctly'), ('correctly', 'machine'), ('machine', 'learning'), ('learning', 'algorithms'), ('algorithms', 'MLAs'), ('MLAs', 'can'), ('can', 'utilise'), ('utilise', 'a'), ('a', 'wide'), ('wide', 'range'), ('range', 'of'), ('of', 'company'), ('company', 'characteristics'), ('characteristics', 'to'), ('to', 'predict'), ('predict', 'stock'), ('stock', 'returns'), ('returns', 'without'), ('without', 'overfitting'), ('overfitting', 'By'), ('By', 'employing'), ('employing', 'effective'), ('effective', 'feature'), ('feature', 'engineering'), ('engineering', 'and'), ('and', 'combining'), ('combining', 'forecasts'), ('forecasts', 'MLAs'), ('MLAs', 'can'), ('can', 'generate'), ('generate', 'results'), ('results', 'that'), ('that', 'far'), ('far', 'surpass'), ('surpass', 'those'), ('those', 'obtained'), ('obtained', 'from'), ('from', 'basic'), ('basic', 'linear'), ('linear', 'techniques'), ('techniques', 'like'), ('like', 'OLS')]\n",
      "\n",
      "Trigrams: [('In', 'the', 'mediaservices'), ('the', 'mediaservices', 'provider'), ('mediaservices', 'provider', 'Netflix'), ('provider', 'Netflix', 'held'), ('Netflix', 'held', 'the'), ('held', 'the', 'first'), ('the', 'first', 'Netflix'), ('first', 'Netflix', 'Prize'), ('Netflix', 'Prize', 'competition'), ('Prize', 'competition', 'to'), ('competition', 'to', 'find'), ('to', 'find', 'a'), ('find', 'a', 'program'), ('a', 'program', 'to'), ('program', 'to', 'better'), ('to', 'better', 'predict'), ('better', 'predict', 'user'), ('predict', 'user', 'preferences'), ('user', 'preferences', 'and'), ('preferences', 'and', 'improve'), ('and', 'improve', 'the'), ('improve', 'the', 'accuracy'), ('the', 'accuracy', 'of'), ('accuracy', 'of', 'its'), ('of', 'its', 'existing'), ('its', 'existing', 'Cinematch'), ('existing', 'Cinematch', 'movie'), ('Cinematch', 'movie', 'recommendation'), ('movie', 'recommendation', 'algorithm'), ('recommendation', 'algorithm', 'by'), ('algorithm', 'by', 'at'), ('by', 'at', 'least'), ('at', 'least', 'A'), ('least', 'A', 'joint'), ('A', 'joint', 'team'), ('joint', 'team', 'made'), ('team', 'made', 'up'), ('made', 'up', 'of'), ('up', 'of', 'researchers'), ('of', 'researchers', 'from'), ('researchers', 'from', 'ATT'), ('from', 'ATT', 'LabsResearch'), ('ATT', 'LabsResearch', 'in'), ('LabsResearch', 'in', 'collaboration'), ('in', 'collaboration', 'with'), ('collaboration', 'with', 'the'), ('with', 'the', 'teams'), ('the', 'teams', 'Big'), ('teams', 'Big', 'Chaos'), ('Big', 'Chaos', 'and'), ('Chaos', 'and', 'Pragmatic'), ('and', 'Pragmatic', 'Theory'), ('Pragmatic', 'Theory', 'built'), ('Theory', 'built', 'an'), ('built', 'an', 'ensemble'), ('an', 'ensemble', 'model'), ('ensemble', 'model', 'to'), ('model', 'to', 'win'), ('to', 'win', 'the'), ('win', 'the', 'Grand'), ('the', 'Grand', 'Prize'), ('Grand', 'Prize', 'in'), ('Prize', 'in', 'for'), ('in', 'for', 'million'), ('for', 'million', 'Shortly'), ('million', 'Shortly', 'after'), ('Shortly', 'after', 'the'), ('after', 'the', 'prize'), ('the', 'prize', 'was'), ('prize', 'was', 'awarded'), ('was', 'awarded', 'Netflix'), ('awarded', 'Netflix', 'realised'), ('Netflix', 'realised', 'that'), ('realised', 'that', 'viewers'), ('that', 'viewers', 'ratings'), ('viewers', 'ratings', 'were'), ('ratings', 'were', 'not'), ('were', 'not', 'the'), ('not', 'the', 'best'), ('the', 'best', 'indicators'), ('best', 'indicators', 'of'), ('indicators', 'of', 'their'), ('of', 'their', 'viewing'), ('their', 'viewing', 'patterns'), ('viewing', 'patterns', 'everything'), ('patterns', 'everything', 'is'), ('everything', 'is', 'a'), ('is', 'a', 'recommendation'), ('a', 'recommendation', 'and'), ('recommendation', 'and', 'they'), ('and', 'they', 'changed'), ('they', 'changed', 'their'), ('changed', 'their', 'recommendation'), ('their', 'recommendation', 'engine'), ('recommendation', 'engine', 'accordingly'), ('engine', 'accordingly', 'In'), ('accordingly', 'In', 'The'), ('In', 'The', 'Wall'), ('The', 'Wall', 'Street'), ('Wall', 'Street', 'Journal'), ('Street', 'Journal', 'wrote'), ('Journal', 'wrote', 'about'), ('wrote', 'about', 'the'), ('about', 'the', 'firm'), ('the', 'firm', 'Rebellion'), ('firm', 'Rebellion', 'Research'), ('Rebellion', 'Research', 'and'), ('Research', 'and', 'their'), ('and', 'their', 'use'), ('their', 'use', 'of'), ('use', 'of', 'machine'), ('of', 'machine', 'learning'), ('machine', 'learning', 'to'), ('learning', 'to', 'predict'), ('to', 'predict', 'the'), ('predict', 'the', 'financial'), ('the', 'financial', 'crisis'), ('financial', 'crisis', 'In'), ('crisis', 'In', 'cofounder'), ('In', 'cofounder', 'of'), ('cofounder', 'of', 'Sun'), ('of', 'Sun', 'Microsystems'), ('Sun', 'Microsystems', 'Vinod'), ('Microsystems', 'Vinod', 'Khosla'), ('Vinod', 'Khosla', 'predicted'), ('Khosla', 'predicted', 'that'), ('predicted', 'that', 'of'), ('that', 'of', 'medical'), ('of', 'medical', 'doctors'), ('medical', 'doctors', 'jobs'), ('doctors', 'jobs', 'would'), ('jobs', 'would', 'be'), ('would', 'be', 'lost'), ('be', 'lost', 'in'), ('lost', 'in', 'the'), ('in', 'the', 'next'), ('the', 'next', 'two'), ('next', 'two', 'decades'), ('two', 'decades', 'to'), ('decades', 'to', 'automated'), ('to', 'automated', 'machine'), ('automated', 'machine', 'learning'), ('machine', 'learning', 'medical'), ('learning', 'medical', 'diagnostic'), ('medical', 'diagnostic', 'software'), ('diagnostic', 'software', 'In'), ('software', 'In', 'it'), ('In', 'it', 'was'), ('it', 'was', 'reported'), ('was', 'reported', 'that'), ('reported', 'that', 'a'), ('that', 'a', 'machine'), ('a', 'machine', 'learning'), ('machine', 'learning', 'algorithm'), ('learning', 'algorithm', 'had'), ('algorithm', 'had', 'been'), ('had', 'been', 'applied'), ('been', 'applied', 'in'), ('applied', 'in', 'the'), ('in', 'the', 'field'), ('the', 'field', 'of'), ('field', 'of', 'art'), ('of', 'art', 'history'), ('art', 'history', 'to'), ('history', 'to', 'study'), ('to', 'study', 'fine'), ('study', 'fine', 'art'), ('fine', 'art', 'paintings'), ('art', 'paintings', 'and'), ('paintings', 'and', 'that'), ('and', 'that', 'it'), ('that', 'it', 'may'), ('it', 'may', 'have'), ('may', 'have', 'revealed'), ('have', 'revealed', 'previously'), ('revealed', 'previously', 'unrecognised'), ('previously', 'unrecognised', 'influences'), ('unrecognised', 'influences', 'among'), ('influences', 'among', 'artists'), ('among', 'artists', 'In'), ('artists', 'In', 'Springer'), ('In', 'Springer', 'Nature'), ('Springer', 'Nature', 'published'), ('Nature', 'published', 'the'), ('published', 'the', 'first'), ('the', 'first', 'research'), ('first', 'research', 'book'), ('research', 'book', 'created'), ('book', 'created', 'using'), ('created', 'using', 'machine'), ('using', 'machine', 'learning'), ('machine', 'learning', 'In'), ('learning', 'In', 'machine'), ('In', 'machine', 'learning'), ('machine', 'learning', 'technology'), ('learning', 'technology', 'was'), ('technology', 'was', 'used'), ('was', 'used', 'to'), ('used', 'to', 'help'), ('to', 'help', 'make'), ('help', 'make', 'diagnoses'), ('make', 'diagnoses', 'and'), ('diagnoses', 'and', 'aid'), ('and', 'aid', 'researchers'), ('aid', 'researchers', 'in'), ('researchers', 'in', 'developing'), ('in', 'developing', 'a'), ('developing', 'a', 'cure'), ('a', 'cure', 'for'), ('cure', 'for', 'COVID'), ('for', 'COVID', 'Machine'), ('COVID', 'Machine', 'learning'), ('Machine', 'learning', 'was'), ('learning', 'was', 'recently'), ('was', 'recently', 'applied'), ('recently', 'applied', 'to'), ('applied', 'to', 'predict'), ('to', 'predict', 'the'), ('predict', 'the', 'proenvironmental'), ('the', 'proenvironmental', 'behaviour'), ('proenvironmental', 'behaviour', 'of'), ('behaviour', 'of', 'travellers'), ('of', 'travellers', 'Recently'), ('travellers', 'Recently', 'machine'), ('Recently', 'machine', 'learning'), ('machine', 'learning', 'technology'), ('learning', 'technology', 'was'), ('technology', 'was', 'also'), ('was', 'also', 'applied'), ('also', 'applied', 'to'), ('applied', 'to', 'optimise'), ('to', 'optimise', 'smartphones'), ('optimise', 'smartphones', 'performance'), ('smartphones', 'performance', 'and'), ('performance', 'and', 'thermal'), ('and', 'thermal', 'behaviour'), ('thermal', 'behaviour', 'based'), ('behaviour', 'based', 'on'), ('based', 'on', 'the'), ('on', 'the', 'users'), ('the', 'users', 'interaction'), ('users', 'interaction', 'with'), ('interaction', 'with', 'the'), ('with', 'the', 'phone'), ('the', 'phone', 'When'), ('phone', 'When', 'applied'), ('When', 'applied', 'correctly'), ('applied', 'correctly', 'machine'), ('correctly', 'machine', 'learning'), ('machine', 'learning', 'algorithms'), ('learning', 'algorithms', 'MLAs'), ('algorithms', 'MLAs', 'can'), ('MLAs', 'can', 'utilise'), ('can', 'utilise', 'a'), ('utilise', 'a', 'wide'), ('a', 'wide', 'range'), ('wide', 'range', 'of'), ('range', 'of', 'company'), ('of', 'company', 'characteristics'), ('company', 'characteristics', 'to'), ('characteristics', 'to', 'predict'), ('to', 'predict', 'stock'), ('predict', 'stock', 'returns'), ('stock', 'returns', 'without'), ('returns', 'without', 'overfitting'), ('without', 'overfitting', 'By'), ('overfitting', 'By', 'employing'), ('By', 'employing', 'effective'), ('employing', 'effective', 'feature'), ('effective', 'feature', 'engineering'), ('feature', 'engineering', 'and'), ('engineering', 'and', 'combining'), ('and', 'combining', 'forecasts'), ('combining', 'forecasts', 'MLAs'), ('forecasts', 'MLAs', 'can'), ('MLAs', 'can', 'generate'), ('can', 'generate', 'results'), ('generate', 'results', 'that'), ('results', 'that', 'far'), ('that', 'far', 'surpass'), ('far', 'surpass', 'those'), ('surpass', 'those', 'obtained'), ('those', 'obtained', 'from'), ('obtained', 'from', 'basic'), ('from', 'basic', 'linear'), ('basic', 'linear', 'techniques'), ('linear', 'techniques', 'like'), ('techniques', 'like', 'OLS')]\n",
      "\n",
      "Document: Recent advancements in machine learning have extended into the field of quantum chemistry where novel algorithms now enable the prediction of solvent effects on chemical reactions thereby offering new tools for chemists to tailor experimental conditions for optimal outcomes\n",
      "\n",
      "\n",
      "Unigrams: [('Recent',), ('advancements',), ('in',), ('machine',), ('learning',), ('have',), ('extended',), ('into',), ('the',), ('field',), ('of',), ('quantum',), ('chemistry',), ('where',), ('novel',), ('algorithms',), ('now',), ('enable',), ('the',), ('prediction',), ('of',), ('solvent',), ('effects',), ('on',), ('chemical',), ('reactions',), ('thereby',), ('offering',), ('new',), ('tools',), ('for',), ('chemists',), ('to',), ('tailor',), ('experimental',), ('conditions',), ('for',), ('optimal',), ('outcomes',)]\n",
      "\n",
      "Bigrams: [('Recent', 'advancements'), ('advancements', 'in'), ('in', 'machine'), ('machine', 'learning'), ('learning', 'have'), ('have', 'extended'), ('extended', 'into'), ('into', 'the'), ('the', 'field'), ('field', 'of'), ('of', 'quantum'), ('quantum', 'chemistry'), ('chemistry', 'where'), ('where', 'novel'), ('novel', 'algorithms'), ('algorithms', 'now'), ('now', 'enable'), ('enable', 'the'), ('the', 'prediction'), ('prediction', 'of'), ('of', 'solvent'), ('solvent', 'effects'), ('effects', 'on'), ('on', 'chemical'), ('chemical', 'reactions'), ('reactions', 'thereby'), ('thereby', 'offering'), ('offering', 'new'), ('new', 'tools'), ('tools', 'for'), ('for', 'chemists'), ('chemists', 'to'), ('to', 'tailor'), ('tailor', 'experimental'), ('experimental', 'conditions'), ('conditions', 'for'), ('for', 'optimal'), ('optimal', 'outcomes')]\n",
      "\n",
      "Trigrams: [('Recent', 'advancements', 'in'), ('advancements', 'in', 'machine'), ('in', 'machine', 'learning'), ('machine', 'learning', 'have'), ('learning', 'have', 'extended'), ('have', 'extended', 'into'), ('extended', 'into', 'the'), ('into', 'the', 'field'), ('the', 'field', 'of'), ('field', 'of', 'quantum'), ('of', 'quantum', 'chemistry'), ('quantum', 'chemistry', 'where'), ('chemistry', 'where', 'novel'), ('where', 'novel', 'algorithms'), ('novel', 'algorithms', 'now'), ('algorithms', 'now', 'enable'), ('now', 'enable', 'the'), ('enable', 'the', 'prediction'), ('the', 'prediction', 'of'), ('prediction', 'of', 'solvent'), ('of', 'solvent', 'effects'), ('solvent', 'effects', 'on'), ('effects', 'on', 'chemical'), ('on', 'chemical', 'reactions'), ('chemical', 'reactions', 'thereby'), ('reactions', 'thereby', 'offering'), ('thereby', 'offering', 'new'), ('offering', 'new', 'tools'), ('new', 'tools', 'for'), ('tools', 'for', 'chemists'), ('for', 'chemists', 'to'), ('chemists', 'to', 'tailor'), ('to', 'tailor', 'experimental'), ('tailor', 'experimental', 'conditions'), ('experimental', 'conditions', 'for'), ('conditions', 'for', 'optimal'), ('for', 'optimal', 'outcomes')]\n",
      "\n",
      "Document: Machine Learning is becoming a useful tool to investigate and predict evacuation decision making in large scale and small scale disasters Different solutions have been tested to predict if and when householders decide to evacuate during wildfires and hurricanes Other applications have been focusing on pre evacuation decisions in building fires\n",
      "\n",
      "\n",
      "Unigrams: [('Machine',), ('Learning',), ('is',), ('becoming',), ('a',), ('useful',), ('tool',), ('to',), ('investigate',), ('and',), ('predict',), ('evacuation',), ('decision',), ('making',), ('in',), ('large',), ('scale',), ('and',), ('small',), ('scale',), ('disasters',), ('Different',), ('solutions',), ('have',), ('been',), ('tested',), ('to',), ('predict',), ('if',), ('and',), ('when',), ('householders',), ('decide',), ('to',), ('evacuate',), ('during',), ('wildfires',), ('and',), ('hurricanes',), ('Other',), ('applications',), ('have',), ('been',), ('focusing',), ('on',), ('pre',), ('evacuation',), ('decisions',), ('in',), ('building',), ('fires',)]\n",
      "\n",
      "Bigrams: [('Machine', 'Learning'), ('Learning', 'is'), ('is', 'becoming'), ('becoming', 'a'), ('a', 'useful'), ('useful', 'tool'), ('tool', 'to'), ('to', 'investigate'), ('investigate', 'and'), ('and', 'predict'), ('predict', 'evacuation'), ('evacuation', 'decision'), ('decision', 'making'), ('making', 'in'), ('in', 'large'), ('large', 'scale'), ('scale', 'and'), ('and', 'small'), ('small', 'scale'), ('scale', 'disasters'), ('disasters', 'Different'), ('Different', 'solutions'), ('solutions', 'have'), ('have', 'been'), ('been', 'tested'), ('tested', 'to'), ('to', 'predict'), ('predict', 'if'), ('if', 'and'), ('and', 'when'), ('when', 'householders'), ('householders', 'decide'), ('decide', 'to'), ('to', 'evacuate'), ('evacuate', 'during'), ('during', 'wildfires'), ('wildfires', 'and'), ('and', 'hurricanes'), ('hurricanes', 'Other'), ('Other', 'applications'), ('applications', 'have'), ('have', 'been'), ('been', 'focusing'), ('focusing', 'on'), ('on', 'pre'), ('pre', 'evacuation'), ('evacuation', 'decisions'), ('decisions', 'in'), ('in', 'building'), ('building', 'fires')]\n",
      "\n",
      "Trigrams: [('Machine', 'Learning', 'is'), ('Learning', 'is', 'becoming'), ('is', 'becoming', 'a'), ('becoming', 'a', 'useful'), ('a', 'useful', 'tool'), ('useful', 'tool', 'to'), ('tool', 'to', 'investigate'), ('to', 'investigate', 'and'), ('investigate', 'and', 'predict'), ('and', 'predict', 'evacuation'), ('predict', 'evacuation', 'decision'), ('evacuation', 'decision', 'making'), ('decision', 'making', 'in'), ('making', 'in', 'large'), ('in', 'large', 'scale'), ('large', 'scale', 'and'), ('scale', 'and', 'small'), ('and', 'small', 'scale'), ('small', 'scale', 'disasters'), ('scale', 'disasters', 'Different'), ('disasters', 'Different', 'solutions'), ('Different', 'solutions', 'have'), ('solutions', 'have', 'been'), ('have', 'been', 'tested'), ('been', 'tested', 'to'), ('tested', 'to', 'predict'), ('to', 'predict', 'if'), ('predict', 'if', 'and'), ('if', 'and', 'when'), ('and', 'when', 'householders'), ('when', 'householders', 'decide'), ('householders', 'decide', 'to'), ('decide', 'to', 'evacuate'), ('to', 'evacuate', 'during'), ('evacuate', 'during', 'wildfires'), ('during', 'wildfires', 'and'), ('wildfires', 'and', 'hurricanes'), ('and', 'hurricanes', 'Other'), ('hurricanes', 'Other', 'applications'), ('Other', 'applications', 'have'), ('applications', 'have', 'been'), ('have', 'been', 'focusing'), ('been', 'focusing', 'on'), ('focusing', 'on', 'pre'), ('on', 'pre', 'evacuation'), ('pre', 'evacuation', 'decisions'), ('evacuation', 'decisions', 'in'), ('decisions', 'in', 'building'), ('in', 'building', 'fires')]\n",
      "\n",
      "Document: Machine learning is also emerging as a promising tool in geotechnical engineering where it is used to support tasks such as ground classification hazard prediction and site characterization Recent research emphasizes a move toward datacentric methods in this field where machine learning is not a replacement for engineering judgment but a way to enhance it using sitespecific data and patterns\n",
      "\n",
      "\n",
      "Unigrams: [('Machine',), ('learning',), ('is',), ('also',), ('emerging',), ('as',), ('a',), ('promising',), ('tool',), ('in',), ('geotechnical',), ('engineering',), ('where',), ('it',), ('is',), ('used',), ('to',), ('support',), ('tasks',), ('such',), ('as',), ('ground',), ('classification',), ('hazard',), ('prediction',), ('and',), ('site',), ('characterization',), ('Recent',), ('research',), ('emphasizes',), ('a',), ('move',), ('toward',), ('datacentric',), ('methods',), ('in',), ('this',), ('field',), ('where',), ('machine',), ('learning',), ('is',), ('not',), ('a',), ('replacement',), ('for',), ('engineering',), ('judgment',), ('but',), ('a',), ('way',), ('to',), ('enhance',), ('it',), ('using',), ('sitespecific',), ('data',), ('and',), ('patterns',)]\n",
      "\n",
      "Bigrams: [('Machine', 'learning'), ('learning', 'is'), ('is', 'also'), ('also', 'emerging'), ('emerging', 'as'), ('as', 'a'), ('a', 'promising'), ('promising', 'tool'), ('tool', 'in'), ('in', 'geotechnical'), ('geotechnical', 'engineering'), ('engineering', 'where'), ('where', 'it'), ('it', 'is'), ('is', 'used'), ('used', 'to'), ('to', 'support'), ('support', 'tasks'), ('tasks', 'such'), ('such', 'as'), ('as', 'ground'), ('ground', 'classification'), ('classification', 'hazard'), ('hazard', 'prediction'), ('prediction', 'and'), ('and', 'site'), ('site', 'characterization'), ('characterization', 'Recent'), ('Recent', 'research'), ('research', 'emphasizes'), ('emphasizes', 'a'), ('a', 'move'), ('move', 'toward'), ('toward', 'datacentric'), ('datacentric', 'methods'), ('methods', 'in'), ('in', 'this'), ('this', 'field'), ('field', 'where'), ('where', 'machine'), ('machine', 'learning'), ('learning', 'is'), ('is', 'not'), ('not', 'a'), ('a', 'replacement'), ('replacement', 'for'), ('for', 'engineering'), ('engineering', 'judgment'), ('judgment', 'but'), ('but', 'a'), ('a', 'way'), ('way', 'to'), ('to', 'enhance'), ('enhance', 'it'), ('it', 'using'), ('using', 'sitespecific'), ('sitespecific', 'data'), ('data', 'and'), ('and', 'patterns')]\n",
      "\n",
      "Trigrams: [('Machine', 'learning', 'is'), ('learning', 'is', 'also'), ('is', 'also', 'emerging'), ('also', 'emerging', 'as'), ('emerging', 'as', 'a'), ('as', 'a', 'promising'), ('a', 'promising', 'tool'), ('promising', 'tool', 'in'), ('tool', 'in', 'geotechnical'), ('in', 'geotechnical', 'engineering'), ('geotechnical', 'engineering', 'where'), ('engineering', 'where', 'it'), ('where', 'it', 'is'), ('it', 'is', 'used'), ('is', 'used', 'to'), ('used', 'to', 'support'), ('to', 'support', 'tasks'), ('support', 'tasks', 'such'), ('tasks', 'such', 'as'), ('such', 'as', 'ground'), ('as', 'ground', 'classification'), ('ground', 'classification', 'hazard'), ('classification', 'hazard', 'prediction'), ('hazard', 'prediction', 'and'), ('prediction', 'and', 'site'), ('and', 'site', 'characterization'), ('site', 'characterization', 'Recent'), ('characterization', 'Recent', 'research'), ('Recent', 'research', 'emphasizes'), ('research', 'emphasizes', 'a'), ('emphasizes', 'a', 'move'), ('a', 'move', 'toward'), ('move', 'toward', 'datacentric'), ('toward', 'datacentric', 'methods'), ('datacentric', 'methods', 'in'), ('methods', 'in', 'this'), ('in', 'this', 'field'), ('this', 'field', 'where'), ('field', 'where', 'machine'), ('where', 'machine', 'learning'), ('machine', 'learning', 'is'), ('learning', 'is', 'not'), ('is', 'not', 'a'), ('not', 'a', 'replacement'), ('a', 'replacement', 'for'), ('replacement', 'for', 'engineering'), ('for', 'engineering', 'judgment'), ('engineering', 'judgment', 'but'), ('judgment', 'but', 'a'), ('but', 'a', 'way'), ('a', 'way', 'to'), ('way', 'to', 'enhance'), ('to', 'enhance', 'it'), ('enhance', 'it', 'using'), ('it', 'using', 'sitespecific'), ('using', 'sitespecific', 'data'), ('sitespecific', 'data', 'and'), ('data', 'and', 'patterns')]\n",
      "\n",
      "Document: Although machine learning has been transformative in some fields machinelearning programs often fail to deliver expected results Reasons for this are numerous lack of suitable data lack of access to the data data bias privacy problems badly chosen tasks and algorithms wrong tools and people lack of resources and evaluation problems\n",
      "\n",
      "\n",
      "Unigrams: [('Although',), ('machine',), ('learning',), ('has',), ('been',), ('transformative',), ('in',), ('some',), ('fields',), ('machinelearning',), ('programs',), ('often',), ('fail',), ('to',), ('deliver',), ('expected',), ('results',), ('Reasons',), ('for',), ('this',), ('are',), ('numerous',), ('lack',), ('of',), ('suitable',), ('data',), ('lack',), ('of',), ('access',), ('to',), ('the',), ('data',), ('data',), ('bias',), ('privacy',), ('problems',), ('badly',), ('chosen',), ('tasks',), ('and',), ('algorithms',), ('wrong',), ('tools',), ('and',), ('people',), ('lack',), ('of',), ('resources',), ('and',), ('evaluation',), ('problems',)]\n",
      "\n",
      "Bigrams: [('Although', 'machine'), ('machine', 'learning'), ('learning', 'has'), ('has', 'been'), ('been', 'transformative'), ('transformative', 'in'), ('in', 'some'), ('some', 'fields'), ('fields', 'machinelearning'), ('machinelearning', 'programs'), ('programs', 'often'), ('often', 'fail'), ('fail', 'to'), ('to', 'deliver'), ('deliver', 'expected'), ('expected', 'results'), ('results', 'Reasons'), ('Reasons', 'for'), ('for', 'this'), ('this', 'are'), ('are', 'numerous'), ('numerous', 'lack'), ('lack', 'of'), ('of', 'suitable'), ('suitable', 'data'), ('data', 'lack'), ('lack', 'of'), ('of', 'access'), ('access', 'to'), ('to', 'the'), ('the', 'data'), ('data', 'data'), ('data', 'bias'), ('bias', 'privacy'), ('privacy', 'problems'), ('problems', 'badly'), ('badly', 'chosen'), ('chosen', 'tasks'), ('tasks', 'and'), ('and', 'algorithms'), ('algorithms', 'wrong'), ('wrong', 'tools'), ('tools', 'and'), ('and', 'people'), ('people', 'lack'), ('lack', 'of'), ('of', 'resources'), ('resources', 'and'), ('and', 'evaluation'), ('evaluation', 'problems')]\n",
      "\n",
      "Trigrams: [('Although', 'machine', 'learning'), ('machine', 'learning', 'has'), ('learning', 'has', 'been'), ('has', 'been', 'transformative'), ('been', 'transformative', 'in'), ('transformative', 'in', 'some'), ('in', 'some', 'fields'), ('some', 'fields', 'machinelearning'), ('fields', 'machinelearning', 'programs'), ('machinelearning', 'programs', 'often'), ('programs', 'often', 'fail'), ('often', 'fail', 'to'), ('fail', 'to', 'deliver'), ('to', 'deliver', 'expected'), ('deliver', 'expected', 'results'), ('expected', 'results', 'Reasons'), ('results', 'Reasons', 'for'), ('Reasons', 'for', 'this'), ('for', 'this', 'are'), ('this', 'are', 'numerous'), ('are', 'numerous', 'lack'), ('numerous', 'lack', 'of'), ('lack', 'of', 'suitable'), ('of', 'suitable', 'data'), ('suitable', 'data', 'lack'), ('data', 'lack', 'of'), ('lack', 'of', 'access'), ('of', 'access', 'to'), ('access', 'to', 'the'), ('to', 'the', 'data'), ('the', 'data', 'data'), ('data', 'data', 'bias'), ('data', 'bias', 'privacy'), ('bias', 'privacy', 'problems'), ('privacy', 'problems', 'badly'), ('problems', 'badly', 'chosen'), ('badly', 'chosen', 'tasks'), ('chosen', 'tasks', 'and'), ('tasks', 'and', 'algorithms'), ('and', 'algorithms', 'wrong'), ('algorithms', 'wrong', 'tools'), ('wrong', 'tools', 'and'), ('tools', 'and', 'people'), ('and', 'people', 'lack'), ('people', 'lack', 'of'), ('lack', 'of', 'resources'), ('of', 'resources', 'and'), ('resources', 'and', 'evaluation'), ('and', 'evaluation', 'problems')]\n",
      "\n",
      "Document: The black box theory poses another yet significant challenge Black box refers to a situation where the algorithm or the process of producing an output is entirely opaque meaning that even the coders of the algorithm cannot audit the pattern that the machine extracted out of the data The House of Lords Select Committee which claimed that such an intelligence system that could have a substantial impact on an individuals life would not be considered acceptable unless it provided a full and satisfactory explanation for the decisions it makes\n",
      "\n",
      "\n",
      "Unigrams: [('The',), ('black',), ('box',), ('theory',), ('poses',), ('another',), ('yet',), ('significant',), ('challenge',), ('Black',), ('box',), ('refers',), ('to',), ('a',), ('situation',), ('where',), ('the',), ('algorithm',), ('or',), ('the',), ('process',), ('of',), ('producing',), ('an',), ('output',), ('is',), ('entirely',), ('opaque',), ('meaning',), ('that',), ('even',), ('the',), ('coders',), ('of',), ('the',), ('algorithm',), ('cannot',), ('audit',), ('the',), ('pattern',), ('that',), ('the',), ('machine',), ('extracted',), ('out',), ('of',), ('the',), ('data',), ('The',), ('House',), ('of',), ('Lords',), ('Select',), ('Committee',), ('which',), ('claimed',), ('that',), ('such',), ('an',), ('intelligence',), ('system',), ('that',), ('could',), ('have',), ('a',), ('substantial',), ('impact',), ('on',), ('an',), ('individuals',), ('life',), ('would',), ('not',), ('be',), ('considered',), ('acceptable',), ('unless',), ('it',), ('provided',), ('a',), ('full',), ('and',), ('satisfactory',), ('explanation',), ('for',), ('the',), ('decisions',), ('it',), ('makes',)]\n",
      "\n",
      "Bigrams: [('The', 'black'), ('black', 'box'), ('box', 'theory'), ('theory', 'poses'), ('poses', 'another'), ('another', 'yet'), ('yet', 'significant'), ('significant', 'challenge'), ('challenge', 'Black'), ('Black', 'box'), ('box', 'refers'), ('refers', 'to'), ('to', 'a'), ('a', 'situation'), ('situation', 'where'), ('where', 'the'), ('the', 'algorithm'), ('algorithm', 'or'), ('or', 'the'), ('the', 'process'), ('process', 'of'), ('of', 'producing'), ('producing', 'an'), ('an', 'output'), ('output', 'is'), ('is', 'entirely'), ('entirely', 'opaque'), ('opaque', 'meaning'), ('meaning', 'that'), ('that', 'even'), ('even', 'the'), ('the', 'coders'), ('coders', 'of'), ('of', 'the'), ('the', 'algorithm'), ('algorithm', 'cannot'), ('cannot', 'audit'), ('audit', 'the'), ('the', 'pattern'), ('pattern', 'that'), ('that', 'the'), ('the', 'machine'), ('machine', 'extracted'), ('extracted', 'out'), ('out', 'of'), ('of', 'the'), ('the', 'data'), ('data', 'The'), ('The', 'House'), ('House', 'of'), ('of', 'Lords'), ('Lords', 'Select'), ('Select', 'Committee'), ('Committee', 'which'), ('which', 'claimed'), ('claimed', 'that'), ('that', 'such'), ('such', 'an'), ('an', 'intelligence'), ('intelligence', 'system'), ('system', 'that'), ('that', 'could'), ('could', 'have'), ('have', 'a'), ('a', 'substantial'), ('substantial', 'impact'), ('impact', 'on'), ('on', 'an'), ('an', 'individuals'), ('individuals', 'life'), ('life', 'would'), ('would', 'not'), ('not', 'be'), ('be', 'considered'), ('considered', 'acceptable'), ('acceptable', 'unless'), ('unless', 'it'), ('it', 'provided'), ('provided', 'a'), ('a', 'full'), ('full', 'and'), ('and', 'satisfactory'), ('satisfactory', 'explanation'), ('explanation', 'for'), ('for', 'the'), ('the', 'decisions'), ('decisions', 'it'), ('it', 'makes')]\n",
      "\n",
      "Trigrams: [('The', 'black', 'box'), ('black', 'box', 'theory'), ('box', 'theory', 'poses'), ('theory', 'poses', 'another'), ('poses', 'another', 'yet'), ('another', 'yet', 'significant'), ('yet', 'significant', 'challenge'), ('significant', 'challenge', 'Black'), ('challenge', 'Black', 'box'), ('Black', 'box', 'refers'), ('box', 'refers', 'to'), ('refers', 'to', 'a'), ('to', 'a', 'situation'), ('a', 'situation', 'where'), ('situation', 'where', 'the'), ('where', 'the', 'algorithm'), ('the', 'algorithm', 'or'), ('algorithm', 'or', 'the'), ('or', 'the', 'process'), ('the', 'process', 'of'), ('process', 'of', 'producing'), ('of', 'producing', 'an'), ('producing', 'an', 'output'), ('an', 'output', 'is'), ('output', 'is', 'entirely'), ('is', 'entirely', 'opaque'), ('entirely', 'opaque', 'meaning'), ('opaque', 'meaning', 'that'), ('meaning', 'that', 'even'), ('that', 'even', 'the'), ('even', 'the', 'coders'), ('the', 'coders', 'of'), ('coders', 'of', 'the'), ('of', 'the', 'algorithm'), ('the', 'algorithm', 'cannot'), ('algorithm', 'cannot', 'audit'), ('cannot', 'audit', 'the'), ('audit', 'the', 'pattern'), ('the', 'pattern', 'that'), ('pattern', 'that', 'the'), ('that', 'the', 'machine'), ('the', 'machine', 'extracted'), ('machine', 'extracted', 'out'), ('extracted', 'out', 'of'), ('out', 'of', 'the'), ('of', 'the', 'data'), ('the', 'data', 'The'), ('data', 'The', 'House'), ('The', 'House', 'of'), ('House', 'of', 'Lords'), ('of', 'Lords', 'Select'), ('Lords', 'Select', 'Committee'), ('Select', 'Committee', 'which'), ('Committee', 'which', 'claimed'), ('which', 'claimed', 'that'), ('claimed', 'that', 'such'), ('that', 'such', 'an'), ('such', 'an', 'intelligence'), ('an', 'intelligence', 'system'), ('intelligence', 'system', 'that'), ('system', 'that', 'could'), ('that', 'could', 'have'), ('could', 'have', 'a'), ('have', 'a', 'substantial'), ('a', 'substantial', 'impact'), ('substantial', 'impact', 'on'), ('impact', 'on', 'an'), ('on', 'an', 'individuals'), ('an', 'individuals', 'life'), ('individuals', 'life', 'would'), ('life', 'would', 'not'), ('would', 'not', 'be'), ('not', 'be', 'considered'), ('be', 'considered', 'acceptable'), ('considered', 'acceptable', 'unless'), ('acceptable', 'unless', 'it'), ('unless', 'it', 'provided'), ('it', 'provided', 'a'), ('provided', 'a', 'full'), ('a', 'full', 'and'), ('full', 'and', 'satisfactory'), ('and', 'satisfactory', 'explanation'), ('satisfactory', 'explanation', 'for'), ('explanation', 'for', 'the'), ('for', 'the', 'decisions'), ('the', 'decisions', 'it'), ('decisions', 'it', 'makes')]\n",
      "\n",
      "Document: In  a selfdriving car from Uber failed to detect a pedestrian who was killed after a collision Attempts to use machine learning in healthcare with the IBM Watson system failed to deliver even after years of time and billions of dollars invested Microsofts Bing Chat chatbot has been reported to produce hostile and offensive response against its users\n",
      "\n",
      "\n",
      "Unigrams: [('In',), ('a',), ('selfdriving',), ('car',), ('from',), ('Uber',), ('failed',), ('to',), ('detect',), ('a',), ('pedestrian',), ('who',), ('was',), ('killed',), ('after',), ('a',), ('collision',), ('Attempts',), ('to',), ('use',), ('machine',), ('learning',), ('in',), ('healthcare',), ('with',), ('the',), ('IBM',), ('Watson',), ('system',), ('failed',), ('to',), ('deliver',), ('even',), ('after',), ('years',), ('of',), ('time',), ('and',), ('billions',), ('of',), ('dollars',), ('invested',), ('Microsofts',), ('Bing',), ('Chat',), ('chatbot',), ('has',), ('been',), ('reported',), ('to',), ('produce',), ('hostile',), ('and',), ('offensive',), ('response',), ('against',), ('its',), ('users',)]\n",
      "\n",
      "Bigrams: [('In', 'a'), ('a', 'selfdriving'), ('selfdriving', 'car'), ('car', 'from'), ('from', 'Uber'), ('Uber', 'failed'), ('failed', 'to'), ('to', 'detect'), ('detect', 'a'), ('a', 'pedestrian'), ('pedestrian', 'who'), ('who', 'was'), ('was', 'killed'), ('killed', 'after'), ('after', 'a'), ('a', 'collision'), ('collision', 'Attempts'), ('Attempts', 'to'), ('to', 'use'), ('use', 'machine'), ('machine', 'learning'), ('learning', 'in'), ('in', 'healthcare'), ('healthcare', 'with'), ('with', 'the'), ('the', 'IBM'), ('IBM', 'Watson'), ('Watson', 'system'), ('system', 'failed'), ('failed', 'to'), ('to', 'deliver'), ('deliver', 'even'), ('even', 'after'), ('after', 'years'), ('years', 'of'), ('of', 'time'), ('time', 'and'), ('and', 'billions'), ('billions', 'of'), ('of', 'dollars'), ('dollars', 'invested'), ('invested', 'Microsofts'), ('Microsofts', 'Bing'), ('Bing', 'Chat'), ('Chat', 'chatbot'), ('chatbot', 'has'), ('has', 'been'), ('been', 'reported'), ('reported', 'to'), ('to', 'produce'), ('produce', 'hostile'), ('hostile', 'and'), ('and', 'offensive'), ('offensive', 'response'), ('response', 'against'), ('against', 'its'), ('its', 'users')]\n",
      "\n",
      "Trigrams: [('In', 'a', 'selfdriving'), ('a', 'selfdriving', 'car'), ('selfdriving', 'car', 'from'), ('car', 'from', 'Uber'), ('from', 'Uber', 'failed'), ('Uber', 'failed', 'to'), ('failed', 'to', 'detect'), ('to', 'detect', 'a'), ('detect', 'a', 'pedestrian'), ('a', 'pedestrian', 'who'), ('pedestrian', 'who', 'was'), ('who', 'was', 'killed'), ('was', 'killed', 'after'), ('killed', 'after', 'a'), ('after', 'a', 'collision'), ('a', 'collision', 'Attempts'), ('collision', 'Attempts', 'to'), ('Attempts', 'to', 'use'), ('to', 'use', 'machine'), ('use', 'machine', 'learning'), ('machine', 'learning', 'in'), ('learning', 'in', 'healthcare'), ('in', 'healthcare', 'with'), ('healthcare', 'with', 'the'), ('with', 'the', 'IBM'), ('the', 'IBM', 'Watson'), ('IBM', 'Watson', 'system'), ('Watson', 'system', 'failed'), ('system', 'failed', 'to'), ('failed', 'to', 'deliver'), ('to', 'deliver', 'even'), ('deliver', 'even', 'after'), ('even', 'after', 'years'), ('after', 'years', 'of'), ('years', 'of', 'time'), ('of', 'time', 'and'), ('time', 'and', 'billions'), ('and', 'billions', 'of'), ('billions', 'of', 'dollars'), ('of', 'dollars', 'invested'), ('dollars', 'invested', 'Microsofts'), ('invested', 'Microsofts', 'Bing'), ('Microsofts', 'Bing', 'Chat'), ('Bing', 'Chat', 'chatbot'), ('Chat', 'chatbot', 'has'), ('chatbot', 'has', 'been'), ('has', 'been', 'reported'), ('been', 'reported', 'to'), ('reported', 'to', 'produce'), ('to', 'produce', 'hostile'), ('produce', 'hostile', 'and'), ('hostile', 'and', 'offensive'), ('and', 'offensive', 'response'), ('offensive', 'response', 'against'), ('response', 'against', 'its'), ('against', 'its', 'users')]\n",
      "\n",
      "Document: Machine learning has been used as a strategy to update the evidence related to a systematic review and increased reviewer burden related to the growth of biomedical literature While it has improved with training sets it has not yet developed sufficiently to reduce the workload burden without limiting the necessary sensitivity for the findings research themselves\n",
      "\n",
      "\n",
      "Unigrams: [('Machine',), ('learning',), ('has',), ('been',), ('used',), ('as',), ('a',), ('strategy',), ('to',), ('update',), ('the',), ('evidence',), ('related',), ('to',), ('a',), ('systematic',), ('review',), ('and',), ('increased',), ('reviewer',), ('burden',), ('related',), ('to',), ('the',), ('growth',), ('of',), ('biomedical',), ('literature',), ('While',), ('it',), ('has',), ('improved',), ('with',), ('training',), ('sets',), ('it',), ('has',), ('not',), ('yet',), ('developed',), ('sufficiently',), ('to',), ('reduce',), ('the',), ('workload',), ('burden',), ('without',), ('limiting',), ('the',), ('necessary',), ('sensitivity',), ('for',), ('the',), ('findings',), ('research',), ('themselves',)]\n",
      "\n",
      "Bigrams: [('Machine', 'learning'), ('learning', 'has'), ('has', 'been'), ('been', 'used'), ('used', 'as'), ('as', 'a'), ('a', 'strategy'), ('strategy', 'to'), ('to', 'update'), ('update', 'the'), ('the', 'evidence'), ('evidence', 'related'), ('related', 'to'), ('to', 'a'), ('a', 'systematic'), ('systematic', 'review'), ('review', 'and'), ('and', 'increased'), ('increased', 'reviewer'), ('reviewer', 'burden'), ('burden', 'related'), ('related', 'to'), ('to', 'the'), ('the', 'growth'), ('growth', 'of'), ('of', 'biomedical'), ('biomedical', 'literature'), ('literature', 'While'), ('While', 'it'), ('it', 'has'), ('has', 'improved'), ('improved', 'with'), ('with', 'training'), ('training', 'sets'), ('sets', 'it'), ('it', 'has'), ('has', 'not'), ('not', 'yet'), ('yet', 'developed'), ('developed', 'sufficiently'), ('sufficiently', 'to'), ('to', 'reduce'), ('reduce', 'the'), ('the', 'workload'), ('workload', 'burden'), ('burden', 'without'), ('without', 'limiting'), ('limiting', 'the'), ('the', 'necessary'), ('necessary', 'sensitivity'), ('sensitivity', 'for'), ('for', 'the'), ('the', 'findings'), ('findings', 'research'), ('research', 'themselves')]\n",
      "\n",
      "Trigrams: [('Machine', 'learning', 'has'), ('learning', 'has', 'been'), ('has', 'been', 'used'), ('been', 'used', 'as'), ('used', 'as', 'a'), ('as', 'a', 'strategy'), ('a', 'strategy', 'to'), ('strategy', 'to', 'update'), ('to', 'update', 'the'), ('update', 'the', 'evidence'), ('the', 'evidence', 'related'), ('evidence', 'related', 'to'), ('related', 'to', 'a'), ('to', 'a', 'systematic'), ('a', 'systematic', 'review'), ('systematic', 'review', 'and'), ('review', 'and', 'increased'), ('and', 'increased', 'reviewer'), ('increased', 'reviewer', 'burden'), ('reviewer', 'burden', 'related'), ('burden', 'related', 'to'), ('related', 'to', 'the'), ('to', 'the', 'growth'), ('the', 'growth', 'of'), ('growth', 'of', 'biomedical'), ('of', 'biomedical', 'literature'), ('biomedical', 'literature', 'While'), ('literature', 'While', 'it'), ('While', 'it', 'has'), ('it', 'has', 'improved'), ('has', 'improved', 'with'), ('improved', 'with', 'training'), ('with', 'training', 'sets'), ('training', 'sets', 'it'), ('sets', 'it', 'has'), ('it', 'has', 'not'), ('has', 'not', 'yet'), ('not', 'yet', 'developed'), ('yet', 'developed', 'sufficiently'), ('developed', 'sufficiently', 'to'), ('sufficiently', 'to', 'reduce'), ('to', 'reduce', 'the'), ('reduce', 'the', 'workload'), ('the', 'workload', 'burden'), ('workload', 'burden', 'without'), ('burden', 'without', 'limiting'), ('without', 'limiting', 'the'), ('limiting', 'the', 'necessary'), ('the', 'necessary', 'sensitivity'), ('necessary', 'sensitivity', 'for'), ('sensitivity', 'for', 'the'), ('for', 'the', 'findings'), ('the', 'findings', 'research'), ('findings', 'research', 'themselves')]\n",
      "\n",
      "Document: Explainable AI XAI or Interpretable AI or Explainable Machine Learning XML is artificial intelligence AI in which humans can understand the decisions or predictions made by the AI It contrasts with the black box concept in machine learning where even its designers cannot explain why an AI arrived at a specific decision By refining the mental models of users of AIpowered systems and dismantling their misconceptions XAI promises to help users perform more effectively XAI may be an implementation of the social right to explanation\n",
      "\n",
      "\n",
      "Unigrams: [('Explainable',), ('AI',), ('XAI',), ('or',), ('Interpretable',), ('AI',), ('or',), ('Explainable',), ('Machine',), ('Learning',), ('XML',), ('is',), ('artificial',), ('intelligence',), ('AI',), ('in',), ('which',), ('humans',), ('can',), ('understand',), ('the',), ('decisions',), ('or',), ('predictions',), ('made',), ('by',), ('the',), ('AI',), ('It',), ('contrasts',), ('with',), ('the',), ('black',), ('box',), ('concept',), ('in',), ('machine',), ('learning',), ('where',), ('even',), ('its',), ('designers',), ('cannot',), ('explain',), ('why',), ('an',), ('AI',), ('arrived',), ('at',), ('a',), ('specific',), ('decision',), ('By',), ('refining',), ('the',), ('mental',), ('models',), ('of',), ('users',), ('of',), ('AIpowered',), ('systems',), ('and',), ('dismantling',), ('their',), ('misconceptions',), ('XAI',), ('promises',), ('to',), ('help',), ('users',), ('perform',), ('more',), ('effectively',), ('XAI',), ('may',), ('be',), ('an',), ('implementation',), ('of',), ('the',), ('social',), ('right',), ('to',), ('explanation',)]\n",
      "\n",
      "Bigrams: [('Explainable', 'AI'), ('AI', 'XAI'), ('XAI', 'or'), ('or', 'Interpretable'), ('Interpretable', 'AI'), ('AI', 'or'), ('or', 'Explainable'), ('Explainable', 'Machine'), ('Machine', 'Learning'), ('Learning', 'XML'), ('XML', 'is'), ('is', 'artificial'), ('artificial', 'intelligence'), ('intelligence', 'AI'), ('AI', 'in'), ('in', 'which'), ('which', 'humans'), ('humans', 'can'), ('can', 'understand'), ('understand', 'the'), ('the', 'decisions'), ('decisions', 'or'), ('or', 'predictions'), ('predictions', 'made'), ('made', 'by'), ('by', 'the'), ('the', 'AI'), ('AI', 'It'), ('It', 'contrasts'), ('contrasts', 'with'), ('with', 'the'), ('the', 'black'), ('black', 'box'), ('box', 'concept'), ('concept', 'in'), ('in', 'machine'), ('machine', 'learning'), ('learning', 'where'), ('where', 'even'), ('even', 'its'), ('its', 'designers'), ('designers', 'cannot'), ('cannot', 'explain'), ('explain', 'why'), ('why', 'an'), ('an', 'AI'), ('AI', 'arrived'), ('arrived', 'at'), ('at', 'a'), ('a', 'specific'), ('specific', 'decision'), ('decision', 'By'), ('By', 'refining'), ('refining', 'the'), ('the', 'mental'), ('mental', 'models'), ('models', 'of'), ('of', 'users'), ('users', 'of'), ('of', 'AIpowered'), ('AIpowered', 'systems'), ('systems', 'and'), ('and', 'dismantling'), ('dismantling', 'their'), ('their', 'misconceptions'), ('misconceptions', 'XAI'), ('XAI', 'promises'), ('promises', 'to'), ('to', 'help'), ('help', 'users'), ('users', 'perform'), ('perform', 'more'), ('more', 'effectively'), ('effectively', 'XAI'), ('XAI', 'may'), ('may', 'be'), ('be', 'an'), ('an', 'implementation'), ('implementation', 'of'), ('of', 'the'), ('the', 'social'), ('social', 'right'), ('right', 'to'), ('to', 'explanation')]\n",
      "\n",
      "Trigrams: [('Explainable', 'AI', 'XAI'), ('AI', 'XAI', 'or'), ('XAI', 'or', 'Interpretable'), ('or', 'Interpretable', 'AI'), ('Interpretable', 'AI', 'or'), ('AI', 'or', 'Explainable'), ('or', 'Explainable', 'Machine'), ('Explainable', 'Machine', 'Learning'), ('Machine', 'Learning', 'XML'), ('Learning', 'XML', 'is'), ('XML', 'is', 'artificial'), ('is', 'artificial', 'intelligence'), ('artificial', 'intelligence', 'AI'), ('intelligence', 'AI', 'in'), ('AI', 'in', 'which'), ('in', 'which', 'humans'), ('which', 'humans', 'can'), ('humans', 'can', 'understand'), ('can', 'understand', 'the'), ('understand', 'the', 'decisions'), ('the', 'decisions', 'or'), ('decisions', 'or', 'predictions'), ('or', 'predictions', 'made'), ('predictions', 'made', 'by'), ('made', 'by', 'the'), ('by', 'the', 'AI'), ('the', 'AI', 'It'), ('AI', 'It', 'contrasts'), ('It', 'contrasts', 'with'), ('contrasts', 'with', 'the'), ('with', 'the', 'black'), ('the', 'black', 'box'), ('black', 'box', 'concept'), ('box', 'concept', 'in'), ('concept', 'in', 'machine'), ('in', 'machine', 'learning'), ('machine', 'learning', 'where'), ('learning', 'where', 'even'), ('where', 'even', 'its'), ('even', 'its', 'designers'), ('its', 'designers', 'cannot'), ('designers', 'cannot', 'explain'), ('cannot', 'explain', 'why'), ('explain', 'why', 'an'), ('why', 'an', 'AI'), ('an', 'AI', 'arrived'), ('AI', 'arrived', 'at'), ('arrived', 'at', 'a'), ('at', 'a', 'specific'), ('a', 'specific', 'decision'), ('specific', 'decision', 'By'), ('decision', 'By', 'refining'), ('By', 'refining', 'the'), ('refining', 'the', 'mental'), ('the', 'mental', 'models'), ('mental', 'models', 'of'), ('models', 'of', 'users'), ('of', 'users', 'of'), ('users', 'of', 'AIpowered'), ('of', 'AIpowered', 'systems'), ('AIpowered', 'systems', 'and'), ('systems', 'and', 'dismantling'), ('and', 'dismantling', 'their'), ('dismantling', 'their', 'misconceptions'), ('their', 'misconceptions', 'XAI'), ('misconceptions', 'XAI', 'promises'), ('XAI', 'promises', 'to'), ('promises', 'to', 'help'), ('to', 'help', 'users'), ('help', 'users', 'perform'), ('users', 'perform', 'more'), ('perform', 'more', 'effectively'), ('more', 'effectively', 'XAI'), ('effectively', 'XAI', 'may'), ('XAI', 'may', 'be'), ('may', 'be', 'an'), ('be', 'an', 'implementation'), ('an', 'implementation', 'of'), ('implementation', 'of', 'the'), ('of', 'the', 'social'), ('the', 'social', 'right'), ('social', 'right', 'to'), ('right', 'to', 'explanation')]\n",
      "\n",
      "Document: Settling on a bad overly complex theory gerrymandered to fit all the past training data is known as overfitting Many systems attempt to reduce overfitting by rewarding a theory in accordance with how well it fits the data but penalising the theory in accordance with how complex the theory is\n",
      "\n",
      "\n",
      "Unigrams: [('Settling',), ('on',), ('a',), ('bad',), ('overly',), ('complex',), ('theory',), ('gerrymandered',), ('to',), ('fit',), ('all',), ('the',), ('past',), ('training',), ('data',), ('is',), ('known',), ('as',), ('overfitting',), ('Many',), ('systems',), ('attempt',), ('to',), ('reduce',), ('overfitting',), ('by',), ('rewarding',), ('a',), ('theory',), ('in',), ('accordance',), ('with',), ('how',), ('well',), ('it',), ('fits',), ('the',), ('data',), ('but',), ('penalising',), ('the',), ('theory',), ('in',), ('accordance',), ('with',), ('how',), ('complex',), ('the',), ('theory',), ('is',)]\n",
      "\n",
      "Bigrams: [('Settling', 'on'), ('on', 'a'), ('a', 'bad'), ('bad', 'overly'), ('overly', 'complex'), ('complex', 'theory'), ('theory', 'gerrymandered'), ('gerrymandered', 'to'), ('to', 'fit'), ('fit', 'all'), ('all', 'the'), ('the', 'past'), ('past', 'training'), ('training', 'data'), ('data', 'is'), ('is', 'known'), ('known', 'as'), ('as', 'overfitting'), ('overfitting', 'Many'), ('Many', 'systems'), ('systems', 'attempt'), ('attempt', 'to'), ('to', 'reduce'), ('reduce', 'overfitting'), ('overfitting', 'by'), ('by', 'rewarding'), ('rewarding', 'a'), ('a', 'theory'), ('theory', 'in'), ('in', 'accordance'), ('accordance', 'with'), ('with', 'how'), ('how', 'well'), ('well', 'it'), ('it', 'fits'), ('fits', 'the'), ('the', 'data'), ('data', 'but'), ('but', 'penalising'), ('penalising', 'the'), ('the', 'theory'), ('theory', 'in'), ('in', 'accordance'), ('accordance', 'with'), ('with', 'how'), ('how', 'complex'), ('complex', 'the'), ('the', 'theory'), ('theory', 'is')]\n",
      "\n",
      "Trigrams: [('Settling', 'on', 'a'), ('on', 'a', 'bad'), ('a', 'bad', 'overly'), ('bad', 'overly', 'complex'), ('overly', 'complex', 'theory'), ('complex', 'theory', 'gerrymandered'), ('theory', 'gerrymandered', 'to'), ('gerrymandered', 'to', 'fit'), ('to', 'fit', 'all'), ('fit', 'all', 'the'), ('all', 'the', 'past'), ('the', 'past', 'training'), ('past', 'training', 'data'), ('training', 'data', 'is'), ('data', 'is', 'known'), ('is', 'known', 'as'), ('known', 'as', 'overfitting'), ('as', 'overfitting', 'Many'), ('overfitting', 'Many', 'systems'), ('Many', 'systems', 'attempt'), ('systems', 'attempt', 'to'), ('attempt', 'to', 'reduce'), ('to', 'reduce', 'overfitting'), ('reduce', 'overfitting', 'by'), ('overfitting', 'by', 'rewarding'), ('by', 'rewarding', 'a'), ('rewarding', 'a', 'theory'), ('a', 'theory', 'in'), ('theory', 'in', 'accordance'), ('in', 'accordance', 'with'), ('accordance', 'with', 'how'), ('with', 'how', 'well'), ('how', 'well', 'it'), ('well', 'it', 'fits'), ('it', 'fits', 'the'), ('fits', 'the', 'data'), ('the', 'data', 'but'), ('data', 'but', 'penalising'), ('but', 'penalising', 'the'), ('penalising', 'the', 'theory'), ('the', 'theory', 'in'), ('theory', 'in', 'accordance'), ('in', 'accordance', 'with'), ('accordance', 'with', 'how'), ('with', 'how', 'complex'), ('how', 'complex', 'the'), ('complex', 'the', 'theory'), ('the', 'theory', 'is')]\n",
      "\n",
      "Document: Learners can also disappoint by learning the wrong lesson A toy example is that an image classifier trained only on pictures of brown horses and black cats might conclude that all brown patches are likely to be horses A realworld example is that unlike humans current image classifiers often do not primarily make judgements from the spatial relationship between components of the picture and they learn relationships between pixels that humans are oblivious to but that still correlate with images of certain types of real objects Modifying these patterns on a legitimate image can result in adversarial images that the system misclassifies\n",
      "\n",
      "\n",
      "Unigrams: [('Learners',), ('can',), ('also',), ('disappoint',), ('by',), ('learning',), ('the',), ('wrong',), ('lesson',), ('A',), ('toy',), ('example',), ('is',), ('that',), ('an',), ('image',), ('classifier',), ('trained',), ('only',), ('on',), ('pictures',), ('of',), ('brown',), ('horses',), ('and',), ('black',), ('cats',), ('might',), ('conclude',), ('that',), ('all',), ('brown',), ('patches',), ('are',), ('likely',), ('to',), ('be',), ('horses',), ('A',), ('realworld',), ('example',), ('is',), ('that',), ('unlike',), ('humans',), ('current',), ('image',), ('classifiers',), ('often',), ('do',), ('not',), ('primarily',), ('make',), ('judgements',), ('from',), ('the',), ('spatial',), ('relationship',), ('between',), ('components',), ('of',), ('the',), ('picture',), ('and',), ('they',), ('learn',), ('relationships',), ('between',), ('pixels',), ('that',), ('humans',), ('are',), ('oblivious',), ('to',), ('but',), ('that',), ('still',), ('correlate',), ('with',), ('images',), ('of',), ('certain',), ('types',), ('of',), ('real',), ('objects',), ('Modifying',), ('these',), ('patterns',), ('on',), ('a',), ('legitimate',), ('image',), ('can',), ('result',), ('in',), ('adversarial',), ('images',), ('that',), ('the',), ('system',), ('misclassifies',)]\n",
      "\n",
      "Bigrams: [('Learners', 'can'), ('can', 'also'), ('also', 'disappoint'), ('disappoint', 'by'), ('by', 'learning'), ('learning', 'the'), ('the', 'wrong'), ('wrong', 'lesson'), ('lesson', 'A'), ('A', 'toy'), ('toy', 'example'), ('example', 'is'), ('is', 'that'), ('that', 'an'), ('an', 'image'), ('image', 'classifier'), ('classifier', 'trained'), ('trained', 'only'), ('only', 'on'), ('on', 'pictures'), ('pictures', 'of'), ('of', 'brown'), ('brown', 'horses'), ('horses', 'and'), ('and', 'black'), ('black', 'cats'), ('cats', 'might'), ('might', 'conclude'), ('conclude', 'that'), ('that', 'all'), ('all', 'brown'), ('brown', 'patches'), ('patches', 'are'), ('are', 'likely'), ('likely', 'to'), ('to', 'be'), ('be', 'horses'), ('horses', 'A'), ('A', 'realworld'), ('realworld', 'example'), ('example', 'is'), ('is', 'that'), ('that', 'unlike'), ('unlike', 'humans'), ('humans', 'current'), ('current', 'image'), ('image', 'classifiers'), ('classifiers', 'often'), ('often', 'do'), ('do', 'not'), ('not', 'primarily'), ('primarily', 'make'), ('make', 'judgements'), ('judgements', 'from'), ('from', 'the'), ('the', 'spatial'), ('spatial', 'relationship'), ('relationship', 'between'), ('between', 'components'), ('components', 'of'), ('of', 'the'), ('the', 'picture'), ('picture', 'and'), ('and', 'they'), ('they', 'learn'), ('learn', 'relationships'), ('relationships', 'between'), ('between', 'pixels'), ('pixels', 'that'), ('that', 'humans'), ('humans', 'are'), ('are', 'oblivious'), ('oblivious', 'to'), ('to', 'but'), ('but', 'that'), ('that', 'still'), ('still', 'correlate'), ('correlate', 'with'), ('with', 'images'), ('images', 'of'), ('of', 'certain'), ('certain', 'types'), ('types', 'of'), ('of', 'real'), ('real', 'objects'), ('objects', 'Modifying'), ('Modifying', 'these'), ('these', 'patterns'), ('patterns', 'on'), ('on', 'a'), ('a', 'legitimate'), ('legitimate', 'image'), ('image', 'can'), ('can', 'result'), ('result', 'in'), ('in', 'adversarial'), ('adversarial', 'images'), ('images', 'that'), ('that', 'the'), ('the', 'system'), ('system', 'misclassifies')]\n",
      "\n",
      "Trigrams: [('Learners', 'can', 'also'), ('can', 'also', 'disappoint'), ('also', 'disappoint', 'by'), ('disappoint', 'by', 'learning'), ('by', 'learning', 'the'), ('learning', 'the', 'wrong'), ('the', 'wrong', 'lesson'), ('wrong', 'lesson', 'A'), ('lesson', 'A', 'toy'), ('A', 'toy', 'example'), ('toy', 'example', 'is'), ('example', 'is', 'that'), ('is', 'that', 'an'), ('that', 'an', 'image'), ('an', 'image', 'classifier'), ('image', 'classifier', 'trained'), ('classifier', 'trained', 'only'), ('trained', 'only', 'on'), ('only', 'on', 'pictures'), ('on', 'pictures', 'of'), ('pictures', 'of', 'brown'), ('of', 'brown', 'horses'), ('brown', 'horses', 'and'), ('horses', 'and', 'black'), ('and', 'black', 'cats'), ('black', 'cats', 'might'), ('cats', 'might', 'conclude'), ('might', 'conclude', 'that'), ('conclude', 'that', 'all'), ('that', 'all', 'brown'), ('all', 'brown', 'patches'), ('brown', 'patches', 'are'), ('patches', 'are', 'likely'), ('are', 'likely', 'to'), ('likely', 'to', 'be'), ('to', 'be', 'horses'), ('be', 'horses', 'A'), ('horses', 'A', 'realworld'), ('A', 'realworld', 'example'), ('realworld', 'example', 'is'), ('example', 'is', 'that'), ('is', 'that', 'unlike'), ('that', 'unlike', 'humans'), ('unlike', 'humans', 'current'), ('humans', 'current', 'image'), ('current', 'image', 'classifiers'), ('image', 'classifiers', 'often'), ('classifiers', 'often', 'do'), ('often', 'do', 'not'), ('do', 'not', 'primarily'), ('not', 'primarily', 'make'), ('primarily', 'make', 'judgements'), ('make', 'judgements', 'from'), ('judgements', 'from', 'the'), ('from', 'the', 'spatial'), ('the', 'spatial', 'relationship'), ('spatial', 'relationship', 'between'), ('relationship', 'between', 'components'), ('between', 'components', 'of'), ('components', 'of', 'the'), ('of', 'the', 'picture'), ('the', 'picture', 'and'), ('picture', 'and', 'they'), ('and', 'they', 'learn'), ('they', 'learn', 'relationships'), ('learn', 'relationships', 'between'), ('relationships', 'between', 'pixels'), ('between', 'pixels', 'that'), ('pixels', 'that', 'humans'), ('that', 'humans', 'are'), ('humans', 'are', 'oblivious'), ('are', 'oblivious', 'to'), ('oblivious', 'to', 'but'), ('to', 'but', 'that'), ('but', 'that', 'still'), ('that', 'still', 'correlate'), ('still', 'correlate', 'with'), ('correlate', 'with', 'images'), ('with', 'images', 'of'), ('images', 'of', 'certain'), ('of', 'certain', 'types'), ('certain', 'types', 'of'), ('types', 'of', 'real'), ('of', 'real', 'objects'), ('real', 'objects', 'Modifying'), ('objects', 'Modifying', 'these'), ('Modifying', 'these', 'patterns'), ('these', 'patterns', 'on'), ('patterns', 'on', 'a'), ('on', 'a', 'legitimate'), ('a', 'legitimate', 'image'), ('legitimate', 'image', 'can'), ('image', 'can', 'result'), ('can', 'result', 'in'), ('result', 'in', 'adversarial'), ('in', 'adversarial', 'images'), ('adversarial', 'images', 'that'), ('images', 'that', 'the'), ('that', 'the', 'system'), ('the', 'system', 'misclassifies')]\n",
      "\n",
      "Document: Adversarial vulnerabilities can also result in nonlinear systems or from nonpattern perturbations For some systems it is possible to change the output by only changing a single adversarially chosen pixel Machine learning models are often vulnerable to manipulation or evasion via adversarial machine learning\n",
      "\n",
      "\n",
      "Unigrams: [('Adversarial',), ('vulnerabilities',), ('can',), ('also',), ('result',), ('in',), ('nonlinear',), ('systems',), ('or',), ('from',), ('nonpattern',), ('perturbations',), ('For',), ('some',), ('systems',), ('it',), ('is',), ('possible',), ('to',), ('change',), ('the',), ('output',), ('by',), ('only',), ('changing',), ('a',), ('single',), ('adversarially',), ('chosen',), ('pixel',), ('Machine',), ('learning',), ('models',), ('are',), ('often',), ('vulnerable',), ('to',), ('manipulation',), ('or',), ('evasion',), ('via',), ('adversarial',), ('machine',), ('learning',)]\n",
      "\n",
      "Bigrams: [('Adversarial', 'vulnerabilities'), ('vulnerabilities', 'can'), ('can', 'also'), ('also', 'result'), ('result', 'in'), ('in', 'nonlinear'), ('nonlinear', 'systems'), ('systems', 'or'), ('or', 'from'), ('from', 'nonpattern'), ('nonpattern', 'perturbations'), ('perturbations', 'For'), ('For', 'some'), ('some', 'systems'), ('systems', 'it'), ('it', 'is'), ('is', 'possible'), ('possible', 'to'), ('to', 'change'), ('change', 'the'), ('the', 'output'), ('output', 'by'), ('by', 'only'), ('only', 'changing'), ('changing', 'a'), ('a', 'single'), ('single', 'adversarially'), ('adversarially', 'chosen'), ('chosen', 'pixel'), ('pixel', 'Machine'), ('Machine', 'learning'), ('learning', 'models'), ('models', 'are'), ('are', 'often'), ('often', 'vulnerable'), ('vulnerable', 'to'), ('to', 'manipulation'), ('manipulation', 'or'), ('or', 'evasion'), ('evasion', 'via'), ('via', 'adversarial'), ('adversarial', 'machine'), ('machine', 'learning')]\n",
      "\n",
      "Trigrams: [('Adversarial', 'vulnerabilities', 'can'), ('vulnerabilities', 'can', 'also'), ('can', 'also', 'result'), ('also', 'result', 'in'), ('result', 'in', 'nonlinear'), ('in', 'nonlinear', 'systems'), ('nonlinear', 'systems', 'or'), ('systems', 'or', 'from'), ('or', 'from', 'nonpattern'), ('from', 'nonpattern', 'perturbations'), ('nonpattern', 'perturbations', 'For'), ('perturbations', 'For', 'some'), ('For', 'some', 'systems'), ('some', 'systems', 'it'), ('systems', 'it', 'is'), ('it', 'is', 'possible'), ('is', 'possible', 'to'), ('possible', 'to', 'change'), ('to', 'change', 'the'), ('change', 'the', 'output'), ('the', 'output', 'by'), ('output', 'by', 'only'), ('by', 'only', 'changing'), ('only', 'changing', 'a'), ('changing', 'a', 'single'), ('a', 'single', 'adversarially'), ('single', 'adversarially', 'chosen'), ('adversarially', 'chosen', 'pixel'), ('chosen', 'pixel', 'Machine'), ('pixel', 'Machine', 'learning'), ('Machine', 'learning', 'models'), ('learning', 'models', 'are'), ('models', 'are', 'often'), ('are', 'often', 'vulnerable'), ('often', 'vulnerable', 'to'), ('vulnerable', 'to', 'manipulation'), ('to', 'manipulation', 'or'), ('manipulation', 'or', 'evasion'), ('or', 'evasion', 'via'), ('evasion', 'via', 'adversarial'), ('via', 'adversarial', 'machine'), ('adversarial', 'machine', 'learning')]\n",
      "\n",
      "Document: Researchers have demonstrated how backdoors can be placed undetectably into classifying eg for categories spam and wellvisible not spam of posts machine learning models that are often developed or trained by third parties Parties can change the classification of any input including in cases for which a type of datasoftware transparency is provided possibly including whitebox access\n",
      "\n",
      "\n",
      "Unigrams: [('Researchers',), ('have',), ('demonstrated',), ('how',), ('backdoors',), ('can',), ('be',), ('placed',), ('undetectably',), ('into',), ('classifying',), ('eg',), ('for',), ('categories',), ('spam',), ('and',), ('wellvisible',), ('not',), ('spam',), ('of',), ('posts',), ('machine',), ('learning',), ('models',), ('that',), ('are',), ('often',), ('developed',), ('or',), ('trained',), ('by',), ('third',), ('parties',), ('Parties',), ('can',), ('change',), ('the',), ('classification',), ('of',), ('any',), ('input',), ('including',), ('in',), ('cases',), ('for',), ('which',), ('a',), ('type',), ('of',), ('datasoftware',), ('transparency',), ('is',), ('provided',), ('possibly',), ('including',), ('whitebox',), ('access',)]\n",
      "\n",
      "Bigrams: [('Researchers', 'have'), ('have', 'demonstrated'), ('demonstrated', 'how'), ('how', 'backdoors'), ('backdoors', 'can'), ('can', 'be'), ('be', 'placed'), ('placed', 'undetectably'), ('undetectably', 'into'), ('into', 'classifying'), ('classifying', 'eg'), ('eg', 'for'), ('for', 'categories'), ('categories', 'spam'), ('spam', 'and'), ('and', 'wellvisible'), ('wellvisible', 'not'), ('not', 'spam'), ('spam', 'of'), ('of', 'posts'), ('posts', 'machine'), ('machine', 'learning'), ('learning', 'models'), ('models', 'that'), ('that', 'are'), ('are', 'often'), ('often', 'developed'), ('developed', 'or'), ('or', 'trained'), ('trained', 'by'), ('by', 'third'), ('third', 'parties'), ('parties', 'Parties'), ('Parties', 'can'), ('can', 'change'), ('change', 'the'), ('the', 'classification'), ('classification', 'of'), ('of', 'any'), ('any', 'input'), ('input', 'including'), ('including', 'in'), ('in', 'cases'), ('cases', 'for'), ('for', 'which'), ('which', 'a'), ('a', 'type'), ('type', 'of'), ('of', 'datasoftware'), ('datasoftware', 'transparency'), ('transparency', 'is'), ('is', 'provided'), ('provided', 'possibly'), ('possibly', 'including'), ('including', 'whitebox'), ('whitebox', 'access')]\n",
      "\n",
      "Trigrams: [('Researchers', 'have', 'demonstrated'), ('have', 'demonstrated', 'how'), ('demonstrated', 'how', 'backdoors'), ('how', 'backdoors', 'can'), ('backdoors', 'can', 'be'), ('can', 'be', 'placed'), ('be', 'placed', 'undetectably'), ('placed', 'undetectably', 'into'), ('undetectably', 'into', 'classifying'), ('into', 'classifying', 'eg'), ('classifying', 'eg', 'for'), ('eg', 'for', 'categories'), ('for', 'categories', 'spam'), ('categories', 'spam', 'and'), ('spam', 'and', 'wellvisible'), ('and', 'wellvisible', 'not'), ('wellvisible', 'not', 'spam'), ('not', 'spam', 'of'), ('spam', 'of', 'posts'), ('of', 'posts', 'machine'), ('posts', 'machine', 'learning'), ('machine', 'learning', 'models'), ('learning', 'models', 'that'), ('models', 'that', 'are'), ('that', 'are', 'often'), ('are', 'often', 'developed'), ('often', 'developed', 'or'), ('developed', 'or', 'trained'), ('or', 'trained', 'by'), ('trained', 'by', 'third'), ('by', 'third', 'parties'), ('third', 'parties', 'Parties'), ('parties', 'Parties', 'can'), ('Parties', 'can', 'change'), ('can', 'change', 'the'), ('change', 'the', 'classification'), ('the', 'classification', 'of'), ('classification', 'of', 'any'), ('of', 'any', 'input'), ('any', 'input', 'including'), ('input', 'including', 'in'), ('including', 'in', 'cases'), ('in', 'cases', 'for'), ('cases', 'for', 'which'), ('for', 'which', 'a'), ('which', 'a', 'type'), ('a', 'type', 'of'), ('type', 'of', 'datasoftware'), ('of', 'datasoftware', 'transparency'), ('datasoftware', 'transparency', 'is'), ('transparency', 'is', 'provided'), ('is', 'provided', 'possibly'), ('provided', 'possibly', 'including'), ('possibly', 'including', 'whitebox'), ('including', 'whitebox', 'access')]\n",
      "\n",
      "Document: Classification of machine learning models can be validated by accuracy estimation techniques like the holdout method which splits the data in a training and test set conventionally  training set and  test set designation and evaluates the performance of the training model on the test set In comparison the Kfoldcrossvalidation method randomly partitions the data into K subsets and then K experiments are performed each respectively considering  subset for evaluation and the remaining K subsets for training the model In addition to the holdout and crossvalidation methods bootstrap which samples n instances with replacement from the dataset can be used to assess model accuracy\n",
      "\n",
      "\n",
      "Unigrams: [('Classification',), ('of',), ('machine',), ('learning',), ('models',), ('can',), ('be',), ('validated',), ('by',), ('accuracy',), ('estimation',), ('techniques',), ('like',), ('the',), ('holdout',), ('method',), ('which',), ('splits',), ('the',), ('data',), ('in',), ('a',), ('training',), ('and',), ('test',), ('set',), ('conventionally',), ('training',), ('set',), ('and',), ('test',), ('set',), ('designation',), ('and',), ('evaluates',), ('the',), ('performance',), ('of',), ('the',), ('training',), ('model',), ('on',), ('the',), ('test',), ('set',), ('In',), ('comparison',), ('the',), ('Kfoldcrossvalidation',), ('method',), ('randomly',), ('partitions',), ('the',), ('data',), ('into',), ('K',), ('subsets',), ('and',), ('then',), ('K',), ('experiments',), ('are',), ('performed',), ('each',), ('respectively',), ('considering',), ('subset',), ('for',), ('evaluation',), ('and',), ('the',), ('remaining',), ('K',), ('subsets',), ('for',), ('training',), ('the',), ('model',), ('In',), ('addition',), ('to',), ('the',), ('holdout',), ('and',), ('crossvalidation',), ('methods',), ('bootstrap',), ('which',), ('samples',), ('n',), ('instances',), ('with',), ('replacement',), ('from',), ('the',), ('dataset',), ('can',), ('be',), ('used',), ('to',), ('assess',), ('model',), ('accuracy',)]\n",
      "\n",
      "Bigrams: [('Classification', 'of'), ('of', 'machine'), ('machine', 'learning'), ('learning', 'models'), ('models', 'can'), ('can', 'be'), ('be', 'validated'), ('validated', 'by'), ('by', 'accuracy'), ('accuracy', 'estimation'), ('estimation', 'techniques'), ('techniques', 'like'), ('like', 'the'), ('the', 'holdout'), ('holdout', 'method'), ('method', 'which'), ('which', 'splits'), ('splits', 'the'), ('the', 'data'), ('data', 'in'), ('in', 'a'), ('a', 'training'), ('training', 'and'), ('and', 'test'), ('test', 'set'), ('set', 'conventionally'), ('conventionally', 'training'), ('training', 'set'), ('set', 'and'), ('and', 'test'), ('test', 'set'), ('set', 'designation'), ('designation', 'and'), ('and', 'evaluates'), ('evaluates', 'the'), ('the', 'performance'), ('performance', 'of'), ('of', 'the'), ('the', 'training'), ('training', 'model'), ('model', 'on'), ('on', 'the'), ('the', 'test'), ('test', 'set'), ('set', 'In'), ('In', 'comparison'), ('comparison', 'the'), ('the', 'Kfoldcrossvalidation'), ('Kfoldcrossvalidation', 'method'), ('method', 'randomly'), ('randomly', 'partitions'), ('partitions', 'the'), ('the', 'data'), ('data', 'into'), ('into', 'K'), ('K', 'subsets'), ('subsets', 'and'), ('and', 'then'), ('then', 'K'), ('K', 'experiments'), ('experiments', 'are'), ('are', 'performed'), ('performed', 'each'), ('each', 'respectively'), ('respectively', 'considering'), ('considering', 'subset'), ('subset', 'for'), ('for', 'evaluation'), ('evaluation', 'and'), ('and', 'the'), ('the', 'remaining'), ('remaining', 'K'), ('K', 'subsets'), ('subsets', 'for'), ('for', 'training'), ('training', 'the'), ('the', 'model'), ('model', 'In'), ('In', 'addition'), ('addition', 'to'), ('to', 'the'), ('the', 'holdout'), ('holdout', 'and'), ('and', 'crossvalidation'), ('crossvalidation', 'methods'), ('methods', 'bootstrap'), ('bootstrap', 'which'), ('which', 'samples'), ('samples', 'n'), ('n', 'instances'), ('instances', 'with'), ('with', 'replacement'), ('replacement', 'from'), ('from', 'the'), ('the', 'dataset'), ('dataset', 'can'), ('can', 'be'), ('be', 'used'), ('used', 'to'), ('to', 'assess'), ('assess', 'model'), ('model', 'accuracy')]\n",
      "\n",
      "Trigrams: [('Classification', 'of', 'machine'), ('of', 'machine', 'learning'), ('machine', 'learning', 'models'), ('learning', 'models', 'can'), ('models', 'can', 'be'), ('can', 'be', 'validated'), ('be', 'validated', 'by'), ('validated', 'by', 'accuracy'), ('by', 'accuracy', 'estimation'), ('accuracy', 'estimation', 'techniques'), ('estimation', 'techniques', 'like'), ('techniques', 'like', 'the'), ('like', 'the', 'holdout'), ('the', 'holdout', 'method'), ('holdout', 'method', 'which'), ('method', 'which', 'splits'), ('which', 'splits', 'the'), ('splits', 'the', 'data'), ('the', 'data', 'in'), ('data', 'in', 'a'), ('in', 'a', 'training'), ('a', 'training', 'and'), ('training', 'and', 'test'), ('and', 'test', 'set'), ('test', 'set', 'conventionally'), ('set', 'conventionally', 'training'), ('conventionally', 'training', 'set'), ('training', 'set', 'and'), ('set', 'and', 'test'), ('and', 'test', 'set'), ('test', 'set', 'designation'), ('set', 'designation', 'and'), ('designation', 'and', 'evaluates'), ('and', 'evaluates', 'the'), ('evaluates', 'the', 'performance'), ('the', 'performance', 'of'), ('performance', 'of', 'the'), ('of', 'the', 'training'), ('the', 'training', 'model'), ('training', 'model', 'on'), ('model', 'on', 'the'), ('on', 'the', 'test'), ('the', 'test', 'set'), ('test', 'set', 'In'), ('set', 'In', 'comparison'), ('In', 'comparison', 'the'), ('comparison', 'the', 'Kfoldcrossvalidation'), ('the', 'Kfoldcrossvalidation', 'method'), ('Kfoldcrossvalidation', 'method', 'randomly'), ('method', 'randomly', 'partitions'), ('randomly', 'partitions', 'the'), ('partitions', 'the', 'data'), ('the', 'data', 'into'), ('data', 'into', 'K'), ('into', 'K', 'subsets'), ('K', 'subsets', 'and'), ('subsets', 'and', 'then'), ('and', 'then', 'K'), ('then', 'K', 'experiments'), ('K', 'experiments', 'are'), ('experiments', 'are', 'performed'), ('are', 'performed', 'each'), ('performed', 'each', 'respectively'), ('each', 'respectively', 'considering'), ('respectively', 'considering', 'subset'), ('considering', 'subset', 'for'), ('subset', 'for', 'evaluation'), ('for', 'evaluation', 'and'), ('evaluation', 'and', 'the'), ('and', 'the', 'remaining'), ('the', 'remaining', 'K'), ('remaining', 'K', 'subsets'), ('K', 'subsets', 'for'), ('subsets', 'for', 'training'), ('for', 'training', 'the'), ('training', 'the', 'model'), ('the', 'model', 'In'), ('model', 'In', 'addition'), ('In', 'addition', 'to'), ('addition', 'to', 'the'), ('to', 'the', 'holdout'), ('the', 'holdout', 'and'), ('holdout', 'and', 'crossvalidation'), ('and', 'crossvalidation', 'methods'), ('crossvalidation', 'methods', 'bootstrap'), ('methods', 'bootstrap', 'which'), ('bootstrap', 'which', 'samples'), ('which', 'samples', 'n'), ('samples', 'n', 'instances'), ('n', 'instances', 'with'), ('instances', 'with', 'replacement'), ('with', 'replacement', 'from'), ('replacement', 'from', 'the'), ('from', 'the', 'dataset'), ('the', 'dataset', 'can'), ('dataset', 'can', 'be'), ('can', 'be', 'used'), ('be', 'used', 'to'), ('used', 'to', 'assess'), ('to', 'assess', 'model'), ('assess', 'model', 'accuracy')]\n",
      "\n",
      "Document: In addition to overall accuracy investigators frequently report sensitivity and specificity meaning true positive rate TPR and true negative rate TNR respectively Similarly investigators sometimes report the false positive rate FPR as well as the false negative rate FNR However these rates are ratios that fail to reveal their numerators and denominators Receiver operating characteristic ROC along with the accompanying Area Under the ROC Curve AUC offer additional tools for classification model assessment Higher AUC is associated with a better performing model\n",
      "\n",
      "\n",
      "Unigrams: [('In',), ('addition',), ('to',), ('overall',), ('accuracy',), ('investigators',), ('frequently',), ('report',), ('sensitivity',), ('and',), ('specificity',), ('meaning',), ('true',), ('positive',), ('rate',), ('TPR',), ('and',), ('true',), ('negative',), ('rate',), ('TNR',), ('respectively',), ('Similarly',), ('investigators',), ('sometimes',), ('report',), ('the',), ('false',), ('positive',), ('rate',), ('FPR',), ('as',), ('well',), ('as',), ('the',), ('false',), ('negative',), ('rate',), ('FNR',), ('However',), ('these',), ('rates',), ('are',), ('ratios',), ('that',), ('fail',), ('to',), ('reveal',), ('their',), ('numerators',), ('and',), ('denominators',), ('Receiver',), ('operating',), ('characteristic',), ('ROC',), ('along',), ('with',), ('the',), ('accompanying',), ('Area',), ('Under',), ('the',), ('ROC',), ('Curve',), ('AUC',), ('offer',), ('additional',), ('tools',), ('for',), ('classification',), ('model',), ('assessment',), ('Higher',), ('AUC',), ('is',), ('associated',), ('with',), ('a',), ('better',), ('performing',), ('model',)]\n",
      "\n",
      "Bigrams: [('In', 'addition'), ('addition', 'to'), ('to', 'overall'), ('overall', 'accuracy'), ('accuracy', 'investigators'), ('investigators', 'frequently'), ('frequently', 'report'), ('report', 'sensitivity'), ('sensitivity', 'and'), ('and', 'specificity'), ('specificity', 'meaning'), ('meaning', 'true'), ('true', 'positive'), ('positive', 'rate'), ('rate', 'TPR'), ('TPR', 'and'), ('and', 'true'), ('true', 'negative'), ('negative', 'rate'), ('rate', 'TNR'), ('TNR', 'respectively'), ('respectively', 'Similarly'), ('Similarly', 'investigators'), ('investigators', 'sometimes'), ('sometimes', 'report'), ('report', 'the'), ('the', 'false'), ('false', 'positive'), ('positive', 'rate'), ('rate', 'FPR'), ('FPR', 'as'), ('as', 'well'), ('well', 'as'), ('as', 'the'), ('the', 'false'), ('false', 'negative'), ('negative', 'rate'), ('rate', 'FNR'), ('FNR', 'However'), ('However', 'these'), ('these', 'rates'), ('rates', 'are'), ('are', 'ratios'), ('ratios', 'that'), ('that', 'fail'), ('fail', 'to'), ('to', 'reveal'), ('reveal', 'their'), ('their', 'numerators'), ('numerators', 'and'), ('and', 'denominators'), ('denominators', 'Receiver'), ('Receiver', 'operating'), ('operating', 'characteristic'), ('characteristic', 'ROC'), ('ROC', 'along'), ('along', 'with'), ('with', 'the'), ('the', 'accompanying'), ('accompanying', 'Area'), ('Area', 'Under'), ('Under', 'the'), ('the', 'ROC'), ('ROC', 'Curve'), ('Curve', 'AUC'), ('AUC', 'offer'), ('offer', 'additional'), ('additional', 'tools'), ('tools', 'for'), ('for', 'classification'), ('classification', 'model'), ('model', 'assessment'), ('assessment', 'Higher'), ('Higher', 'AUC'), ('AUC', 'is'), ('is', 'associated'), ('associated', 'with'), ('with', 'a'), ('a', 'better'), ('better', 'performing'), ('performing', 'model')]\n",
      "\n",
      "Trigrams: [('In', 'addition', 'to'), ('addition', 'to', 'overall'), ('to', 'overall', 'accuracy'), ('overall', 'accuracy', 'investigators'), ('accuracy', 'investigators', 'frequently'), ('investigators', 'frequently', 'report'), ('frequently', 'report', 'sensitivity'), ('report', 'sensitivity', 'and'), ('sensitivity', 'and', 'specificity'), ('and', 'specificity', 'meaning'), ('specificity', 'meaning', 'true'), ('meaning', 'true', 'positive'), ('true', 'positive', 'rate'), ('positive', 'rate', 'TPR'), ('rate', 'TPR', 'and'), ('TPR', 'and', 'true'), ('and', 'true', 'negative'), ('true', 'negative', 'rate'), ('negative', 'rate', 'TNR'), ('rate', 'TNR', 'respectively'), ('TNR', 'respectively', 'Similarly'), ('respectively', 'Similarly', 'investigators'), ('Similarly', 'investigators', 'sometimes'), ('investigators', 'sometimes', 'report'), ('sometimes', 'report', 'the'), ('report', 'the', 'false'), ('the', 'false', 'positive'), ('false', 'positive', 'rate'), ('positive', 'rate', 'FPR'), ('rate', 'FPR', 'as'), ('FPR', 'as', 'well'), ('as', 'well', 'as'), ('well', 'as', 'the'), ('as', 'the', 'false'), ('the', 'false', 'negative'), ('false', 'negative', 'rate'), ('negative', 'rate', 'FNR'), ('rate', 'FNR', 'However'), ('FNR', 'However', 'these'), ('However', 'these', 'rates'), ('these', 'rates', 'are'), ('rates', 'are', 'ratios'), ('are', 'ratios', 'that'), ('ratios', 'that', 'fail'), ('that', 'fail', 'to'), ('fail', 'to', 'reveal'), ('to', 'reveal', 'their'), ('reveal', 'their', 'numerators'), ('their', 'numerators', 'and'), ('numerators', 'and', 'denominators'), ('and', 'denominators', 'Receiver'), ('denominators', 'Receiver', 'operating'), ('Receiver', 'operating', 'characteristic'), ('operating', 'characteristic', 'ROC'), ('characteristic', 'ROC', 'along'), ('ROC', 'along', 'with'), ('along', 'with', 'the'), ('with', 'the', 'accompanying'), ('the', 'accompanying', 'Area'), ('accompanying', 'Area', 'Under'), ('Area', 'Under', 'the'), ('Under', 'the', 'ROC'), ('the', 'ROC', 'Curve'), ('ROC', 'Curve', 'AUC'), ('Curve', 'AUC', 'offer'), ('AUC', 'offer', 'additional'), ('offer', 'additional', 'tools'), ('additional', 'tools', 'for'), ('tools', 'for', 'classification'), ('for', 'classification', 'model'), ('classification', 'model', 'assessment'), ('model', 'assessment', 'Higher'), ('assessment', 'Higher', 'AUC'), ('Higher', 'AUC', 'is'), ('AUC', 'is', 'associated'), ('is', 'associated', 'with'), ('associated', 'with', 'a'), ('with', 'a', 'better'), ('a', 'better', 'performing'), ('better', 'performing', 'model')]\n",
      "\n",
      "Document: \n",
      "\n",
      "\n",
      "Unigrams: []\n",
      "\n",
      "Bigrams: []\n",
      "\n",
      "Trigrams: []\n",
      "\n",
      "Document: The ethics of artificial intelligence covers a broad range of topics within AI that are considered to have particular ethical stakes This includes algorithmic biases fairness automated decisionmaking accountability privacy and regulation It also covers various emerging or potential future challenges such as machine ethics how to make machines that behave ethically lethal autonomous weapon systems arms race dynamics AI safety and alignment technological unemployment AIenabled misinformation how to treat certain AI systems if they have a moral status AI welfare and rights artificial superintelligence and existential risks\n",
      "\n",
      "\n",
      "Unigrams: [('The',), ('ethics',), ('of',), ('artificial',), ('intelligence',), ('covers',), ('a',), ('broad',), ('range',), ('of',), ('topics',), ('within',), ('AI',), ('that',), ('are',), ('considered',), ('to',), ('have',), ('particular',), ('ethical',), ('stakes',), ('This',), ('includes',), ('algorithmic',), ('biases',), ('fairness',), ('automated',), ('decisionmaking',), ('accountability',), ('privacy',), ('and',), ('regulation',), ('It',), ('also',), ('covers',), ('various',), ('emerging',), ('or',), ('potential',), ('future',), ('challenges',), ('such',), ('as',), ('machine',), ('ethics',), ('how',), ('to',), ('make',), ('machines',), ('that',), ('behave',), ('ethically',), ('lethal',), ('autonomous',), ('weapon',), ('systems',), ('arms',), ('race',), ('dynamics',), ('AI',), ('safety',), ('and',), ('alignment',), ('technological',), ('unemployment',), ('AIenabled',), ('misinformation',), ('how',), ('to',), ('treat',), ('certain',), ('AI',), ('systems',), ('if',), ('they',), ('have',), ('a',), ('moral',), ('status',), ('AI',), ('welfare',), ('and',), ('rights',), ('artificial',), ('superintelligence',), ('and',), ('existential',), ('risks',)]\n",
      "\n",
      "Bigrams: [('The', 'ethics'), ('ethics', 'of'), ('of', 'artificial'), ('artificial', 'intelligence'), ('intelligence', 'covers'), ('covers', 'a'), ('a', 'broad'), ('broad', 'range'), ('range', 'of'), ('of', 'topics'), ('topics', 'within'), ('within', 'AI'), ('AI', 'that'), ('that', 'are'), ('are', 'considered'), ('considered', 'to'), ('to', 'have'), ('have', 'particular'), ('particular', 'ethical'), ('ethical', 'stakes'), ('stakes', 'This'), ('This', 'includes'), ('includes', 'algorithmic'), ('algorithmic', 'biases'), ('biases', 'fairness'), ('fairness', 'automated'), ('automated', 'decisionmaking'), ('decisionmaking', 'accountability'), ('accountability', 'privacy'), ('privacy', 'and'), ('and', 'regulation'), ('regulation', 'It'), ('It', 'also'), ('also', 'covers'), ('covers', 'various'), ('various', 'emerging'), ('emerging', 'or'), ('or', 'potential'), ('potential', 'future'), ('future', 'challenges'), ('challenges', 'such'), ('such', 'as'), ('as', 'machine'), ('machine', 'ethics'), ('ethics', 'how'), ('how', 'to'), ('to', 'make'), ('make', 'machines'), ('machines', 'that'), ('that', 'behave'), ('behave', 'ethically'), ('ethically', 'lethal'), ('lethal', 'autonomous'), ('autonomous', 'weapon'), ('weapon', 'systems'), ('systems', 'arms'), ('arms', 'race'), ('race', 'dynamics'), ('dynamics', 'AI'), ('AI', 'safety'), ('safety', 'and'), ('and', 'alignment'), ('alignment', 'technological'), ('technological', 'unemployment'), ('unemployment', 'AIenabled'), ('AIenabled', 'misinformation'), ('misinformation', 'how'), ('how', 'to'), ('to', 'treat'), ('treat', 'certain'), ('certain', 'AI'), ('AI', 'systems'), ('systems', 'if'), ('if', 'they'), ('they', 'have'), ('have', 'a'), ('a', 'moral'), ('moral', 'status'), ('status', 'AI'), ('AI', 'welfare'), ('welfare', 'and'), ('and', 'rights'), ('rights', 'artificial'), ('artificial', 'superintelligence'), ('superintelligence', 'and'), ('and', 'existential'), ('existential', 'risks')]\n",
      "\n",
      "Trigrams: [('The', 'ethics', 'of'), ('ethics', 'of', 'artificial'), ('of', 'artificial', 'intelligence'), ('artificial', 'intelligence', 'covers'), ('intelligence', 'covers', 'a'), ('covers', 'a', 'broad'), ('a', 'broad', 'range'), ('broad', 'range', 'of'), ('range', 'of', 'topics'), ('of', 'topics', 'within'), ('topics', 'within', 'AI'), ('within', 'AI', 'that'), ('AI', 'that', 'are'), ('that', 'are', 'considered'), ('are', 'considered', 'to'), ('considered', 'to', 'have'), ('to', 'have', 'particular'), ('have', 'particular', 'ethical'), ('particular', 'ethical', 'stakes'), ('ethical', 'stakes', 'This'), ('stakes', 'This', 'includes'), ('This', 'includes', 'algorithmic'), ('includes', 'algorithmic', 'biases'), ('algorithmic', 'biases', 'fairness'), ('biases', 'fairness', 'automated'), ('fairness', 'automated', 'decisionmaking'), ('automated', 'decisionmaking', 'accountability'), ('decisionmaking', 'accountability', 'privacy'), ('accountability', 'privacy', 'and'), ('privacy', 'and', 'regulation'), ('and', 'regulation', 'It'), ('regulation', 'It', 'also'), ('It', 'also', 'covers'), ('also', 'covers', 'various'), ('covers', 'various', 'emerging'), ('various', 'emerging', 'or'), ('emerging', 'or', 'potential'), ('or', 'potential', 'future'), ('potential', 'future', 'challenges'), ('future', 'challenges', 'such'), ('challenges', 'such', 'as'), ('such', 'as', 'machine'), ('as', 'machine', 'ethics'), ('machine', 'ethics', 'how'), ('ethics', 'how', 'to'), ('how', 'to', 'make'), ('to', 'make', 'machines'), ('make', 'machines', 'that'), ('machines', 'that', 'behave'), ('that', 'behave', 'ethically'), ('behave', 'ethically', 'lethal'), ('ethically', 'lethal', 'autonomous'), ('lethal', 'autonomous', 'weapon'), ('autonomous', 'weapon', 'systems'), ('weapon', 'systems', 'arms'), ('systems', 'arms', 'race'), ('arms', 'race', 'dynamics'), ('race', 'dynamics', 'AI'), ('dynamics', 'AI', 'safety'), ('AI', 'safety', 'and'), ('safety', 'and', 'alignment'), ('and', 'alignment', 'technological'), ('alignment', 'technological', 'unemployment'), ('technological', 'unemployment', 'AIenabled'), ('unemployment', 'AIenabled', 'misinformation'), ('AIenabled', 'misinformation', 'how'), ('misinformation', 'how', 'to'), ('how', 'to', 'treat'), ('to', 'treat', 'certain'), ('treat', 'certain', 'AI'), ('certain', 'AI', 'systems'), ('AI', 'systems', 'if'), ('systems', 'if', 'they'), ('if', 'they', 'have'), ('they', 'have', 'a'), ('have', 'a', 'moral'), ('a', 'moral', 'status'), ('moral', 'status', 'AI'), ('status', 'AI', 'welfare'), ('AI', 'welfare', 'and'), ('welfare', 'and', 'rights'), ('and', 'rights', 'artificial'), ('rights', 'artificial', 'superintelligence'), ('artificial', 'superintelligence', 'and'), ('superintelligence', 'and', 'existential'), ('and', 'existential', 'risks')]\n",
      "\n",
      "Document: Different machine learning approaches can suffer from different data biases A machine learning system trained specifically on current customers may not be able to predict the needs of new customer groups that are not represented in the training data When trained on humanmade data machine learning is likely to pick up the constitutional and unconscious biases already present in society\n",
      "\n",
      "\n",
      "Unigrams: [('Different',), ('machine',), ('learning',), ('approaches',), ('can',), ('suffer',), ('from',), ('different',), ('data',), ('biases',), ('A',), ('machine',), ('learning',), ('system',), ('trained',), ('specifically',), ('on',), ('current',), ('customers',), ('may',), ('not',), ('be',), ('able',), ('to',), ('predict',), ('the',), ('needs',), ('of',), ('new',), ('customer',), ('groups',), ('that',), ('are',), ('not',), ('represented',), ('in',), ('the',), ('training',), ('data',), ('When',), ('trained',), ('on',), ('humanmade',), ('data',), ('machine',), ('learning',), ('is',), ('likely',), ('to',), ('pick',), ('up',), ('the',), ('constitutional',), ('and',), ('unconscious',), ('biases',), ('already',), ('present',), ('in',), ('society',)]\n",
      "\n",
      "Bigrams: [('Different', 'machine'), ('machine', 'learning'), ('learning', 'approaches'), ('approaches', 'can'), ('can', 'suffer'), ('suffer', 'from'), ('from', 'different'), ('different', 'data'), ('data', 'biases'), ('biases', 'A'), ('A', 'machine'), ('machine', 'learning'), ('learning', 'system'), ('system', 'trained'), ('trained', 'specifically'), ('specifically', 'on'), ('on', 'current'), ('current', 'customers'), ('customers', 'may'), ('may', 'not'), ('not', 'be'), ('be', 'able'), ('able', 'to'), ('to', 'predict'), ('predict', 'the'), ('the', 'needs'), ('needs', 'of'), ('of', 'new'), ('new', 'customer'), ('customer', 'groups'), ('groups', 'that'), ('that', 'are'), ('are', 'not'), ('not', 'represented'), ('represented', 'in'), ('in', 'the'), ('the', 'training'), ('training', 'data'), ('data', 'When'), ('When', 'trained'), ('trained', 'on'), ('on', 'humanmade'), ('humanmade', 'data'), ('data', 'machine'), ('machine', 'learning'), ('learning', 'is'), ('is', 'likely'), ('likely', 'to'), ('to', 'pick'), ('pick', 'up'), ('up', 'the'), ('the', 'constitutional'), ('constitutional', 'and'), ('and', 'unconscious'), ('unconscious', 'biases'), ('biases', 'already'), ('already', 'present'), ('present', 'in'), ('in', 'society')]\n",
      "\n",
      "Trigrams: [('Different', 'machine', 'learning'), ('machine', 'learning', 'approaches'), ('learning', 'approaches', 'can'), ('approaches', 'can', 'suffer'), ('can', 'suffer', 'from'), ('suffer', 'from', 'different'), ('from', 'different', 'data'), ('different', 'data', 'biases'), ('data', 'biases', 'A'), ('biases', 'A', 'machine'), ('A', 'machine', 'learning'), ('machine', 'learning', 'system'), ('learning', 'system', 'trained'), ('system', 'trained', 'specifically'), ('trained', 'specifically', 'on'), ('specifically', 'on', 'current'), ('on', 'current', 'customers'), ('current', 'customers', 'may'), ('customers', 'may', 'not'), ('may', 'not', 'be'), ('not', 'be', 'able'), ('be', 'able', 'to'), ('able', 'to', 'predict'), ('to', 'predict', 'the'), ('predict', 'the', 'needs'), ('the', 'needs', 'of'), ('needs', 'of', 'new'), ('of', 'new', 'customer'), ('new', 'customer', 'groups'), ('customer', 'groups', 'that'), ('groups', 'that', 'are'), ('that', 'are', 'not'), ('are', 'not', 'represented'), ('not', 'represented', 'in'), ('represented', 'in', 'the'), ('in', 'the', 'training'), ('the', 'training', 'data'), ('training', 'data', 'When'), ('data', 'When', 'trained'), ('When', 'trained', 'on'), ('trained', 'on', 'humanmade'), ('on', 'humanmade', 'data'), ('humanmade', 'data', 'machine'), ('data', 'machine', 'learning'), ('machine', 'learning', 'is'), ('learning', 'is', 'likely'), ('is', 'likely', 'to'), ('likely', 'to', 'pick'), ('to', 'pick', 'up'), ('pick', 'up', 'the'), ('up', 'the', 'constitutional'), ('the', 'constitutional', 'and'), ('constitutional', 'and', 'unconscious'), ('and', 'unconscious', 'biases'), ('unconscious', 'biases', 'already'), ('biases', 'already', 'present'), ('already', 'present', 'in'), ('present', 'in', 'society')]\n",
      "\n",
      "Document: Systems that are trained on datasets collected with biases may exhibit these biases upon use algorithmic bias thus digitising cultural prejudices For example in  the UKs Commission for Racial Equality found that St Georges Medical School had been using a computer program trained from data of previous admissions staff and that this program had denied nearly  candidates who were found to either be women or have nonEuropean sounding names Using job hiring data from a firm with racist hiring policies may lead to a machine learning system duplicating the bias by scoring job applicants by similarity to previous successful applicants Another example includes predictive policing company Geoliticas predictive algorithm that resulted in disproportionately high levels of overpolicing in lowincome and minority communities after being trained with historical crime data\n",
      "\n",
      "\n",
      "Unigrams: [('Systems',), ('that',), ('are',), ('trained',), ('on',), ('datasets',), ('collected',), ('with',), ('biases',), ('may',), ('exhibit',), ('these',), ('biases',), ('upon',), ('use',), ('algorithmic',), ('bias',), ('thus',), ('digitising',), ('cultural',), ('prejudices',), ('For',), ('example',), ('in',), ('the',), ('UKs',), ('Commission',), ('for',), ('Racial',), ('Equality',), ('found',), ('that',), ('St',), ('Georges',), ('Medical',), ('School',), ('had',), ('been',), ('using',), ('a',), ('computer',), ('program',), ('trained',), ('from',), ('data',), ('of',), ('previous',), ('admissions',), ('staff',), ('and',), ('that',), ('this',), ('program',), ('had',), ('denied',), ('nearly',), ('candidates',), ('who',), ('were',), ('found',), ('to',), ('either',), ('be',), ('women',), ('or',), ('have',), ('nonEuropean',), ('sounding',), ('names',), ('Using',), ('job',), ('hiring',), ('data',), ('from',), ('a',), ('firm',), ('with',), ('racist',), ('hiring',), ('policies',), ('may',), ('lead',), ('to',), ('a',), ('machine',), ('learning',), ('system',), ('duplicating',), ('the',), ('bias',), ('by',), ('scoring',), ('job',), ('applicants',), ('by',), ('similarity',), ('to',), ('previous',), ('successful',), ('applicants',), ('Another',), ('example',), ('includes',), ('predictive',), ('policing',), ('company',), ('Geoliticas',), ('predictive',), ('algorithm',), ('that',), ('resulted',), ('in',), ('disproportionately',), ('high',), ('levels',), ('of',), ('overpolicing',), ('in',), ('lowincome',), ('and',), ('minority',), ('communities',), ('after',), ('being',), ('trained',), ('with',), ('historical',), ('crime',), ('data',)]\n",
      "\n",
      "Bigrams: [('Systems', 'that'), ('that', 'are'), ('are', 'trained'), ('trained', 'on'), ('on', 'datasets'), ('datasets', 'collected'), ('collected', 'with'), ('with', 'biases'), ('biases', 'may'), ('may', 'exhibit'), ('exhibit', 'these'), ('these', 'biases'), ('biases', 'upon'), ('upon', 'use'), ('use', 'algorithmic'), ('algorithmic', 'bias'), ('bias', 'thus'), ('thus', 'digitising'), ('digitising', 'cultural'), ('cultural', 'prejudices'), ('prejudices', 'For'), ('For', 'example'), ('example', 'in'), ('in', 'the'), ('the', 'UKs'), ('UKs', 'Commission'), ('Commission', 'for'), ('for', 'Racial'), ('Racial', 'Equality'), ('Equality', 'found'), ('found', 'that'), ('that', 'St'), ('St', 'Georges'), ('Georges', 'Medical'), ('Medical', 'School'), ('School', 'had'), ('had', 'been'), ('been', 'using'), ('using', 'a'), ('a', 'computer'), ('computer', 'program'), ('program', 'trained'), ('trained', 'from'), ('from', 'data'), ('data', 'of'), ('of', 'previous'), ('previous', 'admissions'), ('admissions', 'staff'), ('staff', 'and'), ('and', 'that'), ('that', 'this'), ('this', 'program'), ('program', 'had'), ('had', 'denied'), ('denied', 'nearly'), ('nearly', 'candidates'), ('candidates', 'who'), ('who', 'were'), ('were', 'found'), ('found', 'to'), ('to', 'either'), ('either', 'be'), ('be', 'women'), ('women', 'or'), ('or', 'have'), ('have', 'nonEuropean'), ('nonEuropean', 'sounding'), ('sounding', 'names'), ('names', 'Using'), ('Using', 'job'), ('job', 'hiring'), ('hiring', 'data'), ('data', 'from'), ('from', 'a'), ('a', 'firm'), ('firm', 'with'), ('with', 'racist'), ('racist', 'hiring'), ('hiring', 'policies'), ('policies', 'may'), ('may', 'lead'), ('lead', 'to'), ('to', 'a'), ('a', 'machine'), ('machine', 'learning'), ('learning', 'system'), ('system', 'duplicating'), ('duplicating', 'the'), ('the', 'bias'), ('bias', 'by'), ('by', 'scoring'), ('scoring', 'job'), ('job', 'applicants'), ('applicants', 'by'), ('by', 'similarity'), ('similarity', 'to'), ('to', 'previous'), ('previous', 'successful'), ('successful', 'applicants'), ('applicants', 'Another'), ('Another', 'example'), ('example', 'includes'), ('includes', 'predictive'), ('predictive', 'policing'), ('policing', 'company'), ('company', 'Geoliticas'), ('Geoliticas', 'predictive'), ('predictive', 'algorithm'), ('algorithm', 'that'), ('that', 'resulted'), ('resulted', 'in'), ('in', 'disproportionately'), ('disproportionately', 'high'), ('high', 'levels'), ('levels', 'of'), ('of', 'overpolicing'), ('overpolicing', 'in'), ('in', 'lowincome'), ('lowincome', 'and'), ('and', 'minority'), ('minority', 'communities'), ('communities', 'after'), ('after', 'being'), ('being', 'trained'), ('trained', 'with'), ('with', 'historical'), ('historical', 'crime'), ('crime', 'data')]\n",
      "\n",
      "Trigrams: [('Systems', 'that', 'are'), ('that', 'are', 'trained'), ('are', 'trained', 'on'), ('trained', 'on', 'datasets'), ('on', 'datasets', 'collected'), ('datasets', 'collected', 'with'), ('collected', 'with', 'biases'), ('with', 'biases', 'may'), ('biases', 'may', 'exhibit'), ('may', 'exhibit', 'these'), ('exhibit', 'these', 'biases'), ('these', 'biases', 'upon'), ('biases', 'upon', 'use'), ('upon', 'use', 'algorithmic'), ('use', 'algorithmic', 'bias'), ('algorithmic', 'bias', 'thus'), ('bias', 'thus', 'digitising'), ('thus', 'digitising', 'cultural'), ('digitising', 'cultural', 'prejudices'), ('cultural', 'prejudices', 'For'), ('prejudices', 'For', 'example'), ('For', 'example', 'in'), ('example', 'in', 'the'), ('in', 'the', 'UKs'), ('the', 'UKs', 'Commission'), ('UKs', 'Commission', 'for'), ('Commission', 'for', 'Racial'), ('for', 'Racial', 'Equality'), ('Racial', 'Equality', 'found'), ('Equality', 'found', 'that'), ('found', 'that', 'St'), ('that', 'St', 'Georges'), ('St', 'Georges', 'Medical'), ('Georges', 'Medical', 'School'), ('Medical', 'School', 'had'), ('School', 'had', 'been'), ('had', 'been', 'using'), ('been', 'using', 'a'), ('using', 'a', 'computer'), ('a', 'computer', 'program'), ('computer', 'program', 'trained'), ('program', 'trained', 'from'), ('trained', 'from', 'data'), ('from', 'data', 'of'), ('data', 'of', 'previous'), ('of', 'previous', 'admissions'), ('previous', 'admissions', 'staff'), ('admissions', 'staff', 'and'), ('staff', 'and', 'that'), ('and', 'that', 'this'), ('that', 'this', 'program'), ('this', 'program', 'had'), ('program', 'had', 'denied'), ('had', 'denied', 'nearly'), ('denied', 'nearly', 'candidates'), ('nearly', 'candidates', 'who'), ('candidates', 'who', 'were'), ('who', 'were', 'found'), ('were', 'found', 'to'), ('found', 'to', 'either'), ('to', 'either', 'be'), ('either', 'be', 'women'), ('be', 'women', 'or'), ('women', 'or', 'have'), ('or', 'have', 'nonEuropean'), ('have', 'nonEuropean', 'sounding'), ('nonEuropean', 'sounding', 'names'), ('sounding', 'names', 'Using'), ('names', 'Using', 'job'), ('Using', 'job', 'hiring'), ('job', 'hiring', 'data'), ('hiring', 'data', 'from'), ('data', 'from', 'a'), ('from', 'a', 'firm'), ('a', 'firm', 'with'), ('firm', 'with', 'racist'), ('with', 'racist', 'hiring'), ('racist', 'hiring', 'policies'), ('hiring', 'policies', 'may'), ('policies', 'may', 'lead'), ('may', 'lead', 'to'), ('lead', 'to', 'a'), ('to', 'a', 'machine'), ('a', 'machine', 'learning'), ('machine', 'learning', 'system'), ('learning', 'system', 'duplicating'), ('system', 'duplicating', 'the'), ('duplicating', 'the', 'bias'), ('the', 'bias', 'by'), ('bias', 'by', 'scoring'), ('by', 'scoring', 'job'), ('scoring', 'job', 'applicants'), ('job', 'applicants', 'by'), ('applicants', 'by', 'similarity'), ('by', 'similarity', 'to'), ('similarity', 'to', 'previous'), ('to', 'previous', 'successful'), ('previous', 'successful', 'applicants'), ('successful', 'applicants', 'Another'), ('applicants', 'Another', 'example'), ('Another', 'example', 'includes'), ('example', 'includes', 'predictive'), ('includes', 'predictive', 'policing'), ('predictive', 'policing', 'company'), ('policing', 'company', 'Geoliticas'), ('company', 'Geoliticas', 'predictive'), ('Geoliticas', 'predictive', 'algorithm'), ('predictive', 'algorithm', 'that'), ('algorithm', 'that', 'resulted'), ('that', 'resulted', 'in'), ('resulted', 'in', 'disproportionately'), ('in', 'disproportionately', 'high'), ('disproportionately', 'high', 'levels'), ('high', 'levels', 'of'), ('levels', 'of', 'overpolicing'), ('of', 'overpolicing', 'in'), ('overpolicing', 'in', 'lowincome'), ('in', 'lowincome', 'and'), ('lowincome', 'and', 'minority'), ('and', 'minority', 'communities'), ('minority', 'communities', 'after'), ('communities', 'after', 'being'), ('after', 'being', 'trained'), ('being', 'trained', 'with'), ('trained', 'with', 'historical'), ('with', 'historical', 'crime'), ('historical', 'crime', 'data')]\n",
      "\n",
      "Document: While responsible collection of data and documentation of algorithmic rules used by a system is considered a critical part of machine learning some researchers blame lack of participation and representation of minority population in the field of AI for machine learnings vulnerability to biases In fact according to research carried out by the Computing Research Association CRA in  female faculty merely make up  of all faculty members who focus on AI among several universities around the world Furthermore among the group of new US resident AI PhD graduates  identified as white  as Asian  as Hispanic and  as African American which further demonstrates a lack of diversity in the field of AI\n",
      "\n",
      "\n",
      "Unigrams: [('While',), ('responsible',), ('collection',), ('of',), ('data',), ('and',), ('documentation',), ('of',), ('algorithmic',), ('rules',), ('used',), ('by',), ('a',), ('system',), ('is',), ('considered',), ('a',), ('critical',), ('part',), ('of',), ('machine',), ('learning',), ('some',), ('researchers',), ('blame',), ('lack',), ('of',), ('participation',), ('and',), ('representation',), ('of',), ('minority',), ('population',), ('in',), ('the',), ('field',), ('of',), ('AI',), ('for',), ('machine',), ('learnings',), ('vulnerability',), ('to',), ('biases',), ('In',), ('fact',), ('according',), ('to',), ('research',), ('carried',), ('out',), ('by',), ('the',), ('Computing',), ('Research',), ('Association',), ('CRA',), ('in',), ('female',), ('faculty',), ('merely',), ('make',), ('up',), ('of',), ('all',), ('faculty',), ('members',), ('who',), ('focus',), ('on',), ('AI',), ('among',), ('several',), ('universities',), ('around',), ('the',), ('world',), ('Furthermore',), ('among',), ('the',), ('group',), ('of',), ('new',), ('US',), ('resident',), ('AI',), ('PhD',), ('graduates',), ('identified',), ('as',), ('white',), ('as',), ('Asian',), ('as',), ('Hispanic',), ('and',), ('as',), ('African',), ('American',), ('which',), ('further',), ('demonstrates',), ('a',), ('lack',), ('of',), ('diversity',), ('in',), ('the',), ('field',), ('of',), ('AI',)]\n",
      "\n",
      "Bigrams: [('While', 'responsible'), ('responsible', 'collection'), ('collection', 'of'), ('of', 'data'), ('data', 'and'), ('and', 'documentation'), ('documentation', 'of'), ('of', 'algorithmic'), ('algorithmic', 'rules'), ('rules', 'used'), ('used', 'by'), ('by', 'a'), ('a', 'system'), ('system', 'is'), ('is', 'considered'), ('considered', 'a'), ('a', 'critical'), ('critical', 'part'), ('part', 'of'), ('of', 'machine'), ('machine', 'learning'), ('learning', 'some'), ('some', 'researchers'), ('researchers', 'blame'), ('blame', 'lack'), ('lack', 'of'), ('of', 'participation'), ('participation', 'and'), ('and', 'representation'), ('representation', 'of'), ('of', 'minority'), ('minority', 'population'), ('population', 'in'), ('in', 'the'), ('the', 'field'), ('field', 'of'), ('of', 'AI'), ('AI', 'for'), ('for', 'machine'), ('machine', 'learnings'), ('learnings', 'vulnerability'), ('vulnerability', 'to'), ('to', 'biases'), ('biases', 'In'), ('In', 'fact'), ('fact', 'according'), ('according', 'to'), ('to', 'research'), ('research', 'carried'), ('carried', 'out'), ('out', 'by'), ('by', 'the'), ('the', 'Computing'), ('Computing', 'Research'), ('Research', 'Association'), ('Association', 'CRA'), ('CRA', 'in'), ('in', 'female'), ('female', 'faculty'), ('faculty', 'merely'), ('merely', 'make'), ('make', 'up'), ('up', 'of'), ('of', 'all'), ('all', 'faculty'), ('faculty', 'members'), ('members', 'who'), ('who', 'focus'), ('focus', 'on'), ('on', 'AI'), ('AI', 'among'), ('among', 'several'), ('several', 'universities'), ('universities', 'around'), ('around', 'the'), ('the', 'world'), ('world', 'Furthermore'), ('Furthermore', 'among'), ('among', 'the'), ('the', 'group'), ('group', 'of'), ('of', 'new'), ('new', 'US'), ('US', 'resident'), ('resident', 'AI'), ('AI', 'PhD'), ('PhD', 'graduates'), ('graduates', 'identified'), ('identified', 'as'), ('as', 'white'), ('white', 'as'), ('as', 'Asian'), ('Asian', 'as'), ('as', 'Hispanic'), ('Hispanic', 'and'), ('and', 'as'), ('as', 'African'), ('African', 'American'), ('American', 'which'), ('which', 'further'), ('further', 'demonstrates'), ('demonstrates', 'a'), ('a', 'lack'), ('lack', 'of'), ('of', 'diversity'), ('diversity', 'in'), ('in', 'the'), ('the', 'field'), ('field', 'of'), ('of', 'AI')]\n",
      "\n",
      "Trigrams: [('While', 'responsible', 'collection'), ('responsible', 'collection', 'of'), ('collection', 'of', 'data'), ('of', 'data', 'and'), ('data', 'and', 'documentation'), ('and', 'documentation', 'of'), ('documentation', 'of', 'algorithmic'), ('of', 'algorithmic', 'rules'), ('algorithmic', 'rules', 'used'), ('rules', 'used', 'by'), ('used', 'by', 'a'), ('by', 'a', 'system'), ('a', 'system', 'is'), ('system', 'is', 'considered'), ('is', 'considered', 'a'), ('considered', 'a', 'critical'), ('a', 'critical', 'part'), ('critical', 'part', 'of'), ('part', 'of', 'machine'), ('of', 'machine', 'learning'), ('machine', 'learning', 'some'), ('learning', 'some', 'researchers'), ('some', 'researchers', 'blame'), ('researchers', 'blame', 'lack'), ('blame', 'lack', 'of'), ('lack', 'of', 'participation'), ('of', 'participation', 'and'), ('participation', 'and', 'representation'), ('and', 'representation', 'of'), ('representation', 'of', 'minority'), ('of', 'minority', 'population'), ('minority', 'population', 'in'), ('population', 'in', 'the'), ('in', 'the', 'field'), ('the', 'field', 'of'), ('field', 'of', 'AI'), ('of', 'AI', 'for'), ('AI', 'for', 'machine'), ('for', 'machine', 'learnings'), ('machine', 'learnings', 'vulnerability'), ('learnings', 'vulnerability', 'to'), ('vulnerability', 'to', 'biases'), ('to', 'biases', 'In'), ('biases', 'In', 'fact'), ('In', 'fact', 'according'), ('fact', 'according', 'to'), ('according', 'to', 'research'), ('to', 'research', 'carried'), ('research', 'carried', 'out'), ('carried', 'out', 'by'), ('out', 'by', 'the'), ('by', 'the', 'Computing'), ('the', 'Computing', 'Research'), ('Computing', 'Research', 'Association'), ('Research', 'Association', 'CRA'), ('Association', 'CRA', 'in'), ('CRA', 'in', 'female'), ('in', 'female', 'faculty'), ('female', 'faculty', 'merely'), ('faculty', 'merely', 'make'), ('merely', 'make', 'up'), ('make', 'up', 'of'), ('up', 'of', 'all'), ('of', 'all', 'faculty'), ('all', 'faculty', 'members'), ('faculty', 'members', 'who'), ('members', 'who', 'focus'), ('who', 'focus', 'on'), ('focus', 'on', 'AI'), ('on', 'AI', 'among'), ('AI', 'among', 'several'), ('among', 'several', 'universities'), ('several', 'universities', 'around'), ('universities', 'around', 'the'), ('around', 'the', 'world'), ('the', 'world', 'Furthermore'), ('world', 'Furthermore', 'among'), ('Furthermore', 'among', 'the'), ('among', 'the', 'group'), ('the', 'group', 'of'), ('group', 'of', 'new'), ('of', 'new', 'US'), ('new', 'US', 'resident'), ('US', 'resident', 'AI'), ('resident', 'AI', 'PhD'), ('AI', 'PhD', 'graduates'), ('PhD', 'graduates', 'identified'), ('graduates', 'identified', 'as'), ('identified', 'as', 'white'), ('as', 'white', 'as'), ('white', 'as', 'Asian'), ('as', 'Asian', 'as'), ('Asian', 'as', 'Hispanic'), ('as', 'Hispanic', 'and'), ('Hispanic', 'and', 'as'), ('and', 'as', 'African'), ('as', 'African', 'American'), ('African', 'American', 'which'), ('American', 'which', 'further'), ('which', 'further', 'demonstrates'), ('further', 'demonstrates', 'a'), ('demonstrates', 'a', 'lack'), ('a', 'lack', 'of'), ('lack', 'of', 'diversity'), ('of', 'diversity', 'in'), ('diversity', 'in', 'the'), ('in', 'the', 'field'), ('the', 'field', 'of'), ('field', 'of', 'AI')]\n",
      "\n",
      "Document: Language models learned from data have been shown to contain humanlike biases Because human languages contain biases machines trained on language corpora will necessarily also learn these biases In  Microsoft tested Tay a chatbot that learned from Twitter and it quickly picked up racist and sexist language\n",
      "\n",
      "\n",
      "Unigrams: [('Language',), ('models',), ('learned',), ('from',), ('data',), ('have',), ('been',), ('shown',), ('to',), ('contain',), ('humanlike',), ('biases',), ('Because',), ('human',), ('languages',), ('contain',), ('biases',), ('machines',), ('trained',), ('on',), ('language',), ('corpora',), ('will',), ('necessarily',), ('also',), ('learn',), ('these',), ('biases',), ('In',), ('Microsoft',), ('tested',), ('Tay',), ('a',), ('chatbot',), ('that',), ('learned',), ('from',), ('Twitter',), ('and',), ('it',), ('quickly',), ('picked',), ('up',), ('racist',), ('and',), ('sexist',), ('language',)]\n",
      "\n",
      "Bigrams: [('Language', 'models'), ('models', 'learned'), ('learned', 'from'), ('from', 'data'), ('data', 'have'), ('have', 'been'), ('been', 'shown'), ('shown', 'to'), ('to', 'contain'), ('contain', 'humanlike'), ('humanlike', 'biases'), ('biases', 'Because'), ('Because', 'human'), ('human', 'languages'), ('languages', 'contain'), ('contain', 'biases'), ('biases', 'machines'), ('machines', 'trained'), ('trained', 'on'), ('on', 'language'), ('language', 'corpora'), ('corpora', 'will'), ('will', 'necessarily'), ('necessarily', 'also'), ('also', 'learn'), ('learn', 'these'), ('these', 'biases'), ('biases', 'In'), ('In', 'Microsoft'), ('Microsoft', 'tested'), ('tested', 'Tay'), ('Tay', 'a'), ('a', 'chatbot'), ('chatbot', 'that'), ('that', 'learned'), ('learned', 'from'), ('from', 'Twitter'), ('Twitter', 'and'), ('and', 'it'), ('it', 'quickly'), ('quickly', 'picked'), ('picked', 'up'), ('up', 'racist'), ('racist', 'and'), ('and', 'sexist'), ('sexist', 'language')]\n",
      "\n",
      "Trigrams: [('Language', 'models', 'learned'), ('models', 'learned', 'from'), ('learned', 'from', 'data'), ('from', 'data', 'have'), ('data', 'have', 'been'), ('have', 'been', 'shown'), ('been', 'shown', 'to'), ('shown', 'to', 'contain'), ('to', 'contain', 'humanlike'), ('contain', 'humanlike', 'biases'), ('humanlike', 'biases', 'Because'), ('biases', 'Because', 'human'), ('Because', 'human', 'languages'), ('human', 'languages', 'contain'), ('languages', 'contain', 'biases'), ('contain', 'biases', 'machines'), ('biases', 'machines', 'trained'), ('machines', 'trained', 'on'), ('trained', 'on', 'language'), ('on', 'language', 'corpora'), ('language', 'corpora', 'will'), ('corpora', 'will', 'necessarily'), ('will', 'necessarily', 'also'), ('necessarily', 'also', 'learn'), ('also', 'learn', 'these'), ('learn', 'these', 'biases'), ('these', 'biases', 'In'), ('biases', 'In', 'Microsoft'), ('In', 'Microsoft', 'tested'), ('Microsoft', 'tested', 'Tay'), ('tested', 'Tay', 'a'), ('Tay', 'a', 'chatbot'), ('a', 'chatbot', 'that'), ('chatbot', 'that', 'learned'), ('that', 'learned', 'from'), ('learned', 'from', 'Twitter'), ('from', 'Twitter', 'and'), ('Twitter', 'and', 'it'), ('and', 'it', 'quickly'), ('it', 'quickly', 'picked'), ('quickly', 'picked', 'up'), ('picked', 'up', 'racist'), ('up', 'racist', 'and'), ('racist', 'and', 'sexist'), ('and', 'sexist', 'language')]\n",
      "\n",
      "Document: In an experiment carried out by ProPublica an investigative journalism organisation a machine learning algorithms insight into the recidivism rates among prisoners falsely flagged black defendants high risk twice as often as white defendants In  Google Photos once tagged a couple of black people as gorillas which caused controversy The gorilla label was subsequently removed and in  it still cannot recognise gorillas Similar issues with recognising nonwhite people have been found in many other systems\n",
      "\n",
      "\n",
      "Unigrams: [('In',), ('an',), ('experiment',), ('carried',), ('out',), ('by',), ('ProPublica',), ('an',), ('investigative',), ('journalism',), ('organisation',), ('a',), ('machine',), ('learning',), ('algorithms',), ('insight',), ('into',), ('the',), ('recidivism',), ('rates',), ('among',), ('prisoners',), ('falsely',), ('flagged',), ('black',), ('defendants',), ('high',), ('risk',), ('twice',), ('as',), ('often',), ('as',), ('white',), ('defendants',), ('In',), ('Google',), ('Photos',), ('once',), ('tagged',), ('a',), ('couple',), ('of',), ('black',), ('people',), ('as',), ('gorillas',), ('which',), ('caused',), ('controversy',), ('The',), ('gorilla',), ('label',), ('was',), ('subsequently',), ('removed',), ('and',), ('in',), ('it',), ('still',), ('cannot',), ('recognise',), ('gorillas',), ('Similar',), ('issues',), ('with',), ('recognising',), ('nonwhite',), ('people',), ('have',), ('been',), ('found',), ('in',), ('many',), ('other',), ('systems',)]\n",
      "\n",
      "Bigrams: [('In', 'an'), ('an', 'experiment'), ('experiment', 'carried'), ('carried', 'out'), ('out', 'by'), ('by', 'ProPublica'), ('ProPublica', 'an'), ('an', 'investigative'), ('investigative', 'journalism'), ('journalism', 'organisation'), ('organisation', 'a'), ('a', 'machine'), ('machine', 'learning'), ('learning', 'algorithms'), ('algorithms', 'insight'), ('insight', 'into'), ('into', 'the'), ('the', 'recidivism'), ('recidivism', 'rates'), ('rates', 'among'), ('among', 'prisoners'), ('prisoners', 'falsely'), ('falsely', 'flagged'), ('flagged', 'black'), ('black', 'defendants'), ('defendants', 'high'), ('high', 'risk'), ('risk', 'twice'), ('twice', 'as'), ('as', 'often'), ('often', 'as'), ('as', 'white'), ('white', 'defendants'), ('defendants', 'In'), ('In', 'Google'), ('Google', 'Photos'), ('Photos', 'once'), ('once', 'tagged'), ('tagged', 'a'), ('a', 'couple'), ('couple', 'of'), ('of', 'black'), ('black', 'people'), ('people', 'as'), ('as', 'gorillas'), ('gorillas', 'which'), ('which', 'caused'), ('caused', 'controversy'), ('controversy', 'The'), ('The', 'gorilla'), ('gorilla', 'label'), ('label', 'was'), ('was', 'subsequently'), ('subsequently', 'removed'), ('removed', 'and'), ('and', 'in'), ('in', 'it'), ('it', 'still'), ('still', 'cannot'), ('cannot', 'recognise'), ('recognise', 'gorillas'), ('gorillas', 'Similar'), ('Similar', 'issues'), ('issues', 'with'), ('with', 'recognising'), ('recognising', 'nonwhite'), ('nonwhite', 'people'), ('people', 'have'), ('have', 'been'), ('been', 'found'), ('found', 'in'), ('in', 'many'), ('many', 'other'), ('other', 'systems')]\n",
      "\n",
      "Trigrams: [('In', 'an', 'experiment'), ('an', 'experiment', 'carried'), ('experiment', 'carried', 'out'), ('carried', 'out', 'by'), ('out', 'by', 'ProPublica'), ('by', 'ProPublica', 'an'), ('ProPublica', 'an', 'investigative'), ('an', 'investigative', 'journalism'), ('investigative', 'journalism', 'organisation'), ('journalism', 'organisation', 'a'), ('organisation', 'a', 'machine'), ('a', 'machine', 'learning'), ('machine', 'learning', 'algorithms'), ('learning', 'algorithms', 'insight'), ('algorithms', 'insight', 'into'), ('insight', 'into', 'the'), ('into', 'the', 'recidivism'), ('the', 'recidivism', 'rates'), ('recidivism', 'rates', 'among'), ('rates', 'among', 'prisoners'), ('among', 'prisoners', 'falsely'), ('prisoners', 'falsely', 'flagged'), ('falsely', 'flagged', 'black'), ('flagged', 'black', 'defendants'), ('black', 'defendants', 'high'), ('defendants', 'high', 'risk'), ('high', 'risk', 'twice'), ('risk', 'twice', 'as'), ('twice', 'as', 'often'), ('as', 'often', 'as'), ('often', 'as', 'white'), ('as', 'white', 'defendants'), ('white', 'defendants', 'In'), ('defendants', 'In', 'Google'), ('In', 'Google', 'Photos'), ('Google', 'Photos', 'once'), ('Photos', 'once', 'tagged'), ('once', 'tagged', 'a'), ('tagged', 'a', 'couple'), ('a', 'couple', 'of'), ('couple', 'of', 'black'), ('of', 'black', 'people'), ('black', 'people', 'as'), ('people', 'as', 'gorillas'), ('as', 'gorillas', 'which'), ('gorillas', 'which', 'caused'), ('which', 'caused', 'controversy'), ('caused', 'controversy', 'The'), ('controversy', 'The', 'gorilla'), ('The', 'gorilla', 'label'), ('gorilla', 'label', 'was'), ('label', 'was', 'subsequently'), ('was', 'subsequently', 'removed'), ('subsequently', 'removed', 'and'), ('removed', 'and', 'in'), ('and', 'in', 'it'), ('in', 'it', 'still'), ('it', 'still', 'cannot'), ('still', 'cannot', 'recognise'), ('cannot', 'recognise', 'gorillas'), ('recognise', 'gorillas', 'Similar'), ('gorillas', 'Similar', 'issues'), ('Similar', 'issues', 'with'), ('issues', 'with', 'recognising'), ('with', 'recognising', 'nonwhite'), ('recognising', 'nonwhite', 'people'), ('nonwhite', 'people', 'have'), ('people', 'have', 'been'), ('have', 'been', 'found'), ('been', 'found', 'in'), ('found', 'in', 'many'), ('in', 'many', 'other'), ('many', 'other', 'systems')]\n",
      "\n",
      "Document: Because of such challenges the effective use of machine learning may take longer to be adopted in other domains Concern for fairness in machine learning that is reducing bias in machine learning and propelling its use for human good is increasingly expressed by artificial intelligence scientists including FeiFei Li who said that theres nothing artificial about AI Its inspired by people its created by people andmost importantlyit impacts people It is a powerful tool we are only just beginning to understand and that is a profound responsibility\n",
      "\n",
      "\n",
      "Unigrams: [('Because',), ('of',), ('such',), ('challenges',), ('the',), ('effective',), ('use',), ('of',), ('machine',), ('learning',), ('may',), ('take',), ('longer',), ('to',), ('be',), ('adopted',), ('in',), ('other',), ('domains',), ('Concern',), ('for',), ('fairness',), ('in',), ('machine',), ('learning',), ('that',), ('is',), ('reducing',), ('bias',), ('in',), ('machine',), ('learning',), ('and',), ('propelling',), ('its',), ('use',), ('for',), ('human',), ('good',), ('is',), ('increasingly',), ('expressed',), ('by',), ('artificial',), ('intelligence',), ('scientists',), ('including',), ('FeiFei',), ('Li',), ('who',), ('said',), ('that',), ('theres',), ('nothing',), ('artificial',), ('about',), ('AI',), ('Its',), ('inspired',), ('by',), ('people',), ('its',), ('created',), ('by',), ('people',), ('andmost',), ('importantlyit',), ('impacts',), ('people',), ('It',), ('is',), ('a',), ('powerful',), ('tool',), ('we',), ('are',), ('only',), ('just',), ('beginning',), ('to',), ('understand',), ('and',), ('that',), ('is',), ('a',), ('profound',), ('responsibility',)]\n",
      "\n",
      "Bigrams: [('Because', 'of'), ('of', 'such'), ('such', 'challenges'), ('challenges', 'the'), ('the', 'effective'), ('effective', 'use'), ('use', 'of'), ('of', 'machine'), ('machine', 'learning'), ('learning', 'may'), ('may', 'take'), ('take', 'longer'), ('longer', 'to'), ('to', 'be'), ('be', 'adopted'), ('adopted', 'in'), ('in', 'other'), ('other', 'domains'), ('domains', 'Concern'), ('Concern', 'for'), ('for', 'fairness'), ('fairness', 'in'), ('in', 'machine'), ('machine', 'learning'), ('learning', 'that'), ('that', 'is'), ('is', 'reducing'), ('reducing', 'bias'), ('bias', 'in'), ('in', 'machine'), ('machine', 'learning'), ('learning', 'and'), ('and', 'propelling'), ('propelling', 'its'), ('its', 'use'), ('use', 'for'), ('for', 'human'), ('human', 'good'), ('good', 'is'), ('is', 'increasingly'), ('increasingly', 'expressed'), ('expressed', 'by'), ('by', 'artificial'), ('artificial', 'intelligence'), ('intelligence', 'scientists'), ('scientists', 'including'), ('including', 'FeiFei'), ('FeiFei', 'Li'), ('Li', 'who'), ('who', 'said'), ('said', 'that'), ('that', 'theres'), ('theres', 'nothing'), ('nothing', 'artificial'), ('artificial', 'about'), ('about', 'AI'), ('AI', 'Its'), ('Its', 'inspired'), ('inspired', 'by'), ('by', 'people'), ('people', 'its'), ('its', 'created'), ('created', 'by'), ('by', 'people'), ('people', 'andmost'), ('andmost', 'importantlyit'), ('importantlyit', 'impacts'), ('impacts', 'people'), ('people', 'It'), ('It', 'is'), ('is', 'a'), ('a', 'powerful'), ('powerful', 'tool'), ('tool', 'we'), ('we', 'are'), ('are', 'only'), ('only', 'just'), ('just', 'beginning'), ('beginning', 'to'), ('to', 'understand'), ('understand', 'and'), ('and', 'that'), ('that', 'is'), ('is', 'a'), ('a', 'profound'), ('profound', 'responsibility')]\n",
      "\n",
      "Trigrams: [('Because', 'of', 'such'), ('of', 'such', 'challenges'), ('such', 'challenges', 'the'), ('challenges', 'the', 'effective'), ('the', 'effective', 'use'), ('effective', 'use', 'of'), ('use', 'of', 'machine'), ('of', 'machine', 'learning'), ('machine', 'learning', 'may'), ('learning', 'may', 'take'), ('may', 'take', 'longer'), ('take', 'longer', 'to'), ('longer', 'to', 'be'), ('to', 'be', 'adopted'), ('be', 'adopted', 'in'), ('adopted', 'in', 'other'), ('in', 'other', 'domains'), ('other', 'domains', 'Concern'), ('domains', 'Concern', 'for'), ('Concern', 'for', 'fairness'), ('for', 'fairness', 'in'), ('fairness', 'in', 'machine'), ('in', 'machine', 'learning'), ('machine', 'learning', 'that'), ('learning', 'that', 'is'), ('that', 'is', 'reducing'), ('is', 'reducing', 'bias'), ('reducing', 'bias', 'in'), ('bias', 'in', 'machine'), ('in', 'machine', 'learning'), ('machine', 'learning', 'and'), ('learning', 'and', 'propelling'), ('and', 'propelling', 'its'), ('propelling', 'its', 'use'), ('its', 'use', 'for'), ('use', 'for', 'human'), ('for', 'human', 'good'), ('human', 'good', 'is'), ('good', 'is', 'increasingly'), ('is', 'increasingly', 'expressed'), ('increasingly', 'expressed', 'by'), ('expressed', 'by', 'artificial'), ('by', 'artificial', 'intelligence'), ('artificial', 'intelligence', 'scientists'), ('intelligence', 'scientists', 'including'), ('scientists', 'including', 'FeiFei'), ('including', 'FeiFei', 'Li'), ('FeiFei', 'Li', 'who'), ('Li', 'who', 'said'), ('who', 'said', 'that'), ('said', 'that', 'theres'), ('that', 'theres', 'nothing'), ('theres', 'nothing', 'artificial'), ('nothing', 'artificial', 'about'), ('artificial', 'about', 'AI'), ('about', 'AI', 'Its'), ('AI', 'Its', 'inspired'), ('Its', 'inspired', 'by'), ('inspired', 'by', 'people'), ('by', 'people', 'its'), ('people', 'its', 'created'), ('its', 'created', 'by'), ('created', 'by', 'people'), ('by', 'people', 'andmost'), ('people', 'andmost', 'importantlyit'), ('andmost', 'importantlyit', 'impacts'), ('importantlyit', 'impacts', 'people'), ('impacts', 'people', 'It'), ('people', 'It', 'is'), ('It', 'is', 'a'), ('is', 'a', 'powerful'), ('a', 'powerful', 'tool'), ('powerful', 'tool', 'we'), ('tool', 'we', 'are'), ('we', 'are', 'only'), ('are', 'only', 'just'), ('only', 'just', 'beginning'), ('just', 'beginning', 'to'), ('beginning', 'to', 'understand'), ('to', 'understand', 'and'), ('understand', 'and', 'that'), ('and', 'that', 'is'), ('that', 'is', 'a'), ('is', 'a', 'profound'), ('a', 'profound', 'responsibility')]\n",
      "\n",
      "Document: There are concerns among health care professionals that these systems might not be designed in the publics interest but as incomegenerating machines This is especially true in the United States where there is a longstanding ethical dilemma of improving health care but also increasing profits For example the algorithms could be designed to provide patients with unnecessary tests or medication in which the algorithms proprietary owners hold stakes There is potential for machine learning in health care to provide professionals an additional tool to diagnose medicate and plan recovery paths for patients but this requires these biases to be mitigated\n",
      "\n",
      "\n",
      "Unigrams: [('There',), ('are',), ('concerns',), ('among',), ('health',), ('care',), ('professionals',), ('that',), ('these',), ('systems',), ('might',), ('not',), ('be',), ('designed',), ('in',), ('the',), ('publics',), ('interest',), ('but',), ('as',), ('incomegenerating',), ('machines',), ('This',), ('is',), ('especially',), ('true',), ('in',), ('the',), ('United',), ('States',), ('where',), ('there',), ('is',), ('a',), ('longstanding',), ('ethical',), ('dilemma',), ('of',), ('improving',), ('health',), ('care',), ('but',), ('also',), ('increasing',), ('profits',), ('For',), ('example',), ('the',), ('algorithms',), ('could',), ('be',), ('designed',), ('to',), ('provide',), ('patients',), ('with',), ('unnecessary',), ('tests',), ('or',), ('medication',), ('in',), ('which',), ('the',), ('algorithms',), ('proprietary',), ('owners',), ('hold',), ('stakes',), ('There',), ('is',), ('potential',), ('for',), ('machine',), ('learning',), ('in',), ('health',), ('care',), ('to',), ('provide',), ('professionals',), ('an',), ('additional',), ('tool',), ('to',), ('diagnose',), ('medicate',), ('and',), ('plan',), ('recovery',), ('paths',), ('for',), ('patients',), ('but',), ('this',), ('requires',), ('these',), ('biases',), ('to',), ('be',), ('mitigated',)]\n",
      "\n",
      "Bigrams: [('There', 'are'), ('are', 'concerns'), ('concerns', 'among'), ('among', 'health'), ('health', 'care'), ('care', 'professionals'), ('professionals', 'that'), ('that', 'these'), ('these', 'systems'), ('systems', 'might'), ('might', 'not'), ('not', 'be'), ('be', 'designed'), ('designed', 'in'), ('in', 'the'), ('the', 'publics'), ('publics', 'interest'), ('interest', 'but'), ('but', 'as'), ('as', 'incomegenerating'), ('incomegenerating', 'machines'), ('machines', 'This'), ('This', 'is'), ('is', 'especially'), ('especially', 'true'), ('true', 'in'), ('in', 'the'), ('the', 'United'), ('United', 'States'), ('States', 'where'), ('where', 'there'), ('there', 'is'), ('is', 'a'), ('a', 'longstanding'), ('longstanding', 'ethical'), ('ethical', 'dilemma'), ('dilemma', 'of'), ('of', 'improving'), ('improving', 'health'), ('health', 'care'), ('care', 'but'), ('but', 'also'), ('also', 'increasing'), ('increasing', 'profits'), ('profits', 'For'), ('For', 'example'), ('example', 'the'), ('the', 'algorithms'), ('algorithms', 'could'), ('could', 'be'), ('be', 'designed'), ('designed', 'to'), ('to', 'provide'), ('provide', 'patients'), ('patients', 'with'), ('with', 'unnecessary'), ('unnecessary', 'tests'), ('tests', 'or'), ('or', 'medication'), ('medication', 'in'), ('in', 'which'), ('which', 'the'), ('the', 'algorithms'), ('algorithms', 'proprietary'), ('proprietary', 'owners'), ('owners', 'hold'), ('hold', 'stakes'), ('stakes', 'There'), ('There', 'is'), ('is', 'potential'), ('potential', 'for'), ('for', 'machine'), ('machine', 'learning'), ('learning', 'in'), ('in', 'health'), ('health', 'care'), ('care', 'to'), ('to', 'provide'), ('provide', 'professionals'), ('professionals', 'an'), ('an', 'additional'), ('additional', 'tool'), ('tool', 'to'), ('to', 'diagnose'), ('diagnose', 'medicate'), ('medicate', 'and'), ('and', 'plan'), ('plan', 'recovery'), ('recovery', 'paths'), ('paths', 'for'), ('for', 'patients'), ('patients', 'but'), ('but', 'this'), ('this', 'requires'), ('requires', 'these'), ('these', 'biases'), ('biases', 'to'), ('to', 'be'), ('be', 'mitigated')]\n",
      "\n",
      "Trigrams: [('There', 'are', 'concerns'), ('are', 'concerns', 'among'), ('concerns', 'among', 'health'), ('among', 'health', 'care'), ('health', 'care', 'professionals'), ('care', 'professionals', 'that'), ('professionals', 'that', 'these'), ('that', 'these', 'systems'), ('these', 'systems', 'might'), ('systems', 'might', 'not'), ('might', 'not', 'be'), ('not', 'be', 'designed'), ('be', 'designed', 'in'), ('designed', 'in', 'the'), ('in', 'the', 'publics'), ('the', 'publics', 'interest'), ('publics', 'interest', 'but'), ('interest', 'but', 'as'), ('but', 'as', 'incomegenerating'), ('as', 'incomegenerating', 'machines'), ('incomegenerating', 'machines', 'This'), ('machines', 'This', 'is'), ('This', 'is', 'especially'), ('is', 'especially', 'true'), ('especially', 'true', 'in'), ('true', 'in', 'the'), ('in', 'the', 'United'), ('the', 'United', 'States'), ('United', 'States', 'where'), ('States', 'where', 'there'), ('where', 'there', 'is'), ('there', 'is', 'a'), ('is', 'a', 'longstanding'), ('a', 'longstanding', 'ethical'), ('longstanding', 'ethical', 'dilemma'), ('ethical', 'dilemma', 'of'), ('dilemma', 'of', 'improving'), ('of', 'improving', 'health'), ('improving', 'health', 'care'), ('health', 'care', 'but'), ('care', 'but', 'also'), ('but', 'also', 'increasing'), ('also', 'increasing', 'profits'), ('increasing', 'profits', 'For'), ('profits', 'For', 'example'), ('For', 'example', 'the'), ('example', 'the', 'algorithms'), ('the', 'algorithms', 'could'), ('algorithms', 'could', 'be'), ('could', 'be', 'designed'), ('be', 'designed', 'to'), ('designed', 'to', 'provide'), ('to', 'provide', 'patients'), ('provide', 'patients', 'with'), ('patients', 'with', 'unnecessary'), ('with', 'unnecessary', 'tests'), ('unnecessary', 'tests', 'or'), ('tests', 'or', 'medication'), ('or', 'medication', 'in'), ('medication', 'in', 'which'), ('in', 'which', 'the'), ('which', 'the', 'algorithms'), ('the', 'algorithms', 'proprietary'), ('algorithms', 'proprietary', 'owners'), ('proprietary', 'owners', 'hold'), ('owners', 'hold', 'stakes'), ('hold', 'stakes', 'There'), ('stakes', 'There', 'is'), ('There', 'is', 'potential'), ('is', 'potential', 'for'), ('potential', 'for', 'machine'), ('for', 'machine', 'learning'), ('machine', 'learning', 'in'), ('learning', 'in', 'health'), ('in', 'health', 'care'), ('health', 'care', 'to'), ('care', 'to', 'provide'), ('to', 'provide', 'professionals'), ('provide', 'professionals', 'an'), ('professionals', 'an', 'additional'), ('an', 'additional', 'tool'), ('additional', 'tool', 'to'), ('tool', 'to', 'diagnose'), ('to', 'diagnose', 'medicate'), ('diagnose', 'medicate', 'and'), ('medicate', 'and', 'plan'), ('and', 'plan', 'recovery'), ('plan', 'recovery', 'paths'), ('recovery', 'paths', 'for'), ('paths', 'for', 'patients'), ('for', 'patients', 'but'), ('patients', 'but', 'this'), ('but', 'this', 'requires'), ('this', 'requires', 'these'), ('requires', 'these', 'biases'), ('these', 'biases', 'to'), ('biases', 'to', 'be'), ('to', 'be', 'mitigated')]\n",
      "\n",
      "Document: Since the s advances in both machine learning algorithms and computer hardware have led to more efficient methods for training deep neural networks a particular narrow subdomain of machine learning that contain many layers of nonlinear hidden units By  graphics processing units GPUs often with AIspecific enhancements had displaced CPUs as the dominant method of training largescale commercial cloud AI OpenAI estimated the hardware compute used in the largest deep learning projects from AlexNet  to AlphaZero  and found a fold increase in the amount of compute required with a doublingtime trendline of  months\n",
      "\n",
      "\n",
      "Unigrams: [('Since',), ('the',), ('s',), ('advances',), ('in',), ('both',), ('machine',), ('learning',), ('algorithms',), ('and',), ('computer',), ('hardware',), ('have',), ('led',), ('to',), ('more',), ('efficient',), ('methods',), ('for',), ('training',), ('deep',), ('neural',), ('networks',), ('a',), ('particular',), ('narrow',), ('subdomain',), ('of',), ('machine',), ('learning',), ('that',), ('contain',), ('many',), ('layers',), ('of',), ('nonlinear',), ('hidden',), ('units',), ('By',), ('graphics',), ('processing',), ('units',), ('GPUs',), ('often',), ('with',), ('AIspecific',), ('enhancements',), ('had',), ('displaced',), ('CPUs',), ('as',), ('the',), ('dominant',), ('method',), ('of',), ('training',), ('largescale',), ('commercial',), ('cloud',), ('AI',), ('OpenAI',), ('estimated',), ('the',), ('hardware',), ('compute',), ('used',), ('in',), ('the',), ('largest',), ('deep',), ('learning',), ('projects',), ('from',), ('AlexNet',), ('to',), ('AlphaZero',), ('and',), ('found',), ('a',), ('fold',), ('increase',), ('in',), ('the',), ('amount',), ('of',), ('compute',), ('required',), ('with',), ('a',), ('doublingtime',), ('trendline',), ('of',), ('months',)]\n",
      "\n",
      "Bigrams: [('Since', 'the'), ('the', 's'), ('s', 'advances'), ('advances', 'in'), ('in', 'both'), ('both', 'machine'), ('machine', 'learning'), ('learning', 'algorithms'), ('algorithms', 'and'), ('and', 'computer'), ('computer', 'hardware'), ('hardware', 'have'), ('have', 'led'), ('led', 'to'), ('to', 'more'), ('more', 'efficient'), ('efficient', 'methods'), ('methods', 'for'), ('for', 'training'), ('training', 'deep'), ('deep', 'neural'), ('neural', 'networks'), ('networks', 'a'), ('a', 'particular'), ('particular', 'narrow'), ('narrow', 'subdomain'), ('subdomain', 'of'), ('of', 'machine'), ('machine', 'learning'), ('learning', 'that'), ('that', 'contain'), ('contain', 'many'), ('many', 'layers'), ('layers', 'of'), ('of', 'nonlinear'), ('nonlinear', 'hidden'), ('hidden', 'units'), ('units', 'By'), ('By', 'graphics'), ('graphics', 'processing'), ('processing', 'units'), ('units', 'GPUs'), ('GPUs', 'often'), ('often', 'with'), ('with', 'AIspecific'), ('AIspecific', 'enhancements'), ('enhancements', 'had'), ('had', 'displaced'), ('displaced', 'CPUs'), ('CPUs', 'as'), ('as', 'the'), ('the', 'dominant'), ('dominant', 'method'), ('method', 'of'), ('of', 'training'), ('training', 'largescale'), ('largescale', 'commercial'), ('commercial', 'cloud'), ('cloud', 'AI'), ('AI', 'OpenAI'), ('OpenAI', 'estimated'), ('estimated', 'the'), ('the', 'hardware'), ('hardware', 'compute'), ('compute', 'used'), ('used', 'in'), ('in', 'the'), ('the', 'largest'), ('largest', 'deep'), ('deep', 'learning'), ('learning', 'projects'), ('projects', 'from'), ('from', 'AlexNet'), ('AlexNet', 'to'), ('to', 'AlphaZero'), ('AlphaZero', 'and'), ('and', 'found'), ('found', 'a'), ('a', 'fold'), ('fold', 'increase'), ('increase', 'in'), ('in', 'the'), ('the', 'amount'), ('amount', 'of'), ('of', 'compute'), ('compute', 'required'), ('required', 'with'), ('with', 'a'), ('a', 'doublingtime'), ('doublingtime', 'trendline'), ('trendline', 'of'), ('of', 'months')]\n",
      "\n",
      "Trigrams: [('Since', 'the', 's'), ('the', 's', 'advances'), ('s', 'advances', 'in'), ('advances', 'in', 'both'), ('in', 'both', 'machine'), ('both', 'machine', 'learning'), ('machine', 'learning', 'algorithms'), ('learning', 'algorithms', 'and'), ('algorithms', 'and', 'computer'), ('and', 'computer', 'hardware'), ('computer', 'hardware', 'have'), ('hardware', 'have', 'led'), ('have', 'led', 'to'), ('led', 'to', 'more'), ('to', 'more', 'efficient'), ('more', 'efficient', 'methods'), ('efficient', 'methods', 'for'), ('methods', 'for', 'training'), ('for', 'training', 'deep'), ('training', 'deep', 'neural'), ('deep', 'neural', 'networks'), ('neural', 'networks', 'a'), ('networks', 'a', 'particular'), ('a', 'particular', 'narrow'), ('particular', 'narrow', 'subdomain'), ('narrow', 'subdomain', 'of'), ('subdomain', 'of', 'machine'), ('of', 'machine', 'learning'), ('machine', 'learning', 'that'), ('learning', 'that', 'contain'), ('that', 'contain', 'many'), ('contain', 'many', 'layers'), ('many', 'layers', 'of'), ('layers', 'of', 'nonlinear'), ('of', 'nonlinear', 'hidden'), ('nonlinear', 'hidden', 'units'), ('hidden', 'units', 'By'), ('units', 'By', 'graphics'), ('By', 'graphics', 'processing'), ('graphics', 'processing', 'units'), ('processing', 'units', 'GPUs'), ('units', 'GPUs', 'often'), ('GPUs', 'often', 'with'), ('often', 'with', 'AIspecific'), ('with', 'AIspecific', 'enhancements'), ('AIspecific', 'enhancements', 'had'), ('enhancements', 'had', 'displaced'), ('had', 'displaced', 'CPUs'), ('displaced', 'CPUs', 'as'), ('CPUs', 'as', 'the'), ('as', 'the', 'dominant'), ('the', 'dominant', 'method'), ('dominant', 'method', 'of'), ('method', 'of', 'training'), ('of', 'training', 'largescale'), ('training', 'largescale', 'commercial'), ('largescale', 'commercial', 'cloud'), ('commercial', 'cloud', 'AI'), ('cloud', 'AI', 'OpenAI'), ('AI', 'OpenAI', 'estimated'), ('OpenAI', 'estimated', 'the'), ('estimated', 'the', 'hardware'), ('the', 'hardware', 'compute'), ('hardware', 'compute', 'used'), ('compute', 'used', 'in'), ('used', 'in', 'the'), ('in', 'the', 'largest'), ('the', 'largest', 'deep'), ('largest', 'deep', 'learning'), ('deep', 'learning', 'projects'), ('learning', 'projects', 'from'), ('projects', 'from', 'AlexNet'), ('from', 'AlexNet', 'to'), ('AlexNet', 'to', 'AlphaZero'), ('to', 'AlphaZero', 'and'), ('AlphaZero', 'and', 'found'), ('and', 'found', 'a'), ('found', 'a', 'fold'), ('a', 'fold', 'increase'), ('fold', 'increase', 'in'), ('increase', 'in', 'the'), ('in', 'the', 'amount'), ('the', 'amount', 'of'), ('amount', 'of', 'compute'), ('of', 'compute', 'required'), ('compute', 'required', 'with'), ('required', 'with', 'a'), ('with', 'a', 'doublingtime'), ('a', 'doublingtime', 'trendline'), ('doublingtime', 'trendline', 'of'), ('trendline', 'of', 'months')]\n",
      "\n",
      "Document: Tensor Processing Units TPUs are specialised hardware accelerators developed by Google specifically for machine learning workloads Unlike generalpurpose GPUs and FPGAs TPUs are optimised for tensor computations making them particularly efficient for deep learning tasks such as training and inference They are widely used in Google Cloud AI services and largescale machine learning models like Googles DeepMind AlphaFold and large language models TPUs leverage matrix multiplication units and highbandwidth memory to accelerate computations while maintaining energy efficiency Since their introduction in  TPUs have become a key component of AI infrastructure especially in cloudbased environments\n",
      "\n",
      "\n",
      "Unigrams: [('Tensor',), ('Processing',), ('Units',), ('TPUs',), ('are',), ('specialised',), ('hardware',), ('accelerators',), ('developed',), ('by',), ('Google',), ('specifically',), ('for',), ('machine',), ('learning',), ('workloads',), ('Unlike',), ('generalpurpose',), ('GPUs',), ('and',), ('FPGAs',), ('TPUs',), ('are',), ('optimised',), ('for',), ('tensor',), ('computations',), ('making',), ('them',), ('particularly',), ('efficient',), ('for',), ('deep',), ('learning',), ('tasks',), ('such',), ('as',), ('training',), ('and',), ('inference',), ('They',), ('are',), ('widely',), ('used',), ('in',), ('Google',), ('Cloud',), ('AI',), ('services',), ('and',), ('largescale',), ('machine',), ('learning',), ('models',), ('like',), ('Googles',), ('DeepMind',), ('AlphaFold',), ('and',), ('large',), ('language',), ('models',), ('TPUs',), ('leverage',), ('matrix',), ('multiplication',), ('units',), ('and',), ('highbandwidth',), ('memory',), ('to',), ('accelerate',), ('computations',), ('while',), ('maintaining',), ('energy',), ('efficiency',), ('Since',), ('their',), ('introduction',), ('in',), ('TPUs',), ('have',), ('become',), ('a',), ('key',), ('component',), ('of',), ('AI',), ('infrastructure',), ('especially',), ('in',), ('cloudbased',), ('environments',)]\n",
      "\n",
      "Bigrams: [('Tensor', 'Processing'), ('Processing', 'Units'), ('Units', 'TPUs'), ('TPUs', 'are'), ('are', 'specialised'), ('specialised', 'hardware'), ('hardware', 'accelerators'), ('accelerators', 'developed'), ('developed', 'by'), ('by', 'Google'), ('Google', 'specifically'), ('specifically', 'for'), ('for', 'machine'), ('machine', 'learning'), ('learning', 'workloads'), ('workloads', 'Unlike'), ('Unlike', 'generalpurpose'), ('generalpurpose', 'GPUs'), ('GPUs', 'and'), ('and', 'FPGAs'), ('FPGAs', 'TPUs'), ('TPUs', 'are'), ('are', 'optimised'), ('optimised', 'for'), ('for', 'tensor'), ('tensor', 'computations'), ('computations', 'making'), ('making', 'them'), ('them', 'particularly'), ('particularly', 'efficient'), ('efficient', 'for'), ('for', 'deep'), ('deep', 'learning'), ('learning', 'tasks'), ('tasks', 'such'), ('such', 'as'), ('as', 'training'), ('training', 'and'), ('and', 'inference'), ('inference', 'They'), ('They', 'are'), ('are', 'widely'), ('widely', 'used'), ('used', 'in'), ('in', 'Google'), ('Google', 'Cloud'), ('Cloud', 'AI'), ('AI', 'services'), ('services', 'and'), ('and', 'largescale'), ('largescale', 'machine'), ('machine', 'learning'), ('learning', 'models'), ('models', 'like'), ('like', 'Googles'), ('Googles', 'DeepMind'), ('DeepMind', 'AlphaFold'), ('AlphaFold', 'and'), ('and', 'large'), ('large', 'language'), ('language', 'models'), ('models', 'TPUs'), ('TPUs', 'leverage'), ('leverage', 'matrix'), ('matrix', 'multiplication'), ('multiplication', 'units'), ('units', 'and'), ('and', 'highbandwidth'), ('highbandwidth', 'memory'), ('memory', 'to'), ('to', 'accelerate'), ('accelerate', 'computations'), ('computations', 'while'), ('while', 'maintaining'), ('maintaining', 'energy'), ('energy', 'efficiency'), ('efficiency', 'Since'), ('Since', 'their'), ('their', 'introduction'), ('introduction', 'in'), ('in', 'TPUs'), ('TPUs', 'have'), ('have', 'become'), ('become', 'a'), ('a', 'key'), ('key', 'component'), ('component', 'of'), ('of', 'AI'), ('AI', 'infrastructure'), ('infrastructure', 'especially'), ('especially', 'in'), ('in', 'cloudbased'), ('cloudbased', 'environments')]\n",
      "\n",
      "Trigrams: [('Tensor', 'Processing', 'Units'), ('Processing', 'Units', 'TPUs'), ('Units', 'TPUs', 'are'), ('TPUs', 'are', 'specialised'), ('are', 'specialised', 'hardware'), ('specialised', 'hardware', 'accelerators'), ('hardware', 'accelerators', 'developed'), ('accelerators', 'developed', 'by'), ('developed', 'by', 'Google'), ('by', 'Google', 'specifically'), ('Google', 'specifically', 'for'), ('specifically', 'for', 'machine'), ('for', 'machine', 'learning'), ('machine', 'learning', 'workloads'), ('learning', 'workloads', 'Unlike'), ('workloads', 'Unlike', 'generalpurpose'), ('Unlike', 'generalpurpose', 'GPUs'), ('generalpurpose', 'GPUs', 'and'), ('GPUs', 'and', 'FPGAs'), ('and', 'FPGAs', 'TPUs'), ('FPGAs', 'TPUs', 'are'), ('TPUs', 'are', 'optimised'), ('are', 'optimised', 'for'), ('optimised', 'for', 'tensor'), ('for', 'tensor', 'computations'), ('tensor', 'computations', 'making'), ('computations', 'making', 'them'), ('making', 'them', 'particularly'), ('them', 'particularly', 'efficient'), ('particularly', 'efficient', 'for'), ('efficient', 'for', 'deep'), ('for', 'deep', 'learning'), ('deep', 'learning', 'tasks'), ('learning', 'tasks', 'such'), ('tasks', 'such', 'as'), ('such', 'as', 'training'), ('as', 'training', 'and'), ('training', 'and', 'inference'), ('and', 'inference', 'They'), ('inference', 'They', 'are'), ('They', 'are', 'widely'), ('are', 'widely', 'used'), ('widely', 'used', 'in'), ('used', 'in', 'Google'), ('in', 'Google', 'Cloud'), ('Google', 'Cloud', 'AI'), ('Cloud', 'AI', 'services'), ('AI', 'services', 'and'), ('services', 'and', 'largescale'), ('and', 'largescale', 'machine'), ('largescale', 'machine', 'learning'), ('machine', 'learning', 'models'), ('learning', 'models', 'like'), ('models', 'like', 'Googles'), ('like', 'Googles', 'DeepMind'), ('Googles', 'DeepMind', 'AlphaFold'), ('DeepMind', 'AlphaFold', 'and'), ('AlphaFold', 'and', 'large'), ('and', 'large', 'language'), ('large', 'language', 'models'), ('language', 'models', 'TPUs'), ('models', 'TPUs', 'leverage'), ('TPUs', 'leverage', 'matrix'), ('leverage', 'matrix', 'multiplication'), ('matrix', 'multiplication', 'units'), ('multiplication', 'units', 'and'), ('units', 'and', 'highbandwidth'), ('and', 'highbandwidth', 'memory'), ('highbandwidth', 'memory', 'to'), ('memory', 'to', 'accelerate'), ('to', 'accelerate', 'computations'), ('accelerate', 'computations', 'while'), ('computations', 'while', 'maintaining'), ('while', 'maintaining', 'energy'), ('maintaining', 'energy', 'efficiency'), ('energy', 'efficiency', 'Since'), ('efficiency', 'Since', 'their'), ('Since', 'their', 'introduction'), ('their', 'introduction', 'in'), ('introduction', 'in', 'TPUs'), ('in', 'TPUs', 'have'), ('TPUs', 'have', 'become'), ('have', 'become', 'a'), ('become', 'a', 'key'), ('a', 'key', 'component'), ('key', 'component', 'of'), ('component', 'of', 'AI'), ('of', 'AI', 'infrastructure'), ('AI', 'infrastructure', 'especially'), ('infrastructure', 'especially', 'in'), ('especially', 'in', 'cloudbased'), ('in', 'cloudbased', 'environments')]\n",
      "\n",
      "Document: Neuromorphic computing refers to a class of computing systems designed to emulate the structure and functionality of biological neural networks These systems may be implemented through softwarebased simulations on conventional hardware or through specialised hardware architectures\n",
      "\n",
      "\n",
      "Unigrams: [('Neuromorphic',), ('computing',), ('refers',), ('to',), ('a',), ('class',), ('of',), ('computing',), ('systems',), ('designed',), ('to',), ('emulate',), ('the',), ('structure',), ('and',), ('functionality',), ('of',), ('biological',), ('neural',), ('networks',), ('These',), ('systems',), ('may',), ('be',), ('implemented',), ('through',), ('softwarebased',), ('simulations',), ('on',), ('conventional',), ('hardware',), ('or',), ('through',), ('specialised',), ('hardware',), ('architectures',)]\n",
      "\n",
      "Bigrams: [('Neuromorphic', 'computing'), ('computing', 'refers'), ('refers', 'to'), ('to', 'a'), ('a', 'class'), ('class', 'of'), ('of', 'computing'), ('computing', 'systems'), ('systems', 'designed'), ('designed', 'to'), ('to', 'emulate'), ('emulate', 'the'), ('the', 'structure'), ('structure', 'and'), ('and', 'functionality'), ('functionality', 'of'), ('of', 'biological'), ('biological', 'neural'), ('neural', 'networks'), ('networks', 'These'), ('These', 'systems'), ('systems', 'may'), ('may', 'be'), ('be', 'implemented'), ('implemented', 'through'), ('through', 'softwarebased'), ('softwarebased', 'simulations'), ('simulations', 'on'), ('on', 'conventional'), ('conventional', 'hardware'), ('hardware', 'or'), ('or', 'through'), ('through', 'specialised'), ('specialised', 'hardware'), ('hardware', 'architectures')]\n",
      "\n",
      "Trigrams: [('Neuromorphic', 'computing', 'refers'), ('computing', 'refers', 'to'), ('refers', 'to', 'a'), ('to', 'a', 'class'), ('a', 'class', 'of'), ('class', 'of', 'computing'), ('of', 'computing', 'systems'), ('computing', 'systems', 'designed'), ('systems', 'designed', 'to'), ('designed', 'to', 'emulate'), ('to', 'emulate', 'the'), ('emulate', 'the', 'structure'), ('the', 'structure', 'and'), ('structure', 'and', 'functionality'), ('and', 'functionality', 'of'), ('functionality', 'of', 'biological'), ('of', 'biological', 'neural'), ('biological', 'neural', 'networks'), ('neural', 'networks', 'These'), ('networks', 'These', 'systems'), ('These', 'systems', 'may'), ('systems', 'may', 'be'), ('may', 'be', 'implemented'), ('be', 'implemented', 'through'), ('implemented', 'through', 'softwarebased'), ('through', 'softwarebased', 'simulations'), ('softwarebased', 'simulations', 'on'), ('simulations', 'on', 'conventional'), ('on', 'conventional', 'hardware'), ('conventional', 'hardware', 'or'), ('hardware', 'or', 'through'), ('or', 'through', 'specialised'), ('through', 'specialised', 'hardware'), ('specialised', 'hardware', 'architectures')]\n",
      "\n",
      "Document: A physical neural network is a specific type of neuromorphic hardware that relies on electrically adjustable materials such as memristors to emulate the function of neural synapses The term physical neural network highlights the use of physical hardware for computation as opposed to softwarebased implementations It broadly refers to artificial neural networks that use materials with adjustable resistance to replicate neural synapses\n",
      "\n",
      "\n",
      "Unigrams: [('A',), ('physical',), ('neural',), ('network',), ('is',), ('a',), ('specific',), ('type',), ('of',), ('neuromorphic',), ('hardware',), ('that',), ('relies',), ('on',), ('electrically',), ('adjustable',), ('materials',), ('such',), ('as',), ('memristors',), ('to',), ('emulate',), ('the',), ('function',), ('of',), ('neural',), ('synapses',), ('The',), ('term',), ('physical',), ('neural',), ('network',), ('highlights',), ('the',), ('use',), ('of',), ('physical',), ('hardware',), ('for',), ('computation',), ('as',), ('opposed',), ('to',), ('softwarebased',), ('implementations',), ('It',), ('broadly',), ('refers',), ('to',), ('artificial',), ('neural',), ('networks',), ('that',), ('use',), ('materials',), ('with',), ('adjustable',), ('resistance',), ('to',), ('replicate',), ('neural',), ('synapses',)]\n",
      "\n",
      "Bigrams: [('A', 'physical'), ('physical', 'neural'), ('neural', 'network'), ('network', 'is'), ('is', 'a'), ('a', 'specific'), ('specific', 'type'), ('type', 'of'), ('of', 'neuromorphic'), ('neuromorphic', 'hardware'), ('hardware', 'that'), ('that', 'relies'), ('relies', 'on'), ('on', 'electrically'), ('electrically', 'adjustable'), ('adjustable', 'materials'), ('materials', 'such'), ('such', 'as'), ('as', 'memristors'), ('memristors', 'to'), ('to', 'emulate'), ('emulate', 'the'), ('the', 'function'), ('function', 'of'), ('of', 'neural'), ('neural', 'synapses'), ('synapses', 'The'), ('The', 'term'), ('term', 'physical'), ('physical', 'neural'), ('neural', 'network'), ('network', 'highlights'), ('highlights', 'the'), ('the', 'use'), ('use', 'of'), ('of', 'physical'), ('physical', 'hardware'), ('hardware', 'for'), ('for', 'computation'), ('computation', 'as'), ('as', 'opposed'), ('opposed', 'to'), ('to', 'softwarebased'), ('softwarebased', 'implementations'), ('implementations', 'It'), ('It', 'broadly'), ('broadly', 'refers'), ('refers', 'to'), ('to', 'artificial'), ('artificial', 'neural'), ('neural', 'networks'), ('networks', 'that'), ('that', 'use'), ('use', 'materials'), ('materials', 'with'), ('with', 'adjustable'), ('adjustable', 'resistance'), ('resistance', 'to'), ('to', 'replicate'), ('replicate', 'neural'), ('neural', 'synapses')]\n",
      "\n",
      "Trigrams: [('A', 'physical', 'neural'), ('physical', 'neural', 'network'), ('neural', 'network', 'is'), ('network', 'is', 'a'), ('is', 'a', 'specific'), ('a', 'specific', 'type'), ('specific', 'type', 'of'), ('type', 'of', 'neuromorphic'), ('of', 'neuromorphic', 'hardware'), ('neuromorphic', 'hardware', 'that'), ('hardware', 'that', 'relies'), ('that', 'relies', 'on'), ('relies', 'on', 'electrically'), ('on', 'electrically', 'adjustable'), ('electrically', 'adjustable', 'materials'), ('adjustable', 'materials', 'such'), ('materials', 'such', 'as'), ('such', 'as', 'memristors'), ('as', 'memristors', 'to'), ('memristors', 'to', 'emulate'), ('to', 'emulate', 'the'), ('emulate', 'the', 'function'), ('the', 'function', 'of'), ('function', 'of', 'neural'), ('of', 'neural', 'synapses'), ('neural', 'synapses', 'The'), ('synapses', 'The', 'term'), ('The', 'term', 'physical'), ('term', 'physical', 'neural'), ('physical', 'neural', 'network'), ('neural', 'network', 'highlights'), ('network', 'highlights', 'the'), ('highlights', 'the', 'use'), ('the', 'use', 'of'), ('use', 'of', 'physical'), ('of', 'physical', 'hardware'), ('physical', 'hardware', 'for'), ('hardware', 'for', 'computation'), ('for', 'computation', 'as'), ('computation', 'as', 'opposed'), ('as', 'opposed', 'to'), ('opposed', 'to', 'softwarebased'), ('to', 'softwarebased', 'implementations'), ('softwarebased', 'implementations', 'It'), ('implementations', 'It', 'broadly'), ('It', 'broadly', 'refers'), ('broadly', 'refers', 'to'), ('refers', 'to', 'artificial'), ('to', 'artificial', 'neural'), ('artificial', 'neural', 'networks'), ('neural', 'networks', 'that'), ('networks', 'that', 'use'), ('that', 'use', 'materials'), ('use', 'materials', 'with'), ('materials', 'with', 'adjustable'), ('with', 'adjustable', 'resistance'), ('adjustable', 'resistance', 'to'), ('resistance', 'to', 'replicate'), ('to', 'replicate', 'neural'), ('replicate', 'neural', 'synapses')]\n",
      "\n",
      "Document: Embedded machine learning is a subfield of machine learning where models are deployed on embedded systems with limited computing resources such as wearable computers edge devices and microcontrollers Running models directly on these devices eliminates the need to transfer and store data on cloud servers for further processing thereby reducing the risk of data breaches privacy leaks and theft of intellectual property personal data and business secrets Embedded machine learning can be achieved through various techniques such as hardware acceleration approximate computing and model optimisation Common optimisation techniques include pruning quantisation knowledge distillation lowrank factorisation network architecture search and parameter sharing\n",
      "\n",
      "\n",
      "Unigrams: [('Embedded',), ('machine',), ('learning',), ('is',), ('a',), ('subfield',), ('of',), ('machine',), ('learning',), ('where',), ('models',), ('are',), ('deployed',), ('on',), ('embedded',), ('systems',), ('with',), ('limited',), ('computing',), ('resources',), ('such',), ('as',), ('wearable',), ('computers',), ('edge',), ('devices',), ('and',), ('microcontrollers',), ('Running',), ('models',), ('directly',), ('on',), ('these',), ('devices',), ('eliminates',), ('the',), ('need',), ('to',), ('transfer',), ('and',), ('store',), ('data',), ('on',), ('cloud',), ('servers',), ('for',), ('further',), ('processing',), ('thereby',), ('reducing',), ('the',), ('risk',), ('of',), ('data',), ('breaches',), ('privacy',), ('leaks',), ('and',), ('theft',), ('of',), ('intellectual',), ('property',), ('personal',), ('data',), ('and',), ('business',), ('secrets',), ('Embedded',), ('machine',), ('learning',), ('can',), ('be',), ('achieved',), ('through',), ('various',), ('techniques',), ('such',), ('as',), ('hardware',), ('acceleration',), ('approximate',), ('computing',), ('and',), ('model',), ('optimisation',), ('Common',), ('optimisation',), ('techniques',), ('include',), ('pruning',), ('quantisation',), ('knowledge',), ('distillation',), ('lowrank',), ('factorisation',), ('network',), ('architecture',), ('search',), ('and',), ('parameter',), ('sharing',)]\n",
      "\n",
      "Bigrams: [('Embedded', 'machine'), ('machine', 'learning'), ('learning', 'is'), ('is', 'a'), ('a', 'subfield'), ('subfield', 'of'), ('of', 'machine'), ('machine', 'learning'), ('learning', 'where'), ('where', 'models'), ('models', 'are'), ('are', 'deployed'), ('deployed', 'on'), ('on', 'embedded'), ('embedded', 'systems'), ('systems', 'with'), ('with', 'limited'), ('limited', 'computing'), ('computing', 'resources'), ('resources', 'such'), ('such', 'as'), ('as', 'wearable'), ('wearable', 'computers'), ('computers', 'edge'), ('edge', 'devices'), ('devices', 'and'), ('and', 'microcontrollers'), ('microcontrollers', 'Running'), ('Running', 'models'), ('models', 'directly'), ('directly', 'on'), ('on', 'these'), ('these', 'devices'), ('devices', 'eliminates'), ('eliminates', 'the'), ('the', 'need'), ('need', 'to'), ('to', 'transfer'), ('transfer', 'and'), ('and', 'store'), ('store', 'data'), ('data', 'on'), ('on', 'cloud'), ('cloud', 'servers'), ('servers', 'for'), ('for', 'further'), ('further', 'processing'), ('processing', 'thereby'), ('thereby', 'reducing'), ('reducing', 'the'), ('the', 'risk'), ('risk', 'of'), ('of', 'data'), ('data', 'breaches'), ('breaches', 'privacy'), ('privacy', 'leaks'), ('leaks', 'and'), ('and', 'theft'), ('theft', 'of'), ('of', 'intellectual'), ('intellectual', 'property'), ('property', 'personal'), ('personal', 'data'), ('data', 'and'), ('and', 'business'), ('business', 'secrets'), ('secrets', 'Embedded'), ('Embedded', 'machine'), ('machine', 'learning'), ('learning', 'can'), ('can', 'be'), ('be', 'achieved'), ('achieved', 'through'), ('through', 'various'), ('various', 'techniques'), ('techniques', 'such'), ('such', 'as'), ('as', 'hardware'), ('hardware', 'acceleration'), ('acceleration', 'approximate'), ('approximate', 'computing'), ('computing', 'and'), ('and', 'model'), ('model', 'optimisation'), ('optimisation', 'Common'), ('Common', 'optimisation'), ('optimisation', 'techniques'), ('techniques', 'include'), ('include', 'pruning'), ('pruning', 'quantisation'), ('quantisation', 'knowledge'), ('knowledge', 'distillation'), ('distillation', 'lowrank'), ('lowrank', 'factorisation'), ('factorisation', 'network'), ('network', 'architecture'), ('architecture', 'search'), ('search', 'and'), ('and', 'parameter'), ('parameter', 'sharing')]\n",
      "\n",
      "Trigrams: [('Embedded', 'machine', 'learning'), ('machine', 'learning', 'is'), ('learning', 'is', 'a'), ('is', 'a', 'subfield'), ('a', 'subfield', 'of'), ('subfield', 'of', 'machine'), ('of', 'machine', 'learning'), ('machine', 'learning', 'where'), ('learning', 'where', 'models'), ('where', 'models', 'are'), ('models', 'are', 'deployed'), ('are', 'deployed', 'on'), ('deployed', 'on', 'embedded'), ('on', 'embedded', 'systems'), ('embedded', 'systems', 'with'), ('systems', 'with', 'limited'), ('with', 'limited', 'computing'), ('limited', 'computing', 'resources'), ('computing', 'resources', 'such'), ('resources', 'such', 'as'), ('such', 'as', 'wearable'), ('as', 'wearable', 'computers'), ('wearable', 'computers', 'edge'), ('computers', 'edge', 'devices'), ('edge', 'devices', 'and'), ('devices', 'and', 'microcontrollers'), ('and', 'microcontrollers', 'Running'), ('microcontrollers', 'Running', 'models'), ('Running', 'models', 'directly'), ('models', 'directly', 'on'), ('directly', 'on', 'these'), ('on', 'these', 'devices'), ('these', 'devices', 'eliminates'), ('devices', 'eliminates', 'the'), ('eliminates', 'the', 'need'), ('the', 'need', 'to'), ('need', 'to', 'transfer'), ('to', 'transfer', 'and'), ('transfer', 'and', 'store'), ('and', 'store', 'data'), ('store', 'data', 'on'), ('data', 'on', 'cloud'), ('on', 'cloud', 'servers'), ('cloud', 'servers', 'for'), ('servers', 'for', 'further'), ('for', 'further', 'processing'), ('further', 'processing', 'thereby'), ('processing', 'thereby', 'reducing'), ('thereby', 'reducing', 'the'), ('reducing', 'the', 'risk'), ('the', 'risk', 'of'), ('risk', 'of', 'data'), ('of', 'data', 'breaches'), ('data', 'breaches', 'privacy'), ('breaches', 'privacy', 'leaks'), ('privacy', 'leaks', 'and'), ('leaks', 'and', 'theft'), ('and', 'theft', 'of'), ('theft', 'of', 'intellectual'), ('of', 'intellectual', 'property'), ('intellectual', 'property', 'personal'), ('property', 'personal', 'data'), ('personal', 'data', 'and'), ('data', 'and', 'business'), ('and', 'business', 'secrets'), ('business', 'secrets', 'Embedded'), ('secrets', 'Embedded', 'machine'), ('Embedded', 'machine', 'learning'), ('machine', 'learning', 'can'), ('learning', 'can', 'be'), ('can', 'be', 'achieved'), ('be', 'achieved', 'through'), ('achieved', 'through', 'various'), ('through', 'various', 'techniques'), ('various', 'techniques', 'such'), ('techniques', 'such', 'as'), ('such', 'as', 'hardware'), ('as', 'hardware', 'acceleration'), ('hardware', 'acceleration', 'approximate'), ('acceleration', 'approximate', 'computing'), ('approximate', 'computing', 'and'), ('computing', 'and', 'model'), ('and', 'model', 'optimisation'), ('model', 'optimisation', 'Common'), ('optimisation', 'Common', 'optimisation'), ('Common', 'optimisation', 'techniques'), ('optimisation', 'techniques', 'include'), ('techniques', 'include', 'pruning'), ('include', 'pruning', 'quantisation'), ('pruning', 'quantisation', 'knowledge'), ('quantisation', 'knowledge', 'distillation'), ('knowledge', 'distillation', 'lowrank'), ('distillation', 'lowrank', 'factorisation'), ('lowrank', 'factorisation', 'network'), ('factorisation', 'network', 'architecture'), ('network', 'architecture', 'search'), ('architecture', 'search', 'and'), ('search', 'and', 'parameter'), ('and', 'parameter', 'sharing')]\n",
      "\n",
      "Document: Software suites containing a variety of machine learning algorithms include the following\n",
      "\n",
      "\n",
      "Unigrams: [('Software',), ('suites',), ('containing',), ('a',), ('variety',), ('of',), ('machine',), ('learning',), ('algorithms',), ('include',), ('the',), ('following',)]\n",
      "\n",
      "Bigrams: [('Software', 'suites'), ('suites', 'containing'), ('containing', 'a'), ('a', 'variety'), ('variety', 'of'), ('of', 'machine'), ('machine', 'learning'), ('learning', 'algorithms'), ('algorithms', 'include'), ('include', 'the'), ('the', 'following')]\n",
      "\n",
      "Trigrams: [('Software', 'suites', 'containing'), ('suites', 'containing', 'a'), ('containing', 'a', 'variety'), ('a', 'variety', 'of'), ('variety', 'of', 'machine'), ('of', 'machine', 'learning'), ('machine', 'learning', 'algorithms'), ('learning', 'algorithms', 'include'), ('algorithms', 'include', 'the'), ('include', 'the', 'following')]\n",
      "TF-IDF Matrix Numerical: \n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "TF-IDF Matrix Categorical:\n",
      "                abandoned  abandoned by  abandoned by ai  ability  ability of  \\\n",
      "\\nDocument 1          0.0           0.0              0.0      0.0         0.0   \n",
      "\\nDocument 2          0.0           0.0              0.0      0.0         0.0   \n",
      "\\nDocument 3          0.0           0.0              0.0      0.0         0.0   \n",
      "\\nDocument 4          0.0           0.0              0.0      0.0         0.0   \n",
      "\\nDocument 5          0.0           0.0              0.0      0.0         0.0   \n",
      "...                   ...           ...              ...      ...         ...   \n",
      "\\nDocument 109        0.0           0.0              0.0      0.0         0.0   \n",
      "\\nDocument 110        0.0           0.0              0.0      0.0         0.0   \n",
      "\\nDocument 111        0.0           0.0              0.0      0.0         0.0   \n",
      "\\nDocument 112        0.0           0.0              0.0      0.0         0.0   \n",
      "\\nDocument 113        0.0           0.0              0.0      0.0         0.0   \n",
      "\n",
      "                ability of learning  ability to  ability to reproduce  able  \\\n",
      "\\nDocument 1                    0.0         0.0                   0.0   0.0   \n",
      "\\nDocument 2                    0.0         0.0                   0.0   0.0   \n",
      "\\nDocument 3                    0.0         0.0                   0.0   0.0   \n",
      "\\nDocument 4                    0.0         0.0                   0.0   0.0   \n",
      "\\nDocument 5                    0.0         0.0                   0.0   0.0   \n",
      "...                             ...         ...                   ...   ...   \n",
      "\\nDocument 109                  0.0         0.0                   0.0   0.0   \n",
      "\\nDocument 110                  0.0         0.0                   0.0   0.0   \n",
      "\\nDocument 111                  0.0         0.0                   0.0   0.0   \n",
      "\\nDocument 112                  0.0         0.0                   0.0   0.0   \n",
      "\\nDocument 113                  0.0         0.0                   0.0   0.0   \n",
      "\n",
      "                able to  ...  you can  you can not  zeros  zeros multilinear  \\\n",
      "\\nDocument 1        0.0  ...      0.0          0.0    0.0                0.0   \n",
      "\\nDocument 2        0.0  ...      0.0          0.0    0.0                0.0   \n",
      "\\nDocument 3        0.0  ...      0.0          0.0    0.0                0.0   \n",
      "\\nDocument 4        0.0  ...      0.0          0.0    0.0                0.0   \n",
      "\\nDocument 5        0.0  ...      0.0          0.0    0.0                0.0   \n",
      "...                 ...  ...      ...          ...    ...                ...   \n",
      "\\nDocument 109      0.0  ...      0.0          0.0    0.0                0.0   \n",
      "\\nDocument 110      0.0  ...      0.0          0.0    0.0                0.0   \n",
      "\\nDocument 111      0.0  ...      0.0          0.0    0.0                0.0   \n",
      "\\nDocument 112      0.0  ...      0.0          0.0    0.0                0.0   \n",
      "\\nDocument 113      0.0  ...      0.0          0.0    0.0                0.0   \n",
      "\n",
      "                zeros multilinear subspace  zip  zip file  zip file and  \\\n",
      "\\nDocument 1                           0.0  0.0       0.0           0.0   \n",
      "\\nDocument 2                           0.0  0.0       0.0           0.0   \n",
      "\\nDocument 3                           0.0  0.0       0.0           0.0   \n",
      "\\nDocument 4                           0.0  0.0       0.0           0.0   \n",
      "\\nDocument 5                           0.0  0.0       0.0           0.0   \n",
      "...                                    ...  ...       ...           ...   \n",
      "\\nDocument 109                         0.0  0.0       0.0           0.0   \n",
      "\\nDocument 110                         0.0  0.0       0.0           0.0   \n",
      "\\nDocument 111                         0.0  0.0       0.0           0.0   \n",
      "\\nDocument 112                         0.0  0.0       0.0           0.0   \n",
      "\\nDocument 113                         0.0  0.0       0.0           0.0   \n",
      "\n",
      "                zip files  zip files compressed  \n",
      "\\nDocument 1          0.0                   0.0  \n",
      "\\nDocument 2          0.0                   0.0  \n",
      "\\nDocument 3          0.0                   0.0  \n",
      "\\nDocument 4          0.0                   0.0  \n",
      "\\nDocument 5          0.0                   0.0  \n",
      "...                   ...                   ...  \n",
      "\\nDocument 109        0.0                   0.0  \n",
      "\\nDocument 110        0.0                   0.0  \n",
      "\\nDocument 111        0.0                   0.0  \n",
      "\\nDocument 112        0.0                   0.0  \n",
      "\\nDocument 113        0.0                   0.0  \n",
      "\n",
      "[113 rows x 15891 columns]\n"
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "    print(f\"\\nDocument: {doc}\\n\")\n",
    "    print(\"\\nUnigrams:\", generate_ngrams(doc, 1))\n",
    "    print(\"\\nBigrams:\", generate_ngrams(doc, 2))\n",
    "    print(\"\\nTrigrams:\", generate_ngrams(doc, 3))\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,3))  # Includes unigrams, bigrams, and trigrams\n",
    "tfidf_matrix = vectorizer.fit_transform(docs)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "print(\"TF-IDF Matrix Numerical: \")\n",
    "print(tfidf_matrix.toarray())\n",
    "\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), index=[f\"\\nDocument {i+1}\" for i in range(len(docs))], columns=feature_names)\n",
    "\n",
    "print(\"\\nTF-IDF Matrix Categorical:\")\n",
    "print(tfidf_df)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
