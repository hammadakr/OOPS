{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21fc7825",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to C:\\Users\\Fayez\n",
      "[nltk_data]     Siddiqui\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('words')\n",
    "from nltk.corpus import words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "631b41a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximum_matching(input_str):\n",
    "    input_str=input_str.replace(\" \",\"\")\n",
    "    tokens = []\n",
    "    corpus = set(word.lower() for word in words.words())  # Use set for O(1) lookups\n",
    "    n = len(input_str)\n",
    "    i = 0\n",
    "    \n",
    "    while i < n:\n",
    "        max_len = 0\n",
    "        # Find longest match starting at position i (up to remaining length)\n",
    "        for j in range(i+1, min(i+20, n)+1):  # Limit word length to 20 for efficiency\n",
    "            candidate = input_str[i:j].lower()\n",
    "            if candidate in corpus and j-i > max_len:\n",
    "                max_len = j - i\n",
    "                \n",
    "        if max_len > 0:\n",
    "            # Add original case version of the matched word\n",
    "            tokens.append(input_str[i:i+max_len])\n",
    "            i += max_len\n",
    "        else:\n",
    "            # No match found, add single character and move forward\n",
    "            tokens.append(input_str[i])\n",
    "            i += 1\n",
    "            \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9e7626f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "link=\"https://en.wikipedia.org/wiki/Machine_learning\"\n",
    "\n",
    "data=requests.get(link)\n",
    "\n",
    "soup_1 = BeautifulSoup(data.text, \"html.parser\")\n",
    "\n",
    "para=soup_1.find_all(\"p\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba2243a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "string=\"\"\n",
    "for p in para :\n",
    "    string+=p.get_text()\n",
    "uni=list(set(string))\n",
    "special_char=[]\n",
    "for  i in uni :\n",
    "    if not i.isalpha() :\n",
    "        special_char.append(i)\n",
    "special_char.remove(\" \")\n",
    "\n",
    "for i in special_char :\n",
    "    string=string.replace(i,\"\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bac9e7da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Machine',\n",
       " 'learning',\n",
       " 'M',\n",
       " 'Lisa',\n",
       " 'field',\n",
       " 'of',\n",
       " 'study',\n",
       " 'inartificial',\n",
       " 'intelligence',\n",
       " 'concerned',\n",
       " 'with',\n",
       " 'the',\n",
       " 'development',\n",
       " 'and',\n",
       " 'study',\n",
       " 'of',\n",
       " 'statistical',\n",
       " 'algorithm',\n",
       " 'st',\n",
       " 'hat',\n",
       " 'can',\n",
       " 'learn',\n",
       " 'from',\n",
       " 'data',\n",
       " 'and',\n",
       " 'general',\n",
       " 'is',\n",
       " 'e',\n",
       " 'tou',\n",
       " 'n',\n",
       " 'seen',\n",
       " 'data',\n",
       " 'and',\n",
       " 'thus',\n",
       " 'perform',\n",
       " 'task',\n",
       " 'swith',\n",
       " 'out',\n",
       " 'explicit',\n",
       " 'instruction',\n",
       " 'sWithin',\n",
       " 'as',\n",
       " 'u',\n",
       " 'b',\n",
       " 'discipline',\n",
       " 'in',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'advance',\n",
       " 'sin',\n",
       " 'the',\n",
       " 'field',\n",
       " 'of',\n",
       " 'deep',\n",
       " 'learning',\n",
       " 'have',\n",
       " 'allow',\n",
       " 'ed',\n",
       " 'neural',\n",
       " 'network',\n",
       " 'sac',\n",
       " 'lasso',\n",
       " 'f',\n",
       " 'statistical',\n",
       " 'algorithm',\n",
       " 'st',\n",
       " 'os',\n",
       " 'ur',\n",
       " 'passman',\n",
       " 'y',\n",
       " 'previous',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'approach',\n",
       " 'es',\n",
       " 'in',\n",
       " 'performance',\n",
       " 'M',\n",
       " 'L',\n",
       " 'find',\n",
       " 'sap',\n",
       " 'plication',\n",
       " 'in',\n",
       " 'many',\n",
       " 'field',\n",
       " 'sin',\n",
       " 'c',\n",
       " 'lu',\n",
       " 'ding',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'process',\n",
       " 'ing',\n",
       " 'computer',\n",
       " 'vision',\n",
       " 'speech',\n",
       " 'recognition',\n",
       " 'em',\n",
       " 'ail',\n",
       " 'filtering',\n",
       " 'agriculture',\n",
       " 'and',\n",
       " 'medicine',\n",
       " 'Thea',\n",
       " 'p',\n",
       " 'plication',\n",
       " 'of',\n",
       " 'M',\n",
       " 'L',\n",
       " 'to',\n",
       " 'business',\n",
       " 'problem',\n",
       " 'sis',\n",
       " 'known',\n",
       " 'asp',\n",
       " 'red',\n",
       " 'i',\n",
       " 'c',\n",
       " 'ti',\n",
       " 'v',\n",
       " 'ean',\n",
       " 'aly',\n",
       " 'tic',\n",
       " 's',\n",
       " 'Statistics',\n",
       " 'and',\n",
       " 'mathematical',\n",
       " 'opt',\n",
       " 'imi',\n",
       " 'sat',\n",
       " 'ion',\n",
       " 'mathematical',\n",
       " 'program',\n",
       " 'ming',\n",
       " 'method',\n",
       " 's',\n",
       " 'comprise',\n",
       " 'the',\n",
       " 'foundation',\n",
       " 'so',\n",
       " 'f',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'Data',\n",
       " 'mining',\n",
       " 'is',\n",
       " 'are',\n",
       " 'lated',\n",
       " 'field',\n",
       " 'of',\n",
       " 'study',\n",
       " 'focus',\n",
       " 'ing',\n",
       " 'one',\n",
       " 'x',\n",
       " 'ploratory',\n",
       " 'data',\n",
       " 'analysis',\n",
       " 'ED',\n",
       " 'A',\n",
       " 'via',\n",
       " 'unsupervised',\n",
       " 'learning',\n",
       " 'From',\n",
       " 'at',\n",
       " 'he',\n",
       " 'ore',\n",
       " 'tical',\n",
       " 'viewpoint',\n",
       " 'probably',\n",
       " 'approximately',\n",
       " 'correct',\n",
       " 'learning',\n",
       " 'provide',\n",
       " 'sa',\n",
       " 'framework',\n",
       " 'ford',\n",
       " 'es',\n",
       " 'crib',\n",
       " 'ing',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'The',\n",
       " 'term',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'wasco',\n",
       " 'in',\n",
       " 'ed',\n",
       " 'inby',\n",
       " 'Arthur',\n",
       " 'Samuel',\n",
       " 'anI',\n",
       " 'B',\n",
       " 'Mem',\n",
       " 'ploy',\n",
       " 'e',\n",
       " 'ean',\n",
       " 'd',\n",
       " 'pioneer',\n",
       " 'in',\n",
       " 'the',\n",
       " 'field',\n",
       " 'of',\n",
       " 'computer',\n",
       " 'gaming',\n",
       " 'anda',\n",
       " 'r',\n",
       " 'ti',\n",
       " 'fi',\n",
       " 'c',\n",
       " 'i',\n",
       " 'alin',\n",
       " 'tell',\n",
       " 'i',\n",
       " 'gen',\n",
       " 'ce',\n",
       " 'The',\n",
       " 'synonym',\n",
       " 'self',\n",
       " 'teaching',\n",
       " 'computer',\n",
       " 'swa',\n",
       " 'sal',\n",
       " 'souse',\n",
       " 'dint',\n",
       " 'hist',\n",
       " 'i',\n",
       " 'me',\n",
       " 'period',\n",
       " 'Although',\n",
       " 'thee',\n",
       " 'ar',\n",
       " 'lie',\n",
       " 'st',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'model',\n",
       " 'was',\n",
       " 'introduce',\n",
       " 'dint',\n",
       " 'he',\n",
       " 's',\n",
       " 'when',\n",
       " 'Arthur',\n",
       " 'Samuel',\n",
       " 'invent',\n",
       " 'ed',\n",
       " 'a',\n",
       " 'program',\n",
       " 'that',\n",
       " 'calculated',\n",
       " 'thew',\n",
       " 'inning',\n",
       " 'chance',\n",
       " 'inch',\n",
       " 'e',\n",
       " 'c',\n",
       " 'ker',\n",
       " 's',\n",
       " 'fore',\n",
       " 'ach',\n",
       " 'side',\n",
       " 'the',\n",
       " 'history',\n",
       " 'of',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'root',\n",
       " 's',\n",
       " 'back',\n",
       " 'tode',\n",
       " 'cade',\n",
       " 'so',\n",
       " 'f',\n",
       " 'human',\n",
       " 'desire',\n",
       " 'ande',\n",
       " 'f',\n",
       " 'fort',\n",
       " 'tost',\n",
       " 'ud',\n",
       " 'y',\n",
       " 'human',\n",
       " 'cognitive',\n",
       " 'process',\n",
       " 'es',\n",
       " 'InCan',\n",
       " 'ad',\n",
       " 'ian',\n",
       " 'psychologist',\n",
       " 'Donald',\n",
       " 'He',\n",
       " 'b',\n",
       " 'b',\n",
       " 'publish',\n",
       " 'ed',\n",
       " 'theb',\n",
       " 'o',\n",
       " 'ok',\n",
       " 'TheO',\n",
       " 'r',\n",
       " 'gan',\n",
       " 'i',\n",
       " 'zati',\n",
       " 'on',\n",
       " 'of',\n",
       " 'Behavior',\n",
       " 'in',\n",
       " 'which',\n",
       " 'hein',\n",
       " 'trod',\n",
       " 'u',\n",
       " 'ce',\n",
       " 'da',\n",
       " 'theoretical',\n",
       " 'neural',\n",
       " 'structure',\n",
       " 'formed',\n",
       " 'by',\n",
       " 'certain',\n",
       " 'interaction',\n",
       " 'sam',\n",
       " 'on',\n",
       " 'g',\n",
       " 'nerve',\n",
       " 'cell',\n",
       " 'sHe',\n",
       " 'b',\n",
       " 'b',\n",
       " 's',\n",
       " 'model',\n",
       " 'of',\n",
       " 'neuron',\n",
       " 'sinter',\n",
       " 'acting',\n",
       " 'with',\n",
       " 'oneanother',\n",
       " 'seta',\n",
       " 'groundwork',\n",
       " 'forhow',\n",
       " 'AI',\n",
       " 'sand',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'algorithm',\n",
       " 's',\n",
       " 'work',\n",
       " 'undern',\n",
       " 'ode',\n",
       " 'sora',\n",
       " 'r',\n",
       " 'ti',\n",
       " 'fi',\n",
       " 'c',\n",
       " 'i',\n",
       " 'aln',\n",
       " 'eu',\n",
       " 'ron',\n",
       " 'sus',\n",
       " 'ed',\n",
       " 'by',\n",
       " 'computer',\n",
       " 'st',\n",
       " 'o',\n",
       " 'communicate',\n",
       " 'data',\n",
       " 'Other',\n",
       " 'researcher',\n",
       " 's',\n",
       " 'who',\n",
       " 'have',\n",
       " 'studied',\n",
       " 'human',\n",
       " 'cognitive',\n",
       " 'system',\n",
       " 's',\n",
       " 'contribute',\n",
       " 'd',\n",
       " 'tot',\n",
       " 'hem',\n",
       " 'ode',\n",
       " 'r',\n",
       " 'n',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'tech',\n",
       " 'nolo',\n",
       " 'gie',\n",
       " 'sa',\n",
       " 'swell',\n",
       " 'in',\n",
       " 'c',\n",
       " 'lu',\n",
       " 'ding',\n",
       " 'logician',\n",
       " 'Walter',\n",
       " 'Pit',\n",
       " 't',\n",
       " 'sand',\n",
       " 'Warren',\n",
       " 'M',\n",
       " 'c',\n",
       " 'Cull',\n",
       " 'och',\n",
       " 'whop',\n",
       " 'ro',\n",
       " 'pose',\n",
       " 'd',\n",
       " 'thee',\n",
       " 'ar',\n",
       " 'ly',\n",
       " 'mathematical',\n",
       " 'model',\n",
       " 'so',\n",
       " 'f',\n",
       " 'neural',\n",
       " 'network',\n",
       " 'st',\n",
       " 'o',\n",
       " 'come',\n",
       " 'upwith',\n",
       " 'algorithm',\n",
       " 'st',\n",
       " 'hat',\n",
       " 'mirror',\n",
       " 'human',\n",
       " 'thought',\n",
       " 'process',\n",
       " 'es',\n",
       " 'Byth',\n",
       " 'e',\n",
       " 'early',\n",
       " 'sane',\n",
       " 'x',\n",
       " 'peri',\n",
       " 'mental',\n",
       " 'learning',\n",
       " 'machine',\n",
       " 'with',\n",
       " 'punch',\n",
       " 'ed',\n",
       " 'tape',\n",
       " 'memory',\n",
       " 'call',\n",
       " 'ed',\n",
       " 'C',\n",
       " 'y',\n",
       " 'bert',\n",
       " 'ron',\n",
       " 'had',\n",
       " 'been',\n",
       " 'develop',\n",
       " 'ed',\n",
       " 'by',\n",
       " 'Ray',\n",
       " 'theo',\n",
       " 'n',\n",
       " 'Company',\n",
       " 'toa',\n",
       " 'na',\n",
       " 'lyse',\n",
       " 'sonar',\n",
       " 'signal',\n",
       " 'select',\n",
       " 'roc',\n",
       " 'ar',\n",
       " 'di',\n",
       " 'og',\n",
       " 'ram',\n",
       " 'sand',\n",
       " 'speech',\n",
       " 'pattern',\n",
       " 'susi',\n",
       " 'n',\n",
       " 'g',\n",
       " 'rudimentary',\n",
       " 'reinforcement',\n",
       " 'learning',\n",
       " 'It',\n",
       " 'was',\n",
       " 'repetitively',\n",
       " 'trained',\n",
       " 'by',\n",
       " 'ahum',\n",
       " 'an',\n",
       " 'operator',\n",
       " 'teacher',\n",
       " 'tore',\n",
       " 'cog',\n",
       " 'ni',\n",
       " 'se',\n",
       " 'pattern',\n",
       " 'sand',\n",
       " 'equip',\n",
       " 'ped',\n",
       " 'with',\n",
       " 'ago',\n",
       " 'of',\n",
       " 'button',\n",
       " 'to',\n",
       " 'cause',\n",
       " 'it',\n",
       " 'tore',\n",
       " 'evaluate',\n",
       " 'incorrect',\n",
       " 'decision',\n",
       " 'sAre',\n",
       " 'presentative',\n",
       " 'book',\n",
       " 'on',\n",
       " 'research',\n",
       " 'into',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'during',\n",
       " 'the',\n",
       " 'swa',\n",
       " 's',\n",
       " 'Nils',\n",
       " 'sons',\n",
       " 'book',\n",
       " 'on',\n",
       " 'Learning',\n",
       " 'Machine',\n",
       " 's',\n",
       " 'dealing',\n",
       " 'mostly',\n",
       " 'with',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'for',\n",
       " 'pattern',\n",
       " 'classification',\n",
       " 'Interest',\n",
       " 'related',\n",
       " 'top',\n",
       " 'attern',\n",
       " 'recognition',\n",
       " 'continued',\n",
       " 'into',\n",
       " 'the',\n",
       " 'sa',\n",
       " 's',\n",
       " 'describe',\n",
       " 'd',\n",
       " 'by',\n",
       " 'Dud',\n",
       " 'aa',\n",
       " 'n',\n",
       " 'dHa',\n",
       " 'r',\n",
       " 'tin',\n",
       " 'In',\n",
       " 'are',\n",
       " 'port',\n",
       " 'was',\n",
       " 'given',\n",
       " 'onus',\n",
       " 'ing',\n",
       " 'teaching',\n",
       " 'strategi',\n",
       " 'ess',\n",
       " 'o',\n",
       " 'that',\n",
       " 'ana',\n",
       " 'r',\n",
       " 'ti',\n",
       " 'fi',\n",
       " 'c',\n",
       " 'i',\n",
       " 'aln',\n",
       " 'eu',\n",
       " 'ra',\n",
       " 'l',\n",
       " 'network',\n",
       " 'learn',\n",
       " 'store',\n",
       " 'cog',\n",
       " 'ni',\n",
       " 'sech',\n",
       " 'ara',\n",
       " 'c',\n",
       " 'te',\n",
       " 'r',\n",
       " 's',\n",
       " 'letter',\n",
       " 's',\n",
       " 'digit',\n",
       " 'sand',\n",
       " 'special',\n",
       " 'symbol',\n",
       " 's',\n",
       " 'from',\n",
       " 'a',\n",
       " 'computer',\n",
       " 'terminal',\n",
       " 'Tom',\n",
       " 'M',\n",
       " 'Mitchell',\n",
       " 'provided',\n",
       " 'awide',\n",
       " 'ly',\n",
       " 'quote',\n",
       " 'd',\n",
       " 'more',\n",
       " 'formal',\n",
       " 'definition',\n",
       " 'oft',\n",
       " 'heal',\n",
       " 'gor',\n",
       " 'it',\n",
       " 'h',\n",
       " 'm',\n",
       " 's',\n",
       " 'studied',\n",
       " 'in',\n",
       " 'thema',\n",
       " 'chine',\n",
       " 'learning',\n",
       " 'field',\n",
       " 'A',\n",
       " 'computer',\n",
       " 'program',\n",
       " 'is',\n",
       " 'said',\n",
       " 'tole',\n",
       " 'arn',\n",
       " 'from',\n",
       " 'experience',\n",
       " 'E',\n",
       " 'with',\n",
       " 'respect',\n",
       " 'to',\n",
       " 'some',\n",
       " 'class',\n",
       " 'oft',\n",
       " 'ask',\n",
       " 'sTand',\n",
       " 'performance',\n",
       " 'measure',\n",
       " 'Pi',\n",
       " 'fit',\n",
       " 's',\n",
       " 'performance',\n",
       " 'attask',\n",
       " 'sin',\n",
       " 'Ta',\n",
       " 's',\n",
       " 'measured',\n",
       " 'by',\n",
       " 'Pimp',\n",
       " 'rove',\n",
       " 'swithe',\n",
       " 'x',\n",
       " 'peri',\n",
       " 'en',\n",
       " 'ceE',\n",
       " 'This',\n",
       " 'definition',\n",
       " 'oft',\n",
       " 'het',\n",
       " 'ask',\n",
       " 'sin',\n",
       " 'which',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'is',\n",
       " 'concerned',\n",
       " 'offer',\n",
       " 'sa',\n",
       " 'fundamentally',\n",
       " 'operational',\n",
       " 'definition',\n",
       " 'rather',\n",
       " 'than',\n",
       " 'de',\n",
       " 'fining',\n",
       " 'the',\n",
       " 'field',\n",
       " 'incognitive',\n",
       " 'term',\n",
       " 'sT',\n",
       " 'his',\n",
       " 'follow',\n",
       " 'sAl',\n",
       " 'anTu',\n",
       " 'ring',\n",
       " 's',\n",
       " 'proposal',\n",
       " 'in',\n",
       " 'hispa',\n",
       " 'per',\n",
       " 'C',\n",
       " 'om',\n",
       " 'put',\n",
       " 'ing',\n",
       " 'Machinery',\n",
       " 'andI',\n",
       " 'n',\n",
       " 'tell',\n",
       " 'i',\n",
       " 'gen',\n",
       " 'ce',\n",
       " 'in',\n",
       " 'which',\n",
       " 'the',\n",
       " 'question',\n",
       " 'Can',\n",
       " 'machine',\n",
       " 'st',\n",
       " 'hin',\n",
       " 'k',\n",
       " 'is',\n",
       " 'replace',\n",
       " 'd',\n",
       " 'with',\n",
       " 'the',\n",
       " 'question',\n",
       " 'Can',\n",
       " 'machine',\n",
       " 's',\n",
       " 'dow',\n",
       " 'hat',\n",
       " 'wea',\n",
       " 'st',\n",
       " 'hin',\n",
       " 'king',\n",
       " 'en',\n",
       " 'tities',\n",
       " 'cand',\n",
       " 'oM',\n",
       " 'ode',\n",
       " 'r',\n",
       " 'n',\n",
       " 'day',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'ha',\n",
       " 'st',\n",
       " 'woo',\n",
       " 'b',\n",
       " 'j',\n",
       " 'e',\n",
       " 'c',\n",
       " 'ti',\n",
       " 'v',\n",
       " 'es',\n",
       " 'One',\n",
       " 'ist',\n",
       " 'o',\n",
       " 'class',\n",
       " 'if',\n",
       " 'y',\n",
       " 'data',\n",
       " 'based',\n",
       " 'on',\n",
       " 'model',\n",
       " 's',\n",
       " 'which',\n",
       " 'have',\n",
       " 'been',\n",
       " 'develop',\n",
       " 'ed',\n",
       " 'theo',\n",
       " 'the',\n",
       " 'r',\n",
       " 'purpose',\n",
       " 'ist',\n",
       " 'om',\n",
       " 'ake',\n",
       " 'prediction',\n",
       " 's',\n",
       " 'for',\n",
       " 'future',\n",
       " 'outcome',\n",
       " 's',\n",
       " 'based',\n",
       " 'on',\n",
       " 'these',\n",
       " 'model',\n",
       " 'sAh',\n",
       " 'y',\n",
       " 'pot',\n",
       " 'het',\n",
       " 'i',\n",
       " 'cal',\n",
       " 'algorithm',\n",
       " 'specific',\n",
       " 'to',\n",
       " 'class',\n",
       " 'if',\n",
       " 'yin',\n",
       " 'g',\n",
       " 'data',\n",
       " 'may',\n",
       " 'use',\n",
       " 'computer',\n",
       " 'vision',\n",
       " 'of',\n",
       " 'mole',\n",
       " 'scoup',\n",
       " 'led',\n",
       " 'with',\n",
       " 'supervise',\n",
       " 'd',\n",
       " 'learning',\n",
       " 'ino',\n",
       " 'r',\n",
       " 'de',\n",
       " 'r',\n",
       " 'tot',\n",
       " 'rain',\n",
       " 'it',\n",
       " 'to',\n",
       " 'class',\n",
       " 'if',\n",
       " 'y',\n",
       " 'theca',\n",
       " 'n',\n",
       " 'cerous',\n",
       " 'mole',\n",
       " 'sAm',\n",
       " 'ach',\n",
       " 'in',\n",
       " 'el',\n",
       " 'earning',\n",
       " 'algorithm',\n",
       " 'forst',\n",
       " 'ock',\n",
       " 'trading',\n",
       " 'may',\n",
       " 'inform',\n",
       " 'the',\n",
       " 'trader',\n",
       " 'off',\n",
       " 'utu',\n",
       " 'repot',\n",
       " 'entia',\n",
       " 'l',\n",
       " 'prediction',\n",
       " 'sAsa',\n",
       " 'scientific',\n",
       " 'end',\n",
       " 'ea',\n",
       " 'v',\n",
       " 'our',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'grew',\n",
       " 'out',\n",
       " 'oft',\n",
       " 'he',\n",
       " 'quest',\n",
       " 'fora',\n",
       " 'r',\n",
       " 'ti',\n",
       " 'fi',\n",
       " 'c',\n",
       " 'i',\n",
       " 'alin',\n",
       " 'tell',\n",
       " 'i',\n",
       " 'gen',\n",
       " 'ce',\n",
       " 'AI',\n",
       " 'In',\n",
       " 'thee',\n",
       " 'ar',\n",
       " 'ly',\n",
       " 'days',\n",
       " 'of',\n",
       " 'AIas',\n",
       " 'ana',\n",
       " 'cade',\n",
       " 'mi',\n",
       " 'c',\n",
       " 'discipline',\n",
       " 'some',\n",
       " 'researcher',\n",
       " 's',\n",
       " 'were',\n",
       " 'interested',\n",
       " 'in',\n",
       " 'ha',\n",
       " 'v',\n",
       " 'ing',\n",
       " 'machine',\n",
       " 's',\n",
       " 'learn',\n",
       " 'from',\n",
       " 'data',\n",
       " 'They',\n",
       " 'attempt',\n",
       " 'ed',\n",
       " 'toa',\n",
       " 'p',\n",
       " 'proa',\n",
       " 'c',\n",
       " 'h',\n",
       " 'the',\n",
       " 'problem',\n",
       " 'with',\n",
       " 'various',\n",
       " 'symbolic',\n",
       " 'method',\n",
       " 'sa',\n",
       " 'swell',\n",
       " 'as',\n",
       " 'what',\n",
       " 'were',\n",
       " 'then',\n",
       " 'term',\n",
       " 'ed',\n",
       " 'neural',\n",
       " 'network',\n",
       " 'st',\n",
       " 'he',\n",
       " 'sewer',\n",
       " 'em',\n",
       " 'os',\n",
       " 't',\n",
       " 'ly',\n",
       " 'percept',\n",
       " 'ron',\n",
       " 'sand',\n",
       " 'other',\n",
       " 'model',\n",
       " 'st',\n",
       " 'hat',\n",
       " 'were',\n",
       " 'later',\n",
       " 'found',\n",
       " 'tobe',\n",
       " 'reinvention',\n",
       " 'soft',\n",
       " 'he',\n",
       " 'general',\n",
       " 'is',\n",
       " 'ed',\n",
       " 'linear',\n",
       " 'model',\n",
       " 'so',\n",
       " 'f',\n",
       " 'statistics',\n",
       " 'Probabilistic',\n",
       " 'reasoning',\n",
       " 'was',\n",
       " 'also',\n",
       " 'employed',\n",
       " 'especially',\n",
       " 'in',\n",
       " 'automat',\n",
       " 'ed',\n",
       " 'medical',\n",
       " 'diagnosis',\n",
       " 'However',\n",
       " 'ani',\n",
       " 'n',\n",
       " 'creasing',\n",
       " 'emphasis',\n",
       " 'on',\n",
       " 'the',\n",
       " 'logical',\n",
       " 'knowledge',\n",
       " 'based',\n",
       " 'approach',\n",
       " 'cause',\n",
       " 'dari',\n",
       " 'f',\n",
       " 't',\n",
       " 'between',\n",
       " 'AI',\n",
       " 'and',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'Probabilistic',\n",
       " 'system',\n",
       " 's',\n",
       " 'were',\n",
       " 'plagued',\n",
       " 'byth',\n",
       " 'e',\n",
       " 'ore',\n",
       " 'tical',\n",
       " 'and',\n",
       " 'practical',\n",
       " 'problem',\n",
       " 'so',\n",
       " 'f',\n",
       " 'data',\n",
       " 'acquisition',\n",
       " 'andre',\n",
       " 'presentation',\n",
       " 'Bye',\n",
       " 'x',\n",
       " 'pert',\n",
       " 'system',\n",
       " 'shad',\n",
       " 'comet',\n",
       " ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maximum_matching(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "477c5712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Machine': 5,\n",
       " 'learning': 192,\n",
       " 'ML': 3,\n",
       " 'is': 125,\n",
       " 'a': 241,\n",
       " 'field': 19,\n",
       " 'of': 268,\n",
       " 'study': 8,\n",
       " 'in': 156,\n",
       " 'artificial': 25,\n",
       " 'intelligence': 10,\n",
       " 'concerned': 3,\n",
       " 'with': 54,\n",
       " 'the': 358,\n",
       " 'development': 1,\n",
       " 'and': 214,\n",
       " 'statistical': 10,\n",
       " 'algorithms': 44,\n",
       " 'that': 108,\n",
       " 'can': 48,\n",
       " 'learn': 10,\n",
       " 'from': 52,\n",
       " 'data': 97,\n",
       " 'generalise': 2,\n",
       " 'to': 231,\n",
       " 'unseen': 3,\n",
       " 'thus': 3,\n",
       " 'perform': 11,\n",
       " 'tasks': 12,\n",
       " 'without': 10,\n",
       " 'explicit': 2,\n",
       " 'instructions': 1,\n",
       " 'Within': 1,\n",
       " 'subdiscipline': 1,\n",
       " 'machine': 106,\n",
       " 'advances': 2,\n",
       " 'deep': 7,\n",
       " 'have': 29,\n",
       " 'allowed': 1,\n",
       " 'neural': 19,\n",
       " 'networks': 16,\n",
       " 'class': 11,\n",
       " 'surpass': 2,\n",
       " 'many': 13,\n",
       " 'previous': 5,\n",
       " 'approaches': 9,\n",
       " 'performanceML': 1,\n",
       " 'finds': 3,\n",
       " 'application': 3,\n",
       " 'fields': 5,\n",
       " 'including': 9,\n",
       " 'natural': 3,\n",
       " 'language': 5,\n",
       " 'processing': 5,\n",
       " 'computer': 11,\n",
       " 'vision': 5,\n",
       " 'speech': 5,\n",
       " 'recognition': 4,\n",
       " 'email': 3,\n",
       " 'filtering': 2,\n",
       " 'agriculture': 1,\n",
       " 'medicine': 1,\n",
       " 'The': 23,\n",
       " 'business': 2,\n",
       " 'problems': 11,\n",
       " 'known': 11,\n",
       " 'as': 79,\n",
       " 'predictive': 6,\n",
       " 'analyticsStatistics': 1,\n",
       " 'mathematical': 10,\n",
       " 'optimisation': 7,\n",
       " 'programming': 8,\n",
       " 'methods': 25,\n",
       " 'comprise': 1,\n",
       " 'foundations': 1,\n",
       " 'Data': 3,\n",
       " 'mining': 11,\n",
       " 'related': 9,\n",
       " 'focusing': 2,\n",
       " 'on': 57,\n",
       " 'exploratory': 1,\n",
       " 'analysis': 13,\n",
       " 'EDA': 1,\n",
       " 'via': 3,\n",
       " 'unsupervised': 13,\n",
       " 'learningFrom': 1,\n",
       " 'theoretical': 7,\n",
       " 'viewpoint': 1,\n",
       " 'probably': 2,\n",
       " 'approximately': 3,\n",
       " 'correct': 2,\n",
       " 'provides': 2,\n",
       " 'framework': 2,\n",
       " 'for': 69,\n",
       " 'describing': 1,\n",
       " 'learningThe': 1,\n",
       " 'term': 6,\n",
       " 'was': 20,\n",
       " 'coined': 1,\n",
       " 'by': 62,\n",
       " 'Arthur': 2,\n",
       " 'Samuel': 2,\n",
       " 'an': 46,\n",
       " 'IBM': 2,\n",
       " 'employee': 1,\n",
       " 'pioneer': 1,\n",
       " 'gaming': 1,\n",
       " 'synonym': 1,\n",
       " 'selfteaching': 1,\n",
       " 'computers': 3,\n",
       " 'also': 22,\n",
       " 'used': 37,\n",
       " 'this': 10,\n",
       " 'time': 10,\n",
       " 'periodAlthough': 1,\n",
       " 'earliest': 1,\n",
       " 'model': 48,\n",
       " 'introduced': 4,\n",
       " 's': 8,\n",
       " 'when': 9,\n",
       " 'invented': 1,\n",
       " 'program': 7,\n",
       " 'calculated': 1,\n",
       " 'winning': 1,\n",
       " 'chance': 1,\n",
       " 'checkers': 1,\n",
       " 'each': 13,\n",
       " 'side': 1,\n",
       " 'history': 4,\n",
       " 'roots': 1,\n",
       " 'back': 2,\n",
       " 'decades': 2,\n",
       " 'human': 10,\n",
       " 'desire': 1,\n",
       " 'effort': 1,\n",
       " 'cognitive': 3,\n",
       " 'processes': 3,\n",
       " 'In': 30,\n",
       " 'Canadian': 1,\n",
       " 'psychologist': 1,\n",
       " 'Donald': 1,\n",
       " 'Hebb': 1,\n",
       " 'published': 2,\n",
       " 'book': 4,\n",
       " 'Organization': 1,\n",
       " 'Behavior': 1,\n",
       " 'which': 22,\n",
       " 'he': 1,\n",
       " 'structure': 3,\n",
       " 'formed': 2,\n",
       " 'certain': 5,\n",
       " 'interactions': 1,\n",
       " 'among': 6,\n",
       " 'nerve': 1,\n",
       " 'cells': 1,\n",
       " 'Hebbs': 1,\n",
       " 'neurons': 10,\n",
       " 'interacting': 1,\n",
       " 'one': 14,\n",
       " 'another': 3,\n",
       " 'set': 32,\n",
       " 'groundwork': 1,\n",
       " 'how': 11,\n",
       " 'AIs': 1,\n",
       " 'work': 3,\n",
       " 'under': 9,\n",
       " 'nodes': 2,\n",
       " 'or': 56,\n",
       " 'communicate': 1,\n",
       " 'Other': 3,\n",
       " 'researchers': 7,\n",
       " 'who': 6,\n",
       " 'studied': 3,\n",
       " 'systems': 25,\n",
       " 'contributed': 1,\n",
       " 'modern': 1,\n",
       " 'technologies': 1,\n",
       " 'well': 5,\n",
       " 'logician': 1,\n",
       " 'Walter': 1,\n",
       " 'Pitts': 1,\n",
       " 'Warren': 1,\n",
       " 'McCulloch': 1,\n",
       " 'proposed': 1,\n",
       " 'early': 3,\n",
       " 'models': 32,\n",
       " 'come': 3,\n",
       " 'up': 6,\n",
       " 'mirror': 1,\n",
       " 'thought': 2,\n",
       " 'processesBy': 1,\n",
       " 'experimental': 2,\n",
       " 'punched': 1,\n",
       " 'tape': 1,\n",
       " 'memory': 3,\n",
       " 'called': 14,\n",
       " 'Cybertron': 1,\n",
       " 'had': 9,\n",
       " 'been': 23,\n",
       " 'developed': 6,\n",
       " 'Raytheon': 1,\n",
       " 'Company': 1,\n",
       " 'analyse': 2,\n",
       " 'sonar': 1,\n",
       " 'signals': 2,\n",
       " 'electrocardiograms': 1,\n",
       " 'patterns': 8,\n",
       " 'using': 13,\n",
       " 'rudimentary': 1,\n",
       " 'reinforcement': 7,\n",
       " 'It': 14,\n",
       " 'repetitively': 1,\n",
       " 'trained': 14,\n",
       " 'operatorteacher': 1,\n",
       " 'recognise': 3,\n",
       " 'equipped': 1,\n",
       " 'goof': 1,\n",
       " 'button': 1,\n",
       " 'cause': 1,\n",
       " 'it': 28,\n",
       " 'reevaluate': 1,\n",
       " 'incorrect': 1,\n",
       " 'decisions': 7,\n",
       " 'A': 10,\n",
       " 'representative': 5,\n",
       " 'research': 10,\n",
       " 'into': 18,\n",
       " 'during': 3,\n",
       " 'Nilssons': 1,\n",
       " 'Learning': 3,\n",
       " 'Machines': 1,\n",
       " 'dealing': 2,\n",
       " 'mostly': 2,\n",
       " 'pattern': 5,\n",
       " 'classification': 19,\n",
       " 'Interest': 1,\n",
       " 'continued': 2,\n",
       " 'described': 1,\n",
       " 'Duda': 1,\n",
       " 'Hart': 1,\n",
       " 'report': 3,\n",
       " 'given': 7,\n",
       " 'teaching': 1,\n",
       " 'strategies': 1,\n",
       " 'so': 5,\n",
       " 'network': 12,\n",
       " 'learns': 5,\n",
       " 'characters': 1,\n",
       " 'letters': 1,\n",
       " 'digits': 1,\n",
       " 'special': 2,\n",
       " 'symbols': 1,\n",
       " 'terminalTom': 1,\n",
       " 'M': 1,\n",
       " 'Mitchell': 1,\n",
       " 'provided': 4,\n",
       " 'widely': 2,\n",
       " 'quoted': 1,\n",
       " 'more': 13,\n",
       " 'formal': 1,\n",
       " 'definition': 4,\n",
       " 'said': 3,\n",
       " 'experience': 4,\n",
       " 'E': 2,\n",
       " 'respect': 3,\n",
       " 'some': 12,\n",
       " 'T': 2,\n",
       " 'performance': 11,\n",
       " 'measure': 2,\n",
       " 'P': 2,\n",
       " 'if': 7,\n",
       " 'its': 17,\n",
       " 'at': 6,\n",
       " 'measured': 1,\n",
       " 'improves': 2,\n",
       " 'This': 17,\n",
       " 'offers': 1,\n",
       " 'fundamentally': 1,\n",
       " 'operational': 1,\n",
       " 'rather': 3,\n",
       " 'than': 4,\n",
       " 'defining': 2,\n",
       " 'terms': 3,\n",
       " 'follows': 1,\n",
       " 'Alan': 1,\n",
       " 'Turings': 1,\n",
       " 'proposal': 1,\n",
       " 'his': 1,\n",
       " 'paper': 1,\n",
       " 'Computing': 2,\n",
       " 'Machinery': 1,\n",
       " 'Intelligence': 1,\n",
       " 'question': 2,\n",
       " 'Can': 2,\n",
       " 'machines': 7,\n",
       " 'think': 1,\n",
       " 'replaced': 1,\n",
       " 'do': 8,\n",
       " 'what': 3,\n",
       " 'we': 3,\n",
       " 'thinking': 1,\n",
       " 'entities': 1,\n",
       " 'doModernday': 1,\n",
       " 'has': 22,\n",
       " 'two': 8,\n",
       " 'objectives': 2,\n",
       " 'One': 2,\n",
       " 'classify': 2,\n",
       " 'based': 10,\n",
       " 'other': 16,\n",
       " 'purpose': 1,\n",
       " 'make': 10,\n",
       " 'predictions': 12,\n",
       " 'future': 5,\n",
       " 'outcomes': 2,\n",
       " 'these': 16,\n",
       " 'hypothetical': 1,\n",
       " 'algorithm': 24,\n",
       " 'specific': 6,\n",
       " 'classifying': 2,\n",
       " 'may': 14,\n",
       " 'use': 12,\n",
       " 'moles': 2,\n",
       " 'coupled': 1,\n",
       " 'supervised': 13,\n",
       " 'order': 5,\n",
       " 'train': 3,\n",
       " 'cancerous': 1,\n",
       " 'stock': 2,\n",
       " 'trading': 1,\n",
       " 'inform': 1,\n",
       " 'trader': 1,\n",
       " 'potential': 4,\n",
       " 'predictionsAs': 1,\n",
       " 'scientific': 1,\n",
       " 'endeavour': 1,\n",
       " 'grew': 1,\n",
       " 'out': 6,\n",
       " 'quest': 1,\n",
       " 'AI': 24,\n",
       " 'days': 1,\n",
       " 'academic': 1,\n",
       " 'discipline': 1,\n",
       " 'were': 9,\n",
       " 'interested': 1,\n",
       " 'having': 3,\n",
       " 'They': 3,\n",
       " 'attempted': 1,\n",
       " 'approach': 9,\n",
       " 'problem': 5,\n",
       " 'various': 8,\n",
       " 'symbolic': 2,\n",
       " 'then': 7,\n",
       " 'termed': 1,\n",
       " 'perceptrons': 2,\n",
       " 'later': 1,\n",
       " 'found': 7,\n",
       " 'be': 46,\n",
       " 'reinventions': 1,\n",
       " 'generalised': 1,\n",
       " 'linear': 9,\n",
       " 'statistics': 8,\n",
       " 'Probabilistic': 2,\n",
       " 'reasoning': 2,\n",
       " 'employed': 3,\n",
       " 'especially': 4,\n",
       " 'automated': 3,\n",
       " 'medical': 6,\n",
       " 'diagnosisHowever': 1,\n",
       " 'increasing': 2,\n",
       " 'emphasis': 1,\n",
       " 'logical': 3,\n",
       " 'knowledgebased': 1,\n",
       " 'caused': 2,\n",
       " 'rift': 1,\n",
       " 'between': 18,\n",
       " 'plagued': 1,\n",
       " 'practical': 2,\n",
       " 'acquisition': 1,\n",
       " 'representation': 8,\n",
       " 'By': 5,\n",
       " 'expert': 1,\n",
       " 'dominate': 1,\n",
       " 'favour': 1,\n",
       " 'Work': 1,\n",
       " 'symbolicknowledgebased': 1,\n",
       " 'did': 1,\n",
       " 'continue': 1,\n",
       " 'within': 8,\n",
       " 'leading': 4,\n",
       " 'inductive': 3,\n",
       " 'logic': 8,\n",
       " 'programmingILP': 1,\n",
       " 'but': 16,\n",
       " 'line': 3,\n",
       " 'now': 2,\n",
       " 'outside': 2,\n",
       " 'proper': 1,\n",
       " 'information': 6,\n",
       " 'retrieval': 1,\n",
       " 'Neural': 1,\n",
       " 'abandoned': 1,\n",
       " 'science': 3,\n",
       " 'around': 2,\n",
       " 'same': 6,\n",
       " 'too': 2,\n",
       " 'AICS': 1,\n",
       " 'connectionism': 1,\n",
       " 'disciplines': 2,\n",
       " 'John': 1,\n",
       " 'Hopfield': 1,\n",
       " 'David': 1,\n",
       " 'Rumelhart': 1,\n",
       " 'Geoffrey': 1,\n",
       " 'Hinton': 1,\n",
       " 'Their': 1,\n",
       " 'main': 1,\n",
       " 'success': 1,\n",
       " 'came': 1,\n",
       " 'mids': 1,\n",
       " 'reinvention': 1,\n",
       " 'backpropagationMachine': 1,\n",
       " 'reorganised': 1,\n",
       " 'recognised': 1,\n",
       " 'own': 1,\n",
       " 'started': 1,\n",
       " 'f lo ur ish': 1,\n",
       " 'changed': 2,\n",
       " 'goal': 4,\n",
       " 'achiev ing': 1,\n",
       " 't ack ling': 1,\n",
       " 'sol v able': 1,\n",
       " 'nature': 3,\n",
       " 's hi f ted': 1,\n",
       " 'focus': 2,\n",
       " 'a way': 1,\n",
       " 'in h er ited': 1,\n",
       " 'toward': 3,\n",
       " 'b or row ed': 1,\n",
       " 'f u z z y': 1,\n",
       " 'probability': 4,\n",
       " 'theory There': 1,\n",
       " 'clo se': 1,\n",
       " 'connection': 5,\n",
       " 'compression': 10,\n",
       " 'system': 12,\n",
       " 'predicts': 2,\n",
       " 'post er i or': 1,\n",
       " 'probabilities': 3,\n",
       " 'sequence': 2,\n",
       " 'entire': 1,\n",
       " 'optimal': 4,\n",
       " 'ar ith m etic': 1,\n",
       " 'coding': 2,\n",
       " 'output': 13,\n",
       " 'distribution': 6,\n",
       " 'Conversely': 2,\n",
       " 'compressor': 2,\n",
       " 'prediction': 6,\n",
       " 'finding': 3,\n",
       " 'symbol': 1,\n",
       " 'compres ses': 1,\n",
       " 'best': 7,\n",
       " 'e qu iv a len ce': 1,\n",
       " 'just ification': 1,\n",
       " 'ben ch mark': 1,\n",
       " 'general': 5,\n",
       " 'intelligence An': 1,\n",
       " 'alternative': 2,\n",
       " 'view': 1,\n",
       " 'show': 3,\n",
       " 'implicitly': 3,\n",
       " 'map': 2,\n",
       " 'str ings': 1,\n",
       " 'implicit': 1,\n",
       " 'feature': 13,\n",
       " 'space': 7,\n",
       " 'vectors': 3,\n",
       " 'compression based': 1,\n",
       " 'similarity': 6,\n",
       " 'measures': 2,\n",
       " 'compute': 4,\n",
       " 'spaces': 2,\n",
       " 'For': 11,\n",
       " 'C': 2,\n",
       " 'define': 2,\n",
       " 'associated': 6,\n",
       " 'vector': 5,\n",
       " 'ℵ': 1,\n",
       " 'such': 27,\n",
       " 'map s': 1,\n",
       " 'input': 18,\n",
       " 'str ing': 1,\n",
       " 'x': 4,\n",
       " 'corresponding': 2,\n",
       " 'nor m': 1,\n",
       " 'An': 6,\n",
       " 'ex ha ust ive': 1,\n",
       " 'examination': 2,\n",
       " 'underlying': 5,\n",
       " 'all': 8,\n",
       " 'pre clu ded': 1,\n",
       " 'in stead': 1,\n",
       " 'ch oo ses': 1,\n",
       " 'exam ine': 1,\n",
       " 'three': 2,\n",
       " 'loss less': 1,\n",
       " 'LZ W': 1,\n",
       " 'LZ': 1,\n",
       " 'P P MA ccording': 1,\n",
       " 'AI X I': 1,\n",
       " 'theory': 16,\n",
       " 'directly': 4,\n",
       " 'explain ed': 1,\n",
       " 'H ut ter': 1,\n",
       " 'Prize': 3,\n",
       " 'possible': 3,\n",
       " 's mal le st': 1,\n",
       " 'software': 6,\n",
       " 'generates': 2,\n",
       " 'example': 20,\n",
       " 'zip': 2,\n",
       " 'files': 2,\n",
       " 'compress ed': 1,\n",
       " 'size': 2,\n",
       " 'includes': 4,\n",
       " 'both': 7,\n",
       " 'file': 2,\n",
       " 'unzip p ing': 1,\n",
       " 's ince': 1,\n",
       " 'y o u': 1,\n",
       " 'not': 24,\n",
       " 'unzip': 1,\n",
       " 'there': 3,\n",
       " 'even': 5,\n",
       " 'smaller': 2,\n",
       " 'combined': 3,\n",
       " 'form Examples': 1,\n",
       " 'AIpowered': 3,\n",
       " 'au dio video': 1,\n",
       " 'include': 11,\n",
       " 'N VID I A': 1,\n",
       " 'M a x ine': 1,\n",
       " 'AI V C': 1,\n",
       " 'Examples': 3,\n",
       " 'image': 9,\n",
       " 'Open C V': 1,\n",
       " 'Tensor F low': 1,\n",
       " 'MA T L A B s': 1,\n",
       " 'Image': 2,\n",
       " 'Processing': 2,\n",
       " 'To ol box': 1,\n",
       " 'I P T': 1,\n",
       " 'High F id el ity': 1,\n",
       " 'Gener ative': 1,\n",
       " 'Comp ression In': 1,\n",
       " 'kmeans': 2,\n",
       " 'clustering': 5,\n",
       " 'util iz ed': 1,\n",
       " 'compress': 1,\n",
       " 'group ing': 1,\n",
       " 'similar': 4,\n",
       " 'points': 8,\n",
       " 'clusters': 5,\n",
       " 'technique': 3,\n",
       " 'si mp li fi es': 1,\n",
       " 'hand ling': 1,\n",
       " 'extensive': 2,\n",
       " 'datasets': 3,\n",
       " 'lack': 6,\n",
       " 'predefined': 2,\n",
       " 'labels': 7,\n",
       " 'wid es pre ad': 1,\n",
       " 'compression Data': 1,\n",
       " 'ai ms': 1,\n",
       " 'reduce': 4,\n",
       " 'enh anc ing': 1,\n",
       " 'storage': 2,\n",
       " 'efficiency': 3,\n",
       " 'spe ed ing': 1,\n",
       " 'trans mission': 1,\n",
       " 'K means': 1,\n",
       " 'partition': 1,\n",
       " 'dataset': 3,\n",
       " 'spec ified': 1,\n",
       " 'number': 5,\n",
       " 'k': 1,\n",
       " 'represented': 11,\n",
       " 'centro id': 1,\n",
       " 'process': 13,\n",
       " 'con den ses': 1,\n",
       " 'compact': 1,\n",
       " 'P art icular ly': 1,\n",
       " 'ben e fic ial': 1,\n",
       " 'signal': 11,\n",
       " 'a ids': 1,\n",
       " 'reduction': 6,\n",
       " 'repl ac ing': 1,\n",
       " 'groups': 2,\n",
       " 'their': 19,\n",
       " 'centro ids': 1,\n",
       " 'thereby': 4,\n",
       " 'pres erv ing': 1,\n",
       " 'core': 2,\n",
       " 'original': 2,\n",
       " 'while': 9,\n",
       " 'significantly': 3,\n",
       " 'decreas ing': 1,\n",
       " 'required': 2,\n",
       " 'space Machine': 1,\n",
       " 'often': 16,\n",
       " 'employ': 1,\n",
       " 'over l ap': 1,\n",
       " 'focuses': 2,\n",
       " 'properties': 3,\n",
       " 'learned': 10,\n",
       " 'training': 48,\n",
       " 'discovery': 5,\n",
       " 'previously': 4,\n",
       " 'unknown': 4,\n",
       " 'step': 3,\n",
       " 'knowledge': 12,\n",
       " 'databases': 3,\n",
       " 'uses': 4,\n",
       " 'different': 5,\n",
       " 'go als': 1,\n",
       " 'hand': 1,\n",
       " 'employ s': 1,\n",
       " 'preprocessing': 2,\n",
       " 'improve': 4,\n",
       " 'learner': 4,\n",
       " 'accuracy': 7,\n",
       " 'M uch': 1,\n",
       " 'con fusion': 1,\n",
       " 'communities': 2,\n",
       " 'separate': 3,\n",
       " 'con ferences': 1,\n",
       " 'journ als': 1,\n",
       " 'E C ML': 1,\n",
       " 'P KDD': 1,\n",
       " 'being': 6,\n",
       " 'maj or': 1,\n",
       " 'excep tion': 1,\n",
       " 'comes': 1,\n",
       " 'basic': 2,\n",
       " 'assumptions': 2,\n",
       " 'they': 6,\n",
       " 'usually': 2,\n",
       " 'evaluated': 2,\n",
       " 'ability': 2,\n",
       " 're produce': 1,\n",
       " 'KDD': 2,\n",
       " 'key': 4,\n",
       " 'task': 4,\n",
       " 'E valu ated': 1,\n",
       " 'un inform ed': 1,\n",
       " 'method': 10,\n",
       " 'will': 6,\n",
       " 'e as ily': 1,\n",
       " 'out performed': 1,\n",
       " 'typ ical': 1,\n",
       " 'cannot': 5,\n",
       " 'd ue': 1,\n",
       " 'un avail ability': 1,\n",
       " 'data Machine': 1,\n",
       " 'in timate': 1,\n",
       " 'ties': 1,\n",
       " 'Many': 4,\n",
       " 'are': 62,\n",
       " 'form ulated': 1,\n",
       " 'minimis ation': 1,\n",
       " 'loss': 1,\n",
       " 'function': 12,\n",
       " 'examples': 13,\n",
       " 'L os s': 1,\n",
       " 'functions': 5,\n",
       " 'express': 1,\n",
       " 'dis c rep an cy': 1,\n",
       " 'act ual': 1,\n",
       " 'instances': 5,\n",
       " 'w ants': 1,\n",
       " 'assign': 1,\n",
       " 'label': 2,\n",
       " 'correctly': 3,\n",
       " 'predict': 9,\n",
       " 'pre assign ed': 1,\n",
       " 'examples Ch ar acter iz ing': 1,\n",
       " 'generalisation': 4,\n",
       " 'active': 2,\n",
       " 'topic': 2,\n",
       " 'current': 3,\n",
       " 'algorithms Machine': 1,\n",
       " 'closely': 2,\n",
       " 'dist inc t': 1,\n",
       " 'principal': 4,\n",
       " 'dra w s': 1,\n",
       " 'population': 2,\n",
       " 'in ferences': 1,\n",
       " 'sample': 2,\n",
       " 'general is able': 1,\n",
       " 'A ccording': 1,\n",
       " 'M ic ha el': 1,\n",
       " 'I': 1,\n",
       " 'J ord an': 1,\n",
       " 'ide as': 1,\n",
       " 'method o logical': 1,\n",
       " 'princip les': 1,\n",
       " 'tools': 4,\n",
       " 'long': 1,\n",
       " 'pre history': 1,\n",
       " 'He': 1,\n",
       " 'sugges ted': 1,\n",
       " 'place h ol der': 1,\n",
       " 'call': 2,\n",
       " 'overall': 2,\n",
       " 'field Con ventional': 1,\n",
       " 'analy ses': 1,\n",
       " 'require': 4,\n",
       " 'pri or i': 1,\n",
       " 'selection': 3,\n",
       " 'most': 2,\n",
       " 'suitable': 2,\n",
       " 'addition': 6,\n",
       " 'only': 9,\n",
       " 'significant': 2,\n",
       " 'theore t ically': 1,\n",
       " 're le v ant': 1,\n",
       " 'variables': 13,\n",
       " 'inclu ded': 1,\n",
       " 'contrast': 4,\n",
       " 'built': 4,\n",
       " 'pre struct ured': 1,\n",
       " 's hap e': 1,\n",
       " 'detect ing': 1,\n",
       " 'accurate': 3,\n",
       " 'ul timate': 1,\n",
       " 'be Le o': 1,\n",
       " 'B re i man': 1,\n",
       " 'dist ing u ished': 1,\n",
       " 'modelling': 3,\n",
       " 'paradigms': 2,\n",
       " 'algorithmic': 5,\n",
       " 'where in': 1,\n",
       " 'means': 1,\n",
       " 'less': 2,\n",
       " 'like': 10,\n",
       " 'Random': 1,\n",
       " 'F ore st Some': 1,\n",
       " 'statist ic i ans': 1,\n",
       " 'adopted': 2,\n",
       " 'learning An aly tical': 1,\n",
       " 'computational': 5,\n",
       " 'techniques': 15,\n",
       " 'derived': 2,\n",
       " 'de e pro oted': 1,\n",
       " 'physics': 2,\n",
       " 'dis ordered': 1,\n",
       " 'extended': 3,\n",
       " 'largescale': 4,\n",
       " 'eg': 6,\n",
       " 'weight': 3,\n",
       " 'Statist ical': 1,\n",
       " 'applications': 6,\n",
       " 'area': 4,\n",
       " 'diagnost ics A': 1,\n",
       " 'objective': 2,\n",
       " 'General isation': 1,\n",
       " 'context': 3,\n",
       " 'accur ately': 1,\n",
       " 'new': 13,\n",
       " 'example st ask s': 1,\n",
       " 'after': 6,\n",
       " 'experi en c ed': 1,\n",
       " 'generally': 2,\n",
       " 'considered': 6,\n",
       " 'o c curren ces': 1,\n",
       " 'build': 3,\n",
       " 'about': 9,\n",
       " 'enables': 2,\n",
       " 'produce': 3,\n",
       " 'sufficiently': 2,\n",
       " 'cases The': 1,\n",
       " 'branch': 2,\n",
       " 'Because': 2,\n",
       " 'sets': 3,\n",
       " 'finite': 2,\n",
       " 'uncer tain': 1,\n",
       " 'does': 3,\n",
       " 'yield': 1,\n",
       " 'gu ar an te es': 1,\n",
       " 'Instead': 3,\n",
       " 'probabilistic': 4,\n",
       " 'bounds': 2,\n",
       " 'qu ite': 1,\n",
       " 'common': 4,\n",
       " 'bias variance': 1,\n",
       " 'de comp os ition': 1,\n",
       " 'way': 5,\n",
       " 'quan ti fy': 1,\n",
       " 'error For': 1,\n",
       " 'complexity': 6,\n",
       " 'hypothesis': 4,\n",
       " 's ho uld': 1,\n",
       " 'match': 1,\n",
       " 'If': 2,\n",
       " 'complex': 4,\n",
       " 'fit ted': 1,\n",
       " 'increased': 2,\n",
       " 'response': 2,\n",
       " 'error': 1,\n",
       " 'decreases': 2,\n",
       " 'B ut': 1,\n",
       " 'sub j ect': 1,\n",
       " 'overfitting': 6,\n",
       " 'po ore r In': 1,\n",
       " 'theor ists': 1,\n",
       " 'feas i bility': 1,\n",
       " 'computation': 3,\n",
       " 'feasible': 1,\n",
       " 'd one': 1,\n",
       " 'polynomial': 4,\n",
       " 'There': 3,\n",
       " 'kinds': 2,\n",
       " 'results': 5,\n",
       " 'P o sitive': 1,\n",
       " 'N eg ative': 1,\n",
       " 'classes': 2,\n",
       " 'time Machine': 1,\n",
       " 'tra dition ally': 1,\n",
       " 'divid ed': 1,\n",
       " 'broad': 3,\n",
       " 'categories': 4,\n",
       " 'correspon d': 1,\n",
       " 'depending': 2,\n",
       " 'feedback': 2,\n",
       " 'avail able': 1,\n",
       " 'system Although': 1,\n",
       " 'advanta ges': 1,\n",
       " 'limit ations': 1,\n",
       " 'no': 2,\n",
       " 'single': 4,\n",
       " 'work s': 1,\n",
       " 'problems Supervised': 1,\n",
       " 'contains': 2,\n",
       " 'inputs': 9,\n",
       " 'desired': 2,\n",
       " 'outputs': 5,\n",
       " 'consists': 2,\n",
       " 'Each': 2,\n",
       " 'supervisory': 2,\n",
       " 'array': 2,\n",
       " 'sometimes': 3,\n",
       " 'matrix': 5,\n",
       " 'Th rough': 1,\n",
       " 'iter ative': 1,\n",
       " 'allows': 3,\n",
       " 'determine': 2,\n",
       " 'part': 2,\n",
       " 'over': 3,\n",
       " 'task Typ es': 1,\n",
       " 'supervised learning': 1,\n",
       " 'regression': 14,\n",
       " 'Classification': 1,\n",
       " 're str ic ted': 1,\n",
       " 'limited': 3,\n",
       " 'values': 3,\n",
       " 'take': 5,\n",
       " 'any': 8,\n",
       " 'numer ical': 1,\n",
       " 'value': 3,\n",
       " 'range': 3,\n",
       " 'fil ters': 1,\n",
       " 'email s': 1,\n",
       " 'in coming': 1,\n",
       " 'fol der': 1,\n",
       " 'predicting': 2,\n",
       " 'per s ons': 1,\n",
       " 'he ight': 1,\n",
       " 'factors': 2,\n",
       " 'age': 1,\n",
       " 'gen et ics': 1,\n",
       " 'forecas ting': 1,\n",
       " 'temp er at ures': 1,\n",
       " 'historical': 2,\n",
       " 'data Similar ity': 1,\n",
       " 'objects': 4,\n",
       " 'ran king': 1,\n",
       " 'recommendation': 4,\n",
       " 'vis ual': 1,\n",
       " 'ident ity': 1,\n",
       " 'tr ack ing': 1,\n",
       " 'f ace': 1,\n",
       " 'verification': 1,\n",
       " 'spe ak er': 1,\n",
       " 'verification Unsupervised': 1,\n",
       " 'find': 2,\n",
       " 'structures': 2,\n",
       " 'labelled': 6,\n",
       " 'classifi ed': 1,\n",
       " 'categor ised': 1,\n",
       " 'respon ding': 1,\n",
       " 'identify': 4,\n",
       " 'commonalities': 2,\n",
       " 're act': 1,\n",
       " 'presence': 2,\n",
       " 'abs ence': 1,\n",
       " 'piece': 1,\n",
       " 'C entral': 1,\n",
       " 'dimensionality': 4,\n",
       " 'density': 2,\n",
       " 'estimation Cl ust er': 1,\n",
       " 'assign ment': 1,\n",
       " 'observations': 5,\n",
       " 'subsets': 3,\n",
       " 'cluster': 4,\n",
       " 'according': 3,\n",
       " 'pred esi gn ated': 1,\n",
       " 'criter i a': 1,\n",
       " 'drawn': 2,\n",
       " 'dis similar': 1,\n",
       " 'Different': 3,\n",
       " 'defined': 2,\n",
       " 'met ric': 1,\n",
       " 'internal': 4,\n",
       " 'compact ness': 1,\n",
       " 'members': 3,\n",
       " 'separ ation': 1,\n",
       " 'difference': 2,\n",
       " 'estimated': 2,\n",
       " 'graph': 2,\n",
       " 'connec tivity A': 1,\n",
       " 'type': 4,\n",
       " 'self supervised': 1,\n",
       " 'involves': 3,\n",
       " 'generating': 2,\n",
       " 'its elf Semisupervised': 1,\n",
       " 'falls': 3,\n",
       " 'comple t ely': 1,\n",
       " 'Some': 2,\n",
       " 'mis sing': 1,\n",
       " 'yet': 3,\n",
       " 'machinelearning': 2,\n",
       " 'unlabelled': 3,\n",
       " 'conjunc tion': 1,\n",
       " 'small': 2,\n",
       " 'amount': 2,\n",
       " 'consider able': 1,\n",
       " 'improve ment': 1,\n",
       " 'accuracyIn': 2,\n",
       " 'we ak ly': 1,\n",
       " 'no is y': 1,\n",
       " 'imprecise': 2,\n",
       " 'ho wever': 1,\n",
       " 'che a per': 1,\n",
       " 'obtain': 1,\n",
       " 'resulting': 2,\n",
       " 'lar ger': 1,\n",
       " 'effective': 3,\n",
       " 'sets Reinforcement': 1,\n",
       " 'ag ents': 1,\n",
       " 'o ught': 1,\n",
       " 'actions': 2,\n",
       " 'environment': 8,\n",
       " 'ma x imis e': 1,\n",
       " 'no tion': 1,\n",
       " 'cu mul ative': 1,\n",
       " 'reward': 3,\n",
       " 'D ue': 1,\n",
       " 'general ity': 1,\n",
       " 'game': 2,\n",
       " 'control': 1,\n",
       " 'oper ations': 1,\n",
       " 'simul ation based': 1,\n",
       " 'multi agent': 1,\n",
       " 's w ar m': 1,\n",
       " 'genetic': 7,\n",
       " 'typically': 6,\n",
       " 'M ark o v': 1,\n",
       " 'decision': 15,\n",
       " 'MDP': 2,\n",
       " 'dynamic': 2,\n",
       " 'Reinforcement': 2,\n",
       " 'assu me': 1,\n",
       " 'exact': 2,\n",
       " 'in feasible': 1,\n",
       " 'autonomous': 2,\n",
       " 've h ic les': 1,\n",
       " 'play': 1,\n",
       " 'against': 2,\n",
       " 'op p onent D i mension ality': 1,\n",
       " 'reducing': 4,\n",
       " 'random': 5,\n",
       " 'consider ation': 1,\n",
       " 'obtain ing': 1,\n",
       " 'wor ds': 1,\n",
       " 'dimension': 1,\n",
       " 'features': 11,\n",
       " 'M o st': 1,\n",
       " 'either': 5,\n",
       " 'elimin ation': 1,\n",
       " ...}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "def get_stats(vocab):\n",
    "    \n",
    "    pairs = defaultdict(int)\n",
    "    for word, freq in vocab.items():\n",
    "        symbols = word.split()\n",
    "        for i in range(len(symbols)-1):\n",
    "            pairs[symbols[i],symbols[i+1]] += freq\n",
    "    return pairs\n",
    "\n",
    "def merge_vocab(pair, v_in):\n",
    "    \n",
    "    v_out = {}\n",
    "    bigram = re.escape(' '.join(pair))\n",
    "    p = re.compile(r'(?<!\\S)' + bigram + r'(?!\\S)')\n",
    "    for word in v_in:\n",
    "        w_out = p.sub(''.join(pair), word)\n",
    "        v_out[w_out] = v_in[word]\n",
    "    return v_out\n",
    "\n",
    "def get_vocab(data):\n",
    "    \n",
    "    vocab = defaultdict(int)\n",
    "    for line in data:\n",
    "        for word in line.split():\n",
    "            vocab[' '.join(list(word)) ] += 1\n",
    "    return vocab\n",
    "\n",
    "def byte_pair_encoding(data, n):\n",
    "    \n",
    "    vocab = get_vocab(data)\n",
    "    for i in range(n):\n",
    "        pairs = get_stats(vocab)\n",
    "        best = max(pairs, key=pairs.get)\n",
    "        vocab = merge_vocab(best, vocab)\n",
    "    return vocab\n",
    "\n",
    "\n",
    "\n",
    "n = 2500\n",
    "bpe_pairs = byte_pair_encoding(string.split(\".\"), n)\n",
    "bpe_pairs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
